\chapter{Soluzioni per problemi intrattabili}
A questo punto è chiaro che per alcuni problemi non è sempre possibile trovare
la soluzione ottima in tempo \emph{polinomiale}. Per arrivare comunque ad una
soluzione siamo dunque costretti a rinunciare a qualcosa, e questo significa
perdere una o più delle seguenti caratteristiche:
\begin{itemize}
    \item \emph{Generalità}: potremmo accettare di definire un algoritmo che
    sia efficiente solo per alcuni casi dell'input;
    \item \emph{Ottimalità}: potremmo accettare di ottenere soluzioni \q{vicine}
    a quella ottima;
    \item \emph{Formalità}: potremmo accettare di definire un algoritmo che
    sperimentalmente dimostri fornire risultati buoni;
    \item \emph{Efficienza}: potremmo accettare di perdere in efficienza, ma
    ottenere la soluzione globalmente ottima;
\end{itemize}
Come vedremo in questo capitolo, ciascuno di questi punti è associato ad una
particolare categoria di algoritmi.

\section{Algoritmi pseudo-polinomiali}
Partiamo con un problema ormai noto: \hyperref[prob:33]{SUBSET-SUM}.
Abbiamo già risolto questo problema utilizzando il \emph{backtracking}, ora
però proviamo risolverlo di nuovo con una soluzione basata su
\emph{programmazione dinamica} per poi confrontare le \emph{complessità} delle
due soluzioni ottenute.

\subsection{Problema del subset sum}
\paragraph{Soluzione con programmazione dinamica}
Come al solito, definiamo una \emph{tabella delle soluzioni}
$DP[0\dots n][0\dots k]$ tale per cui $DP[i][r]$ è \texttt{true} se esiste un
sottoinsieme dei primi $i$ valori di $A$ la cui somma sia esattamente $r$,
\texttt{false} altrimenti:
\[DP[i][r]=\begin{cases}
    \texttt{true} & r=0\\
    \texttt{false} & r>0\wedge i=0\\
    DP[i-1][r] & r>0\wedge i>0\wedge A[i]>r\\
    DP[i-1][r] or DP[i-1][r-A[i]] & r>0\wedge i>0\wedge A[i]\leq r
\end{cases}\]
Le prime due clausole di questa definizione fanno sì che i valori della prima
colonna della tabella siano tutti \texttt{true} e quelli della prima riga, ad
eccezione del primo, siano tutti \texttt{false}. È giusto che sia così perché
se $r=0$ è sufficiente considerare l'insieme vuoto, mentre se $i=0$ e $r>0$
non è possibile definire alcun sottoinsieme diverso da quello vuoto.

\begin{minicode}{Soluzione basata su programmazione dinamica}
\ind\bc{boolean} subsetSum(\bc{int}[] A, \bc{int} n, \bc{int} k)\\
    \bc{boolean}[][] DP = new \bc{boolean}[0\dots n][0\dots k] = \{false\}\\
    \indf for (i = 0 to n) do\hfill\com{Prima colonna}
        DP[i][0] = true\hfill\com{Obiettivo raggiunto}
    \indf for (r = 1 to k) do\hfill\com{Prima riga}
        DP[0][r] = false\hfill\com{Valori terminati}
    \indf for (i = 1 to n) do\\
        \indff for (r = 1 to A[i] - 1) do\hfill\com{$r<A[i]$}
            DP[i][r] = DP[i - 1][r]\\
        \indff for (r = A[i] to k) do\hfill\com{$r\geq A[i]$}
            DP[i][r] = DP[i - 1][r] or DP[i - 1][r - A[i]]\\
    \indf return DP[n][k]
\end{minicode}
\noindent
La \emph{complessità} di questa soluzione è $\Theta(nk)$ perché $DP$ ha quella
dimensione.

\paragraph{Soluzione con backtracking}
\begin{minicode}{Soluzione basata su backtracking}
\ind\bc{boolean} ssRec(\bc{int}[] A, \bc{int} i, \bc{int} r)\\
    \indf if (r == 0) then\hfill\com{Obiettivo raggiunto}
        return true\\
    \indf else if (i == 0) then\hfill\com{Valori terminati}
        return false\\
    \indf else if (A[i] > r) then\\
        return ssRec(A, i - 1, r)\\
    \indf else \\
        return ssRec(A, i - 1, r) or ssRec(A, i - 1, r - A[i])
\end{minicode}

\noindent
Poiché nel caso peggiore vengono eseguite 2 chiamate ricorsive per ogni livello,
la \emph{complessità} è $O(2^n)$.

\paragraph{Soluzione con memoization}
Possiamo scrivere una soluzione basata su \emph{memoization} in cui, per non
dover inizializzare l'intera tabella, memorizziamo le soluzioni in un \emph{dizionario}.

\begin{minicode}{Soluzione basata su backtracking}
    \ind\bc{boolean} ssRec(\bc{int}[] A, \bc{int} i, \bc{int} r, \bc{DICTIONARY} DP)\\
        \indf if (r == 0) then\hfill\com{Obiettivo raggiunto}
            return true\\
        \indf else if (i == 0) then\hfill\com{Valori terminati}
            return false\\
        \indf else\\
            \bc{boolean} res = DP.lookup($\langle$i, r$\rangle$)\\
            \indff if (res == nil) then\hfill\com{La soluzione non è ancora stata calcolata}
                res = ssRec(A, i - 1, r, DP)\hfill\com{Valore non preso}
                \indfff if (A[i] $\leq$ r) then\\
                    res = res or ssRec(A, i - 1, r - A[i], DP)\hfill\com{Valore preso}
                \indfff DP.insert($\langle$i, r$\rangle$, res)\\
            \indff return res
\end{minicode}

\noindent
In questo caso l'algoritmo è limitato superiormente sia da $O(nk)$ che da
$O(2^n)$. Il primo limite dipende dal fatto che, nel caso peggiore, il
\emph{dizionario} viene popolato con tutti gli $nk$ valori come avviene nella
soluzione con \emph{programmazione dinamica} classica.

Se invece il vettore $A$ fosse popolato interamente di $1$, ad ogni livello
della ricorsione si realizzerebbero due chiamate, portando quindi la complessità
a $O(2^n)$. Di conseguenza, la \emph{complessità} della soluzione con
\emph{memoization} è $O(\min(nk, 2^n))$.

\bigskip\noindent
La \emph{complessità} $O(nk)$ è \emph{polinomiale}?

Precedentemente abbiamo già risposto a questa domanda, dicendo che no, non è
una \emph{complessità polinomiale}, bensì \emph{pseudo-polinomiale}. Il motivo è
che $k$ è parte dell'input e non una sua dimensione. In particolare, $k$ viene
rappresentato da $t=\lceil\log k\rceil$ cifre binarie, quindi $O(nk)$ può anche
essere scritto come $O(n2^t)$ che è una \emph{complessità esponenziale}.

\subsection[Problemi fortemente e debolmente NP-completi]
{Problemi fortemente e debolmente $\mathbb{NP}$-completi}
Per continuare la discussione sul tema della \emph{pseudo-polinomialità}
introduciamo i \emph{problemi fortemente e debolmente $\mathbb{NP}$-completi}.

\begin{definition}[Dimensioni del problema]
    Dati un problema decisionale $R$ e un'istanza $I$, chiamiamo $d$ la lunghezza
    della stringa binaria che codifica $I$ e definiamo il valore $\#$ come il
    più grande numero che appare in $I$.
\end{definition}

\noindent
Ad esempio, per i problemi SUBSET-SUM, \hyperref[prob:28]{CLIQUE} e
\hyperref[prob:30]{TSP}, i valori $d$ ed $\#$ sono i seguenti:

\begin{table}[h!]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \bc{Problema} & \bm{$I$} & \bm{$\#$} & \bm{$d$}\\
        \hline
        SUBSET-SUM & $\{n, k, A\}$ & $\max\{n, k, \max(A)\}$ & $O(n \log\#)$\\
        \hline
        CLIQUE & $\{n,m,k,G\}$ & $\max\{n,m,k\}$ & $O(n+m+\log\#)$\\
        \hline
        TSP & $\{n,k,d\}$ & $\max\{n,k,\max(d)\}$ & $O(n^2\log\#)$\\
        \hline
    \end{tabular}
\end{table}

\noindent
L'idea dietro il valore $\#$ è che se tutti i valori sono codificati nello
stesso modo (e.g. tutti i valori di $A$ sono interi a 32 bit), il valore maggiore
definisce la dimensione minima della stringa di codifica per ciascun valore di
quell'insieme. Conseguentemente, poiché $d$ descrive la dimensione della stringa
di codifica dell'intero input, il suo valore dipende dalla numerosità dell'input
e dalla dimensione di ciascuna sua componente.

Da qui,  nel problema SUBSET-SUM, $d$ è definito come $O(n\log\#)$ perché
l'input è composto da $n+2$ valori: $n$, $k$ e gli $n$ valori del vettore $A$.
Ciascuno di quegli elementi poi, richiede $\#$ bit per essere rappresentato, e
nel \emph{criterio di costo uniforme} tutto ciò si traduce in una
\emph{complessità} di $O(n\log\#)$.

\begin{definition}[Problema fortemenete $\mathbb{NP}$-completo]
    Sia $R_{pol}$ il problema $R$ ristretto ai dati di input per i quali $\#$
    è limitato superiormente da $T_p(d)$, con $T_p$ funzione polinomiale di $d$.
    $R$ è fortemente $\mathbb{NP}$-completo se e solo se $R_{pol}$ è
    $\mathbb{NP}$-completo.
\end{definition}

\begin{definition}[Problema debolmente $\mathbb{NP}$-completo]
    Se un problema $\mathbb{NP}$-completo non è fortemente $\mathbb{NP}$-completo,
    allora è debolmente $\mathbb{NP}$-completo.
\end{definition}

\paragraph{Dimostrazione che SUBSET-SUM è debolmente $\mathbb{NP}$-completo}
\begin{proof}[Dimostrazione]
    Supponiamo che $A[i]\leq k\quad\forall i\in\{1,\dots,n\}$, perché in ogni
    caso valori più grandi di $k$ non potrebbero essere parte della soluzione.
    Se $k=O(n^c)$, allora il valore $\#$ è definito come $\#=\max\{n, k, a_1,
    \dots, a_n\}=O(n^c)$. Ora, la soluzione basata su \emph{programmazione
    dinamica} ha \emph{complessità} $O(nk)=O(n^{c+1})$ che è \emph{polinomiale},
    e quindi appartenente a $\mathbb{P}$, quindi SUBSET-SUM non è \emph{fortemente
    $\mathbb{NP}$-completo}.
\end{proof}

\begin{definition}[Complessità pseduo-polinomiale]
    Un algoritmo ha complessità pseudo-polinomiale se risolve un certo problema
    $R$, per qualsiasi input $I$, in tempo $T_p(\#,d)$, con $T_p$ funzione
    con tempo polinomiale non costante in $\#$.
\end{definition}
\begin{definition}[Legame tra $\mathbb{NP}$-completezza e pseudo-polinomialità]
    Nessun problema fortemente $\mathbb{NP}$-completo è risolvibile da un
    algoritmo pseudo-polinomiale, a meno che non valga $\mathbb{P}=\mathbb{NP}$.
\end{definition}
\begin{note}
    Gli algoritmi per SUBSET-SUM e \hyperref[prob:34]{KNAPSACK} sono
    \emph{pseudo-polinomiali}.
\end{note}

\paragraph{Dimostrazione che CLIQUE è fortemente $\mathbb{NP}$-completo}
\begin{proof}[Dimostrazione]
    Possiamo supporre $k\leq n$, perché altrimenti la risposta sarebbe
    sicuramente \texttt{false}. Se è così, il valore $\#$ è definito come
    $\#=\max\{n,m,k\}=\max\{n,m\}$. Conseguentemente, $d$ vale $O(n+m+\log\#)=
    O(n+m)$. Ora, siccome $\#$ definito in questo modo è già limitato superiormente
    da $O(n+m)$, il problema ristretto è uguale alla versione completa di CLIQUE
    che è \emph{$\mathbb{NP}$-completo}, quindi CLIQUE è un problema
    \emph{fortemente $\mathbb{NP}$-completo}.
\end{proof}

\noindent
L'idea alla base di questo tipo di dimostrazioni è quella di considerare
un sottoinsieme degli input, calcolare $\#$ e $d$ a partire dall'input
ridotto e, se la versione ridotta del problema ha \emph{complessità
polinomiale}, allora il problema originale è \emph{debolmente
$\mathbb{NP}$-completo} e ammette una soluzione di costo \emph{pseudo-polinomiale}.

\begin{note}
    Ovviamente, qualsiasi problema che è riducibile ad un problema
    \emph{debolmente $\mathbb{NP}$-completo} è esso stesso \emph{debolmente
    $\mathbb{NP}$-completo}. Ad esempio, \hyperref[prob:32]{PARTITION} può
    essere ridotto a SUBSET-SUM scegliendo come $k$ la meta della somma di tutti
    i valori presenti, e siccome SUBSET-SUM è \emph{debolmente
    $\mathbb{NP}$-completo}, lo è anche PARTITION.
\end{note}

\section{Algoritmi di approssimazione}
Diversamente da quanto fatto finora, per la trattazione degli \emph{algoritmi
di approssimazione} consideriamo \emph{problemi di ottimizzazione} invece di
\emph{problemi decisionali}.

\begin{definition}[Algoritmo di approssimazione]
    Se è possibile dimostrare che esiste un limite superiore o inferiore al
    rapporto tra la soluzione trovata e la soluzione ottima, allora l'algoritmo
    usato per ricavare la soluzione non ottima è detto essere un algoritmo di
    approssimazione.
\end{definition}
\begin{definition}[Algoritmo di \bm{$\alpha(n)$}-approssimazione]
    Dato un problema di ottimizzazione sul quale è definita una funzione di costo
    non negativa $c$, un algoritmo si dice essere di $\alpha(n)$-approssimazione
    se fornisce una soluzione ammissibile $x$, il cui costo $c(x)$ non si discosti
    dal costo $c(x^*)$ della soluzione ottima $x^*$ per più di un fattore
    $\alpha(n)$, per qualunque input di dimensione $n$.
\end{definition}

\noindent
I \emph{problemi di ottimizzazione} si dividono in due sotto-categorie:
\emph{problemi di massimizzazione} e \emph{problemi di minimizzazione}.
A seconda della sotto-categoria di appartenenza del problema, un \emph{algoritmo
di approssimazione} è tale se soddisfa una delle seguenti relazioni:
\[\begin{array}{rccclll}
    \alpha(n)c(x^*) & \leq & c(x) & \leq & c(x^*) & \quad\alpha(n)<1 & \quad\emph{Problema di massimizzazione}\\
    c(x^*) & \leq & c(x) & \leq & \alpha(n)c(x^*) & \quad\alpha(n)>1 & \quad\emph{Problema di minimizzazione}
\end{array}\]

\begin{note}
    Il fattore $\alpha(n)$ può dipendere da $n$ o essere una costante, in ogni
    caso, dimostrare che il valore scelto sia rispettato dall'algoritmo è ciò che
    rende quell'algoritmo un \emph{algoritmo di approssimazione}.
\end{note}

\subsection{Problema del bin packing approssimato}
\begin{problem}[Problema del bin packing]
    Dato un vettore $A$ contenente $n$ interi positivi, rappresentanti ciascuno il
    volume di un oggetto, e un intero positivo $k$, rappresentante la capacità di
    una scatola e tale per cui $A[i]\leq k\quad\forall i\in\{1,\dots,n\}$,
    trovare una partizione dell'insieme di indici $\{1,\dots,n\}$ che minimizzi
    il numero di sottoinsiemi disgiunti tali che $\sum_{i\in S}A[i]\leq k$
    per ogni insieme $S$ della partizione.
\end{problem}
\begin{note}
    In pratica, si vuole capire come distribuire $n$ oggetti in delle scatole
    in modo che il numero di scatole totali sia minimo.
\end{note}

\noindent
Questo problema può essere approcciato in una quantità di modi, i primi che
potrebbero venire in mente sono il \emph{best fit} e il \emph{first fit}.
Il primo cerca di piazzare ogni oggetto nella scatola in cui la capacità residua
dopo l'inserimento è minima. Il secondo invece, prende un oggetto alla volta e
lo inserisce nella prima scatola con capacità sufficiente per contenerlo.

\bigskip\noindent
Consideriamo l'algoritmo \emph{first fit} e proviamo a vedere se è un
\emph{algoritmo di approssimazione}.

\begin{proof}[Dimostrazione]
    Sia $N$ il numero di scatole usate dall'algoritmo \emph{first fit}. Il numero
    minimo di scatole utilizzabili $N^*$ è limitato inferiormente da:
    \[N^*\geq\frac{\sum_{i=1}^nA[i]}{k}\]
    Poiché non possono esserci due scatole riempite per meno della metà\footnotemark,
    $N$ è limitato superiormente da:
    \[N\leq\frac{\sum_{i=1}^nA[i]}{k/2}\]
    Se è così, vale quanto segue:
    \[N\leq\frac{\sum_{i=1}^nA[i]}{k/2}=2\frac{\sum_{i=1}^nA[i]}{k}\leq 2N^*\]
    Da qui risulta che il fattore $\alpha(n)$ vale $2$.
\end{proof}
\begin{note}
    È anche possibile dimostrare limiti più stretti, ma quello che ci importa è
    aver dimostrato con successo che \emph{first fit} è un \emph{algoritmo di
    approssimazione} per il problema del \emph{bin packing}.
\end{note}

\footnotetext{Non possono esserci due scatole riempite per meno della metà perché
il contenuto di una di quelle due sarebbe stato messo nell'altra}

\subsection{Problema del commesso viaggiatore modificato}
\begin{problem}[Commesso viaggiatore con disuguaglianze triangolari ($\bc{\Delta}$-TSP)]
    Date $n$ città e una matrice $d$ delle distanze tra esse tale per cui:
    \[d[i][j]\leq d[i][k]+d[k][j]\quad\forall i,j,k: 1\leq i,j,k\leq n\]
    trovare un percorso che parta da una città, visiti tutte le altre
    esattamente una volta e ritorni alla città di partenza, in modo che la
    distanza complessiva percorsa sia minima.
\end{problem}
\begin{note}
    Le distanze tra le città devono rispettare la cosiddetta \q{disuguaglianza
    triangolare}.
\end{note}
\begin{figure}[h!]
    \centering
    \subfloat[Con disuguaglianza triangolare]{\begin{graph}
        \tikzset{node distance=35mm}

        \node[main] (b) {$b$};
        \node[main] (a) [below left of=b] {$a$};
        \node[main] (c) [below right of=b] {$c$};

        \node[] (d) [below of=b] {$d[a][c]\leq d[a][b]+d[b][c]$};

        \path[-]    (a) edge node[above left] {$3$} (b)
                    (a) edge node[above] {$5$} (c)
                    (b) edge node[above right] {$3$} (c);
    \end{graph}}
    \hspace{1.5cm}
    \subfloat[Senza disuguaglianza triangolare]{\begin{graph}
        \tikzset{node distance=35mm}

        \node[main] (b) {$b$};
        \node[main] (a) [below left of=b] {$a$};
        \node[main] (c) [below right of=b] {$c$};

        \node[] (d) [below of=b] {$d[a][c]\geq d[a][b]+d[b][c]$};

        \path[-]    (a) edge node[above left] {$2$} (b)
                    (a) edge node[above] {$5$} (c)
                    (b) edge node[above right] {$2$} (c);
    \end{graph}}
    \caption{\emph{Grafo} con e senza disuguaglianza triangolare}
\end{figure}

\paragraph{$\mathbb{NP}$-completezza di \bm{$\Delta$}-TSP}
Possiamo dimostrare che $\Delta$-TSP è \emph{riducibile polinomialmente} a
\hyperref[prob:35]{HAMILTONIAN-CIRCUIT} e poiché questo è
\emph{$\mathbb{NP}$-completo}, lo è anche $\Delta$-TSP.

\begin{proof}[Dimostrazione]
    Sia $G=(V,E)$ un \emph{grafo non orientato} avente un \emph{nodo} per ognuna
    delle $n$ città, e definiamo a partire da esso una matrice delle distanze
    tale per cui:
    \[d[i][j]=\begin{cases}
        1 & (i,j)\in E\\
        2 & (i,j)\notin E
    \end{cases}\]
    Poiché valgono le disuguaglianze triangolari, per ogni coppia di \emph{nodi}
    $i$, $j$ vale $d[i][j]\leq 2\leq d[i][k]+d[k[j]]$. A questo punto, $G$ ha
    un circuito hamiltoniano se e solo se esiste un \emph{cammino} in $d$ di
    lunghezza $n$ e passante per ogni \emph{nodo}.
\end{proof}
\begin{note}
    La matrice $d$ definisce il costo dell'arco tra ogni coppia di \emph{nodi},
    quindi ci permette di trattare $G$ come se fosse un \emph{grafo completo}.
\end{note}

\noindent
In generale possiamo sempre interpretare TSP o $\Delta$-TSP come il problema di
ricercare il circuito hamiltoniano di peso minimo su un \emph{grafo pesato
completo}.

\paragraph{Algoritmo in generale}
Per definire un \emph{algoritmo di approssimazione} per $\Delta$-TSP
partiamo proprio da questa interpretazione. In particolare, consideriamo un
circuito hamiltoniano e ne cancelliamo un \emph{arco} in modo da ottenere un
\emph{albero di copertura}.

\begin{definition}[Lemma sul costo dell'albero di copertura di peso minimo]
    Qualunque circuito hamiltoniano $\pi$ ha un costo $c(\pi)$ che è superiore
    al costo $mst$ di un albero di copertura di peso minimo dello stesso grafo.
    Ovvero, per ogni circuito hamiltoniano $\pi$ vale $mst<c(\pi)$.
\end{definition}

\begin{figure}[ht!]
\centering
\scalebox{1}{\begin{graph}
    \tikzset{
        cell/.style={rectangle, draw, minimum size=10mm, font=\large},
        empty/.style={inner sep=0},
        pos/.style args={#1:#2 from #3}{
          at=(#3.#1), anchor=#1+180, shift=(#1:#2)
        }
    }

    \def\labels{1 2 3 4 5}
    \def\numbers{%
        0 3 4 2 7
        3 0 4 6 3
        4 4 0 5 8
        2 6 5 0 6
        7 3 8 6 0
    }
    \readarray\labels\la[1,5]
    \readarray\numbers\num[5,5]

    \foreach \x in {1,...,5}
        \foreach \y in {1,...,5}
        {
            \ifthenelse{\x = 1\and\y=1}{
                \node[cell] (\x\y) at (\x-1,-\y+1) [label=above:{$\la[1,1]$},
                label=left:{$\la[1,1]$}] {};
            }{
                \ifthenelse{\x=1}{
                    \node[cell] (\x\y) at (\x-1,-\y+1) [label=left:{$\la[1,\y]$}]
                    {$\num[\x,\y]$};
                }{
                    \ifthenelse{\y = 1}{
                        \node[cell] (\x\y) at (\x-1,-\y+1)[label=above:{$\la[1,\x]$}]
                        {$\num[\x,\y]$};
                    }{
                        \ifthenelse{\num[\x,\y]=0}{
                            \node[cell] (\x\y) at (\x-1,-\y+1) {};
                        }{
                            \node[cell] (\x\y) at (\x-1,-\y+1) {$\num[\x,\y]$};
                        }
                    }
                }    
            }
        }

    \node[empty]    (0) [right of=53, shift={(30mm,-2.5mm)}] {};
    \node[main]     (1) [pos=90:20mm from 0] {$1$};
    \node[main]     (2) [pos=18:20mm from 0] {$2$};
    \node[main]     (3) [pos=-54:20mm from 0] {$3$};
    \node[main]     (4) [pos=-126:20mm from 0] {$4$};
    \node[main]     (5) [pos=-198:20mm from 0] {$5$};

    \path[-,dashed] (1) edge node[fill=white] {$3$} (2)
                    (1) edge node[fill=white] {$7$} (5)
                    (2) edge node[fill=white] {$6$} (4)
                    (3) edge node[fill=white] {$8$} (5)
                    (3) edge node[fill=white] {$5$} (4);

    \path[-]
                    (1) edge[line width=1.3pt] node[fill=white] {$4$} (3)
                    (1) edge[line width=1.3pt] node[fill=white] {$2$} (4)
                    (2) edge[line width=1.3pt] node[fill=white] {$3$} (5)
                    (2) edge[line width=1.3pt] node[fill=white] {$4$} (3)
                    (5) edge[line width=1.3pt] node[fill=white] {$6$} (4);
\end{graph}}
\caption{Interpretazione di $\Delta$-TSP come circuito hamiltoniano pesato}
\end{figure}

\begin{proof}[Dimostrazione]
    Supponiamo per assurdo che esista un circuito hamiltoniano $\pi$ di costo
    $c(\pi)\leq mst$. Se eliminiamo un \emph{arco} di $\pi$ otteniamo un altro
    \emph{albero di copertura} $mst'$ di costo $mst'<c(\pi)\leq mst$. Questo
    genera una contraddizione in quanto avevo supposto che $mst$ fosse il costo
    dell'\emph{albero di copertura di peso minimo}.
\end{proof}

\noindent
Quindi, se individuiamo un \emph{albero di copertura} di peso $mst$ e ne
percorriamo ogni \emph{arco} due volte, prima in un senso e poi nell'altro,
otteniamo un circuito di costo $2\cdot mst$ nel quale ogni \emph{nodo} viene
visitato una o due volte. Ovviamente questo non è un circuito hamiltoniano, ma
se saltiamo i \emph{nodi} già visitati e passiamo direttamente a quelli non
visitati, poiché valgono le disuguaglianze triangolare, il costo del circuito
$\pi$ così ottenuto è inferiore o uguale a $2\cdot mst$.

\bigskip\noindent
Di conseguenza, vale:
\[c(\pi)\leq 2\cdot mst\leq 2\cdot c(\pi^*)\]
dove $c(\pi^*)$ è il costo del circuito hamiltoniano di peso minimo e $2$ corrisponde
anche al valore del fattore $\alpha(n)$.

\begin{eg}[Esempio d'esecuzione]
    Consideriamo il seguente grafo completo sul quale abbiamo individuato
    un albero di copertura di peso minimo:
    
    \begin{figure}[h!]
        \centering
        \scalebox{0.95}{\begin{graph}
            \node[main] (1) {$1$};
            \node[main] (2) [below right of=1, shift={(15mm, 3mm)}] {$2$};
            \node[main] (3) [below of=2, shift={(3mm, 0mm)}] {$3$};
            \node[main] (4) [left of=3, shift={(-20mm, -1mm)}] {$4$};
            \node[main] (5) [right of=3, shift={(20mm, 7mm)}] {$5$};
            \node[main] (6) [below right of=5, shift={(6mm, 6mm)}] {$6$};
            \node[main] (7) [above of=6, shift={(5mm, 10mm)}] {$7$};

            \path[-]    (1) edge[line width=1.3pt] (2)
                        (2) edge[line width=1.3pt] (3)
                        (3) edge[line width=1.3pt] (4)
                        (3) edge[line width=1.3pt] (5)
                        (5) edge[line width=1.3pt] (6)
                        (5) edge[line width=1.3pt] (7);

            \draw[, dashed]
                        (1) edge[bend left=5] (7)
                        (7) edge[bend left=5] (6)
                        (6) edge[bend left=10] (4)
                        (6) edge[bend left=10] (3)
                        (4) edge[bend left=5] (1)
                        (3) edge[bend left=5] (1)
                        (3) edge[bend left=5] (7)
                        (4) edge[bend left=5] (2)
                        (4) edge[bend left=8] (5)
                        (4) edge (7)
                        (2) edge (7)
                        (2) edge (5)
                        (2) edge[bend left=25] (6)
                        (1) edge[bend left=25] (6)
                        (1) edge[bend right=15] (5);
        \end{graph}}
    \end{figure}

    \noindent
    Se adesso percorressimo ogni arco dell'albero di copertura individuato in
    entrambi i sensi, otterremmo il seguente circuito:

    \begin{figure}[h!]
        \centering
        \scalebox{1}{\begin{graph}
            \node[main] (1) {$1$};
            \node[main] (2) [below right of=1, shift={(15mm, 3mm)}] {$2$};
            \node[main] (3) [below of=2, shift={(3mm, 0mm)}] {$3$};
            \node[main] (4) [left of=3, shift={(-20mm, -1mm)}] {$4$};
            \node[main] (5) [right of=3, shift={(20mm, 7mm)}] {$5$};
            \node[main] (6) [below right of=5, shift={(6mm, 6mm)}] {$6$};
            \node[main] (7) [above of=6, shift={(5mm, 10mm)}] {$7$};

            \path[->, bend left=15]
                        (1) edge (2)
                        (2) edge (3)
                        (3) edge (4)
                        (3) edge (5)
                        (5) edge (6)
                        (5) edge (7);

            \path[<-, bend right=15]
                        (1) edge (2)
                        (2) edge (3)
                        (3) edge (4)
                        (3) edge (5)
                        (5) edge (6)
                        (5) edge (7);
        \end{graph}}
    \end{figure}

    \noindent
    A questo punto, sfruttando le disuguaglianze triangolari, otteniamo che,
    per esempio, per passare dal nodo $7$ al nodo $6$ conviene usare l'arco
    $(7,6)$ invece che tornare indietro sul nodo $5$ già visitato:

    \begin{figure}[h!]
        \centering
        \scalebox{1}{\begin{graph}
            \node[main] (1) {$1$};
            \node[main] (2) [below right of=1, shift={(15mm, 3mm)}] {$2$};
            \node[main] (3) [below of=2, shift={(3mm, 0mm)}] {$3$};
            \node[main] (4) [left of=3, shift={(-20mm, -1mm)}] {$4$};
            \node[main] (5) [right of=3, shift={(20mm, 7mm)}] {$5$};
            \node[main] (6) [below right of=5, shift={(6mm, 6mm)}] {$6$};
            \node[main] (7) [above of=6, shift={(5mm, 10mm)}] {$7$};

            \path[->, bend left=15]
                        (5) edge (7)
                        (7) edge (6);

            \path[->, bend left=15, dashed]
                        (7) edge (5)
                        (5) edge (6);
        \end{graph}}
    \end{figure}

    \noindent
    Applicando la stessa nozione a tutti gli altri nodi, otteniamo finalmente
    un circuito hamiltoniano:

    \begin{figure}[h!]
        \centering
        \scalebox{1}{\begin{graph}
            \node[main] (1) {$1$};
            \node[main] (2) [below right of=1, shift={(15mm, 3mm)}] {$2$};
            \node[main] (3) [below of=2, shift={(3mm, 0mm)}] {$3$};
            \node[main] (4) [left of=3, shift={(-20mm, -1mm)}] {$4$};
            \node[main] (5) [right of=3, shift={(20mm, 7mm)}] {$5$};
            \node[main] (6) [below right of=5, shift={(6mm, 6mm)}] {$6$};
            \node[main] (7) [above of=6, shift={(5mm, 10mm)}] {$7$};

            \path[->, bend left=15]
                        (1) edge (5)
                        (5) edge (7)
                        (7) edge (6)
                        (6) edge (3)
                        (3) edge (4)
                        (4) edge (2)
                        (2) edge (1);
        \end{graph}}
    \end{figure}    
\end{eg}

\paragraph{Complessità}
L'algoritmo proposto sfrutta l'\emph{Algoritmo di Kruskal} per la ricerca
dell'\emph{albero di copertura di peso minimo} e una \emph{visita in
profondità}. L'\emph{Algoritmo di Kruskal} costa $O(n^2\log n)$, la \emph{vista}
$O(n)$, quindi la \emph{complessità} totale è $T(n)=O(n^2\log n)$.

\begin{definition}[Teorema di non approssimabilità di TSP]
    Non esiste alcun algoritmo di $\alpha(n)$-approssimazione per TSP tale
    che $c(x')\leq s\cdot c(x^*)$, con $s\in\mathbb{N}$, a meno che non valga
    $\mathbb{P}=\mathbb{NP}$.
\end{definition}