%% ================================================================================
%% This LaTeX file was created by AbiWord.                                         
%% AbiWord is a free, Open Source word processor.                                  
%% More information about AbiWord is available at http://www.abisource.com/        
%% ================================================================================

\documentclass[a4paper,portrait,12pt]{article}
\usepackage[latin1]{inputenc}
\usepackage{calc}
\usepackage{setspace}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage[normalem]{ulem}
%% Please revise the following command, if your babel
%% package does not support en-US
\usepackage[en]{babel}
\usepackage{color}
\usepackage{hyperref}
 
\begin{document}


\begin{flushleft}
Probabilit\`{a} e Statistica
\end{flushleft}


\begin{flushleft}
Note del corso 2020/21
\end{flushleft}


\begin{flushleft}
LUIGI AMEDEO BIANCHI
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
\newpage
\newpage
INDICE
\end{flushleft}


\begin{flushleft}
INTRODUZIONE
\end{flushleft}





... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .... 9





\begin{flushleft}
Cosa \`{e} la probabilit\`{a}?
\end{flushleft}





.. ... ... ... ... ... ... ... ... ... ... ... ... ... ... .... 9





\begin{flushleft}
I. Probabilit\`{a} . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
\end{flushleft}


\begin{flushleft}
1. COMBINATORIA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
\end{flushleft}


1.1.


1.2.


1.3.


1.4.


1.5.


1.6.





\begin{flushleft}
I tre principi della combinatoria . . . . . . . .
\end{flushleft}


\begin{flushleft}
Permutazioni e anagrammi . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Combinazioni e coefficiente binomiale . . . .
\end{flushleft}


\begin{flushleft}
Un po' di probabilit\`{a} . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
L'importanza della clausola {``}equiprobabili''
\end{flushleft}


\begin{flushleft}
Problemi . . . . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





13


16


19


21


21


23





\begin{flushleft}
2. UNA NUOVA PROBABILIT\`{A} . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
\end{flushleft}


2.1.


2.2.


2.3.


2.4.





\begin{flushleft}
Algebre e tribù . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Spazi di probabilit\`{a} . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Propriet\`{a} della (misura di) probabilit\`{a}
\end{flushleft}


\begin{flushleft}
Problemi . . . . . . . . . . . . . . . . . . . .
\end{flushleft}





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





28


31


33


37





\begin{flushleft}
3. PROBABILIT\`{A} CONDIZIONATA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
\end{flushleft}


\begin{flushleft}
3.1. Teorema di Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
\end{flushleft}


\begin{flushleft}
3.1.1. Esperimenti ripetuti (divagazione) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
\end{flushleft}


\begin{flushleft}
4. COSTRUIRE PROBABILIT\`{A} . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
\end{flushleft}


\begin{flushleft}
4.1. Spazi finiti o numerabili . . . . . .
\end{flushleft}


\begin{flushleft}
4.2. Lo spazio dei numeri reali . . . .
\end{flushleft}


\begin{flushleft}
4.2.1. Il teorema di Carath\'{e}odory
\end{flushleft}


\begin{flushleft}
4.3. Spazi prodotto . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
4.4. Farsi le ossa . . . . . . . . . . . . . .
\end{flushleft}





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





.


.


.


.


.





55


56


60


60


63





\begin{flushleft}
5. VARIABILI ALEATORIE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
\end{flushleft}


\begin{flushleft}
5.1. Variabili aleatorie discrete e continue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
\end{flushleft}


\begin{flushleft}
5.1.1. Variabili aleatorie discrete . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
\end{flushleft}


\begin{flushleft}
5.1.2. Variabili aleatorie assolutamente continue . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
\end{flushleft}


. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83





\begin{flushleft}
6. TRASFORMAZIONI DI VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
6.1. Trasformazioni lineari . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
\end{flushleft}


\begin{flushleft}
6.1.1. La costante di rinormalizzazione . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
\end{flushleft}


\begin{flushleft}
6.2. Trasformazioni non lineari . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
\end{flushleft}


\begin{flushleft}
7. VETTORI ALEATORI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
\end{flushleft}


\begin{flushleft}
7.1. Vettori aleatori discreti . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
\end{flushleft}


\begin{flushleft}
7.2. Vettori aleatori assolutamente continui . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
\end{flushleft}


\begin{flushleft}
7.3. Vettori aleatori misti . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
\end{flushleft}


5





\newpage
6





\begin{flushleft}
INDICE
\end{flushleft}





\begin{flushleft}
8. MODELLI DI VARIABILI ALEATORIE DISCRETE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
\end{flushleft}


\begin{flushleft}
8.1. Bernoulliane . . . . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.2. Binomiali . . . . . . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.2.1. Bernoulliane e binomiali in R . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Densit\`{a} discreta . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Funzione di ripartizione . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Altre funzioni . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.3. Lo schema di Bernoulli . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.4. Geometriche . . . . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.4.1. Geometriche in R . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.5. Binomiali negative . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.5.1. Binomiali negative in R . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.5.2. Riproducibilit\`{a} . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.6. Ipergeometriche . . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Massima verosimiglianza (divagazione)
\end{flushleft}


\begin{flushleft}
8.6.1. Ipergeometriche in R . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.7. Poisson . . . . . . . . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.7.1. Poissoniane in R . . . . . . . . . . . . . . . . . .
\end{flushleft}





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





103


104


106


106


106


106


106


107


110


110


111


112


114


114


115


118


121





\begin{flushleft}
9. SPERANZA, VARIANZA E ALTRI INDICATORI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
\end{flushleft}


\begin{flushleft}
9.1. Variabili aleatorie discrete . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
9.1.1. Valore atteso di alcune variabili aleatorie note
\end{flushleft}


\begin{flushleft}
Bernoulliane . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Binomiali . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Poissoniane . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Ipergeometriche . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Geometriche . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Binomiali negative . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
9.2. Variabili aleatorie assolutamente continue . . . . .
\end{flushleft}


\begin{flushleft}
9.3. Momenti di una variabile aleatoria . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
9.3.1. Varianza di alcune variabili aleatorie note . .
\end{flushleft}


\begin{flushleft}
Bernoulliane . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Binomiali . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Geometriche . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Binomiali negative . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
Poissoniane . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
9.4. Disuguaglianze . . . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
9.5. Covarianza e correlazione . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
9.6. Altri indicatori di una distribuzione . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
9.7. Speranza e varianza condizionate . . . . . . . . . . .
\end{flushleft}





.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.


.





123


126


126


126


126


126


127


127


128


129


131


131


132


132


133


133


133


134


137


142





. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145





\begin{flushleft}
10. MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}


\begin{flushleft}
10.1. Uniformi . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.1.1. Uniformi in R . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.1.2. Indicatori per le uniformi . . .
\end{flushleft}


\begin{flushleft}
10.2. Esponenziali . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.2.1. Esponenziali in R . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.2.2. Indicatori per le esponenziali
\end{flushleft}


\begin{flushleft}
10.3. Gaussiane o normali . . . . . . . . .
\end{flushleft}





. .


.


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .


. .





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





145


145


146


146


147


147


148





\begin{flushleft}
\newpage
INDICE
\end{flushleft}





7





\begin{flushleft}
10.3.1. Indicatori per la normale standard
\end{flushleft}


\begin{flushleft}
10.3.2. Indicatori per una normale . . . .
\end{flushleft}


\begin{flushleft}
10.3.3. Gaussiane in R . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.3.4. Normali multivariate . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.4. Chi quadro . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.4.1. Chi quadro in R . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.4.2. Indicatori delle chi quadro . . . . .
\end{flushleft}


\begin{flushleft}
10.5. t di Student . . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
10.5.1. t di Student in R . . . . . . . . . . . .
\end{flushleft}





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.





150


151


152


152


154


156


156


156


157





\begin{flushleft}
11. TEOREMI LIMITE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
\end{flushleft}


\begin{flushleft}
11.1. Convergenza di variabili aleatorie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
\end{flushleft}


\begin{flushleft}
11.2. Teoremi limite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
\end{flushleft}





\begin{flushleft}
II. Statistica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
\end{flushleft}


\begin{flushleft}
12. STIME PUNTUALI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
\end{flushleft}


\begin{flushleft}
12.1. Introduzione alla Statistica . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
12.2. Stimatori e stime . . . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
12.2.1. Alcuni stimatori . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
12.2.2. Distribuzione degli stimatori . . . . .
\end{flushleft}


\begin{flushleft}
12.3. Costruire stimatori . . . . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
12.3.1. Metodo dei momenti . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
12.3.2. Metodo di massima verosimiglianza
\end{flushleft}





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





.


.


.


.


.


.


.





169


171


173


174


176


177


178





\begin{flushleft}
13. INTERVALLI DI CONFIDENZA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
\end{flushleft}


\begin{flushleft}
13.1. Media di una normale di varianza nota . . . . . . .
\end{flushleft}


\begin{flushleft}
13.1.1. Intervalli bilaterali di confidenza . . . . . . . .
\end{flushleft}


\begin{flushleft}
13.1.2. Intervalli unilaterali di confidenza . . . . . . .
\end{flushleft}


\begin{flushleft}
13.2. Costruire intervalli di confidenza . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
13.3. Intervalli di confidenza per la differenza di medie
\end{flushleft}


\begin{flushleft}
13.4. Intervalli di confidenza approssimati . . . . . . . .
\end{flushleft}


\begin{flushleft}
13.4.1. Popolazione Bernoulliana . . . . . . . . . . . .
\end{flushleft}


\begin{flushleft}
13.4.2. Popolazione Poissoniana . . . . . . . . . . . . .
\end{flushleft}





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.





181


182


184


185


186


188


188


190





\begin{flushleft}
14. TEST STATISTICI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
\end{flushleft}


14.1.


14.2.


14.3.


14.4.





\begin{flushleft}
Impostare test statistici .
\end{flushleft}


\begin{flushleft}
Il p-dei-dati . . . . . . . .
\end{flushleft}


\begin{flushleft}
Test statistici unilaterali
\end{flushleft}


\begin{flushleft}
Tabelle riassuntive . . .
\end{flushleft}





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





194


197


199


202





\begin{flushleft}
III. Appendici . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
\end{flushleft}


\begin{flushleft}
APPENDICE A. RICHIAMI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
\end{flushleft}


\begin{flushleft}
A.1. Richiami di teoria elementare degli insiemi . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
\end{flushleft}


\begin{flushleft}
A.2. Serie aritmetica e serie geometrica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
\end{flushleft}


\begin{flushleft}
A.3. L'integrale gaussiano . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
\end{flushleft}


\begin{flushleft}
APPENDICE B. TAVOLE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
\end{flushleft}


\begin{flushleft}
Come si leggono le tavole?
\end{flushleft}





. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215





\begin{flushleft}
\newpage
\newpage
Lezione 1
\end{flushleft}





\begin{flushleft}
INTRODUZIONE
\end{flushleft}


\begin{flushleft}
Queste note coprono ed espandono quanto presentato nel corso di Probabilit\`{a} e Statistica tenuto
\end{flushleft}


\begin{flushleft}
nel secondo semestre dell'anno accademico 2019/20 e dell'anno accademico 2020/21 al Corso di
\end{flushleft}


\begin{flushleft}
Laurea triennale in Informatica.
\end{flushleft}


\begin{flushleft}
Parte di queste note (le prime lezioni) \`{e} stata pubblicata dalla casa editrice Scienza Express nella
\end{flushleft}


\begin{flushleft}
collana UMath. Per parte di queste note ho preso ispirazione dalle note del corso del prof. Claudio
\end{flushleft}


\begin{flushleft}
Agostinelli. Tra le altre fonti devo ringraziare il prof. Francesco Morandin dell'Universit\`{a} di
\end{flushleft}


\begin{flushleft}
Parma e il libro Probabilit\`{a} e Statistica per l'ingegneria e le scienze di Sheldon Ross, pubblicato da
\end{flushleft}


\begin{flushleft}
Apogeo.
\end{flushleft}


\begin{flushleft}
Le note sono scritte in TEXMACS (https://www.texmacs.org). Alcune delle immagini sono
\end{flushleft}


\begin{flushleft}
realizzate in TikZ, altre in R.
\end{flushleft}





\begin{flushleft}
COSA \`{E} LA PROBABILIT\`{A}?
\end{flushleft}


\begin{flushleft}
Possiamo vedere la probabilit\`{a} come uno strumento per misurare l'incertezza, pensata in diverse
\end{flushleft}


\begin{flushleft}
accezioni: tra casi o soggetti, nel tempo, nello spazio, nella misurazione...
\end{flushleft}


\begin{flushleft}
Abbiamo tutti un'idea intuitiva di cosa intendiamo parlando di probabilit\`{a} nel linguaggio
\end{flushleft}


\begin{flushleft}
informale di tutti i giorni: qualcosa \`{e} tanto più probabile quanto meno ci sorprenderebbe vederla
\end{flushleft}


\begin{flushleft}
accadere. Tuttavia abbiamo bisogno di passare a un linguaggio più formale, per mezzo della
\end{flushleft}


\begin{flushleft}
matematica, per assicurarci che queste valutazioni siano coerenti. Il linguaggio naturale, infatti,
\end{flushleft}


\begin{flushleft}
lascia aperti spiragli a possibili fraintendimenti, dovuti in parte all'uso di {``}categorie mentali''
\end{flushleft}


\begin{flushleft}
diverse.
\end{flushleft}


\begin{flushleft}
Esempio 1. Linda \`{e} una giovane donna che ha studiato Scienze Sociali a Pisa. Negli anni dell'universit\`{a} ha partecipato a numerose manifestazioni contro la discriminazione delle minoranze,
\end{flushleft}


\begin{flushleft}
anche nel mondo accademico. Durante la visita del Presidente della Repubblica all'Ateneo di Pisa
\end{flushleft}


\begin{flushleft}
si \`{e} fatta portavoce delle richieste degli studenti, chiedendo pubblicamente al Presidente di intervenire per ampliare gli strumenti finanziari a sostegno degli studenti in difficolt\`{a} economiche.
\end{flushleft}


\begin{flushleft}
Si \`{e} laureata con una tesi critica dell'impatto negativo del mondo della finanza sulla societ\`{a}.
\end{flushleft}


\begin{flushleft}
\`{E} più probabile che oggi Linda sia impiegata in banca o che sia responsabile delle pari opportunit\`{a} in Banca Etica?
\end{flushleft}


\begin{flushleft}
L'esempio precedente \`{e} stato proposto, in versioni leggermente diverse, dagli psicologi israeliani Kahneman e Tverski in alcuni loro studi. Dei volontari intervistati una considerevole maggioranza assegnava una probabilit\`{a} maggiore alla seconda opzione. \`{E} una storia che ci tenta:
\end{flushleft}


\begin{flushleft}
ci sembra più in linea con il racconto precedente, si sposa meglio con l'idea che ci siamo fatti
\end{flushleft}


\begin{flushleft}
di Linda. Eppure, da un punto di vista della coerenza logica, \`{e} la risposta sbagliata.
\end{flushleft}


\begin{flushleft}
Infatti se Linda lavora come responsabile delle pari opportunit\`{a} in Banca Etica, allora \`{e}
\end{flushleft}


\begin{flushleft}
un'impiegata in una banca e di conseguenza \`{e} il primo evento ad avere una probabilit\`{a} maggiore. Se Linda non lavora in banca, allora non lavora nemmeno in Banca Etica, ma potrebbe
\end{flushleft}


\begin{flushleft}
aver accettato un lavoro in un'altra banca (per necessit\`{a}, perch\'{e} ha cambiato le proprie idee o
\end{flushleft}


\begin{flushleft}
magari solo per caso), quindi ci sono più modi in cui Linda sta lavorando in una banca qualunque che non modi in cui \`{e} in Banca Etica e addirittura specificamente come responsabile delle
\end{flushleft}


\begin{flushleft}
pari opportunit\`{a}.
\end{flushleft}


9





\newpage
10





\begin{flushleft}
INTRODUZIONE
\end{flushleft}





\begin{flushleft}
Anche per risolvere problemi di questo tipo, negli anni Trenta del secolo scorso \`{e} stata sviluppata la cosiddetta teoria assiomatica della probabilit\`{a}, principalmente da A. Kolmogorov. Questa
\end{flushleft}


\begin{flushleft}
teoria, su cui si baser\`{a} la prima parte di questo corso, identifica alcuni assiomi e alcune propriet\`{a}
\end{flushleft}


\begin{flushleft}
che una probabilit\`{a} deve avere per essere coerente. Dice inoltre come \`{e} possibile manipolare
\end{flushleft}


\begin{flushleft}
matematicamente le probabilit\`{a}, da cui il nome di calcolo delle probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
La teoria assiomatica, per\`{o}, non d\`{a} un teorema di unicit\`{a} della probabilit\`{a}: non garantisce che
\end{flushleft}


\begin{flushleft}
esista una e una sola scelta di probabilit\`{a} che soddisfa gli assiomi. Gli assiomi danno dei vincoli,
\end{flushleft}


\begin{flushleft}
ma lasciano anche libert\`{a} di scelta: certi aspetti di una probabilit\`{a} sono una scelta di modello,
\end{flushleft}


\begin{flushleft}
dipendono da quello che vogliamo rappresentare, ma anche da posizioni filosofiche. Possiamo
\end{flushleft}


\begin{flushleft}
parlare di probabilit\`{a} frequentista o soggettivista (detta anche bayesiana), principalmente, ma ci
\end{flushleft}


\begin{flushleft}
sono poi numerose sfumature e interpretazioni, come la probabilit\`{a} logica, la probabilit\`{a} comparativa e così via. Non approfondiremo questi aspetti, anche se vedremo qualche accenno in
\end{flushleft}


\begin{flushleft}
seguito, perch\'{e} vale quanto detto prima: qualunque sia il nostro approccio filosofico, la nostra
\end{flushleft}


\begin{flushleft}
scelta di probabilit\`{a} deve soddisfare gli assiomi e di conseguenza godr\`{a} delle propriet\`{a} che studieremo come conseguenza degli assiomi stessi.
\end{flushleft}


\begin{flushleft}
Pu\`{o} essere difficile mettere assieme la nostra idea di matematica come strumento deterministico (e assoluto) per eccellenza con il concetto di probabilit\`{a} e l'incertezza che le associamo.
\end{flushleft}


\begin{flushleft}
Possiamo per\`{o} cercare di capire la situazione con un'analogia: la matematica \`{e} il sistema operativo, mentre la probabilit\`{a} \`{e} un programma lato utente, un'interfaccia tra il mondo reale e le sue
\end{flushleft}


\begin{flushleft}
incertezze e la matematica. La probabilit\`{a} traduce (o rappresenta) l'incertezza in termini matematici permettendoci così di usare questo potente linguaggio formale per studiare situazioni non
\end{flushleft}


\begin{flushleft}
deterministiche.
\end{flushleft}


\begin{flushleft}
Il corso, oltre alla probabilit\`{a}, ha nel nome anche la statistica. Possiamo considerare la statistica come se fosse divisa in due: statistica descrittiva e statistica inferenziale.
\end{flushleft}


\begin{flushleft}
La statistica descrittiva lavora su un'intera popolazione e cerca di descriverla in termini numerici, sintetizzando alcune caratteristiche della popolazione attraverso dei numeri. Tuttavia spesso
\end{flushleft}


\begin{flushleft}
non \`{e} possibile avere dati sull'intera popolazione di interesse, ma si ha accesso solamente a un campione casuale (ecco il primo collegamento con la probabilit\`{a}) della popolazione stessa. La statistica
\end{flushleft}


\begin{flushleft}
inferenziale ci d\`{a} strumenti per dedurre o inferire caratteristiche della popolazione intera a partire
\end{flushleft}


\begin{flushleft}
da misurazioni fatte sul solo campione. Dal momento che il campione \`{e} casuale, questa descrizione dedotta non pu\`{o} essere certa, ma contiene al suo interno una misura di incertezza. Dietro
\end{flushleft}


\begin{flushleft}
alla statistica inferenziale abbiamo modelli probabilistici, per studiare i quali avremo bisogno
\end{flushleft}


\begin{flushleft}
della probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
La probabilit\`{a} e la statistica sono importanti in generale, dal momento che ci permettono
\end{flushleft}


\begin{flushleft}
di descrivere in termini matematici situazioni di incertezza, come quelle che incontriamo tutti
\end{flushleft}


\begin{flushleft}
i giorni, e di prendere decisioni che tengano opportunamente conto di tale incertezza. Nel campo
\end{flushleft}


\begin{flushleft}
specifico dell'informatica, poi, ci sono alcuni temi che si appoggiano alla probabilit\`{a} e alla statistica, ad esempio il machine learning e lo statistical learning, ma anche gli algoritmi casuali,
\end{flushleft}


\begin{flushleft}
alcune strutture dati (tabelle hash ottimizzate), i processi di assegnazione delle risorse (Random
\end{flushleft}


\begin{flushleft}
Access Memory, ma anche cloud), la teoria dei segnali, in particolare nel canali con rumore, gli
\end{flushleft}


\begin{flushleft}
algoritmi di compressione e così via.
\end{flushleft}





\begin{flushleft}
\newpage
Parte I
\end{flushleft}


\begin{flushleft}
Probabilit\`{a}
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
CAPITOLO 1
\end{flushleft}


\begin{flushleft}
COMBINATORIA
\end{flushleft}


\begin{flushleft}
Cominciamo a parlare di probabilit\`{a}, in una situazione speciale in cui tutti i casi sono equiprobabili.
\end{flushleft}


\begin{flushleft}
Possiamo calcolare la probabilit\`{a} di qualcosa semplicemente contando tutti i casi favorevoli (cio\`{e}
\end{flushleft}


\begin{flushleft}
i casi in cui si verifica il qualcosa che cerchiamo) e dividere questo numero per quello di tutti i casi
\end{flushleft}


\begin{flushleft}
possibili.
\end{flushleft}


\begin{flushleft}
\`{E} chiaro per\`{o} che, se da un punto di vista intuitivo questa definizione ci pu\`{o} andare bene, da
\end{flushleft}


\begin{flushleft}
un punto di vista rigoroso lascia molto a desiderare: se non abbiamo ancora definito cosa significhi probabilit\`{a}, come possiamo parlare di casi equiprobabili? Al tempo stesso questo approccio
\end{flushleft}


\begin{flushleft}
\`{e} molto naturale: a ben pensarci tutte le misurazioni iniziano usando un riferimento. Non solo,
\end{flushleft}


\begin{flushleft}
anche storicamente questo \`{e} stato uno dei primi modi di avvicinarsi alla probabilit\`{a}, seppur al
\end{flushleft}


\begin{flushleft}
prezzo di rischiare qualche errore in più.
\end{flushleft}


\begin{flushleft}
Lasciamo per il momento da parte questa perplessit\`{a} e abbracciamo l'approccio intuitivo:
\end{flushleft}


\begin{flushleft}
possiamo comunque vedere numerosi esercizi ed esempi interessanti. Il punto cruciale \`{e} che
\end{flushleft}


\begin{flushleft}
trasformiamo il problema di calcolare la probabilit\`{a} di qualcosa in un conteggio: vogliamo contare i casi favorevoli e i casi totali. La branca della matematica che si occupa di questo tipo di
\end{flushleft}


\begin{flushleft}
problemi si chiama combinatoria.
\end{flushleft}


\begin{flushleft}
Per prima cosa vogliamo introdurre i tre principi fondamentali della combinatoria. Per fare
\end{flushleft}


\begin{flushleft}
questo usiamo il linguaggio della teoria elementare degli insiemi. Chi avesse bisogno di un
\end{flushleft}


\begin{flushleft}
ripasso, trover\`{a} un po' di risultati in Appendice A.1.
\end{flushleft}





\begin{flushleft}
1.1. I TRE PRINCIPI DELLA COMBINATORIA
\end{flushleft}


\begin{flushleft}
Dopo questa breve escursione nella teoria elementare degli insiemi, torniamo alla combinatoria,
\end{flushleft}


\begin{flushleft}
in particolare ai tre principi che avevamo menzionato prima.
\end{flushleft}


\begin{flushleft}
Il primo principio della combinatoria sostituisce il conteggio degli elementi di un insieme con
\end{flushleft}


\begin{flushleft}
il conteggio degli elementi di una sua partizione, ossia con una rappresentazione dell'insieme
\end{flushleft}


\begin{flushleft}
come unione disgiunta di suoi sottoinsiemi. \`{E} il principio che ci apre la via al paradigma del
\end{flushleft}


\begin{flushleft}
divide et impera: spezzare un problema in parti più piccole e mutualmente esclusive affrontandole
\end{flushleft}


\begin{flushleft}
separatamente e combinando alla fine i risultati.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 1.1. Siano A un insieme e \{E i\}ni=1 una partizione di A. Allora \#A = ∑ ni=1 \#E i.
\end{flushleft}


\begin{flushleft}
Cosa c'entra questo con la combinatoria? Proviamo a fare un paio di esempi.
\end{flushleft}


\begin{flushleft}
Esempio 1.2. Con un buono regalo possiamo decidere se avere o un film o un videogioco. Sapendo
\end{flushleft}


\begin{flushleft}
che ci sono 10 film e 6 videogiochi disponibili, in tutto abbiamo 10 + 6 omaggi diversi tra cui
\end{flushleft}


\begin{flushleft}
scegliere quale portarci a casa. In questo caso A \`{e} l'insieme di tutti gli omaggi tra cui possiamo
\end{flushleft}


\begin{flushleft}
scegliere e la sua partizione \`{e} data da E1, insieme dei film disponibili, ed E 2, insieme dei videogiochi disponibili.
\end{flushleft}





\begin{flushleft}
Esempio 1.3. In una scuola ci sono 28 studentesse e studenti del primo anno, 25 del secondo, 21
\end{flushleft}


\begin{flushleft}
del terzo, 26 del quarto e 26 del quinto. In tutto, nella scuola ci sono allora 28 + 25 + 21 + 26 + 26 =
\end{flushleft}


\begin{flushleft}
126 studentesse e studenti; infatti ognuno di loro non pu\`{o} che appartenere a uno e un solo anno
\end{flushleft}


\begin{flushleft}
di corso. Qui A \`{e} l'insieme di tutti gli studenti della scuola, ed E i, per i da 1 a 5, l'insieme di quelli
\end{flushleft}


\begin{flushleft}
dell'i-esimo anno.
\end{flushleft}


13





\newpage
14





\begin{flushleft}
COMBINATORIA
\end{flushleft}





\begin{flushleft}
Per introdurre il secondo principio della combinatoria, ossia il principio del prodotto, dobbiamo
\end{flushleft}


\begin{flushleft}
prima richiamare brevemente il prodotto cartesiano di insiemi.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 1.4. Dati due insiemi A e B, il loro prodotto cartesiano, indicato con A ×B, \`{e} l'insieme delle
\end{flushleft}


\begin{flushleft}
coppie ordinate (a, b) tali che a $\in$ A e b $\in$ B.
\end{flushleft}


\begin{flushleft}
Notiamo l'aggettivo che compare nella precedente definizione: le coppie che consideriamo
\end{flushleft}


\begin{flushleft}
sono ordinate. Questo significa che una coppia non \`{e} determinata solamente dagli elementi che
\end{flushleft}


\begin{flushleft}
la compongono, ma anche dall'ordine in cui compaiono: le due coppie (1, 3) e (3, 1) sono coppie
\end{flushleft}


\begin{flushleft}
ordinate distinte. Vedremo che \`{e} importante non dimenticarsi se stiamo considerando coppie (o
\end{flushleft}


\begin{flushleft}
terne, o n-uple) ordinate o no.
\end{flushleft}


\begin{flushleft}
Ora che sappiamo che cosa \`{e} il prodotto cartesiano, andiamo a vedere perch\'{e} ci interessa in
\end{flushleft}


\begin{flushleft}
combinatoria. In questo caso vogliamo (poco sorprendentemente) contare le coppie ordinate.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 1.5. Dati due insiemi A e B e il loro prodotto cartesiano A×B, vale la seguente uguaglianza:
\end{flushleft}


\begin{flushleft}
\#(A × B) = \#A ⋅ \#B.
\end{flushleft}


\begin{flushleft}
Dobbiamo fare attenzione: in generale i due insiemi A × B e B × A, pur avendo la stessa cardinalit\`{a}, sono diversi, perch\'{e} formati da coppie ordinate diverse. D'altra parte, anche se gli insiemi
\end{flushleft}


\begin{flushleft}
sono distinti, possiamo mostrare una relazione biunivoca tra essi. In particolare la mappa che
\end{flushleft}


\begin{flushleft}
scambia le due componenti soddisfa questa condizione. In effetti, se pensiamo a quello che significano le varie quantit\`{a}, stiamo dicendo che anche se i due insiemi hanno lo stesso numero di
\end{flushleft}


\begin{flushleft}
elementi, non necessariamente sono uguali.
\end{flushleft}


\begin{flushleft}
Esempio 1.6. Per fare un esempio più che classico, pensiamo a un pasto in una mensa o in una
\end{flushleft}


\begin{flushleft}
tavola calda: il pasto consiste di un primo a scelta tra minestra, pasta e riso e di un secondo a
\end{flushleft}


\begin{flushleft}
scelta tra carne, pesce, formaggio, uova e sformato di verdure. In quanti modi diversi possiamo
\end{flushleft}


\begin{flushleft}
comporre un pasto?
\end{flushleft}


\begin{flushleft}
Vogliamo contare le coppie ordinate in cui alla prima componente abbiamo un primo e alla
\end{flushleft}


\begin{flushleft}
seconda un secondo (molto appropriatamente). I modi che abbiamo sono in questo caso 3 ⋅ 5.
\end{flushleft}


\begin{flushleft}
Possiamo leggere il risultato così: per ogni scelta del primo tra i 3 disponibili, abbiamo 5 possibili
\end{flushleft}


\begin{flushleft}
secondi (e viceversa: visto che la moltiplicazione \`{e} commutativa, possiamo anche fissare prima il
\end{flushleft}


\begin{flushleft}
secondo, scegliendolo fra i 5 a nostra disposizione e, in seguito, determina uno dei 3 primi).
\end{flushleft}


\begin{flushleft}
Possiamo definire in modo del tutto simile il prodotto cartesiano tra più di due insiemi, a patto
\end{flushleft}


\begin{flushleft}
che siano in numero finito, e vale un risultato analogo per la sua cardinalit\`{a}.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 1.7. Data una famiglia finita di insiemi \{Ai\} ni=1, prendiamo il loro prodotto cartesiano
\end{flushleft}


\begin{flushleft}
A 1 × ⋅ ⋅ ⋅ × A n che denotiamo anche con ⨂ni=1 A i. Vale la seguente uguaglianza: \#(⨂ ni=1 A i) = ∏ni=1 \#A i.
\end{flushleft}


\begin{flushleft}
Esempio 1.8. Torniamo alla nostra mensa: \`{e} cambiata la gestione e ora, oltre a un primo e a un
\end{flushleft}


\begin{flushleft}
secondo come prima, possiamo scegliere anche un contorno, tra patate, carote, spinaci e piselli e
\end{flushleft}


\begin{flushleft}
un dessert tra budino, cr\`{e}me caramel e gelato. In quanti modi diversi possiamo ora comporre un
\end{flushleft}


\begin{flushleft}
pasto?
\end{flushleft}


\begin{flushleft}
Ora vogliamo contare le 4-uple ordinate, in cui compaiono, nell'ordine, un primo, un secondo,
\end{flushleft}


\begin{flushleft}
un contorno e un dessert. Le scelte sono, nel medesimo ordine, 3, 5, 4 e 3, per un numero totale
\end{flushleft}


\begin{flushleft}
di 3 ⋅ 5 ⋅ 4 ⋅ 3 = 180 modi differenti di comporre un pasto.
\end{flushleft}


\begin{flushleft}
Gli insiemi A i che andiamo a moltiplicare non devono necessariamente essere disgiunti e,
\end{flushleft}


\begin{flushleft}
in realt\`{a}, nemmeno distinti. In particolare nulla ci impedisce di considerare n copie dello stesso
\end{flushleft}


\begin{flushleft}
insieme. In questo caso abbiamo semplicemente l'insieme ⨂ ni=1 A= An, la cui cardinalit\`{a} \`{e} \#(An)=
\end{flushleft}


\begin{flushleft}
(\#A) n.
\end{flushleft}


\begin{flushleft}
Esempio 1.9. Quanti sono i possibili PIN a 6 cifre?
\end{flushleft}





\begin{flushleft}
\newpage
1.1 I TRE PRINCIPI DELLA COMBINATORIA
\end{flushleft}





15





\begin{flushleft}
In questo caso abbiamo A = \{0, 1,..., 9\} come insieme nel quale peschiamo ciascuna delle 6 cifre
\end{flushleft}


\begin{flushleft}
del PIN. Stiamo quindi cercando la cardinalit\`{a} dell'insieme A6, cio\`{e} il numero 10 6.
\end{flushleft}


\begin{flushleft}
Esempio 1.10. Se invece volessimo i PIN a 6 cifre in cui non ci sono cifre consecutive uguali?
\end{flushleft}


\begin{flushleft}
Come prima cosa notiamo che non siamo più nel caso precedente; in particolare ci aspettiamo di ottenere un numero più basso, visto che stiamo considerando un sottoinsieme di tutti i
\end{flushleft}


\begin{flushleft}
PIN possibili. Per la prima cifra1.1 abbiamo 10 possibili valori (tutti i numeri tra 0 e 9). Quando
\end{flushleft}


\begin{flushleft}
passiamo alla seconda cifra, adiacente alla prima, uno dei valori non \`{e} più a nostra disposizione
\end{flushleft}


\begin{flushleft}
(quello scelto per la prima cifra). Ma solamente quel valore va escluso, quindi ci restano 9 scelte
\end{flushleft}


\begin{flushleft}
possibili. Similmente per le cifre successive, per un totale di 10 ⋅ 9 5 possibili PIN che soddisfano la
\end{flushleft}


\begin{flushleft}
nostra condizione.
\end{flushleft}


\begin{flushleft}
Osservazione 1.11. Riguardiamo ancora l'esempio precedente: potremmo pensare di procedere
\end{flushleft}


\begin{flushleft}
in un modo diverso, non necessariamente passando alle cifre vicine. Ad esempio potremmo
\end{flushleft}


\begin{flushleft}
cominciare scegliendo la prima, la terza e la quinta. Siccome esse non si toccano, possiamo scegliere ciascuna di esse in 10 modi. Quando per\`{o} andiamo a considerare la seconda cifra del nostro
\end{flushleft}


\begin{flushleft}
PIN, dobbiamo distinguere due casi, per sapere quante scelte siano possibili: se la prima e la
\end{flushleft}


\begin{flushleft}
terza cifra sono uguali, allora la seconda pu\`{o} essere scelta in 9 modi. Se invece sono diverse tra
\end{flushleft}


\begin{flushleft}
loro, la seconda pu\`{o} essere scelta solamente in 8 modi. Questo modo di conteggiare, per quanto
\end{flushleft}


\begin{flushleft}
corretto e possibile, \`{e} quindi più a rischio per quanto riguarda gli errori di conto.
\end{flushleft}


\begin{flushleft}
Nell'esempio, infatti, stiamo sfruttando un approccio (un algoritmo) che sfrutta una propriet\`{a}
\end{flushleft}


\begin{flushleft}
particolare: non ci interessa quale cifra estraiamo in un dato punto, perch\'{e} stiamo considerando
\end{flushleft}


\begin{flushleft}
qualcosa di invariante rispetto alla scelta specifica della cifra, ossia la cardinalit\`{a} delle cifre che ci
\end{flushleft}


\begin{flushleft}
restano da scegliere al passaggio successivo. \`{E} per questo che fissare cifre del PIN saltando qua e
\end{flushleft}


\begin{flushleft}
l\`{a} non \`{e} altrettanto efficace: non abbiamo un invariante analogo.
\end{flushleft}


\begin{flushleft}
Dopo questa breve divagazione torniamo alla combinatoria e, per concludere questa sezione,
\end{flushleft}


\begin{flushleft}
vediamo il terzo principio della combinatoria. Per farlo, ci mettiamo in una situazione simile a
\end{flushleft}


\begin{flushleft}
quella vista per il primo principio: vogliamo ottenere la cardinalit\`{a} dell'unione di alcuni insiemi,
\end{flushleft}


\begin{flushleft}
lasciando per\`{o} cadere l'ipotesi che siano disgiunti.
\end{flushleft}


\begin{flushleft}
Esempio 1.12. Alcuni eventi della Coppa del Mondo di arrampicata hanno gare di due diverse
\end{flushleft}


\begin{flushleft}
specialit\`{a}: boulder e lead. Sapendo che a uno di questi hanno partecipato 37 atleti nel boulder, 33
\end{flushleft}


\begin{flushleft}
nel lead e 14 a entrambe le specialit\`{a}, quanti erano gli atleti presenti all'evento?
\end{flushleft}


\begin{flushleft}
In analogia a quanto visto per il primo principio, la prima idea che ci viene \`{e} quella di andare a
\end{flushleft}


\begin{flushleft}
sommare i partecipanti al boulder con quelli al lead, ottenendo 37+33=70 atleti. Tuttavia sappiamo
\end{flushleft}


\begin{flushleft}
che il primo principio richiede che gli insiemi siano disgiunti, mentre qui sappiamo che questa
\end{flushleft}


\begin{flushleft}
ipotesi non \`{e} verificata. Cosa cambia? Pensiamo ai 14 atleti che hanno preso parte a entrambe
\end{flushleft}


\begin{flushleft}
le gare di specialit\`{a}: li abbiamo contati due volte, sia nel boulder, sia nel lead, quindi per avere
\end{flushleft}


\begin{flushleft}
il numero totale di atleti presenti dobbiamo sottrarre 14 da 70, ottenendo in tutto 56 partecipanti.
\end{flushleft}


\begin{flushleft}
In generale, possiamo enunciare il terzo principio come segue.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 1.13. Se abbiamo due insiemi A 1 e A2, la cardinalit\`{a} della loro unione sar\`{a}
\end{flushleft}


\begin{flushleft}
\#(A1 $\cup$ A 2) = \#A1 + \#A 2 $-$ \#(A1 $\cap$ A 2).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Possiamo dimostrare questo risultato riconducendoci al primo principio, scrivendo l'unione come unione disgiunta:
\end{flushleft}


\begin{flushleft}
A 1 $\cup$ A2 = (A 1 ∖ A2) $\cup$ (A 2 ∖ A1) $\cup$ (A 1 $\cap$ A2).
\end{flushleft}


\begin{flushleft}
1.1. La prima cifra che inseriamo. Infatti si pu\`{o} osservare abbastanza facilmente che il ragionamento non cambia
\end{flushleft}


\begin{flushleft}
se andiamo a scegliere per prima la cifra in una qualunque posizione (ad esempio in posizione 3), muovendoci poi in
\end{flushleft}


\begin{flushleft}
entrambe le direzioni passando ogni volta a una cifra adiacente a una gi\`{a} scelta.
\end{flushleft}





\newpage
16





\begin{flushleft}
COMBINATORIA
\end{flushleft}





\begin{flushleft}
Ora non ci resta che osservare che A1 = (A 1 ∖ A 2) $\cup$ (A 1 $\cap$ A 2) (e analogamente per A2) e mettere
\end{flushleft}


\begin{flushleft}
assieme i vari pezzi per ottenere quanto cercato.
\end{flushleft}


□


\begin{flushleft}
Anche qui, come in precedenza, nulla ci costringe a considerare solamente due insiemi. Se
\end{flushleft}


\begin{flushleft}
passiamo all'unione di tre insiemi A 1, A2 e A3, iniziamo come prima, sommando le cardinalit\`{a} dei
\end{flushleft}


\begin{flushleft}
tre insiemi e togliendo le (tre) intersezioni degli insiemi a due a due. In questo modo abbiamo
\end{flushleft}


\begin{flushleft}
contato una sola volta tutti gli elementi, tranne quelli di un sottoinsieme: l'intersezione di A1, A 2 e
\end{flushleft}


\begin{flushleft}
A 3. Guardiamo un elemento di questo sottoinsieme: lo abbiamo contato una volta in ciascuno dei
\end{flushleft}


\begin{flushleft}
tre insiemi, lo abbiamo poi tolto una volta per ciascuna delle tre intersezioni a due a due, col risultato che lo abbiamo contato zero volte. Dobbiamo quindi andare ad aggiungere l'intersezione a
\end{flushleft}


\begin{flushleft}
tre,
\end{flushleft}


\begin{flushleft}
\#(A 1 $\cup$ A2 $\cup$ A 3) = \#A1 + \#A 2 + \#A3
\end{flushleft}


\begin{flushleft}
$-$\#(A1 $\cap$ A 2) $-$ \#(A1 $\cap$ A 3) $-$ \#(A2 $\cap$ A 3)
\end{flushleft}


\begin{flushleft}
+\#(A1 $\cap$ A 2 $\cap$ A3).
\end{flushleft}


\begin{flushleft}
Come conseguenza di questo aggiungere e togliere elementi, il terzo principio prende anche il
\end{flushleft}


\begin{flushleft}
nome di principio di inclusione-esclusione.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 1.14. Con n insiemi A 1, . . . , A n abbiamo l'uguaglianza
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\#


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
\#Ai $-$
\end{flushleft}





\begin{flushleft}
Ai =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
\#(Ai $\cap$ A j $\cap$ Ak ) $-$ ⋅ ⋅ ⋅ + ($-$1)n+1 \#
\end{flushleft}





\begin{flushleft}
\#(A i $\cap$ Aj) +
\end{flushleft}


\begin{flushleft}
i$<$ j
\end{flushleft}





\begin{flushleft}
i$<$ j$<$k
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
A i.
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Osservazione 1.15. Osserviamo che se non consideriamo l'intera somma, ma solo i primi addendi,
\end{flushleft}


\begin{flushleft}
possiamo avere una stima del totale. \`{E} una stima dal basso nel caso in cui il primo termine della
\end{flushleft}


\begin{flushleft}
somma che ignoriamo ha segno positivo (cio\`{e} \`{e} in posizione dispari), dall'alto se ha segno negativo (ossia \`{e} in posizione pari).
\end{flushleft}





\begin{flushleft}
1.2. PERMUTAZIONI E ANAGRAMMI
\end{flushleft}


\begin{flushleft}
Pensiamo ora alla seguente situazione: abbiamo un insieme A che contiene n oggetti distinti. Ci
\end{flushleft}


\begin{flushleft}
chiediamo quante siano le permutazioni di questi oggetti, ossia i modi di disporli in fila.
\end{flushleft}


\begin{flushleft}
Iniziamo dal primo oggetto della fila: lo possiamo scegliere a piacere tra tutti gli elementi
\end{flushleft}


\begin{flushleft}
di A, cio\`{e} abbiamo n modi per sceglierlo. Passiamo ora al secondo. Anche senza sapere quale
\end{flushleft}


\begin{flushleft}
elemento di A abbiamo messo al primo posto, sappiamo che ce ne sono rimasti altri n $-$ 1 tra cui
\end{flushleft}


\begin{flushleft}
scegliere: tutti gli elementi di A, tranne quello gi\`{a} usato. Possiamo continuare in questo modo:
\end{flushleft}


\begin{flushleft}
a ogni passo avanti nella fila di oggetti, avremo un elemento in meno tra cui scegliere, fino ad
\end{flushleft}


\begin{flushleft}
arrivare all'ultimo posto, per il quale non ci sar\`{a} rimasto che un solo elemento.
\end{flushleft}


\begin{flushleft}
Scrivendo tutto questo abbiamo che le permutazioni, o riordinamenti, di A sono n ⋅ (n $-$ 1) ⋅ (n $-$
\end{flushleft}


\begin{flushleft}
2) ⋅ ⋅⋅⋅ ⋅ 3 ⋅ 2 ⋅ 1, cio\`{e} il prodotto di tutti i numeri interi positivi minori o uguali di n. Questo prodotto
\end{flushleft}


\begin{flushleft}
\`{e} talmente importante in matematica che viene denotato con un simbolo, n!, detto n fattoriale. Per
\end{flushleft}


\begin{flushleft}
il caso limite n = 0, poniamo 0! = 1, con l'idea che abbiamo un solo modo per ordinare l'insieme
\end{flushleft}


\begin{flushleft}
vuoto.
\end{flushleft}


\begin{flushleft}
Come nel prodotto cartesiano, anche qui l'ordine \`{e} importante. E in un certo senso siamo
\end{flushleft}


\begin{flushleft}
ancora nel caso del prodotto cartesiano: semplicemente partiamo con l'insieme al completo e,
\end{flushleft}


\begin{flushleft}
a ogni passo, lo moltiplichiamo (cartesianamente) con una versione sempre più piccola, che ha
\end{flushleft}


\begin{flushleft}
perso l'elemento appena scelto. Anche se non sappiamo con precisione quale sia l'elemento che
\end{flushleft}


\begin{flushleft}
abbiamo scelto, a ogni passo ce ne sar\`{a} rimasto uno in meno rispetto a quelli che avevamo in
\end{flushleft}


\begin{flushleft}
precedenza.
\end{flushleft}


\begin{flushleft}
Tra gli insiemi da riordinare un ruolo speciale \`{e} costituito dalle parole, intese come insiemi
\end{flushleft}


\begin{flushleft}
di lettere. In questo caso indichiamo i riordinamenti col nome anagrammi. Attenzione, vogliamo
\end{flushleft}


\begin{flushleft}
contare tutti gli anagrammi, non stiamo chiedendo che abbiano senso in qualche lingua.
\end{flushleft}





\begin{flushleft}
\newpage
1.2 PERMUTAZIONI E ANAGRAMMI
\end{flushleft}





17





\begin{flushleft}
Esempio 1.16. Prendiamo ora una parola, ad esempio ``PRENDIAMO'': quanti sono i suoi anagrammi?
\end{flushleft}


\begin{flushleft}
Siamo nello stesso caso visto sopra: il nostro insieme A \`{e} ora
\end{flushleft}


\begin{flushleft}
A = \{P, R, E, N, D, I, A, M, O\}
\end{flushleft}


\begin{flushleft}
e in particolare ha 9 elementi, tutti distinti tra loro. I loro riordinamenti, cio\`{e} gli anagrammi
\end{flushleft}


\begin{flushleft}
di ``PRENDIAMO'', sono quindi 9! = 362880.
\end{flushleft}





\begin{flushleft}
Prima di continuare con altri esempi di anagrammi, parliamo per un momento del fattoriale. Una delle prime cose che possiamo osservare incontrandolo \`{e} quanto velocemente cresce:
\end{flushleft}


\begin{flushleft}
nell'esempio precedente abbiamo visto che 9!=362880, mentre 10! \`{e} 10 volte più grande. Insomma,
\end{flushleft}


\begin{flushleft}
diventa rapidamente complicato scriverlo per esteso e conviene lasciarlo indicato con il suo simbolo finch\'{e} si pu\`{o}. Non solo, nel momento in cui volessimo semplificarlo, ci conviene sfruttare la
\end{flushleft}


\begin{flushleft}
fattorizzazione naturale nascosta nella sua definizione, cio\`{e} la scrittura come prodotto dei primi
\end{flushleft}


\begin{flushleft}
n interi positivi, per semplificare tutto il semplificabile. Vedremo alcuni esempi di queste semplificazioni più avanti, perch\'{e} il fattoriale salter\`{a} fuori spesso (cosa che rende ancora più comoda
\end{flushleft}


\begin{flushleft}
la notazione col punto esclamativo).
\end{flushleft}


\begin{flushleft}
Consideriamo una variante della situazione precedente, molto comune quando stiamo anagrammando parole: cosa succede se abbiamo delle ripetizioni? Nel caso delle parole: cosa succede
\end{flushleft}


\begin{flushleft}
se una lettera compare più volte?
\end{flushleft}


\begin{flushleft}
Esempio 1.17. Consideriamo la parola ``ANAGRAMMI'': quanti sono i suoi anagrammi?
\end{flushleft}


\begin{flushleft}
Sicuramente sono al più 9!, cio\`{e} tutte le permutazioni delle sue lettere. Per\`{o} questo non tiene
\end{flushleft}


\begin{flushleft}
conto del fatto che abbiamo alcune lettere che si ripetono: A compare tre volte, M due. Se contassimo solamente le permutazioni, come fatto prima, staremmo contando come distinti due anagrammi ottenuti scambiando tra loro due lettere uguali (ad esempio le due M). Tuttavia questi
\end{flushleft}


\begin{flushleft}
sono indistinguibili tra loro:
\end{flushleft}


\begin{flushleft}
ANAGRAM 1M 2I=ANAGRAM 2M 1I.
\end{flushleft}


\begin{flushleft}
Dobbiamo allora contare in quanti modi possiamo permutare tra loro le lettere uguali. In questo
\end{flushleft}


\begin{flushleft}
esempio possiamo riordinare le M tra loro in 2! = 2 modi e le A in 3! = 6 modi. Dividiamo allora il
\end{flushleft}


\begin{flushleft}
fattoriale della lunghezza della parola per il numero di permutazioni di ciascun gruppo di lettere
\end{flushleft}


\begin{flushleft}
uguali, cio\`{e} per il fattoriale del numero delle loro occorrenze. In questo caso le permutazioni
\end{flushleft}


\begin{flushleft}
distinte di ``ANAGRAMMI'' sono
\end{flushleft}


9!


362880


=


= 30240.


3! ⋅ 2!


12


\begin{flushleft}
Possiamo seguire questo approccio in generale, non solo per insiemi di lettere: se abbiamo un
\end{flushleft}


\begin{flushleft}
insieme A costituito da n elementi di m tipi diversi (necessariamente deve essere m ⩽ n), ciascun
\end{flushleft}


\begin{flushleft}
tipo i $\in$ \{1, . . . m\} presente in k i copie, le permutazioni possibili di tutti gli elementi di A, non
\end{flushleft}


\begin{flushleft}
distinguendo elementi di uno stesso tipo, sono
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}


.


\begin{flushleft}
k1! ⋅ k 2! ⋅ ⋅ ⋅ ⋅ ⋅ k m!
\end{flushleft}


\begin{flushleft}
Esempio 1.18. In una famiglia \`{e} consuetudine, per le festivit\`{a} invernali, decorare la ringhiera del
\end{flushleft}


\begin{flushleft}
balcone. Per farlo, mettono in fila palline luminose di tre colori: 8 sono rosse, 6 sono verdi e 4
\end{flushleft}


\begin{flushleft}
sono azzurre. Ogni anno vogliono avere una decorazione diversa da quelle degli anni precedenti:
\end{flushleft}


\begin{flushleft}
dopo quanti anni dovranno necessariamente ripetersi?
\end{flushleft}


\begin{flushleft}
Ci sono
\end{flushleft}


18!


9 ⋅ 10 ⋅ ⋅ ⋅ ⋅ ⋅ 17 ⋅ 18


=


= 11 ⋅ 13 ⋅ 14 ⋅ 15 ⋅ 17 ⋅ 18 = 9189180


8! ⋅ 6! ⋅ 4! 2 ⋅ 3 ⋅ 4 ⋅ 5 ⋅ 6 ⋅ 2 ⋅ 3 ⋅ 4





\newpage
18





\begin{flushleft}
COMBINATORIA
\end{flushleft}





\begin{flushleft}
possibili anagrammi delle lampadine a loro disposizione, quindi molto probabilmente ci saremo
\end{flushleft}


\begin{flushleft}
gi\`{a} estinti da un po'. Prima di continuare, notiamo come abbiamo semplificato tutto quello che
\end{flushleft}


\begin{flushleft}
potevamo, prima di fare il conto conclusivo1.2.
\end{flushleft}


\begin{flushleft}
Esempio 1.19. Quanti sono gli anagrammi di ``ANAGRAMMI'' in cui le due ``M'' sono adiacenti?
\end{flushleft}


\begin{flushleft}
Se le due ``M'' devono essere adiacenti, possiamo considerarle come un'unica lettera ``X'' e
\end{flushleft}


\begin{flushleft}
contare gli anagrammi della parola ``ANAGRAXI''.
\end{flushleft}


8!


\begin{flushleft}
A questo punto abbiamo 3! = 6720 anagrammi possibili, avendo 8 lettere di cui una, la ``A'',
\end{flushleft}


\begin{flushleft}
ripetuta 3 volte.
\end{flushleft}


\begin{flushleft}
Esempio 1.20. Goffredo ha recentemente avuto una delusione in amore, quindi odia tutto quello
\end{flushleft}


\begin{flushleft}
che gli ricorda il tema. Nel fare gli anagrammi di ``ANAGRAMMI'' esclude tutti quelli in cui
\end{flushleft}


\begin{flushleft}
compaiono le stringhe ``AMA'' o ``AMI''. Quanti anagrammi gli rimangono?
\end{flushleft}


\begin{flushleft}
Ci conviene contare quanti sono in tutto gli anagrammi, quanti sono quelli con una delle
\end{flushleft}


\begin{flushleft}
stringhe incriminate e sottrarre il secondo numero dal primo. Dobbiamo anche prestare attenzione al fatto che, essendoci più ``A'' e ``M'', potremmo avere più stringhe incriminate in un
\end{flushleft}


\begin{flushleft}
medesimo anagramma. Ci servir\`{a} allora il principio di inclusione-esclusione.
\end{flushleft}


\begin{flushleft}
Cominciamo a codificare ``X''=``AMA'' e ``Y''=``AMI''. Contiamo gli anagrammi che contengono ``AMA'': sono i riordinamenti di ``NGRAMIX'', che sono 7!. Ce ne sono per\`{o} alcuni che
\end{flushleft}


\begin{flushleft}
stiamo contando due volte: quelli in cui compare la stringa ``AMAMA''. Se la chiamiamo ``W'',
\end{flushleft}


\begin{flushleft}
per sapere quanti ne abbiamo contati di troppo, ci basta contare gli anagrammi di ``NGRIW'', che
\end{flushleft}


\begin{flushleft}
sono 5!.
\end{flushleft}


\begin{flushleft}
Passiamo ora agli anagrammi di ``ANAGRAMMI'' che contengono ``AMI'': sono quelli
\end{flushleft}


7!


\begin{flushleft}
di ``NAGRAMY'' cio\`{e} 2! . Anche in questo caso, per\`{o}, ci sono alcuni anagrammi che contengono sia ``AMA'' sia ``AMI'' e che quindi abbiamo gi\`{a} contato in precedenza. Sono quelli della
\end{flushleft}


\begin{flushleft}
parola ``NGRXY'', 5!, ma anche quelli della parola ``NGRAZ'', in cui ``Z''=``AMAMI'', anche
\end{flushleft}


\begin{flushleft}
questi 5!. Quindi gli anagrammi di ``ANAGRAMMI'' che contengono ``AMA'' o ``AMI'' sono
\end{flushleft}


7!


$-$ 5! $-$ 5! = 5! ⋅ (6 ⋅ 7 + 3 ⋅ 7 $-$ 3) = 5! ⋅ 60.


2!


\begin{flushleft}
Ora dobbiamo sottrarre questo numero, che ci dice quanti riordinamenti non vanno bene a Gof9!
\end{flushleft}


\begin{flushleft}
fredo, dal numero di tutte le possibili permutazioni di ``ANAGRAMMI'', che sono 3!2! . La risposta
\end{flushleft}


\begin{flushleft}
\`{e} quindi
\end{flushleft}


9!


$-$ 5! ⋅ 60 = 5!(7 ⋅ 4 ⋅ 9 $-$ 60) = 120 ⋅ 192 = 23040.


3!2!


7! $-$ 5! +





\begin{flushleft}
Torniamo ora al caso in cui tutti gli n elementi del nostro insieme sono distinti tra loro. Questa
\end{flushleft}


\begin{flushleft}
volta, per\`{o}, vogliamo contare quante sono le possibili disposizioni di un numero k ⩽ n di suoi
\end{flushleft}


\begin{flushleft}
elementi.
\end{flushleft}


\begin{flushleft}
Esempio 1.21. Dodici amici hanno organizzato tra loro una lotteria, per la quale hanno 5 premi
\end{flushleft}


\begin{flushleft}
di valore decrescente. Quanti sono i diversi modi di distribuire i premi?
\end{flushleft}


\begin{flushleft}
In un certo senso ci stiamo chiedendo nuovamente quanti siano i modi di mettere in fila i
\end{flushleft}


\begin{flushleft}
12 amici (al primo della fila daremo il primo premio e così via), con la differenza che non ci
\end{flushleft}


\begin{flushleft}
interessa davvero sapere come sono disposti dalla sesta posizione in poi, perch\'{e} uno scambio tra
\end{flushleft}


\begin{flushleft}
due persone oltre la quinta posizione non ha influenza sulla distribuzione dei premi. Abbiamo
\end{flushleft}


\begin{flushleft}
quindi, in questo caso, 12 scelte per il vincitore del primo premio, 11 per il secondo, fino a 8 scelte
\end{flushleft}


\begin{flushleft}
per il vincitore del quinto premio. La risposta \`{e} quindi 12 ⋅ 11 ⋅ 10 ⋅ 9 ⋅ 8 = 95040.
\end{flushleft}


\begin{flushleft}
Possiamo per\`{o} osservare che questo \`{e} il prodotto dei numeri consecutivi da 8 a 12, una quantit\`{a} che sappiamo esprimere come un rapporto di fattoriali:
\end{flushleft}


12!


= 8 ⋅ 9 ⋅ 10 ⋅ 11 ⋅ 12.


7!


\begin{flushleft}
1.2. Non dobbiamo pensare che siano semplificazioni inutili, anche quando abbiamo a portata di mano una calcolatrice o un computer: i fattoriali crescono talmente in fretta che, anche se il risultato finale \`{e} alla loro portata, gli strumenti
\end{flushleft}


\begin{flushleft}
di calcolo possono dare errori di approssimazione prima di arrivare in fondo.
\end{flushleft}





\begin{flushleft}
\newpage
1.3 COMBINAZIONI E COEFFICIENTE BINOMIALE
\end{flushleft}





19





\begin{flushleft}
Questo ci suggerisce un altro modo di vedere lo stesso risultato: le ultime 7 posizioni sono uguali
\end{flushleft}


\begin{flushleft}
tra loro, nel senso che sono tutte non vincenti, quindi stiamo contando le permutazioni di un
\end{flushleft}


\begin{flushleft}
insieme con 5 elementi tutti distinti tra loro e altri 7 tutti dello stesso tipo. Possiamo vederlo come
\end{flushleft}


\begin{flushleft}
l'insieme dei premi: primo, secondo, ..., quinto, niente, niente, ..., niente.
\end{flushleft}


\begin{flushleft}
In casi come questo si parla di permutazioni incomplete o k-permutazioni. Il numero di permutan!
\end{flushleft}


\begin{flushleft}
zioni di k elementi in un insieme di n elementi distinti \`{e} (n $-$ k)! .
\end{flushleft}


\begin{flushleft}
Esempio 1.22. A ogni Gran Premio di Formula E partecipano 24 piloti. Al termine della gara
\end{flushleft}


\begin{flushleft}
vengono assegnati punti (diversi per ciascun piazzamento) ai primi 10 piloti. In quanti modi
\end{flushleft}


\begin{flushleft}
diversi \`{e} possibile assegnare i punteggi?
\end{flushleft}


\begin{flushleft}
Abbiamo in tutto 24! riordinamenti possibili dei piloti. Ai fini della classifica, per\`{o}, contano
\end{flushleft}


\begin{flushleft}
solamente le prime 10 posizioni, quindi non sono diversi tra loro quei riordinamenti che differi24!
\end{flushleft}


\begin{flushleft}
scono solo per permutazioni delle ultime 14 posizioni. Quindi la risposta \`{e} 14! = 7117005772800.
\end{flushleft}


\begin{flushleft}
Esempio 1.23. Nelle gare di Coppa del Mondo di arrampicata, vengono assegnati punti ai primi
\end{flushleft}


\begin{flushleft}
30 classificati. Uomini e donne gareggiano in competizioni separate. Se alla gara di GarmischPartenkirchen hanno preso parte 50 uomini e 48 donne, quanti sono i modi diversi di assegnare
\end{flushleft}


\begin{flushleft}
i punteggi?
\end{flushleft}


\begin{flushleft}
Cominciamo considerando separatamente la classifica maschile e quella femminile. Come
\end{flushleft}


50!


48!


\begin{flushleft}
visto nell'Esempio 1.22, abbiamo (50 $-$ 30)! modi di assegnare punti nella gara maschile e (48 $-$ 30)!
\end{flushleft}


\begin{flushleft}
modi per la gara femminile.
\end{flushleft}


\begin{flushleft}
Dobbiamo ora combinare questi risultati, per avere il numero delle possibili classifiche
\end{flushleft}


\begin{flushleft}
dell'intero evento. Per il secondo principio della combinatoria, siccome i due ambiti sono distinti,
\end{flushleft}


50! 48!


\begin{flushleft}
dobbiamo moltiplicare i due risultati parziali, per avere quello totale: 20! ⋅ 18! . Questo numero
\end{flushleft}


\begin{flushleft}
si pu\`{o} semplificare un po', ma \`{e} dell'ordine di 10 91. Sconsiglio di provare a calcolarlo.
\end{flushleft}


\begin{flushleft}
Resta per il momento in sospeso il caso delle k-permutazioni con ripetizioni. Le idee non sono
\end{flushleft}


\begin{flushleft}
molto diverse da quelle viste finora, ma diventano più semplici se viste sotto una lente diversa,
\end{flushleft}


\begin{flushleft}
quella delle combinazioni, che vedremo ora.
\end{flushleft}





\begin{flushleft}
1.3. COMBINAZIONI E COEFFICIENTE BINOMIALE
\end{flushleft}


\begin{flushleft}
Passiamo a un problema diverso, anche se l'ambientazione \`{e} analoga a quella dell'Esempio 1.22.
\end{flushleft}


\begin{flushleft}
Esempio 1.24. Le qualifiche di Formula E per stabilire l'ordine di partenza in un Gran Premio
\end{flushleft}


\begin{flushleft}
sono divise in due fasi: nella prima concorrono tutti i partecipanti, dopodich\'{e} i 6 più veloci nella
\end{flushleft}


\begin{flushleft}
prima fase competono tra loro nella Super Pole per determinare le prime 6 posizioni. In quanti
\end{flushleft}


\begin{flushleft}
modi diversi possiamo scegliere i 6 piloti (tra i 24 totali) che parteciperanno alla Super Pole?
\end{flushleft}


\begin{flushleft}
Osserviamo che non siamo nella situazione gi\`{a} vista delle permutazioni incomplete, perch\'{e}
\end{flushleft}


\begin{flushleft}
non ci interessa in che ordine siano i primi 6: tutti i risultati delle qualifiche (cio\`{e} tutti gli ordinamenti dei 24 piloti) che differiscono tra loro per riordinamenti dei primi 6 o degli ultimi 18 sono
\end{flushleft}


\begin{flushleft}
equivalenti. Quindi possiamo prendere tutti gli ordinamenti, dividerli per i riordinamenti degli
\end{flushleft}


\begin{flushleft}
ultimi 18, ottenendo le permutazioni incomplete viste prima, e dividere ancora una volta per i
\end{flushleft}


24!


\begin{flushleft}
riarrangiamenti dei primi 6: abbiamo allora 18! ⋅ 6! .
\end{flushleft}


\begin{flushleft}
Quello che abbiamo fatto in questo esempio \`{e} semplicemente contare i modi di scegliere 6
\end{flushleft}


\begin{flushleft}
piloti tra 24. Possiamo generalizzarlo a n e k qualunque tra i numeri naturali, contando i modi
\end{flushleft}


\begin{flushleft}
di scegliere k oggetti tra n disponibili (ovviamente ci aspettiamo di farlo per 0 ⩽ k ⩽ n) o, equivalentemente, di dividere gli n elementi di un insieme in k sottoinsiemi: essi prendono il nome di
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}


\begin{flushleft}
combinazioni di k oggetti scelti tra n. Per quanto appena detto, tali combinazioni saranno k!(n $-$ k)! ,
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
quantit\`{a} per cui introduciamo la notazione k , detta coefficiente binomiale.
\end{flushleft}





\newpage
20





\begin{flushleft}
COMBINATORIA
\end{flushleft}





\begin{flushleft}
Esempio 1.25. Un professore prepara 13 problemi per un esame orale, in modo da poterne assegnare uno diverso a ciascun partecipante. All'esame, per\`{o}, si presentano solo in 3. In quanti modi
\end{flushleft}


\begin{flushleft}
pu\`{o} scegliere 3 problemi da assegnare ai presenti?
\end{flushleft}


\begin{flushleft}
Il professore deve scegliere 3 problemi tra i 13 che ha. Pu\`{o} farlo in 13
\end{flushleft}


\begin{flushleft}
= 286 modi.
\end{flushleft}


3


\begin{flushleft}
Fino a qui pu\`{o} sembrare che il coefficiente binomiale sia solo una comoda scrittura. Ma oltre
\end{flushleft}


\begin{flushleft}
a essere comodo \`{e} anche importante, perch\'{e} tende a saltare fuori molto spesso nei problemi di
\end{flushleft}


\begin{flushleft}
combinatoria, anche più difficili di quelli appena visti. Prima di passare ad altri esempi più interessanti, tuttavia, vediamo alcune propriet\`{a} del coefficiente binomiale.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 1.26. Siano k e n numeri naturali tali che 0 ⩽ k ⩽ n. Valgono le seguenti propriet\`{a}:
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1.


=


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
n$-$k
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2.


=


=1


0


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





3.


\begin{flushleft}
k =0
\end{flushleft}





4.





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
= 2n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n+1
\end{flushleft}


+


=


.


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k +1
\end{flushleft}


\begin{flushleft}
k +1
\end{flushleft}





\begin{flushleft}
Dimostrazione. Lasciata come Problema 1.4.
\end{flushleft}





□





\begin{flushleft}
Anche nel caso del coefficiente binomiale, come per il fattoriale e per la combinatoria in generale, non possiamo andare a fondo e studiare tutte le sue propriet\`{a}. Accenniamo solamente alla
\end{flushleft}


\begin{flushleft}
rappresentazione dei coefficienti binomiali in forma grafica, con il triangolo di Tartaglia1.3 (o di
\end{flushleft}


\begin{flushleft}
Pascal1.4), del quale si pu\`{o} scoprire di più cercando online o consultando altri libri dedicati alla
\end{flushleft}


\begin{flushleft}
combinatoria.
\end{flushleft}


\begin{flushleft}
Ci sono per\`{o} problemi in cui il coefficiente binomiale entra in gioco in maniera non ovvia,
\end{flushleft}


\begin{flushleft}
come possiamo vedere nel prossimo esempio.
\end{flushleft}


\begin{flushleft}
Esempio 1.27. Sul Lungarno a Pisa ci sono 18 palazzi, l'uno accanto all'altro. Il nuovo sindaco
\end{flushleft}


\begin{flushleft}
vuole ridipingerli in modo che siano soddisfatte le seguenti condizioni:
\end{flushleft}


\begin{flushleft}
1. devono essere usati tutti e 7 i colori dell'arcobaleno;
\end{flushleft}


\begin{flushleft}
2. tutti i palazzi del medesimo colore devono essere adiacenti.
\end{flushleft}


\begin{flushleft}
In quanti modi diversi pu\`{o} farlo?
\end{flushleft}


\begin{flushleft}
Cominciamo subito spezzando il problema in due parti: siccome tutti i palazzi del medesimo
\end{flushleft}


\begin{flushleft}
colore sono adiacenti, possiamo separare la scelta dell'ordine dei colori e i modi di colorare i
\end{flushleft}


\begin{flushleft}
palazzi una volta fissato l'ordine dei colori. In particolare nella soluzione comparir\`{a} un fattore 7!
\end{flushleft}


\begin{flushleft}
a contare i possibili riordinamenti dei colori.
\end{flushleft}


\begin{flushleft}
Supponiamo ora fissato l'ordine dei colori. La seconda parte del problema \`{e} scegliere in quanti
\end{flushleft}


\begin{flushleft}
modi possiamo raggruppare i 18 palazzi in 7 sottoinsiemi, tenendo conto dei vincoli. Sentiamo
\end{flushleft}


\begin{flushleft}
puzza di coefficiente binomiale, ma non possiamo usarlo direttamente. Proviamo allora a cambiare punto di vista: mettiamoci sul Lungarno anche noi e guardiamo i palazzi che abbiamo
\end{flushleft}


\begin{flushleft}
accanto. Cominciamo a camminare: prima ne abbiamo un po' di un colore, poi passano al secondo,
\end{flushleft}


\begin{flushleft}
al terzo e così via, fino al passaggio dal sesto al settimo colore. Ehi! Abbiamo 6 cambi di colore,
\end{flushleft}


\begin{flushleft}
per via delle due condizioni. Quanti sono i posti in cui possiamo avere questi cambi di colore?
\end{flushleft}


\begin{flushleft}
Sono possibili a ogni confine tra due palazzi, quindi ne abbiamo uno dopo il primo palazzo,
\end{flushleft}


\begin{flushleft}
uno dopo il secondo e così via fino all'ultimo confine, dopo il penultimo (diciassettesimo) palazzo
\end{flushleft}


\begin{flushleft}
e prima dell'ultimo (diciottesimo). Quindi dobbiamo piazzare 6 cambi di colore in 17 posti possibili, per un contributo di 17
\end{flushleft}


\begin{flushleft}
. In generale, con p palazzi e c colori avremmo pc $-$$-$ 11 possibilit\`{a}.
\end{flushleft}


6


\begin{flushleft}
1.3. Niccol\`{o} Fontana detto Tartaglia (1499 circa -- 1557).
\end{flushleft}


\begin{flushleft}
1.4. Blaise Pascal (1623 -- 1662).
\end{flushleft}





\begin{flushleft}
\newpage
1.5 L'IMPORTANZA DELLA CLAUSOLA {``}EQUIPROBABILI''
\end{flushleft}





\begin{flushleft}
Mettendo assieme i due pezzi del problema, abbiamo allora 7! ⋅
\end{flushleft}





21





17


6





.





\begin{flushleft}
1.4. UN PO' DI PROBABILIT\`{A}
\end{flushleft}


\begin{flushleft}
Abbiamo detto che ci interessavamo ai conteggi e alla combinatoria per poter parlare di probabilit\`{a}. Vediamo allora qualche esempio in cui abbiamo casi equiprobabili per cui possiamo usare
\end{flushleft}


\begin{flushleft}
come definizione di probabilit\`{a} il rapporto tra il numero di casi favorevoli e quello di casi totali.
\end{flushleft}


\begin{flushleft}
Esempio 1.28. Se nel Dipartimento di Informatica ci sono 22 docenti che possono essere in commissione di laurea e una commissione di laurea \`{e} costituita da 5 docenti, con che probabilit\`{a} la
\end{flushleft}


\begin{flushleft}
prossima commissione sar\`{a} composta dai prof. Bianchi, Ronchetti, Ghiloni, Montresor e Kupfer?
\end{flushleft}


\begin{flushleft}
C'\`{e} una sola commissione con quei 5 professori, quindi il numero di casi favorevoli \`{e} uguale
\end{flushleft}


22!


\begin{flushleft}
a 1. Quante sono invece le possibili commissioni? Sono 22
\end{flushleft}


\begin{flushleft}
= 17! 5! = 26334. La probabilit\`{a} di avere
\end{flushleft}


5


1


\begin{flushleft}
proprio quella commissione, allora \`{e} 26334 $\approx$ 0.00004.
\end{flushleft}


\begin{flushleft}
Esempio 1.29. Giocando al Superenalotto con una scheda normale, cio\`{e} scegliendo 6 dei 90 numeri
\end{flushleft}


\begin{flushleft}
possibili, qual \`{e} la probabilit\`{a} dei seguenti risultati?
\end{flushleft}


\begin{flushleft}
i. Fare 6.
\end{flushleft}


\begin{flushleft}
ii. Fare esattamente 5.
\end{flushleft}


\begin{flushleft}
iii. Fare almeno 5.
\end{flushleft}


\begin{flushleft}
iv. Fare esattamente 3.
\end{flushleft}





\begin{flushleft}
Quante sono le possibili sestine? Sono
\end{flushleft}


90!


85 ⋅ 86 ⋅ 87 ⋅ 88 ⋅ 89 ⋅ 90


90


=


=


$\approx$ 6 ⋅ 10 8.


6


6! 84!


2⋅3⋅4⋅5⋅6


\begin{flushleft}
A questo punto dobbiamo solamente contare i casi favorevoli. Nel primo caso abbiamo un solo
\end{flushleft}


\begin{flushleft}
caso favorevole. Nel secondo ne abbiamo 65 84
\end{flushleft}


\begin{flushleft}
=6 ⋅84 e la probabilit\`{a} cercata \`{e} quindi dell'ordine
\end{flushleft}


1


\begin{flushleft}
di 10$-$6. Il terzo caso \`{e} dato dalla somma dei primi due casi, perch\'{e} almeno 5 significa o esattamente 5 o esattamente 6. I modi di fare esattamente 3 sono 63 84
\end{flushleft}


\begin{flushleft}
= 1905680 e la probabilit\`{a}
\end{flushleft}


3


\begin{flushleft}
associata \`{e} circa lo 0.3\%.
\end{flushleft}


\begin{flushleft}
Esempio 1.30. Qual \`{e} la probabilit\`{a} che in un'aula con 70 studenti almeno 2 abbiano lo stesso
\end{flushleft}


\begin{flushleft}
compleanno?
\end{flushleft}


\begin{flushleft}
Calcoliamo la probabilit\`{a} del caso opposto (o complementare), ossia che abbiano tutti compleanni in giorni diversi. Dalla definizione usata finora di probabilit\`{a} abbiamo infatti che la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} del complementare \`{e} il numero di casi non favorevoli diviso il numero di casi totali,
\end{flushleft}


\begin{flushleft}
quindi \`{e} uguale a 1 meno il numero di casi favorevoli diviso il numero di casi totali, dal momento
\end{flushleft}


\begin{flushleft}
che il numero di casi totali \`{e} la somma dei casi favorevoli e di quelli non favorevoli. Calcolando
\end{flushleft}


\begin{flushleft}
una delle due probabilit\`{a}, possiamo ottenere l'altra.
\end{flushleft}


\begin{flushleft}
Andiamo in ordine nell'aula e guardiamo la stringa di 70 giorni di compleanno. Se vogliamo
\end{flushleft}


365!


\begin{flushleft}
che siano tutte diverse tra loro, abbiamo (365 $-$ 70)! modi di sceglierle. Tutte le stringhe possibili
\end{flushleft}


\begin{flushleft}
(con ripetizioni) sono 36570. Facendo il rapporto abbiamo che la probabilit\`{a} che non ci siano due
\end{flushleft}


\begin{flushleft}
persone con il medesimo compleanno \`{e} circa 0.0008, ossia la probabilit\`{a} che almeno due abbiano
\end{flushleft}


\begin{flushleft}
lo stesso compleanno \`{e} maggiore di 99.9\%.
\end{flushleft}





\begin{flushleft}
1.5. L'IMPORTANZA DELLA CLAUSOLA {``}EQUIPROBABILI''
\end{flushleft}


\begin{flushleft}
Dobbiamo per\`{o} controllare che le ipotesi di equiprobabilit\`{a} siano verificate, altrimenti rischiamo
\end{flushleft}


\begin{flushleft}
di sbagliare, anche grossolanamente. Il classico controesempio alla formuletta mnemonica {``}casi
\end{flushleft}


\begin{flushleft}
favorevoli su casi totali'' \`{e} quello della lotteria: ci sono due casi possibili, vincere e non vincere, di
\end{flushleft}


1


\begin{flushleft}
cui uno solo \`{e} a noi favorevole, quindi la probabilit\`{a} di vittoria \`{e} 2 .
\end{flushleft}


\begin{flushleft}
Ce ne sono per\`{o} anche di più subdoli, in cui il risultato con un'interpretazione errata non \`{e} così
\end{flushleft}


\begin{flushleft}
lontano da quello corretto. In questi casi non possiamo sfruttare l'implausibilit\`{a} della probabilit\`{a}
\end{flushleft}


\begin{flushleft}
che otteniamo per accorgerci di aver sbagliato.
\end{flushleft}





\newpage
22





\begin{flushleft}
COMBINATORIA
\end{flushleft}





\begin{flushleft}
Esempio 1.31. Lanciamo due normali dadi a 6 facce. Qual \`{e} la probabilit\`{a} di ottenere almeno
\end{flushleft}


\begin{flushleft}
un 4?
\end{flushleft}


\begin{flushleft}
Quanti sono i possibili risultati, visti come coppie non ordinate? Ne abbiamo sei in cui compare almeno un 1, cinque in cui compare almeno un 2 e non compaiono 1 (abbiamo gi\`{a} contato
\end{flushleft}


6⋅7


\begin{flushleft}
\{1, 2\}) e così via. Le possibili coppie non ordinate sono 2 = 21. Quelle in cui compare almeno un
\end{flushleft}


6


2


\begin{flushleft}
4 sono sei. Quindi potremmo dire che la probabilit\`{a} di vedere almeno un 4 sia 21 = 7 $\approx$ 29\%.
\end{flushleft}


\begin{flushleft}
Come per\`{o} si pu\`{o} notare, queste coppie non ordinate non sono tra loro equiprobabili. E infatti
\end{flushleft}


\begin{flushleft}
se andiamo a contare le coppie ordinate, in cui il primo elemento rappresenta il risultato del
\end{flushleft}


\begin{flushleft}
primo dado e il secondo elemento quello del secondo dado, abbiamo 36 casi possibili, di cui 11
\end{flushleft}


11


\begin{flushleft}
favorevoli, per una probabilit\`{a} di vedere almeno un 4 uguale a 36 $\approx$ 31\%.
\end{flushleft}


\begin{flushleft}
Come avevamo detto prima, considerare le coppie come ordinate oppure no cambia le carte
\end{flushleft}


\begin{flushleft}
in tavola. Alle volte \`{e} l'ambientazione del problema a complicare le cose, ad esempio quando ci
\end{flushleft}


\begin{flushleft}
presenta (come singoli) oggetti che siamo abituati a considerare a coppie.
\end{flushleft}


\begin{flushleft}
Esempio 1.32. In una scarpiera, Andrea ha n paia di scarpe. Se prende a caso un numero pari di
\end{flushleft}


\begin{flushleft}
scarpe inferiore alla met\`{a} del totale, con che probabilit\`{a} non avr\`{a} un paio completo?
\end{flushleft}


\begin{flushleft}
Dobbiamo fare attenzione a non confondere scarpe e paia. Nella scarpiera ci sono 2 n scarpe
\end{flushleft}


\begin{flushleft}
e Andrea ne prende 2 s, con 2 s $<$ n. In quanti modi pu\`{o} farlo? \`{E} un coefficiente binomiale: pu\`{o}
\end{flushleft}


\begin{flushleft}
scegliere le scarpe in 22 ns modi.
\end{flushleft}


\begin{flushleft}
Passiamo allora al secondo conteggio, quello dei casi favorevoli1.5. Cosa vuol dire che non
\end{flushleft}


\begin{flushleft}
ha alcun paio completo? Significa che ha scelto al più una scarpa per ogni paio disponibile e, in
\end{flushleft}


\begin{flushleft}
particolare, ha scelto 2 s tipi di scarpa (cio\`{e} tipi di paia) tra gli n disponibili e per ciascuno di essi
\end{flushleft}


\begin{flushleft}
2s
\end{flushleft}


\begin{flushleft}
(cio\`{e} per 2 s volte) ha scelto una delle due scarpe. In altre parole lo pu\`{o} fare in 2ns ⋅ 21 = 2ns ⋅ 2 2s
\end{flushleft}


\begin{flushleft}
modi diversi. La probabilit\`{a} cercata \`{e} allora
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
2s
\end{flushleft}





\begin{flushleft}
⋅ 22s
\end{flushleft}


\begin{flushleft}
2n
\end{flushleft}


\begin{flushleft}
2s
\end{flushleft}





=





\begin{flushleft}
n! (2 n $-$ 2 s)! 2s
\end{flushleft}


⋅


⋅2 .


\begin{flushleft}
(2 n)! (n $-$ 2 s)!
\end{flushleft}





\begin{flushleft}
Se questo ragionamento non ci convince del tutto, magari perch\'{e} ci confondiamo nel passare da
\end{flushleft}


\begin{flushleft}
scarpe a paia, possiamo provare a calcolare il tutto in altri modi.
\end{flushleft}


\begin{flushleft}
Supponiamo che le scarpe siano tutte in fila e che quelle scelte da Andrea siano le prime 2 s. I
\end{flushleft}


\begin{flushleft}
casi totali sono allora (2 n)!.
\end{flushleft}


\begin{flushleft}
Passiamo allora ai casi favorevoli. Possiamo scegliere la prima scarpa come vogliamo, quindi
\end{flushleft}


\begin{flushleft}
abbiamo 2 n modi di farlo. Per la seconda, non volendo avere paia complete, abbiamo 2 n $-$ 2
\end{flushleft}


\begin{flushleft}
scelte, per la terza 2 n $-$ 4 e così via, fino alla scarpa in posizione 2 s che possiamo scegliere in
\end{flushleft}


\begin{flushleft}
2 n $-$ 2 ⋅ (2 s $-$ 1) = 2 n $-$ 4 s + 2 modi. A questo punto tutti i possibili ordinamenti delle successive
\end{flushleft}


\begin{flushleft}
2 n $-$ 2 s scarpe ci vanno bene, quindi abbiamo un fattore (2 n $-$ 2 s)!.
\end{flushleft}


\begin{flushleft}
I casi favorevoli sono in tutto 2 n ⋅ (2 n $-$ 2) ⋅ (2 n $-$ 4) ⋅ ⋅ ⋅ ⋅ ⋅ ⋅[2 n $-$ 2 ⋅ (2 s $-$ 1)] ⋅ (2 n $-$ 2 s)! e la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} cercata \`{e}
\end{flushleft}


\begin{flushleft}
2 n ⋅ (2 n $-$ 2) ⋅ ⋅ ⋅ ⋅ ⋅ [2 n $-$ 2 ⋅ (2 s $-$ 1)] ⋅ (2 n $-$ 2 s)!
\end{flushleft}


\begin{flushleft}
(2 n $-$ 2 s)!
\end{flushleft}


\begin{flushleft}
= 2 2s ⋅ n ⋅ (n $-$ 1) ⋅ ⋅ ⋅ ⋅ ⋅ [n $-$ (2 s $-$ 1)] ⋅
\end{flushleft}


,


\begin{flushleft}
(2 n)!
\end{flushleft}


\begin{flushleft}
(2 n)!
\end{flushleft}


\begin{flushleft}
cio\`{e} lo stesso risultato ottenuto prima (per fortuna).
\end{flushleft}


\begin{flushleft}
E se volessimo ragionare per probabilit\`{a} sulle singole scarpe, potremmo osservare che la prima
\end{flushleft}


\begin{flushleft}
2n
\end{flushleft}


\begin{flushleft}
2n$-$2
\end{flushleft}


\begin{flushleft}
ci va bene in 2 n casi su 2 n, cio\`{e} con probabilit\`{a} 2 n = 1, la seconda con probabilit\`{a} 2 n $-$ 1 , e così
\end{flushleft}


\begin{flushleft}
2n$-$4 s+2
\end{flushleft}


\begin{flushleft}
via fino alla scarpa numero 2 s che ci va bene con probabilit\`{a} 2 n $-$ 2 s + 1 . Mettendo il tutto assieme,
\end{flushleft}


\begin{flushleft}
2n 2n$-$2
\end{flushleft}


\begin{flushleft}
2 n $-$ 2 ⋅ (2 s $-$ 1)
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}


\begin{flushleft}
(2 n $-$ 2 s)!
\end{flushleft}


⋅


⋅⋅⋅⋅⋅


\begin{flushleft}
= 22s ⋅
\end{flushleft}


⋅


.


\begin{flushleft}
2n 2n$-$1
\end{flushleft}


\begin{flushleft}
2 n $-$ (2 s $-$ 1)
\end{flushleft}


\begin{flushleft}
(n $-$ 2 s)!
\end{flushleft}


\begin{flushleft}
(2 n)!
\end{flushleft}


\begin{flushleft}
1.5. In realt\`{a} per Andrea non sono molto favorevoli.
\end{flushleft}





\begin{flushleft}
\newpage
1.6 PROBLEMI
\end{flushleft}





23





\begin{flushleft}
Come riscaldamento, possiamo fermarci qui: con un po' di creativit\`{a} e di attenzione, sono tantissimi i problemi di probabilit\`{a} che si possono scrivere in termini di casi equiprobabili. Ma come
\end{flushleft}


\begin{flushleft}
detto, la definizione data non ci soddisfa del tutto. Non solo, ci restringe a casi in cui possiamo
\end{flushleft}


\begin{flushleft}
contare cose, quindi in numero finito. E ci obbliga a prestare attenzione al fatto che tutti i casi sono
\end{flushleft}


\begin{flushleft}
equiprobabili (come possiamo ad esempio considerare una moneta truccata?). Non \`{e} impossibile,
\end{flushleft}


\begin{flushleft}
ma come vedremo più avanti, con poca fatica e un po' di astrazione in più, riusciremo affrontare
\end{flushleft}


\begin{flushleft}
problemi e situazioni molto più generali.
\end{flushleft}





\begin{flushleft}
1.6. PROBLEMI
\end{flushleft}


\begin{flushleft}
Problema 1.1. Quante sono le partizioni di un insieme di cardinalit\`{a} n = 10?
\end{flushleft}


\begin{flushleft}
Soluzione. Indichiamo con B n il numero di partizioni distinte di un insieme di cardinalit\`{a} n. Sappiamo che B 0 =
\end{flushleft}


\begin{flushleft}
1, perch\'{e} l'insieme vuoto ha una sola partizione possibile. Se passiamo al caso n = 1, abbiamo nuovamente B 1 = 1.
\end{flushleft}


\begin{flushleft}
Possiamo provare a continuare ancora per qualche passo, ma \`{e} meglio provare a caratterizzare i B n ricorsivamente.
\end{flushleft}


\begin{flushleft}
Supponiamo di avere un insieme E di n elementi numerati da 1 a n e di andare a prendere, in una sua partizione,
\end{flushleft}


\begin{flushleft}
l'insieme S$\subseteq$ E a cui appartiene l'elemento n. A questo punto ci rimangono un certo numero di insiemi nella partizione
\end{flushleft}


\begin{flushleft}
che, tutti assieme, hanno un numero k di elementi (di E), con 0 ⩽ k ⩽ n $-$ 1. Per ciascuno di questi valori di k, possiamo
\end{flushleft}


\begin{flushleft}
scegliere questi k elementi in n $-$k 1 modi, dal momento che abbiamo gi\`{a} usato l'elemento n, e per ciascuna scelta
\end{flushleft}


\begin{flushleft}
abbiamo B k partizioni possibili dei k elementi rimasti.
\end{flushleft}


\begin{flushleft}
Abbiamo allora che
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}





\begin{flushleft}
Bn =
\end{flushleft}


\begin{flushleft}
k=0
\end{flushleft}





\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
Bk,
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
n ⩾ 1,
\end{flushleft}





\begin{flushleft}
i cui primi valori sono B 0 = B 1 = 1, B 2 = 2, B 3 = 5, B 4 = 15, B 5 = 52, B 6 = 203, B 7 = 877, B 8 = 4140, B 9 = 21147, B 10 = 115975.
\end{flushleft}


\begin{flushleft}
Problema 1.2. Quante sono le funzioni iniettive da un insieme A a un insieme B, entrambi di cardinalit\`{a} finita?
\end{flushleft}


\begin{flushleft}
Soluzione. Innanzitutto se vogliamo che esista una funzione iniettiva da A a B \`{e} necessario che B abbia almeno tanti
\end{flushleft}


\begin{flushleft}
elementi quanti A, cio\`{e} \#A ⩽ \#B. A questo punto osserviamo che possiamo scegliere l'immagine del primo elemento
\end{flushleft}


\begin{flushleft}
di A in \#B modi, quella del secondo in \#B $-$ 1 modi e così via, fino all'immagine dell'ultimo elemento di A, che potr\`{a}
\end{flushleft}


\begin{flushleft}
essere scelta in \#B $-$ (\#A $-$ 1) modi. Quindi abbiamo
\end{flushleft}


\begin{flushleft}
\#B ⋅ (\#B $-$ 1) ⋅ ⋅ ⋅ ⋅ ⋅ (\#B $-$ (\#A $-$ 1)) =
\end{flushleft}





\begin{flushleft}
(\#B)!
\end{flushleft}


.


\begin{flushleft}
(\#B $-$ \#A)!
\end{flushleft}





\begin{flushleft}
Possiamo vedere questo risultato anche in un altro modo: ci interessano i riordinamenti degli elementi di B, trascurando per\`{o} tutti gli elementi oltre quello in posizione \#A.
\end{flushleft}


\begin{flushleft}
Problema 1.3. Quante sono le funzioni suriettive da un insieme A a un insieme B, entrambi di cardinalit\`{a} finita?
\end{flushleft}


\begin{flushleft}
Soluzione. Siccome stiamo chiedendo che le funzioni siano suriettive, devono esserci in A almeno tanti elementi
\end{flushleft}


\begin{flushleft}
quanti ce ne sono in B, cio\`{e} \#A ⩾ \#B. Sappiamo che le funzioni da A a B sono \#B \#A, quindi questo impone un limite
\end{flushleft}


\begin{flushleft}
superiore al numero di funzioni suriettive: tra tutte le funzioni, infatti, ci sono ad esempio quelle che hanno nell'immagine tutto B tranne un unico elemento. Vogliamo quindi toglierle dal conteggio di tutte le funzioni. Quante sono le
\end{flushleft}


\begin{flushleft}
funzioni che escludono un solo elemento? Possiamo scegliere l'elemento escluso in \#B modi e, per ciascuna scelta, ci
\end{flushleft}


\begin{flushleft}
sono (\#B $-$ 1)\#A funzioni, quindi dobbiamo sottrarre \#B ⋅ (\#B $-$ 1)\#A a \#B \#A.
\end{flushleft}


\begin{flushleft}
A questo punto dobbiamo considerare le funzioni che escludono due elementi di B dall'immagine, infatti le
\end{flushleft}


\begin{flushleft}
abbiamo sottratte due volte, una volta per ciascuno dei due elementi. Insomma, dobbiamo continuare con il principio di inclusione-esclusione.
\end{flushleft}


\begin{flushleft}
Vediamo esplicitamente quante ne dobbiamo aggiungere: dobbiamo contare in quanti modi possiamo scegliere
\end{flushleft}


\begin{flushleft}
due elementi tra \#B, cio\`{e} \#B
\end{flushleft}


\begin{flushleft}
e, per ciascuno di questi modi, quante sono le funzioni da A all'insieme B tranne questi
\end{flushleft}


2


\begin{flushleft}
due elementi, cio\`{e} (\#B $-$ 2)\#A. Ricordiamo anche che queste vanno aggiunte, perch\'{e} sottratte due volte, poi sar\`{a} il
\end{flushleft}


\begin{flushleft}
turno di quelle con tre elementi esclusi, che sono state sottratte tre volte, ma anche ri-aggiunte tre volte e devono
\end{flushleft}


\begin{flushleft}
quindi essere sottratte di nuovo.
\end{flushleft}


\begin{flushleft}
Mettendo tutto assieme abbiamo l'uguaglianza
\end{flushleft}


\begin{flushleft}
\#B \#A $-$ \#B ⋅ (\#B $-$ 1)\#A +
\end{flushleft}





\begin{flushleft}
\#B
\end{flushleft}


\begin{flushleft}
⋅ (\#B $-$ 2)\#A $-$ ⋅ ⋅ ⋅ =
\end{flushleft}


2





\begin{flushleft}
\#B
\end{flushleft}


\begin{flushleft}
i=0
\end{flushleft}





\begin{flushleft}
($-$1)i ⋅
\end{flushleft}





\begin{flushleft}
\#B
\end{flushleft}


\begin{flushleft}
⋅ (\#B $-$ i)\#A.
\end{flushleft}


\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
Problema 1.4. (PROPOSIZIONE 1.26) Siano k e n numeri naturali tali che 0 ⩽ k ⩽ n. Verificare le seguenti propriet\`{a}:
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1.


=


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
n$-$k
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2.


=


=1


0


\begin{flushleft}
n
\end{flushleft}





\newpage
24





\begin{flushleft}
COMBINATORIA
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





3.


\begin{flushleft}
k=0
\end{flushleft}





4.





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
= 2n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n+1
\end{flushleft}


+


=


.


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k+1
\end{flushleft}


\begin{flushleft}
k+1
\end{flushleft}





\begin{flushleft}
Soluzione. Vediamole in ordine.
\end{flushleft}


\begin{flushleft}
1. In questo caso ci basta scrivere la definizione di coefficiente binomiale e sfruttare la commutativit\`{a} del prodotto,
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


=


=


=


.


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
n$-$k
\end{flushleft}


\begin{flushleft}
k! ⋅ (n $-$ k)! (n $-$ k)! ⋅ [n $-$ (n $-$ k)]!
\end{flushleft}


\begin{flushleft}
Oltre a svolgere il conto, avremmo anche potuto osservare che selezionare k elementi tra n \`{e} equivalente a scegliere
\end{flushleft}


\begin{flushleft}
n $-$ k elementi da scartare tra n.
\end{flushleft}


\begin{flushleft}
2. Questo \`{e} il caso limite del precedente, ma merita qualche parola in più: in quanti modi possiamo scegliere n
\end{flushleft}


\begin{flushleft}
oggetti tra n disponibili? Solamente in 1 modo. Viceversa, potremmo discutere sul fatto che ci sia solo un modo
\end{flushleft}


\begin{flushleft}
di scegliere 0 oggetti tra n (non scegliere alcun oggetto), ma \`{e} quello che esce sostituendo 0 a k nella definizione
\end{flushleft}


\begin{flushleft}
data, poich\'{e} 0! = 1, ed \`{e} anche consistente con la propriet\`{a} vista sopra.
\end{flushleft}


\begin{flushleft}
3. Questa propriet\`{a} \`{e} molto interessante: osservando il triangolo di Tartaglia, notiamo che la somma sulla riga nesima \`{e} uguale a 2 n , cio\`{e} che sommando tutti i coefficienti binomiali che hanno n nella posizione superiore otteniamo 2 n . Per capire come mai, ci appoggiamo al binomio di Newton, ossia allo sviluppo di un binomio elevato a
\end{flushleft}


\begin{flushleft}
potenza n. Sappiamo che
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
(a + b)n =
\end{flushleft}


\begin{flushleft}
⋅ a k ⋅ b (n$-$k).
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k=0
\end{flushleft}





\begin{flushleft}
Possiamo vederlo in modo combinatorio come segue: quando andiamo a fare l'elevamento a potenza, stiamo
\end{flushleft}


\begin{flushleft}
svolgendo il prodotto tra n fattori, ciascuno dei quali \`{e} una copia della somma a + b. Da ogni copia possiamo
\end{flushleft}


\begin{flushleft}
prendere una a o una b. In quanti modi possiamo avere k fattori a e n $-$ k fattori b?
\end{flushleft}


\begin{flushleft}
Dobbiamo solamente scegliere in quali k delle n copie di a + b peschiamo le a, cosa che possiamo fare in nk
\end{flushleft}


\begin{flushleft}
modi. Tornando al quesito iniziale, possiamo a questo punto prendere a = b = 1 e abbiamo nel secondo membro la
\end{flushleft}


\begin{flushleft}
somma cercata, con il primo membro che diventa uguale a 2 n .
\end{flushleft}


\begin{flushleft}
4. Questa \`{e} la propriet\`{a} alla base della costruzione del triangolo di Tartaglia. Immaginiamo di avere n + 1 oggetti in
\end{flushleft}


\begin{flushleft}
fila e di sceglierne k + 1 tra di essi.
\end{flushleft}


\begin{flushleft}
Consideriamo due casi possibili (disgiunti): tutti quelli in cui prendiamo l'ultimo oggetto e tutti quelli in cui
\end{flushleft}


\begin{flushleft}
non lo prendiamo. Essi sono, rispettivamente, nk , perch\'{e} dobbiamo scegliere altri k oggetti tra gli n rimanenti, e
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
, perch\'{e} avendo escluso l'ultimo oggetto, dobbiamo scegliere tutti i k + 1 oggetti tra i rimanenti n.
\end{flushleft}


\begin{flushleft}
k +1
\end{flushleft}


\begin{flushleft}
Se questa dimostrazione non ci piace, possiamo sempre usare le definizioni:
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


+


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k+1
\end{flushleft}





\begin{flushleft}
n!
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}


+


\begin{flushleft}
k!(n $-$ k)! (k + 1)!(n $-$ k + 1)!
\end{flushleft}


\begin{flushleft}
n!(k + 1 + n $-$ k)
\end{flushleft}


=


\begin{flushleft}
(k + 1)!(n $-$ k)!
\end{flushleft}


\begin{flushleft}
n!(n + 1)
\end{flushleft}


=


\begin{flushleft}
(k + 1)![(n + 1) $-$ (k + 1)]!
\end{flushleft}


\begin{flushleft}
n+1
\end{flushleft}


=


.


\begin{flushleft}
k+1
\end{flushleft}


=





\begin{flushleft}
\newpage
CAPITOLO 2
\end{flushleft}


\begin{flushleft}
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}


\begin{flushleft}
Esempio 2.1. Abbiamo un sacchetto che contiene 60 monete, tutte delle stesse dimensioni. Di
\end{flushleft}


\begin{flushleft}
queste, 20 sono d'ottone e hanno una densit\`{a} di 8.5 g⋅cm $-$3, 20 sono d'acciaio, con densit\`{a} 7.8 g⋅cm $-$3
\end{flushleft}


\begin{flushleft}
e 20 sono d'oro, con densit\`{a} 19.2 g⋅cm $-$3. Qual \`{e} la probabilit\`{a} di estrarre una moneta d'oro?
\end{flushleft}


\begin{flushleft}
Possiamo fare una domanda su questa domanda: cosa significa {``}qual \`{e} la probabilit\`{a} di estrarre
\end{flushleft}


\begin{flushleft}
una moneta d'oro?'' Ci sono diversi modi di estrarre una moneta dal sacchetto:
\end{flushleft}


\begin{flushleft}
i. posso pescare senza guardare n\'{e} soppesare;
\end{flushleft}


\begin{flushleft}
ii. posso rovesciare il sacchetto e prendere la moneta che cade per ultima e rimane più in alto
\end{flushleft}


\begin{flushleft}
nella pila delle monete rovesciate;
\end{flushleft}


\begin{flushleft}
iii. posso soppesare tutte le monete e controllarne il colore, prima di scegliere una che ritengo
\end{flushleft}


\begin{flushleft}
essere d'oro;
\end{flushleft}


\begin{flushleft}
iv. posso estrarre un certo numero di monete e fermarmi quando penso di averne una d'oro in
\end{flushleft}


\begin{flushleft}
mano.
\end{flushleft}


\begin{flushleft}
Cosa possiamo dire, a livello ancora intuitivo, sulla probabilit\`{a} che la moneta estratta in questi
\end{flushleft}


\begin{flushleft}
modi sia effettivamente d'oro? Vediamolo caso per caso.
\end{flushleft}


\begin{flushleft}
i. Questa situazione ci ricorda quanto (forse) visto a scuola: abbiamo 20 casi favorevoli, le 20
\end{flushleft}


\begin{flushleft}
monete d'oro, e 60 casi totali. La probabilit\`{a} di estrarre una moneta d'oro \`{e} quindi 1/3. Osserviamo che stiamo dicendo che la probabilit\`{a} di estrarre una particolare moneta delle 60 nel
\end{flushleft}


\begin{flushleft}
sacchetto \`{e} uguale a 1/60.
\end{flushleft}


\begin{flushleft}
ii. Lasciando cadere le monete, possiamo aspettarci che le differenze fisiche (in particolare la
\end{flushleft}


\begin{flushleft}
diversa densit\`{a} e di conseguenza la diversa massa) influiscano sull'ordine di caduta. Non
\end{flushleft}


\begin{flushleft}
\`{e} per\`{o} detto che siamo in grado di descrivere matematicamente (cio\`{e} di modellizzare) con
\end{flushleft}


\begin{flushleft}
precisione come ci\`{o} avviene. Sia che lo sappiamo, sia che non lo sappiamo fare avremo dei
\end{flushleft}


\begin{flushleft}
margini di incertezza (diversi nei due casi). La nostra miglior stima sar\`{a} la probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
iii. In questo caso potremmo pensare di avere la certezza di prendere una moneta d'oro. Tuttavia,
\end{flushleft}


\begin{flushleft}
anche se ne abbiamo la certezza pratica, non possiamo escludere un piccolo margine d'errore.
\end{flushleft}


\begin{flushleft}
La probabilit\`{a} sar\`{a} quindi 1 $-$ 𝜀, con 𝜀 positivo e tanto più piccolo quanto meno riteniamo
\end{flushleft}


\begin{flushleft}
plausibile un errore.
\end{flushleft}


\begin{flushleft}
iv. Rispetto al caso precedente abbiamo molta più incertezza: non stiamo più confrontando tutte
\end{flushleft}


\begin{flushleft}
le monete. Infatti se, dopo aver considerato una moneta, scegliamo di proseguire con una
\end{flushleft}


\begin{flushleft}
nuova estrazione, la moneta sar\`{a} persa per sempre, non potremo più sceglierla. La probabilit\`{a}, dunque, dipender\`{a} da chi estrae e dalla strategia decisionale che sceglie. Come possiamo
\end{flushleft}


\begin{flushleft}
descrivere questa situazione? Quale pu\`{o} essere la probabilit\`{a}?
\end{flushleft}


\begin{flushleft}
Qual \`{e} la morale di questo esempio? Abbiamo bisogno di definire in modo più chiaro la situazione che consideriamo. Abbiamo visto che alcuni esperimenti, come quello di questo esempio,
\end{flushleft}


\begin{flushleft}
hanno risultati che possiamo prevedere solo in parte. Incertezza e previsione sono i punti di
\end{flushleft}


\begin{flushleft}
partenza per parlare di probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.2. Un esperimento si dice aleatorio o casuale se, coi dati iniziali a disposizione, il suo
\end{flushleft}


\begin{flushleft}
risultato \`{e} incerto. In altre parole, se non possiamo prevederne con certezza l'esito.
\end{flushleft}


25





\newpage
26





\begin{flushleft}
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Possiamo osservare che abbiamo preso una definizione abbastanza ampia di esperimento
\end{flushleft}


\begin{flushleft}
aleatorio. L'incertezza, infatti, pu\`{o} essere nei dai iniziali, nella {``}legge'' che governa il fenomeno
\end{flushleft}


\begin{flushleft}
o nella nostra comprensione. Una conseguenza di questo \`{e} che un esperimento quale ad esempio
\end{flushleft}


\begin{flushleft}
il lancio di una moneta pu\`{o} dare origine a esperimenti aleatori (intesi come oggetti matematici)
\end{flushleft}


\begin{flushleft}
distinti: cambiare lo sperimentatore, il tempo o lo spazio pu\`{o} portare a livelli di incertezza diversi.
\end{flushleft}


\begin{flushleft}
Quando dichiareremo un esperimento aleatorio, sar\`{a} importante essere il più precisi possibile
\end{flushleft}


\begin{flushleft}
sulle sue caratteristiche rilevanti. Vedremo più avanti che sottovalutare questo aspetto pu\`{o} avere
\end{flushleft}


\begin{flushleft}
conseguenze significative.
\end{flushleft}


\begin{flushleft}
\`{E} curioso il fatto che la probabilit\`{a} ha preso il ruolo di linguaggio della scienza nel momento in
\end{flushleft}


\begin{flushleft}
cui l'ideale del determinismo \`{e} andato in pezzi con la teoria dei quanti. Gi\`{a} prima, con la meccanica statistica, la probabilit\`{a} aveva mostrato di poter descrivere e predire fenomeni complessi e in
\end{flushleft}


\begin{flushleft}
particolare di poter rappresentare la nostra incertezza (o ignoranza) nello studio di un fenomeno.
\end{flushleft}


\begin{flushleft}
Tuttavia la teoria dei quanti ha mostrato che l'incertezza \`{e} intrinseca in certi fenomeni, quindi la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} non \`{e} più una stampella temporanea in attesa di conoscere il modello deterministico,
\end{flushleft}


\begin{flushleft}
ma \`{e} la descrizione corretta.
\end{flushleft}


\begin{flushleft}
Vogliamo descrivere con precisione, in termini matematici, un esperimento aleatorio. Dobbiamo allora dichiarare tutto quello che lo caratterizza. Come prima cosa, ne consideriamo i
\end{flushleft}


\begin{flushleft}
possibili risultati.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.3. I risultati, a due a due incompatibili, di un esperimento aleatorio prendono il nome di
\end{flushleft}


\begin{flushleft}
esiti. Matematicamente possiamo rappresentarli come elementi di un insieme, detto spazio campionario,
\end{flushleft}


\begin{flushleft}
spazio degli esiti, popolazione o insieme universo e denotato con $\Omega$ o U. Questo insieme contiene tutti
\end{flushleft}


\begin{flushleft}
e soli i possibili risultati dell'esperimento aleatorio.
\end{flushleft}


\begin{flushleft}
Esempio 2.4. Consideriamo un contenitore, detto urna, in cui ci sono un certo numero di oggetti,
\end{flushleft}


\begin{flushleft}
detti biglie, indistinguibili al tatto, ma di diverso colore, ad esempio bianco e nero, oppure bianco,
\end{flushleft}


\begin{flushleft}
rosso e nero. Un esperimento aleatorio pu\`{o} essere l'estrazione di una biglia dall'urna: infiliamo la
\end{flushleft}


\begin{flushleft}
mano nell'urna senza guardare e prendiamo una biglia. Se l'urna contiene biglie bianche, rosse e
\end{flushleft}


\begin{flushleft}
nere, gli esiti possibili sono tre: la biglia estratta \`{e} bianca, oppure \`{e} rossa, oppure \`{e} nera.
\end{flushleft}


\begin{flushleft}
Un diverso esperimento aleatorio pu\`{o} prevedere l'estrazione di due biglie dalla stessa urna,
\end{flushleft}


\begin{flushleft}
con reimmissione, ossia rimettendo la biglia pescata per prima nell'urna (dopo averla guardata) e
\end{flushleft}


\begin{flushleft}
rimescolando le biglie nell'urna, prima di estrarre la seconda biglia. In questo caso lo spazio degli
\end{flushleft}


\begin{flushleft}
esiti, abbreviando i colori con le loro iniziali, \`{e} costituito dalle coppie ordinate
\end{flushleft}


\begin{flushleft}
$\Omega$ = \{(B, B), (B, R), (B, N), (R, B), (R, R), (R, N), (N, B), (N, R), (N, N)\}.
\end{flushleft}


\begin{flushleft}
Un terzo esperimento casuale, sempre con la stessa urna, pu\`{o} essere l'estrazione di due biglie
\end{flushleft}


\begin{flushleft}
senza reimmissione. In questo caso, per\`{o}, abbiamo bisogno di qualche informazione in più sul
\end{flushleft}


\begin{flushleft}
numero di biglie nell'urna. Infatti nei casi precedenti bastava sapere che c'erano biglie di tre colori,
\end{flushleft}


\begin{flushleft}
ossia che c'era almeno una biglia di ciascun colore. In questo caso, invece, se ci fosse, per esempio,
\end{flushleft}


\begin{flushleft}
una sola biglia bianca, la coppia ordinata (B, B) non sarebbe più un esito, poich\'{e} non \`{e} un risultato possibile2.1.
\end{flushleft}


\begin{flushleft}
Osservazione 2.5. Capita spesso che, quando ci si avvicina per la prima volta alla probabilit\`{a}, ci
\end{flushleft}


\begin{flushleft}
si chieda come mai i problemi e gli esempi siano popolati da urne. Non sembrano essere qualcosa
\end{flushleft}


\begin{flushleft}
di cui ci interessiamo spesso, nel mondo reale, quindi perch\'{e} usarli come esempi?
\end{flushleft}


\begin{flushleft}
2.1. In realt\`{a} la questione pu\`{o} essere più sfumata: infatti potremmo non sapere quante biglie bianche ci sono nell'urna.
\end{flushleft}


\begin{flushleft}
In questo caso la coppia (B, B) \`{e} a priori un risultato possibile. Potremo codificare l'informazione sull'assenza di una
\end{flushleft}


\begin{flushleft}
seconda biglia bianca nella probabilit\`{a}, come vedremo più avanti. In generale \`{e} fondamentale che l'insieme universo
\end{flushleft}


\begin{flushleft}
contenga tutti gli esiti, ma abbiamo più flessibilit\`{a} sul fatto che siano i soli elementi dell'insieme.
\end{flushleft}





\begin{flushleft}
\newpage
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}





27





\begin{flushleft}
La risposta \`{e} che le urne, come altri esempi, sono un buon compromesso tra l'astrazione delle
\end{flushleft}


\begin{flushleft}
caratteristiche cruciali dell'esperimento aleatorio, pur lasciando un'immagine sensoriale che sia di
\end{flushleft}


\begin{flushleft}
supporto alla rappresentazione mentale. Ciascuno pu\`{o} scegliere tra le rappresentazioni di esperimenti aleatori equivalenti2.2 quella che genera l'immagine mentale più forte, non necessariamente
\end{flushleft}


\begin{flushleft}
legata al senso della vista o del tatto, ad esempio contenitori con oggetti indistinguibili al tatto
\end{flushleft}


\begin{flushleft}
e alla vista, ma con odori diversi.
\end{flushleft}


\begin{flushleft}
In un esperimento aleatorio, per\`{o}, possiamo osservare altre cose, oltre ai risultati specifici
\end{flushleft}


\begin{flushleft}
finali. Chiamiamo, per ora informalmente, evento un'osservabile dell'esperimento aleatorio, ossia
\end{flushleft}


\begin{flushleft}
un fatto che, al termine dell'esperimento, possiamo dire essere vero o falso, a seconda del risultato dell'esperimento stesso. Nell'estrazione con reimmissione vista nell'Esempio 2.4 un evento
\end{flushleft}


\begin{flushleft}
\`{e} {``}\`{e} stata estratta almeno una biglia bianca''. A seconda dell'esito dell'esperimento potremo dire
\end{flushleft}


\begin{flushleft}
se questo evento \`{e} vero, oppure falso.
\end{flushleft}


\begin{flushleft}
Sembra ragionevole, allora, pensare a un evento come a un insieme di risultati per cui l'evento
\end{flushleft}


\begin{flushleft}
\`{e} vero. Una possibile rappresentazione di un evento \`{e} quindi come insieme di esiti, ossia come
\end{flushleft}


\begin{flushleft}
sottoinsieme di $\Omega$. Diciamo che un vento si verifica o si realizza se il risultato dell'esperimento
\end{flushleft}


\begin{flushleft}
aleatorio \`{e} (come esito) un elemento dell'evento.
\end{flushleft}


\begin{flushleft}
Esempio 2.6. Lanciamo un dado a 6 facce2.3, alcuni possibili eventi sono:
\end{flushleft}


\begin{flushleft}
$-$ esce una faccia con un numero pari, E 1 = \{2, 4, 6\};
\end{flushleft}


\begin{flushleft}
$-$ esce una faccia con un numero minore o uguale a 4, E 2 = \{1, 2, 3, 4\};
\end{flushleft}


\begin{flushleft}
$-$ esce una faccia con un numero maggiore di 6, E 3 = $\emptyset$;
\end{flushleft}


\begin{flushleft}
$-$ esce una faccia con il numero 3, E 4 = \{3\}...
\end{flushleft}


\begin{flushleft}
Vedremo che serve in generale qualche accortezza in più nell'identificare gli eventi coi sottoinsiemi dello spazio degli esiti.
\end{flushleft}


\begin{flushleft}
Ricordiamo che il numero di elementi di un insieme A si chiama cardinalit\`{a} di A e lo indichiamo con la notazione \#A. Finch\'{e} abbiamo a che fare con insiemi finiti, non ci sono troppi
\end{flushleft}


\begin{flushleft}
problemi; ma nel momento in cui passiamo a insiemi infiniti, abbiamo bisogno di un po' più di
\end{flushleft}


\begin{flushleft}
precisione. Diciamo allora che due insiemi A e B hanno la stessa cardinalit\`{a}, cio\`{e} sono equipotenti,
\end{flushleft}


\begin{flushleft}
se esiste una funzione biettiva f : A $\rightarrow$ B. In particolare un insieme equipotente all'insieme ℕ dei
\end{flushleft}


\begin{flushleft}
numeri naturali ha cardinalit\`{a} (infinita) numerabile e questa quantit\`{a} \`{e} denotata con $\aleph$ 0, il primo
\end{flushleft}


\begin{flushleft}
dei numeri cardinali (cio\`{e} usati per indicare le cardinalit\`{a}) infiniti2.4.
\end{flushleft}


\begin{flushleft}
L'insieme universo $\Omega$ in un esperimento aleatorio non ha necessariamente un numero finito
\end{flushleft}


\begin{flushleft}
di elementi: possono essere in numero finito o anche infiniti, numerabili o più che numerabili.
\end{flushleft}


\begin{flushleft}
Vogliamo poter considerare situazioni in cui il numero di esiti \`{e} infinito. Questo ci creerebbe
\end{flushleft}


\begin{flushleft}
qualche problema, se volessimo usare la definizione {``}casi favorevoli su casi totali'', perch\'{e}
\end{flushleft}


\begin{flushleft}
dovremmo confrontare cardinali infiniti, ma per essi non vale la legge di cancellazione. Per risolvere questo problema abbiamo bisogno di rendere più robusta la nostra teoria.
\end{flushleft}


\begin{flushleft}
Prima di proseguire, vediamo alcuni esempi di esperimenti casuali e dei corrispondenti insiemi
\end{flushleft}


\begin{flushleft}
degli esiti.
\end{flushleft}


\begin{flushleft}
$\bullet$ Il lancio di una moneta: in questo caso abbiamo $\Omega$ = \{testa, croce\} che \`{e} un insieme finito.
\end{flushleft}


\begin{flushleft}
$\bullet$ Il numero di tentativi prima di colpire il centro a freccette: qui $\Omega$ = ℕ e ha cardinalit\`{a} numerabile. Infatti non \`{e} possibile stabilire a priori quanti lanci saranno sufficienti (e dare quindi un
\end{flushleft}


\begin{flushleft}
limite superiore a $\Omega$).
\end{flushleft}


\begin{flushleft}
2.2. L'equivalenza in termini probabilistici di esperimenti aleatori verr\`{a} affrontata più avanti, nel Capitolo 5
\end{flushleft}


\begin{flushleft}
2.3. In generale ci sono dadi {``}fisici'' a 2, 4, 6, 8, 10, 12, 20 facce: il primo si chiama anche {``}moneta'', quelli a 4, 6, 8, 12,
\end{flushleft}


\begin{flushleft}
20 facce sono i solidi platonici, mentre quello a 10 facce \`{e} un solido non platonico. Possiamo per\`{o} considerare anche dadi
\end{flushleft}


\begin{flushleft}
con altri numeri di facce, ad esempio 3, 30 o 100. Un dado con n facce \`{e} spesso indicato come dn.
\end{flushleft}


\begin{flushleft}
2.4. Il fatto che $\aleph$0 sia il primo cardinale infinito suggerisce che ce ne siano degli altri, più grandi. Così \`{e}, in effetti, e
\end{flushleft}


\begin{flushleft}
vedremo un esempio nelle prossime pagine.
\end{flushleft}





\newpage
28





\begin{flushleft}
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
$\bullet$ Le possibili lunghezze di un segmento contenuto nell'intervallo reale [0, 1]: il corrispondente
\end{flushleft}


\begin{flushleft}
insieme degli esiti \`{e} $\Omega$ = (0, 1], un intervallo di cardinalit\`{a} pari al continuo.
\end{flushleft}





\begin{flushleft}
2.1. ALGEBRE E TRIBÙ
\end{flushleft}


\begin{flushleft}
Considerare tutti i sottoinsiemi di $\Omega$ significa considerarne l'insieme potenza (o delle parti), che
\end{flushleft}


\begin{flushleft}
ha cardinalit\`{a} 2 \#$\Omega$, che in particolare \`{e} la cardinalit\`{a} del continuo, se $\Omega$ ha cardinalit\`{a} numerabile
\end{flushleft}


\begin{flushleft}
e addirittura strettamente maggiore della cardinalit\`{a} del continuo, se $\Omega$ \`{e} equipotente all'insieme
\end{flushleft}


\begin{flushleft}
ℝ dei numeri reali. Ulteriori dettagli su questi risultati sono in Appendice A.1.
\end{flushleft}


\begin{flushleft}
Avendo richiamato i risultati precedenti sulla cardinalit\`{a} degli insiemi potenza, sorge spontaneo un pensiero: sarebbe bello poter considerare solo una parte dei sottoinsiemi, qualora non
\end{flushleft}


\begin{flushleft}
ci interessassero proprio tutti. Ad esempio, se stessimo scegliendo un numero tra tutti i naturali,
\end{flushleft}


\begin{flushleft}
ma ci interessasse solo sapere se il numero \`{e} pari o no, ci farebbe comodo poter considerare solo
\end{flushleft}


\begin{flushleft}
i due sottoinsiemi {``}numeri pari'' e {``}numeri dispari'', invece che tutti i sottoinsiemi di ℕ.
\end{flushleft}


\begin{flushleft}
Pensiamo infatti al nostro obiettivo: vogliamo definire una probabilit\`{a}, ma vorremmo farlo
\end{flushleft}


\begin{flushleft}
solo su alcuni insiemi, quelli che ci interessano, e non necessariamente su tutti quanti, perch\'{e}
\end{flushleft}


\begin{flushleft}
sarebbe un po' uno spreco. Possiamo pensare che definire la probabilit\`{a} di un evento abbia un
\end{flushleft}


\begin{flushleft}
costo non trascurabile, dal momento che, come vedremo, dobbiamo scegliere tale probabilit\`{a} con
\end{flushleft}


\begin{flushleft}
attenzione in modo che soddisfi certe importanti propriet\`{a}. \`{E} un prezzo che non vogliamo pagare
\end{flushleft}


\begin{flushleft}
inutilmente.
\end{flushleft}


\begin{flushleft}
Il nostro piano \`{e} quindi quello di considerare in generale una famiglia ℱ di sottoinsiemi,
\end{flushleft}


\begin{flushleft}
quindi ℱ $\subseteq$𝒫($\Omega$), ma non necessariamente tutto 𝒫($\Omega$). Ancora una volta, pensiamo al nostro traguardo a lungo termine: definire una probabilit\`{a} su questi sottoinsiemi. Abbiamo quindi bisogno
\end{flushleft}


\begin{flushleft}
che questa famiglia sia, in un qualche senso, {``}stabile''.
\end{flushleft}


\begin{flushleft}
Per capire meglio cosa intendiamo, pensiamo di nuovo al nostro obiettivo: vogliamo definire
\end{flushleft}


\begin{flushleft}
una probabilit\`{a} in modo sensato e vogliamo definirla su questa collezione di insiemi. Vorremmo
\end{flushleft}


\begin{flushleft}
in particolare che questa collezione contenesse l'insieme $\Omega$ e che fosse chiusa rispetto alle operazioni di unione, intersezione e complementare. In altre parole: se due insiemi appartengono
\end{flushleft}


\begin{flushleft}
alla collezione, vorremmo che ci appartenessero anche la loro unione, la loro intersezione e i loro
\end{flushleft}


\begin{flushleft}
complementari.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.7. Una famiglia ℱ di sottoinsiemi di un insieme $\Omega$ \`{e} un'algebra se valgono tutte le seguenti
\end{flushleft}


\begin{flushleft}
propriet\`{a}:
\end{flushleft}





\begin{flushleft}
i. $\Omega$ $\in$ ℱ;
\end{flushleft}


\begin{flushleft}
ii. se A $\in$ ℱ, allora anche il suo complementare Ac $\in$ ℱ;
\end{flushleft}


\begin{flushleft}
iii-finita. se A, B $\in$ ℱ, allora A $\cup$ B $\in$ ℱ.
\end{flushleft}


\begin{flushleft}
Osserviamo che, per come \`{e} scritta, la propriet\`{a} iii-finita della Definizione 2.7 dovrebbe essere
\end{flushleft}


\begin{flushleft}
chiamata iii-binaria. Possiamo per\`{o} estenderla al caso più generale dell'unione finita: se abbiamo
\end{flushleft}


\begin{flushleft}
una famiglia finita (A i)ni=1 di sottoinsiemi di $\Omega$ tali che (Ai) ni=1 $\subseteq$ ℱ, allora per la propriet\`{a} associativa dell'unione ⋃ ni=1 Ai $\in$ ℱ.
\end{flushleft}


\begin{flushleft}
Qualche riga più in alto parlavamo di avere una collezione chiusa anche rispetto all'intersezione. La Definizione 2.7 non menziona esplicitamente l'intersezione e parla solo di unione e
\end{flushleft}


\begin{flushleft}
complementare. Tuttavia ci garantisce anche che un'algebra sia chiusa rispetto all'intersezione,
\end{flushleft}


\begin{flushleft}
assieme ad altre propriet\`{a}, come mostrato nel seguente risultato.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.8. Data un'algebra ℱ su $\Omega$, valgono le seguenti propriet\`{a}:
\end{flushleft}


\begin{flushleft}
1. $\emptyset$ $\in$ ℱ;
\end{flushleft}


\begin{flushleft}
2. se A, B $\in$ ℱ, allora A $\cap$ B $\in$ ℱ;
\end{flushleft}





\begin{flushleft}
\newpage
2.1 ALGEBRE E TRIBÙ
\end{flushleft}





29





\begin{flushleft}
3. se (A i)ni=1 $\subseteq$ ℱ, allora ⋂ ni=1 A i $\in$ ℱ;
\end{flushleft}


\begin{flushleft}
4. se A, B $\in$ ℱ, allora A ∖ B $\in$ ℱ;
\end{flushleft}


\begin{flushleft}
5. se A, B $\in$ ℱ, allora A △ B $\in$ ℱ.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Procediamo in ordine.
\end{flushleft}


\begin{flushleft}
1. Sappiamo che $\Omega$ $\in$ ℱ, per la prima propriet\`{a}, e che anche il suo complementare appartiene a
\end{flushleft}


\begin{flushleft}
ℱ, per la seconda. Ma $\Omega$ c = $\emptyset$, che quindi appartiene a ℱ.
\end{flushleft}


\begin{flushleft}
2. Osserviamo che A $\cap$ B = (Ac $\cup$ B c) c. Ora, sia Ac sia B c appartengono a ℱ, dunque anche Ac $\cup$ B c
\end{flushleft}


\begin{flushleft}
e il suo complementare.
\end{flushleft}


\begin{flushleft}
3. Possiamo iterare il ragionamento visto al punto precedente, sfruttando l'associativit\`{a} dell'intersezione.
\end{flushleft}


\begin{flushleft}
4. Anche qui il trucco \`{e} riscrivere l'insieme in una forma più comoda della precedente: A ∖ B =
\end{flushleft}


\begin{flushleft}
A $\cap$ B c. A questo punto ci basta usare la seconda propriet\`{a} di algebra e la chiusura rispetto
\end{flushleft}


\begin{flushleft}
all'intersezione mostrata sopra.
\end{flushleft}


\begin{flushleft}
5. Riscriviamo A △ B = (A $\cup$ B) $\cap$ (Ac $\cup$ B c) (come fatto in dettaglio nella Proposizione A.2) e concludiamo usando le propriet\`{a} gi\`{a} mostrate.
\end{flushleft}


□


\begin{flushleft}
Esempio 2.9. Prendiamo $\Omega$= \{0,1, 2\}. Allora ℱ =\{$\emptyset$, \{0\},\{1, 2\},$\Omega$\} \`{e} un'algebra su $\Omega$. In particolare
\end{flushleft}


\begin{flushleft}
quest'algebra \`{e} diversa dall'insieme potenza 𝒫($\Omega$).
\end{flushleft}


\begin{flushleft}
Questo ci suggerisce in particolare che, dato un insieme $\Omega$ (con almeno due elementi), esiste
\end{flushleft}


\begin{flushleft}
più di un'algebra su di esso. Quante ne possiamo avere? Nel caso di $\Omega$ finito, le algebre sono tante
\end{flushleft}


\begin{flushleft}
quante le partizioni di $\Omega$, cio\`{e} B \#$\Omega$, come abbiamo visto nel Problema 1.1.
\end{flushleft}


\begin{flushleft}
Esempio 2.10. Prendiamo ora $\Omega$ = \{a, b, c, d, e, f , g\}. Le seguenti famiglie di insiemi non sono
\end{flushleft}


\begin{flushleft}
algebre:
\end{flushleft}


\begin{flushleft}
$\bullet$ ℱ 1 = \{$\emptyset$, \{a, b, c, d, e\}, $\Omega$\}. Infatti manca il complementare di \{a, b, c, d, e\}; il completamento di ℱ 1
\end{flushleft}


\begin{flushleft}
a un'algebra \`{e} \{$\emptyset$, \{a, b, c, d, e\}, \{ f , g\}, $\Omega$\}.
\end{flushleft}


\begin{flushleft}
$\bullet$ ℱ 2 = \{\{a\}, \{b, c, d\}, \{e, f , g\}, $\Omega$\}, poich\'{e} manca un complementare, l'insieme vuoto.
\end{flushleft}


\begin{flushleft}
$\bullet$ ℱ 3 = \{$\emptyset$, \{a\}, \{b\}, \{b, c, d, e, f , g\}, \{a, c, d, e, f , g\}, $\Omega$\}, siccome mancano i due insiemi \{a, b\}, \{c, d, e, f ,
\end{flushleft}


\begin{flushleft}
g\}, l'unione di \{a\} e \{b\} e il suo complementare.
\end{flushleft}


\begin{flushleft}
Nella Definizione 2.7 la terza propriet\`{a} \`{e} chiamata {``}iii-finita'' e non {``}iii'': questo potrebbe
\end{flushleft}


\begin{flushleft}
farci sospettare che esistano famiglie di sottoinsiemi per cui la propriet\`{a} \`{e} sostituita da una sua
\end{flushleft}


\begin{flushleft}
variante infinita. Così \`{e}, ma \`{e} un infinito {``}controllato''.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.11. Una famiglia ℱ di sottoinsiemi di un insieme $\Omega$ \`{e} una tribù (o 𝜎-algebra2.5) se valgono
\end{flushleft}


\begin{flushleft}
tutte le seguenti propriet\`{a}:
\end{flushleft}


\begin{flushleft}
i. $\Omega$ $\in$ ℱ;
\end{flushleft}


\begin{flushleft}
ii. per ogni A $\subseteq$ $\Omega$, se A $\in$ ℱ, allora Ac $\in$ ℱ;
\end{flushleft}


\begin{flushleft}
iii. per ogni famiglia numerabile (Ai)+$\infty$
\end{flushleft}


\begin{flushleft}
i=1 di insiemi di $\Omega$, se tutti gli insiemi A i della famiglia appartengono
\end{flushleft}


\begin{flushleft}
a ℱ, allora ⋃+$\infty$
\end{flushleft}


\begin{flushleft}
A
\end{flushleft}


$\in$


\begin{flushleft}
ℱ.
\end{flushleft}


\begin{flushleft}
i
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}


\begin{flushleft}
Esempio 2.12. L'insieme delle parti di $\Omega$ \`{e} esso stesso una tribù. Possiamo osservare, infatti, che
\end{flushleft}


\begin{flushleft}
soddisfa tutte le propriet\`{a} richieste. Dal momento che include tutti i possibili sottoinsiemi di $\Omega$,
\end{flushleft}


\begin{flushleft}
contiene $\Omega$ stesso, il complementare di ogni sottoinsieme di $\Omega$ e anche ogni unione numerabile di
\end{flushleft}


\begin{flushleft}
sottoinsiemi di $\Omega$.
\end{flushleft}


\begin{flushleft}
2.5. In realt\`{a} questo termine non \`{e} del tutto corretto: bisognerebbe parlare di 𝜎-algebre (o 𝜎-campi) di insiemi, che sono
\end{flushleft}


\begin{flushleft}
un particolare caso di 𝜎-algebre booleane. Nella pratica tra i probabilisti il termine 𝜎-algebra \`{e} sdoganato.
\end{flushleft}





\newpage
30





\begin{flushleft}
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Rispetto alla definizione di algebra, stiamo chiedendo che anche l'unione numerabile sia
\end{flushleft}


\begin{flushleft}
un'operazione interna. Osserviamo inoltre che, se ℱ \`{e} una tribù, \`{e} in particolare un'algebra, ma
\end{flushleft}


\begin{flushleft}
il viceversa non \`{e} vero in generale. Vale tuttavia il risultato seguente.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.13. Sia ℱ un'algebra finita su un insieme $\Omega$. Allora ℱ \`{e} una tribù.
\end{flushleft}


\begin{flushleft}
Dimostrazione. La differenza tra un'algebra e una tribù sta nella propriet\`{a} iii della Definizione iii:
\end{flushleft}


\begin{flushleft}
dobbiamo mostrare che ogni unione numerabile di elementi di ℱ sta in ℱ. Siccome ℱ \`{e} finita,
\end{flushleft}


\begin{flushleft}
contiene solamente un numero finito di elementi, cio\`{e} di sottoinsiemi di $\Omega$. Di conseguenza ogni
\end{flushleft}


\begin{flushleft}
unione numerabile di elementi di ℱ sar\`{a} in realt\`{a} un'unione finita, dal momento che abbiamo solo
\end{flushleft}


\begin{flushleft}
un numero finito di possibili elementi. Tale unione finita appartiene a ℱ, poich\'{e} ℱ \`{e} un'algebra. □
\end{flushleft}


\begin{flushleft}
Quindi, finch\'{e} abbiamo a che fare con insiemi finiti, non abbiamo davvero bisogno di parlare
\end{flushleft}


\begin{flushleft}
di tribù: ci basta controllare che la nostra famiglia di sottoinsiemi sia un'algebra. Questa propriet\`{a}
\end{flushleft}


\begin{flushleft}
ci d\`{a} anche un'interessante condizione necessaria affinch\'{e} una famiglia finita di sottoinsiemi sia
\end{flushleft}


\begin{flushleft}
una tribù: deve avere un numero di elementi uguale a una potenza di 2. Lasciamo da parte la
\end{flushleft}


\begin{flushleft}
dimostrazione (che si pu\`{o} fare per induzione, con qualche accortezza), ma osserviamo che grazie
\end{flushleft}


\begin{flushleft}
a questa condizione abbiamo un modo rapido per dire che una famiglia di sottoinsiemi non \`{e} una
\end{flushleft}


\begin{flushleft}
tribù. Infatti, se una collezione di insiemi ha cardinalit\`{a} diversa da una potenza di 2, sappiamo
\end{flushleft}


\begin{flushleft}
che sicuramente non pu\`{o} essere una tribù.
\end{flushleft}


\begin{flushleft}
Proseguiamo con altre propriet\`{a} di algebre e tribù.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.14. Date su $\Omega$ due algebre ℱ 1 ed ℱ 2, la loro intersezione ℱ 1 $\cap$ℱ 2 \`{e} a sua volta un'algebra
\end{flushleft}


\begin{flushleft}
su $\Omega$. Lo stesso vale se sostituiamo ``algebra'' con ``tribù''.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Dimostriamo questa proposizione per due tribù: in questo modo abbiamo il
\end{flushleft}


\begin{flushleft}
risultato anche per le algebre.
\end{flushleft}


\begin{flushleft}
Dobbiamo far vedere che ℱ 1 $\cap$ ℱ 2 soddisfa le propriet\`{a} di una tribù. Procediamo punto per
\end{flushleft}


\begin{flushleft}
punto.
\end{flushleft}


\begin{flushleft}
i. Siccome ℱ 1 ed ℱ 2 sono tribù, $\Omega$ $\in$ ℱ 1 e $\Omega$ $\in$ ℱ 2, quindi $\Omega$ $\in$ ℱ 1 $\cap$ ℱ 2.
\end{flushleft}


\begin{flushleft}
ii. Sia E $\in$ ℱ 1 $\cap$ ℱ 2, allora E $\in$ ℱ 1 ed E $\in$ ℱ 2. Siccome ℱ 1 ed ℱ 2 sono due tribù, E c $\in$ ℱ 1 ed E c $\in$ ℱ 2,
\end{flushleft}


\begin{flushleft}
quindi E c $\in$ ℱ 1 $\cap$ ℱ 2.
\end{flushleft}


+$\infty$


\begin{flushleft}
iii. Prendiamo (Ei)+$\infty$
\end{flushleft}


\begin{flushleft}
i=1 $\subset$ ℱ 1 $\cap$ ℱ 2. Allora la successione sar\`{a} in entrambe le tribù, (E i)i=1 $\subset$ ℱ 1 ed
\end{flushleft}


+$\infty$


+$\infty$


+$\infty$


+$\infty$


\begin{flushleft}
(E i)i=1 $\subset$ ℱ 2. Di conseguenza, ⋃ i=1 E i $\in$ ℱ 1 e ⋃i=1 E i $\in$ ℱ 2 e quindi anche ⋃i=1 Ei $\in$ ℱ 1 $\cap$ ℱ 2.
\end{flushleft}





\begin{flushleft}
Questo conclude la dimostrazione.
\end{flushleft}





□





\begin{flushleft}
Avendo preso familiarit\`{a} con le tribù, ripensiamo al motivo per cui le abbiamo definite. Dato
\end{flushleft}


\begin{flushleft}
un insieme $\Omega$ e una tribù ℱ su di esso, ci interessano gli elementi di ℱ. Andiamo quindi a dar loro
\end{flushleft}


\begin{flushleft}
un nome.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.15. Sia ℱ una tribù su $\Omega$. Ogni elemento E $\in$ ℱ prende il nome di evento. I singoletti
\end{flushleft}


\begin{flushleft}
in ℱ prendono il nome di eventi elementari. Si dice che un evento E si verifica se il risultato osservato
\end{flushleft}


\begin{flushleft}
dell'esperimento casuale \`{e} un esito appartenente a E.
\end{flushleft}


\begin{flushleft}
Un evento \`{e} un elemento di una famiglia di insiemi, quindi \`{e} lui stesso un insieme. Questo
\end{flushleft}


\begin{flushleft}
pu\`{o} alle volte causare un po' di confusione di terminologia con uno scontro tra elementi e insiemi.
\end{flushleft}


\begin{flushleft}
\`{E} per questo che chiamiamo esiti gli elementi di $\Omega$, eventi gli elementi di ℱ e universo l'insieme $\Omega$.
\end{flushleft}


\begin{flushleft}
Esempio 2.16. Prendiamo un insieme $\Omega$ = \{a, b, c, d\}, e su di esso la tribù ℱ = \{$\emptyset$, \{a\}, \{d\}, \{a, d\}, \{b,
\end{flushleft}


\begin{flushleft}
c\}, \{a, b, c\}, \{b, c, d\}, $\Omega$\}. Allora A = \{a\} \`{e} un evento, in particolare un evento elementare, ma \`{e} anche
\end{flushleft}


\begin{flushleft}
un sottoinsieme di $\Omega$, quindi un insieme, e un elemento di ℱ. A sua volta E = \{a, b, c\} \`{e} un evento,
\end{flushleft}


\begin{flushleft}
ma non elementare, mentre N = \{b\} non \`{e} un evento, poich\'{e} non compare in ℱ.
\end{flushleft}





\begin{flushleft}
\newpage
2.2 SPAZI DI PROBABILIT\`{A}
\end{flushleft}





31





\begin{flushleft}
Non sempre, come vedremo, viene assegnata esplicitamente una tribù e non sempre abbiamo
\end{flushleft}


\begin{flushleft}
una sola scelta possibile, anche quando sappiamo quali eventi vogliamo che siano al suo interno.
\end{flushleft}


\begin{flushleft}
In questi casi pu\`{o} venir comoda la seguente definizione.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.17. Data una famiglia 𝒢 di sottoinsiemi di $\Omega$, definiamo 𝜎(𝒢), detta tribù generata da
\end{flushleft}


\begin{flushleft}
𝒢, la più piccola tribù che contiene 𝒢, cio\`{e}
\end{flushleft}


\begin{flushleft}
𝜎(𝒢) =
\end{flushleft}





\begin{flushleft}
ℱ : ℱ \`{e} una tribù e 𝒢 $\subseteq$ ℱ .
\end{flushleft}





\begin{flushleft}
Se vogliamo, questo \`{e} un modo per semplificarci la vita: sappiamo quali sono gli eventi che
\end{flushleft}


\begin{flushleft}
vogliamo avere e generiamo a partire da essi una famiglia che li contenga e che sia anche una
\end{flushleft}


\begin{flushleft}
tribù. Per farlo possiamo pensare di aggiungere a 𝒢 i complementari di insiemi di 𝒢, poi unioni
\end{flushleft}


\begin{flushleft}
numerabili, poi ancora complementari e così via. Prendiamo la più piccola possibile perch\'{e} non
\end{flushleft}


\begin{flushleft}
vogliamo doverci occupare di più eventi di quanto non sia strettamente necessario. Il perch\'{e} di
\end{flushleft}


\begin{flushleft}
questo essere un po' avari, gi\`{a} menzionato in precedenza, sar\`{a} chiaro nella prossima sezione.
\end{flushleft}


1





1





\begin{flushleft}
Problema 2.1. Consideriamo $\Omega$ = ℝ ed ℱ = \{0, 1\}, 2n+1 , 2n , n $\in$ ℕ . Possiamo osservare che ℱ \`{e} una famiglia di
\end{flushleft}


\begin{flushleft}
sottoinsiemi di $\Omega$, ma non \`{e} n\'{e} un'algebra n\'{e} una tribù. Quali dei seguenti insiemi sono nella tribù 𝜎(ℱ) generata da
\end{flushleft}


\begin{flushleft}
ℱ?
\end{flushleft}


1. \{0\}





2. \{1\}





5. [0, 1]





6.





9. 0,





1


2





1


,1


4





3.





1


2





4.


1





7. 0, 2





8.





1


3


1


,1


4





10. (0, 1)





\begin{flushleft}
Soluzione. TBA
\end{flushleft}





\begin{flushleft}
2.2. SPAZI DI PROBABILIT\`{A}
\end{flushleft}


\begin{flushleft}
Abbiamo fatto tutto questo lavoro di teoria degli insiemi per poter introdurre le prossime tre definizioni sulla probabilit\`{a}. Cominciamo mettendo assieme due oggetti che abbiamo gi\`{a} definito.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.18. Dati un insieme $\Omega$ e una2.6 tribù ℱ su di esso, la coppia ($\Omega$, ℱ) prende il nome di
\end{flushleft}


\begin{flushleft}
spazio probabilizzabile.
\end{flushleft}


\begin{flushleft}
Il nome ci suggerisce che siamo quasi arrivati al nostro obiettivo: abbiamo le fondamenta
\end{flushleft}


\begin{flushleft}
su cui costruire o definire la probabilit\`{a}, anche se siamo ancora a una probabilit\`{a} {``}in potenza''.
\end{flushleft}


\begin{flushleft}
Ricordiamo che vogliamo far sì che ogni evento abbia una probabilit\`{a}, quindi dobbiamo definire una funzione che abbia come dominio ℱ.
\end{flushleft}


\begin{flushleft}
Qui entra in gioco Kolmogorov, che ci dice quali sono le propriet\`{a} che deve soddisfare una
\end{flushleft}


\begin{flushleft}
funzione per essere accettabile come funzione di probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.19. Assegnato uno spazio probabilizzabile ($\Omega$, ℱ), una funzione P: ℱ $\rightarrow$ ℝ si dice funzione o misura2.7 di probabilit\`{a} se soddisfa le seguenti propriet\`{a} (dette assiomi di Kolmogorov):
\end{flushleft}


\begin{flushleft}
1. per ogni evento E, P(E) ⩾ 0 (non negativit\`{a});
\end{flushleft}


\begin{flushleft}
2. P($\Omega$) = 1 (normalizzazione);
\end{flushleft}


\begin{flushleft}
3. data una famiglia numerabile (E i)+$\infty$
\end{flushleft}


\begin{flushleft}
i=1 di eventi a due a due disgiunti (cio\`{e} E i $\cap$ E j = $\emptyset$ se i $\neq$ j) allora
\end{flushleft}


+$\infty$


\begin{flushleft}
P(⋃+$\infty$
\end{flushleft}


\begin{flushleft}
E
\end{flushleft}


)


=


\begin{flushleft}
P(E
\end{flushleft}


)


\begin{flushleft}
(𝜎-additivit\`{a}).
\end{flushleft}


∑


\begin{flushleft}
i
\end{flushleft}


\begin{flushleft}
i=1 i
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Il valore P(E) della funzione in un evento E si dice probabilit\`{a} di E.
\end{flushleft}





\begin{flushleft}
2.6. Abbiamo gi\`{a} visto, ma lo sottolineiamo ancora una volta, che dato $\Omega$, in genere ℱ non \`{e} unica. Scegliere una
\end{flushleft}


\begin{flushleft}
particolare tribù tra quelle disponibili \`{e} una scelta di modello: a priori non esiste una scelta giusta, dipende dal problema
\end{flushleft}


\begin{flushleft}
che stiamo considerando. Di volta in volta, sceglieremo ℱ in modo che sia adatta ai nostri scopi.
\end{flushleft}


\begin{flushleft}
2.7. Il nome misura viene dal fatto che questa funzione misura la grandezza dell'evento in termini di probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Vedremo più avanti che prendendo come $\Omega$ l'intervallo [0, 1], una particolare misura di probabilit\`{a} \`{e} quella che restituisce
\end{flushleft}


\begin{flushleft}
la lunghezza dei segmenti, cio\`{e} la loro misura.
\end{flushleft}





\newpage
32





\begin{flushleft}
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Possiamo considerare una versione finita del terzo assioma: se abbiamo una famiglia finita
\end{flushleft}


\begin{flushleft}
di eventi disgiunti (E i)ni=1, allora P(⋃ ni=1 Ei) = ∑ni=1 P(E i). Chiaramente il terzo assioma implica
\end{flushleft}


\begin{flushleft}
questa versione finita, ma in genere non vale il viceversa, a meno che ℱ non sia un'algebra finita,
\end{flushleft}


\begin{flushleft}
cosa che sappiamo essere vera ogni volta che $\Omega$ \`{e} finito.
\end{flushleft}


\begin{flushleft}
Possiamo ora dare la definizione cui stavamo puntando dall'inizio di questo capitolo.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 2.20. Siano $\Omega$ un insieme, ℱ una tribù su $\Omega$ e P una funzione di probabilit\`{a} su ℱ. La tripla
\end{flushleft}


\begin{flushleft}
($\Omega$, ℱ, P) prende il nome di spazio di probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Esempio 2.21. Se prendiamo $\Omega$ = \{0, 1\}, ℱ = \{$\emptyset$, \{0\}, \{1\}, \{0, 1\}\} = 𝒫($\Omega$) e P tale che
\end{flushleft}


\begin{flushleft}
P($\emptyset$) = 0,
\end{flushleft}





1


\begin{flushleft}
P(\{0\}) = P(\{1\}) = ,
\end{flushleft}


2





\begin{flushleft}
P(\{0, 1\}) = 1,
\end{flushleft}





\begin{flushleft}
abbiamo uno spazio di probabilit\`{a}. Possiamo mostrare che tutte le propriet\`{a} sono soddisfatte: ℱ
\end{flushleft}


\begin{flushleft}
\`{e} una tribù, P(E) ⩾ 0 per ogni E $\in$ ℱ, P($\Omega$) = 1, e P(\{0\}) + P(\{1\}) = 1 = P(\{0, 1\}).
\end{flushleft}


\begin{flushleft}
In particolare se identifichiamo 0 con ``testa'' e 1 con ``croce'', questo \`{e} un modo di rappresentare il lancio di una moneta bilanciata come spazio di probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Esempio 2.22. Prendiamo ora $\Omega$ = \{$\clubsuit$, $\diamondsuit$, $\heartsuit$, $\spadesuit$\} e ℱ = 𝒫($\Omega$). Della probabilit\`{a} P sappiamo quanto
\end{flushleft}


\begin{flushleft}
segue:
\end{flushleft}


\begin{flushleft}
P($\emptyset$) =0 P(\{$\clubsuit$\}) =P(\{$\diamondsuit$\}) =
\end{flushleft}


\begin{flushleft}
P(\{$\spadesuit$\}) =q P(\{$\heartsuit$\}) =p.
\end{flushleft}





1


7


\begin{flushleft}
P(\{$\clubsuit$, $\diamondsuit$, $\spadesuit$\}) =
\end{flushleft}


3


9





\begin{flushleft}
Possiamo determinare p e q tali per cui P pu\`{o} essere una probabilit\`{a}?
\end{flushleft}


\begin{flushleft}
Se vogliamo che P sia una probabilit\`{a}, P($\Omega$) = 1 e quindi
\end{flushleft}


7


\begin{flushleft}
1 = P($\Omega$) = P (\{$\clubsuit$, $\diamondsuit$, $\spadesuit$\} $\cup$ \{$\heartsuit$\}) = P(\{$\clubsuit$, $\diamondsuit$, $\spadesuit$\}) + P(\{$\heartsuit$\}) = + p,
\end{flushleft}


9


\begin{flushleft}
da cui p = 9 . A questo punto possiamo ricavare q, in modo del tutto simile,
\end{flushleft}


2





\begin{flushleft}
1 = P($\Omega$) = P (\{$\clubsuit$\} $\cup$ \{$\diamondsuit$\} $\cup$ \{$\heartsuit$\} $\cup$ \{$\spadesuit$\})
\end{flushleft}


\begin{flushleft}
= P(\{$\clubsuit$\}) + P(\{$\diamondsuit$\}) + P(\{$\heartsuit$\}) + P(\{$\spadesuit$\})
\end{flushleft}


1 1 2


\begin{flushleft}
= + + +q
\end{flushleft}


3 3 9


\begin{flushleft}
da cui q = 3 $-$ 9 = 9 .
\end{flushleft}


\begin{flushleft}
Perch\'{e} questo ci dice che P pu\`{o} essere una probabilit\`{a} (e non che P \`{e} una probabilit\`{a})? Perch\'{e}
\end{flushleft}


2


\begin{flushleft}
non sappiamo quanto valga, ad esempio, P(\{$\clubsuit$, $\diamondsuit$\}). Se fosse P(\{$\clubsuit$, $\diamondsuit$\}) $\neq$ 3 , P non potrebbe essere
\end{flushleft}


\begin{flushleft}
una probabilit\`{a}, perch\'{e} avremmo una contraddizione con il terzo assioma.
\end{flushleft}


1





2





1





\begin{flushleft}
Prima di continuare, vale la pena fare un'osservazione: gli assiomi di Kolmogorov non ci
\end{flushleft}


\begin{flushleft}
dicono come definire la probabilit\`{a} sul nostro spazio probabilizzabile, ma ci permettono di dire
\end{flushleft}


\begin{flushleft}
se una funzione definita su ($\Omega$, ℱ) sia o meno una misura di probabilit\`{a}. C'\`{e} un buon motivo
\end{flushleft}


\begin{flushleft}
per cui gli assiomi non ci garantiscono l'unicit\`{a} della probabilit\`{a}: questa unicit\`{a} non c'\`{e}! Una
\end{flushleft}


\begin{flushleft}
volta fissato lo spazio probabilizzabile, possiamo definire più probabilit\`{a} non equivalenti tra loro.
\end{flushleft}





\begin{flushleft}
Esempio 2.23. Prendiamo $\Omega$ = \{0, 1\}, ℱ = 𝒫($\Omega$), cio\`{e} lo stesso spazio probabilizzabile visto
\end{flushleft}


\begin{flushleft}
nell'Esempio 2.21. Possiamo definire Q: ℱ $\rightarrow$ [0, 1] come segue:
\end{flushleft}


\begin{flushleft}
Q($\emptyset$) = 0,
\end{flushleft}





3


\begin{flushleft}
Q(\{0\}) = ,
\end{flushleft}


5





2


\begin{flushleft}
Q(\{1\}) = ,
\end{flushleft}


5





\begin{flushleft}
Q(\{0, 1\}) = 1.
\end{flushleft}





\begin{flushleft}
Anche la funzione Q appena definita \`{e} una probabilit\`{a}, ma \`{e} diversa dalla probabilit\`{a} P vista
\end{flushleft}


\begin{flushleft}
prima. In particolare, possiamo vedere questo spazio di probabilit\`{a} come un modello matematico
\end{flushleft}


\begin{flushleft}
per una moneta sbilanciata in cui la ``testa'' \`{e} una volta e mezza più probabile della ``croce''.
\end{flushleft}





\begin{flushleft}
\newpage
2.3 PROPRIET\`{A} DELLA (MISURA DI) PROBABILIT\`{A}
\end{flushleft}





33





\begin{flushleft}
Quello che abbiamo visto in quest'ultimo esempio non \`{e} un caso isolato: vedremo più avanti
\end{flushleft}


\begin{flushleft}
come costruire probabilit\`{a} in modo che soddisfino gli assiomi di Kolmogorov, ma siano anche
\end{flushleft}


\begin{flushleft}
buoni modelli per i problemi che considereremo volta per volta.
\end{flushleft}


\begin{flushleft}
Lezione 3
\end{flushleft}





\begin{flushleft}
2.3. PROPRIET\`{A} DELLA (MISURA DI) PROBABILIT\`{A}
\end{flushleft}


\begin{flushleft}
Esempio 2.24. Vogliamo descrivere un esperimento aleatorio in cui un individuo lancia delle
\end{flushleft}


\begin{flushleft}
freccette ad un bersaglio costituito da tre cerchi concentrici, di raggi r, 2 r e 3 r. A seconda della
\end{flushleft}


\begin{flushleft}
corona circolare che la freccia colpisce, il punteggio \`{e}, dall'interno all'esterno, 25, 10 e 5 punti.
\end{flushleft}


5


10





25





\begin{flushleft}
Figura 2.1. Freccette
\end{flushleft}





\begin{flushleft}
Un possibile modo di farlo \`{e} il seguente: scegliamo $\Omega$ = \{1, 2, 3\}, con le tre aree indicizzate dal
\end{flushleft}


\begin{flushleft}
loro raggio (o meglio dal rapporto tra il loro raggio ed r. Osserviamo che con questa scelta stiamo
\end{flushleft}


\begin{flushleft}
escludendo l'eventualit\`{a} che la freccetta manchi il bersaglio (o, con una terminologia che vedremo
\end{flushleft}


\begin{flushleft}
in seguito, stiamo condizionando all'aver colpito il bersaglio). Con questa scelta, come tribù \`{e}
\end{flushleft}


\begin{flushleft}
ragionevole scegliere ℱ = 𝜎\{\{1\}, \{2\}, \{3\}\} = 𝒫($\Omega$).
\end{flushleft}


\begin{flushleft}
Arriviamo alla scelta della probabilit\`{a} P: se non sappiamo nulla delle abilit\`{a} di lancio del giocatore, una possibile descrizione dell'esperimento \`{e} ritenere la probabilit\`{a} di colpire una delle tre
\end{flushleft}


\begin{flushleft}
aree proporzionale alla superficie dell'area stessa. Abbiamo allora
\end{flushleft}





\begin{flushleft}
\{\{\{ P(\{1\}) =
\end{flushleft}


\begin{flushleft}
\{\{ P(\{2\}) =
\end{flushleft}


\{\{


\begin{flushleft}
\{\{ P(\{3\}) =
\end{flushleft}





\begin{flushleft}
𝜋r2
\end{flushleft}


\begin{flushleft}
𝜋 (3 r)2
\end{flushleft}





1





=9





\begin{flushleft}
𝜋 (2 r)2 $-$ 𝜋 r 2
\end{flushleft}


\begin{flushleft}
𝜋 (3 r)2
\end{flushleft}





1





=3





\begin{flushleft}
𝜋 (3 r)2 $-$ 𝜋 (2 r)2
\end{flushleft}


\begin{flushleft}
𝜋 (3 r)2
\end{flushleft}





5





=9





\begin{flushleft}
Possiamo osservare che queste probabilit\`{a} non dipendono dal raggio e quindi dalla superficie
\end{flushleft}


\begin{flushleft}
delle aree, ma solo dai rapporti tra le superfici.
\end{flushleft}


\begin{flushleft}
Inoltre, la probabilit\`{a} di colpire l'area centrale \`{e} 5 volte più piccola di quella di colpire la corona
\end{flushleft}


\begin{flushleft}
circolare più esterna, quindi \`{e} sensato che il punteggio sia 5 volte maggiore, mentre per la corona
\end{flushleft}


\begin{flushleft}
circolare centrale un punteggio più equo (nel senso di proporzionale alla probabilit\`{a}) sarebbe 8.3̄.
\end{flushleft}


\begin{flushleft}
Torneremo a parlare di {``}equit\`{a}'' più avanti nel corso, quando parleremo di speranza matematica.
\end{flushleft}


\begin{flushleft}
Quale potrebbe essere una scelta diversa per $\Omega$? Di quali altri fattori potremmo tenere conto
\end{flushleft}


\begin{flushleft}
nello scegliere P? Quali limitazioni imposte dalle nostre scelte di modello sono quelle di cui vorremmo fare a meno?
\end{flushleft}


\begin{flushleft}
Le propriet\`{a} viste sopra sono quelle essenziali per caratterizzare una probabilit\`{a}. Tuttavia
\end{flushleft}


\begin{flushleft}
ce ne sono molte altre, che possiamo dedurre da quelle enunciate nella Definizione 2.19 e dalle
\end{flushleft}


\begin{flushleft}
propriet\`{a} delle tribù. Nelle prossime pagine ne vedremo un po', alcune ovvie, altre meno. Tutte
\end{flushleft}


\begin{flushleft}
quante, per\`{o}, importanti per manipolare le probabilit\`{a}, come vedremo negli esempi.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.25. La probabilit\`{a} dell'evento $\emptyset$ \`{e} sempre uguale a 0.
\end{flushleft}





\newpage
34





\begin{flushleft}
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Dimostrazione. Osserviamo che $\Omega$ $\cup$ $\emptyset$ = $\Omega$ e che allo stesso tempo $\Omega$ $\cap$ $\emptyset$ = $\emptyset$. Allora abbiamo
\end{flushleft}


\begin{flushleft}
1 = P($\Omega$) = P ($\Omega$ $\cup$ $\emptyset$) = P($\Omega$) + P($\emptyset$) = 1 + P($\emptyset$),
\end{flushleft}


\begin{flushleft}
in cui la prima e la quarta uguaglianza seguono dal secondo assioma nella Definizione 2.19 e la
\end{flushleft}


\begin{flushleft}
terza identit\`{a} dal terzo assioma in versione finita. Da questa identit\`{a} ricaviamo P($\emptyset$) = 0.
\end{flushleft}


□


\begin{flushleft}
PROPOSIZIONE 2.26. Se E $\in$ ℱ, la probabilit\`{a} del suo complementare E c \`{e} P(E c) = 1 $-$ P(E).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Come prima cosa, sappiamo che P \`{e} definita in E c, poich\'{e} ℱ \`{e} una tribù ed \`{e}
\end{flushleft}


\begin{flushleft}
chiusa rispetto all'operazione di complementare. Inoltre, possiamo osservare che E $\cup$ E c = $\Omega$ e che
\end{flushleft}


\begin{flushleft}
E $\cap$ E c = $\emptyset$, quindi
\end{flushleft}


\begin{flushleft}
1 = P($\Omega$) = P (E $\cup$ E c) = P(E) + P(E c),
\end{flushleft}


\begin{flushleft}
in cui l'ultima uguaglianza segue dal terzo assioma (in versione finita) della Definizione 2.19. □
\end{flushleft}


\begin{flushleft}
Questa \`{e} forse la propriet\`{a} della probabilit\`{a} che sfrutteremo più di tutte nello svolgere esercizi e problemi: molte volte infatti ci verranno forniti dati incompleti, che potremo ricostruire in
\end{flushleft}


\begin{flushleft}
questo modo. Capiter\`{a} spesso che il calcolo diretto della probabilit\`{a} di un evento sia molto complicato (ad esempio perch\'{e} ci sono parecchi casi possibili), mentre passando al complementare i
\end{flushleft}


\begin{flushleft}
conti si semplificano notevolmente.
\end{flushleft}


\begin{flushleft}
Esempio 2.27. In un ``Gratta e vinci''2.8 ci sono premi di prima e seconda fascia. La probabilit\`{a} di
\end{flushleft}


1


1


\begin{flushleft}
vincere un premio di prima fascia \`{e} 1000000 , quella di vincere un premio di seconda fascia \`{e} 100 .
\end{flushleft}


\begin{flushleft}
Con che probabilit\`{a}, giocando, non si vince nulla?
\end{flushleft}


\begin{flushleft}
Le due fasce cui appartengono i premi sono distinte tra loro, quindi la probabilit\`{a} di vincere
\end{flushleft}


1


1


10001


\begin{flushleft}
qualcosa \`{e} la somma delle due probabilit\`{a} assegnate, cio\`{e} 1000000 + 100 = 1000000 . Allo stesso tempo,
\end{flushleft}


\begin{flushleft}
non vincere nulla \`{e} l'evento complementare al vincere qualcosa, quindi la sua probabilit\`{a} \`{e}
\end{flushleft}


1 $-$ 1000000 = 1000000 $\approx$ 99\%.


10001





989999





\begin{flushleft}
Vediamo un'altra propriet\`{a}, che prende il nome di monotonia della probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.28. Siano E, F due eventi in ℱ tali che E $\subseteq$F. Allora vale la disuguaglianza P(E) ⩽ P(F).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Possiamo riscrivere F come
\end{flushleft}


\begin{flushleft}
F = (E $\cap$ F) $\cup$ (E c $\cap$ F) = E $\cup$ (E c $\cap$ F),
\end{flushleft}


\begin{flushleft}
che \`{e} un'unione disgiunta. A questo punto
\end{flushleft}


\begin{flushleft}
P(F) = P(E) + P (E c $\cap$ F) ⩾ P(E),
\end{flushleft}


\begin{flushleft}
dove per l'uguaglianza sfruttiamo il terzo assioma (in versione finita) della Definizione 2.19, per
\end{flushleft}


\begin{flushleft}
la disuguaglianza la non negativit\`{a} del primo assioma.
\end{flushleft}


□


\begin{flushleft}
Questo risultato dice formalmente quanto avevamo visto nell'Esempio 1, ossia che un evento
\end{flushleft}


\begin{flushleft}
che \`{e} un caso particolare di un altro ha necessariamente probabilit\`{a} minore o uguale. Tornando
\end{flushleft}


\begin{flushleft}
alle propriet\`{a}, una conseguenza della monotonia della probabilit\`{a} \`{e} la seguente.
\end{flushleft}


\begin{flushleft}
COROLLARIO 2.29. L'immagine della funzione di probabilit\`{a} \`{e} contenuta nell'intervallo unitario [0, 1].
\end{flushleft}


\begin{flushleft}
2.8. Le probabilit\`{a} usate in questo esempio non sono quelle vere, principalmente perch\'{e} ``Gratta e vinci'' comprende
\end{flushleft}


\begin{flushleft}
un'ampia famiglia di lotterie istantanee, che cambia spesso e con premi in numero e taglia variabile. Sono comunque
\end{flushleft}


\begin{flushleft}
probabilit\`{a} di un ordine di grandezza non dissimile da quello vero. Per chi volesse approfondire, le coordinate di riferimento sono quelle del sito dell'agenzia Dogane e Monopoli, dove per legge sono mostrate le probabilit\`{a} dei vari premi
\end{flushleft}


\begin{flushleft}
nelle varie lotterie: https://www.adm.gov.it/portale/monopoli/giochi/lotterie/lotterie\_istantanee/
\end{flushleft}


\begin{flushleft}
lot\_ist\_note. Sempre su questo tema e in generale su quello dei giochi d'azzardo e della probabilit\`{a} a essi collegata, una lettura divertente e interessante \`{e} Fate il nostro gioco.
\end{flushleft}





\begin{flushleft}
\newpage
2.3 PROPRIET\`{A} DELLA (MISURA DI) PROBABILIT\`{A}
\end{flushleft}





35





\begin{flushleft}
Dimostrazione. Segue immediatamente dal fatto che, per ogni evento E $\in$ ℱ, $\emptyset$ $\subseteq$ E $\subseteq$ $\Omega$ e dalla
\end{flushleft}


\begin{flushleft}
monotonia.
\end{flushleft}


□


\begin{flushleft}
Vediamo ora qualcosa che apparentemente abbiamo gi\`{a} incontrato: la probabilit\`{a} dell'unione
\end{flushleft}


\begin{flushleft}
di due eventi.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.30. Siano E, F due eventi in ℱ, allora la probabilit\`{a} della loro unione \`{e}
\end{flushleft}


\begin{flushleft}
P (E $\cup$ F) = P(E) + P(F) $-$ P (E $\cap$ F).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Come nelle dimostrazioni precedenti vogliamo andare a riscrivere questo insieme
\end{flushleft}


\begin{flushleft}
come unione disgiunta. Per farlo, osserviamo che E $\cup$ F = E ∖ F $\cup$ F e che E ∖ F $\cap$ F = $\emptyset$. Allora
\end{flushleft}





\begin{flushleft}
P (E $\cup$ F) = P (E ∖ F) + P(F).
\end{flushleft}


\begin{flushleft}
Tuttavia, non sappiamo quale sia il valore2.9 di P (E ∖ F). Possiamo per\`{o} riscrivere E come E =
\end{flushleft}


\begin{flushleft}
(E $\cap$ F) $\cup$ (E ∖ F), notando che si tratta di un'unione disgiunta, quindi P(E) = P (E $\cap$ F) + P (E ∖ F).
\end{flushleft}


\begin{flushleft}
A questo punto dobbiamo solo andare a sostituire per ottenere la tesi.
\end{flushleft}


□


\begin{flushleft}
Confrontiamo quanto visto ora e l'enunciato in versione finita del terzo assioma: in quest'ultimo
\end{flushleft}


\begin{flushleft}
la probabilit\`{a} dell'unione era la probabilit\`{a} che accadesse esattamente uno dei due eventi (poich\'{e}
\end{flushleft}


\begin{flushleft}
erano mutualmente esclusivi). Qui invece abbiamo una vera unione: stiamo chiedendo che almeno
\end{flushleft}


\begin{flushleft}
uno degli eventi si sia verificato e contempliamo anche la possibilit\`{a} che si siano verificati entrambi.
\end{flushleft}


\begin{flushleft}
In analogia con il principio di inclusione ed esclusione, togliamo la probabilit\`{a} dell'evento intersezione, cio\`{e} {``}sono avvenuti entrambi'', dal totale, per non contarla due volte.
\end{flushleft}





\begin{flushleft}
Esempio 2.31. In un videogioco, la probabilit\`{a} di trovare un oggetto raro in uno dei contenitori
\end{flushleft}


\begin{flushleft}
posti in giro \`{e} del 4\%, mentre quella di trovare un oggetto magico \`{e} del 12\%. La probabilit\`{a} di
\end{flushleft}


\begin{flushleft}
trovare un oggetto raro che sia anche magico \`{e} dell'1\%. Qual \`{e} la probabilit\`{a} di trovare un oggetto
\end{flushleft}


\begin{flushleft}
che sia magico o raro?
\end{flushleft}


\begin{flushleft}
Dobbiamo sommare la probabilit\`{a} di avere un oggetto magico e quella di avere un oggetto
\end{flushleft}


\begin{flushleft}
raro, per un totale del 16\%. Tuttavia, abbiamo contato due volte la probabilit\`{a} di avere un oggetto
\end{flushleft}


\begin{flushleft}
che sia contemporaneamente magico e raro, uguale all'1\%. Dobbiamo quindi sottrarre, ottenendo
\end{flushleft}


15\%.


\begin{flushleft}
Esempio 2.32. In una scuola, la probabilit\`{a} che una studentessa o uno studente abbia in pagella
\end{flushleft}


17


5


\begin{flushleft}
un'insufficienza in matematica \`{e} 24 , che ne abbia una in inglese \`{e} 6 . Quanto vale, come minimo,
\end{flushleft}


\begin{flushleft}
la probabilit\`{a} di avere un'insufficienza in entrambe le materie?
\end{flushleft}


\begin{flushleft}
Questo problema sembra diverso da quello precedente, ma in realt\`{a} possiamo risolverlo in
\end{flushleft}


17


5


37


\begin{flushleft}
modo molto simile. Cominciamo sommando le due probabilit\`{a} che conosciamo: 24 + 6 = 24 . Osserviamo che questa quantit\`{a} \`{e} maggiore di 1.
\end{flushleft}


\begin{flushleft}
Non abbiamo ancora scritto nulla che coinvolga la probabilit\`{a} dell'intersezione, che chiamiamo
\end{flushleft}


\begin{flushleft}
p ed \`{e} la quantit\`{a} che vogliamo calcolare. Sappiamo per\`{o} che la probabilit\`{a} di avere un'insuf17
\end{flushleft}


5


37


\begin{flushleft}
ficienza in almeno una materia \`{e} 24 + 6 $-$ p = 24 $-$ p. Affinch\'{e} sia una probabilit\`{a}, questa quantit\`{a}
\end{flushleft}


\begin{flushleft}
deve essere minore o uguale a 1, cio\`{e}
\end{flushleft}





37


24





\begin{flushleft}
$-$ p ⩽ 1, da cui
\end{flushleft}





37


24





\begin{flushleft}
$-$ 1 ⩽ p, quindi p ⩾ 24 .
\end{flushleft}


13





\begin{flushleft}
Abbiamo una conseguenza immediata della Proposizione 2.30.
\end{flushleft}


\begin{flushleft}
COROLLARIO 2.33. Possiamo maggiorare la probabilit\`{a} dell'unione di due eventi con la somma delle probabilit\`{a} dei due eventi:
\end{flushleft}


\begin{flushleft}
P (E $\cup$ F) ⩽ P(E) + P(F).
\end{flushleft}


\begin{flushleft}
2.9. Anche se sappiamo che \`{e} definita, poich\'{e} E ∖ F = E $\cap$ F c $\in$ ℱ.
\end{flushleft}





\newpage
36





\begin{flushleft}
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Questa propriet\`{a} prende il nome di sub-additivit\`{a}.
\end{flushleft}


\begin{flushleft}
Riguardiamo la Proposizione 2.30 e il parallelo fatto col principio di inclusione-esclusione.
\end{flushleft}


\begin{flushleft}
Non ci sorprende, a questo punto, che come il principio combinatorio vale per un qualunque
\end{flushleft}


\begin{flushleft}
numero finito di insiemi, la Proposizione 2.30 possa essere estesa a un generico numero n di
\end{flushleft}


\begin{flushleft}
eventi.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.34. Sia (E i)ni=1 una famiglia finita di eventi. Allora
\end{flushleft}


\begin{flushleft}
P(
\end{flushleft}


((





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
E)
\end{flushleft}


)) =





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
P(Ei) $-$
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
P (Ei $\cap$ E j) + ⋅ ⋅ ⋅ + ($-$1)
\end{flushleft}





\begin{flushleft}
n+1
\end{flushleft}





\begin{flushleft}
P(
\end{flushleft}


((





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
i$<$ j
\end{flushleft}





))


)





\begin{flushleft}
Ei .
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





(2.1)





\begin{flushleft}
Possiamo generalizzare a questo caso il Corollario 2.33.
\end{flushleft}


\begin{flushleft}
COROLLARIO 2.35. \`{E} possibile maggiorare la probabilit\`{a} di un'unione finita di eventi con la somma delle
\end{flushleft}


\begin{flushleft}
probabilit\`{a}:
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





((


(





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





))


)





\begin{flushleft}
Ei ⩽
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
P(Ei).
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Possiamo in realt\`{a} dare un risultato più raffinato, ripensando ancora una volta a quanto detto
\end{flushleft}


\begin{flushleft}
per il principio di inclusione-esclusione.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.36. La probabilit\`{a} dell'unione di un numero finito di eventi pu\`{o} essere stimata dall'alto
\end{flushleft}


\begin{flushleft}
troncando il secondo membro della (2.1) in modo che il primo termine che tralasciamo sia di segno negativo,
\end{flushleft}


\begin{flushleft}
oppure dal basso, se il primo termine che ignoriamo \`{e} di segno positivo. In particolare
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
P(E i) $-$
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
P (E $\cap$ E ) ⩽ P(
\end{flushleft}


((


\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i$<$ j
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
j
\end{flushleft}





\begin{flushleft}
E)
\end{flushleft}


)) ⩽





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
P(Ei).
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Queste disuguaglianze prendono il nome di disuguaglianze di Bonferroni2.10.
\end{flushleft}


\begin{flushleft}
A differenza di quanto visto per la combinatoria, per\`{o}, per la probabilit\`{a} abbiamo anche il
\end{flushleft}


\begin{flushleft}
caso delle unioni numerabili: abbiamo stabilito nella definizione di tribù che tali unioni di eventi
\end{flushleft}


\begin{flushleft}
fossero esse stesse eventi. Un risultato elementare in questo contesto \`{e} la generalizzazione del
\end{flushleft}


\begin{flushleft}
Corollario 2.35 al caso numerabile, detta anche disuguaglianza di Boole2.11.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 2.37. Data una famiglia numerabile di eventi (E i)+$\infty$
\end{flushleft}


\begin{flushleft}
i=1 , possiamo stimare dall'alto la probabilit\`{a} della sua unione con la somma delle probabilit\`{a} dei singoli eventi:
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





((


(





+$\infty$





))


)





+$\infty$





\begin{flushleft}
Ei ⩽
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
P(Ei).
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Questo significa che la probabilit\`{a} \`{e} 𝜎-sub-additiva.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Per l'unione numerabile al momento abbiamo solo l'assioma 3, quindi dobbiamo
\end{flushleft}


\begin{flushleft}
trovare un modo di riscrivere il problema in termini di unione di eventi disgiunti. Possiamo farlo
\end{flushleft}


\begin{flushleft}
nel modo seguente:
\end{flushleft}


\begin{flushleft}
F1 = E 1
\end{flushleft}





\{\{


\begin{flushleft}
\{\{ F = E ∖
\end{flushleft}


\{


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
2.10. Carlo Emilio Bonferroni (1892 -- 1960).
\end{flushleft}


\begin{flushleft}
2.11. George Boole (1815 -- 1864).
\end{flushleft}





\begin{flushleft}
k $-$1
\end{flushleft}





\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
F i,
\end{flushleft}





\begin{flushleft}
k ⩾ 2.
\end{flushleft}





\begin{flushleft}
\newpage
2.4 PROBLEMI
\end{flushleft}





37





\begin{flushleft}
In questo modo gli eventi F i sono a due a due disgiunti e la loro unione coincide con l'unione degli
\end{flushleft}


\begin{flushleft}
E i. In più, per ogni k $\in$ ℕ, F k $\subseteq$ Ek , quindi possiamo sfruttare la monotonia:
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





((


(





+$\infty$





))


)





\begin{flushleft}
Ei = P
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





((


(





+$\infty$


\begin{flushleft}
i=1
\end{flushleft}





+$\infty$





))


)





\begin{flushleft}
Fi =
\end{flushleft}





+$\infty$





\begin{flushleft}
P(Fi) ⩽
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
P(E i),
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
in cui abbiamo usato per seconda uguaglianza il terzo assioma nella Definizione 2.19 e per la
\end{flushleft}


\begin{flushleft}
disuguaglianza la Proposizione 2.28.
\end{flushleft}


□





\begin{flushleft}
2.4. PROBLEMI
\end{flushleft}


\begin{flushleft}
Problema 2.2. Lanciando un dado a 12 facce in cui ogni faccia pari esce con probabilit\`{a}
\end{flushleft}


1


\begin{flushleft}
probabilit\`{a} 9 , con che probabilit\`{a} esce un multiplo di 3 o di 7?
\end{flushleft}





1


18





\begin{flushleft}
e ogni faccia dispari con
\end{flushleft}





\begin{flushleft}
Soluzione. I multipli di 3 che compaiono sul dado sono 3, 6, 9 e 12, mentre di multipli di 7 c'\`{e} solo il 7. Non ci sono
\end{flushleft}


\begin{flushleft}
numeri che siano multipli di 3 e 7, quindi non ne contiamo alcuno due volte. Di questi numeri, 3 sono dispari e 2 sono
\end{flushleft}


\begin{flushleft}
pari, quindi la probabilit\`{a} cercata \`{e}
\end{flushleft}


1


1 4


3⋅ +2⋅ = .


9


18 9


\begin{flushleft}
Problema 2.3. In una particolare estrazione del Lotto matematico su tutti i numeri naturali, gli infiniti numeri non
\end{flushleft}


\begin{flushleft}
escono tutti con la medesima probabilit\`{a}. Sui numeri dispari abbiamo un po' di informazioni: 1 esce con probabilit\`{a}
\end{flushleft}


1


,


3





1





1





1





\begin{flushleft}
3 con probabilit\`{a} 9 , 5 con probabilit\`{a} 27 e così via. In generale il k-esimo numero dispari esce con probabilit\`{a} 3k . La
\end{flushleft}


\begin{flushleft}
probabilit\`{a} che esca un numero pari, poi, \`{e} doppia rispetto alla probabilit\`{a} che esca un numero pari positivo. Con che
\end{flushleft}


\begin{flushleft}
probabilit\`{a} esce 0?
\end{flushleft}


\begin{flushleft}
Soluzione. Abbiamo una bella collezione di eventi disgiunti, in numero infinito, ma numerabile: tutti i singoletti
\end{flushleft}


\begin{flushleft}
dei numeri dispari e i numeri pari. La probabilit\`{a} che esca un numero dispari \`{e} la somma della serie geometrica,
\end{flushleft}


\begin{flushleft}
$-$k
\end{flushleft}


∑+$\infty$


\begin{flushleft}
k=1 3 = 2 . La probabilit\`{a} che esca un numero pari \`{e} allora 1$-$ 2 = 2 . Chiamiamo E l'insieme dei numeri pari positivi,
\end{flushleft}


1





1





1


2





\begin{flushleft}
allora = P(\{0\}) + P(E) = 2 ⋅ P(E), da cui P(\{0\}) = P(E) =
\end{flushleft}





1





1


.


4





\begin{flushleft}
Problema 2.4. Un'urna contiene 16 biglie bianche e 11 nere. Pescandone 4 assieme, qual \`{e} la probabilit\`{a} che non siano
\end{flushleft}


\begin{flushleft}
tutte del medesimo colore?
\end{flushleft}


\begin{flushleft}
Soluzione. Possiamo risolvere questo esercizio andando a considerare tutti i casi favorevoli, ossia 3 biglie bianche e
\end{flushleft}


\begin{flushleft}
1 nera, 2 bianche e 2 nere, oppure 3 nere e 1 bianca. Tuttavia dovremmo tenere conto dei diversi modi di ottenere le
\end{flushleft}


\begin{flushleft}
varie combinazioni, oltre alle rispettive probabilit\`{a}. Se invece calcoliamo la probabilit\`{a} che le cose non vadano come
\end{flushleft}


\begin{flushleft}
vogliamo, abbiamo meno casi (e più semplici) da considerare.
\end{flushleft}


\begin{flushleft}
Le biglie possono essere tutte del medesimo colore se sono tutte bianche, oppure tutte nere. La probabilit\`{a} che
\end{flushleft}


16 15 14


⋅ ⋅


27 26 25


51600


43


= 351 .


421200





\begin{flushleft}
siano tutte bianche \`{e}
\end{flushleft}





13





\begin{flushleft}
⋅ 24 , che siano tutte nere \`{e}
\end{flushleft}





11


27





10





9





8





\begin{flushleft}
⋅ 26 ⋅ 25 ⋅ 24 . Sommando le probabilit\`{a} di questi due casi
\end{flushleft}





\begin{flushleft}
disgiunti abbiamo
\end{flushleft}


\begin{flushleft}
Dal momento che a noi interessa la probabilit\`{a} dell'evento complementare, per avere
\end{flushleft}


\begin{flushleft}
la risposta non ci resta che sottrarre questo numero da 1:
\end{flushleft}


1$-$





43 308


=


.


351 351





\begin{flushleft}
Problema 2.5. A una festa ciascuna delle n invitate porta un regalo, chiuso in un pacchetto e incartato. Questi pacchetti, tutti della stessa dimensione e con la stessa carta, vengono messi su un tavolo e, nel momento clou della festa,
\end{flushleft}


\begin{flushleft}
ridistribuiti tra le partecipanti. Qual \`{e} la probabilit\`{a} che almeno un'invitata riceva il regalo che ha portato?
\end{flushleft}


\begin{flushleft}
Soluzione. Numeriamo le invitate da 1 a n e mettiamoci nei panni dell'invitata i. La probabilit\`{a} che costei riceva il
\end{flushleft}


1


\begin{flushleft}
proprio pacchetto \`{e} n . Possiamo chiamare Ri l'evento {``}invitata i-esima riceve il proprio regalo''. Quello che vogliamo
\end{flushleft}


\begin{flushleft}
calcolare \`{e} allora la probabilit\`{a} dell'unione di questi Ri al variare di i tra 1 e n: P(⋃ni=1 Ri). Si tratta per\`{o} di eventi non
\end{flushleft}


\begin{flushleft}
disgiunti. Infatti più invitate potrebbero ricevere il proprio pacchetto. Dobbiamo quindi calcolare le probabilit\`{a} delle
\end{flushleft}


\begin{flushleft}
intersezioni e usare il principio di inclusione--esclusione.
\end{flushleft}


1


1


\begin{flushleft}
Se consideriamo due invitate i e j, la probabilit\`{a} che entrambe ricevano il proprio regalo \`{e} n ⋅ n $-$ 1 , corrispondente
\end{flushleft}


\begin{flushleft}
all'evento Ri $\cap$ Rj. Osserviamo che questa probabilit\`{a} dipende, come gi\`{a} P(Ri), solamente da quante invitate sono
\end{flushleft}


\begin{flushleft}
coinvolte e non dalle loro identit\`{a}. In generale, se guardiamo l'evento in cui k invitate ricevono il proprio regalo,
\end{flushleft}


\begin{flushleft}
(n $-$ k)!
\end{flushleft}





\begin{flushleft}
esso avr\`{a} probabilit\`{a} n ⋅ n $-$ 1 ⋅ ⋅ ⋅ ⋅ ⋅ n $-$ (k $-$ 1) = n! . Per ogni k, per\`{o}, abbiamo nk modi di scegliere k invitate tra le
\end{flushleft}


\begin{flushleft}
partecipanti. Allora la probabilit\`{a} cercata, ossia la probabilit\`{a} dell'unione, sar\`{a} data da
\end{flushleft}


1





1





1





\begin{flushleft}
P
\end{flushleft}





(((





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





)))





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Ri =
\end{flushleft}


\begin{flushleft}
k=1
\end{flushleft}





\begin{flushleft}
($-$1)k+1
\end{flushleft}





\begin{flushleft}
n (n $-$ k)!
\end{flushleft}


=


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k=1
\end{flushleft}





1


\begin{flushleft}
($-$1)k+1 .
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





\newpage
38





\begin{flushleft}
UNA NUOVA PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Il problema pu\`{o} dirsi concluso: per valori assegnati di n basta andare a calcolarsi questa somma (finita) a segni alterni.
\end{flushleft}


\begin{flushleft}
Tuttavia, chi avesse gi\`{a} incontrato la funzione esponenziale espressa come serie potrebbe riconoscere l'ultimo membro
\end{flushleft}


\begin{flushleft}
come l'approssimazione al grado n-esimo di 1$-$e $-$1 (e saper dare quindi più facilmente un'approssimazione del valore
\end{flushleft}


\begin{flushleft}
cercato).
\end{flushleft}


\begin{flushleft}
Abbiamo anche la risposta al problema complementare: {``}Qual \`{e} la probabilit\`{a} che nessuna abbia davanti a s\'{e} il
\end{flushleft}


\begin{flushleft}
proprio pacchetto?''. Al crescere del numero delle invitate n, questa quantit\`{a} tende a e $-$1 $\approx$ 37\%.
\end{flushleft}


\begin{flushleft}
Problema 2.6. Una coppia di rapinatori ha svaligiato una banca ed \`{e} in fuga a piedi verso il proprio covo. La citt\`{a} ha
\end{flushleft}


\begin{flushleft}
una struttura tipicamente romana, come si vede in Figura 2.2. Quanti sono i percorsi di lunghezza minima che i ladri
\end{flushleft}


\begin{flushleft}
hanno a disposizione?
\end{flushleft}


\begin{flushleft}
Covo
\end{flushleft}


7


6


5


4


3


2


1


\begin{flushleft}
Banca
\end{flushleft}


13





12





11





10





9





8





7





6





5





4





3





2





1





\begin{flushleft}
Figura 2.2. La fuga dei malfattori
\end{flushleft}


\begin{flushleft}
Soluzione. I rapinatori si muovono solamente lungo le strade e devono necessariamente fare 6 isolati verso Nord e 12
\end{flushleft}


\begin{flushleft}
isolati verso Ovest. Vogliono anche fare meno strada possibile, quindi non si muoveranno mai verso Est o verso Sud.
\end{flushleft}


\begin{flushleft}
Vogliamo allora contare i percorsi costituiti esattamente da 6 spostamenti verso Nord e da 12 verso Ovest. Possiamo vederli come parole di 6 + 12 = 18 lettere, di cui 6 {``}N'' e 12 {``}O''.
\end{flushleft}


\begin{flushleft}
Ci siamo ricondotti quindi al conteggio degli anagrammi di
\end{flushleft}


\begin{flushleft}
``NNNNNNOOOOOOOOOOOO''.
\end{flushleft}


\begin{flushleft}
In tutto i percorsi di lunghezza minima sono
\end{flushleft}





18


6





= 18564.





\begin{flushleft}
Problema 2.7. Nelle stesse ipotesi del problema precedente, la polizia ha avuto una soffiata e ha piazzato due posti di
\end{flushleft}


\begin{flushleft}
blocco, come indicato in Figura 2.3: se i rapinatori passano di lì, vengono arrestati. Se i rapinatori scelgono uniformemente a caso tra tutti i percorsi di lunghezza minima, con che probabilit\`{a} verranno catturati?
\end{flushleft}


\begin{flushleft}
Covo
\end{flushleft}


7


6


5


4


3


2


1


\begin{flushleft}
Banca
\end{flushleft}


13





12





11





10





9





8





7





6





5





4





3





2





1





\begin{flushleft}
Figura 2.3. Malfattori in fuga con posti di blocco
\end{flushleft}


\begin{flushleft}
Soluzione. I casi totali sono tanti quanti i percorsi di lunghezza minima che vanno al covo, gi\`{a} contati nel Problema 2.6: 18
\end{flushleft}


\begin{flushleft}
. Quanti sono quelli che portano alla cattura? Tutti quelli che passano dal primo posto di blocco,
\end{flushleft}


6


\begin{flushleft}
più tutti quelli che passano dal secondo posto di blocco meno quelli che passano da entrambi2.12, usando il principio
\end{flushleft}


\begin{flushleft}
di inclusione-esclusione. Possiamo contare il numero dei possibili percorsi esattamente come prima, eventualmente
\end{flushleft}


\begin{flushleft}
scomponendo il percorso in sotto-percorsi.
\end{flushleft}


\begin{flushleft}
2.12. Osserviamo che questo dipende dalla particolare disposizione scelta dei posti di blocco: ci sono posizionamenti
\end{flushleft}


\begin{flushleft}
della polizia tali per cui non esistono percorsi di lunghezza minima che passano da entrambi.
\end{flushleft}





\begin{flushleft}
\newpage
2.4 PROBLEMI
\end{flushleft}





39





\begin{flushleft}
Contiamo allora quanti sono i percorsi che passano dal primo posto di blocco: 41 ⋅ 1 ⋅ 13
\end{flushleft}


\begin{flushleft}
perch\'{e} dobbiamo rag5
\end{flushleft}


\begin{flushleft}
giungere il nodo (4, 2), passare dal posto di blocco e poi andare dal nodo (5, 2) al covo in (13, 7). In modo simile
\end{flushleft}


\begin{flushleft}
contiamo quanti passano dal secondo, 13
\end{flushleft}


\begin{flushleft}
⋅ 1 ⋅ 41 , e quanti da entrambi, 41 ⋅ 1 ⋅ 83 ⋅ 1 ⋅ 41 . In tutto i percorsi di lun4
\end{flushleft}


\begin{flushleft}
ghezza minima che portano alla cattura sono
\end{flushleft}


4⋅





13


13


+


4


5





\begin{flushleft}
La probabilit\`{a} che vengano catturati \`{e} allora
\end{flushleft}


\begin{flushleft}
lunghezza minima.
\end{flushleft}





$-$4⋅





8


⋅4 =4⋅


3





7112


254


= 663


18564





14


8


$-$4⋅


5


3





= 7112.





\begin{flushleft}
$\approx$ 38.3\%, facendo il rapporto con il numero di percorsi totali di
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
CAPITOLO 3
\end{flushleft}


\begin{flushleft}
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}


\begin{flushleft}
In questo modo la probabilit\`{a} diventa in un certo senso una misura di informazione, ed \`{e} quindi
\end{flushleft}


\begin{flushleft}
naturale pensare che, se accumuliamo nuovi dati riguardo a un evento, possiamo e dobbiamo
\end{flushleft}


\begin{flushleft}
aggiornare la probabilit\`{a} che gli assegniamo. Questo punto di vista \`{e} molto vicino al metodo
\end{flushleft}


\begin{flushleft}
scientifico: non possiamo mai avere certezza di nulla, ma una serie di risultati sperimentali favorevoli a una nostra teoria far\`{a} aumentare la nostra confidenza nel fatto che tale teoria possa dare
\end{flushleft}


\begin{flushleft}
una buona spiegazione.
\end{flushleft}


\begin{flushleft}
Supponiamo, in un certo spazio di probabilit\`{a}, di venire a sapere che un certo evento F si
\end{flushleft}


\begin{flushleft}
\`{e} verificato. Se a questo punto vogliamo valutare di nuovo la probabilit\`{a} di un altro evento E,
\end{flushleft}


\begin{flushleft}
vorremo tener conto delle informazioni in più che abbiamo, ossia che \`{e} successo F. Parliamo in
\end{flushleft}


\begin{flushleft}
questo caso di probabilit\`{a} condizionata.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 3.1. Dato uno spazio di probabilit\`{a} ($\Omega$, ℱ, P) e due eventi E ed F in ℱ, con P(F) $\neq$ 0, definiamo la probabilit\`{a} di E condizionata a F come
\end{flushleft}


\begin{flushleft}
P(E∣ F) =
\end{flushleft}





\begin{flushleft}
P (E $\cap$ F)
\end{flushleft}


.


\begin{flushleft}
P(F)
\end{flushleft}





\begin{flushleft}
Se guardiamo il numeratore della definizione, stiamo considerando solo gli esiti in E che possono verificarsi in un mondo nel quale sappiamo che F non \`{e} più solo una possibilit\`{a}, ma un dato
\end{flushleft}


\begin{flushleft}
di fatto. Per quanto riguarda il denominatore, dividiamo per P(F) perch\'{e} il nostro universo \`{e} ora
\end{flushleft}


\begin{flushleft}
il solo F e, dal momento che vogliamo avere di nuovo una probabilit\`{a}, dobbiamo rinormalizzare
\end{flushleft}


\begin{flushleft}
opportunamente. Nella Figura 3.1 possiamo vedere un'illustrazione in termini di insiemi della
\end{flushleft}


\begin{flushleft}
definizione.
\end{flushleft}





\begin{flushleft}
Ω
\end{flushleft}


\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
F
\end{flushleft}





\begin{flushleft}
F
\end{flushleft}


\begin{flushleft}
E $\cap$F
\end{flushleft}





\begin{flushleft}
Figura 3.1. Nel condizionamento F \`{e} il ``nuovo'' universo
\end{flushleft}





\begin{flushleft}
Esempio 3.2. Rosalia lancia un normale dado a 6 facce. Come spesso accade, il dado cade a terra
\end{flushleft}


\begin{flushleft}
e Rosalia non vede cos'\`{e} uscito. Stefano, che vede il risultato del dado, le dice che \`{e} uscito un
\end{flushleft}


\begin{flushleft}
numero dispari. Qual \`{e} la probabilit\`{a} che Rosalia abbia fatto 3? E qual \`{e} la probabilit\`{a} che non
\end{flushleft}


\begin{flushleft}
abbia fatto 1?
\end{flushleft}


\begin{flushleft}
Stiamo considerando il lancio di un dado a 6 facce. Abbiamo quindi come possibile scelta dello
\end{flushleft}


\begin{flushleft}
spazio degli esiti $\Omega$ = \{1, 2, 3, 4, 5, 6\}, per l'algebra ℱ = 𝒫($\Omega$) e per funzione di probabilit\`{a} quella
\end{flushleft}


1


\begin{flushleft}
che d\`{a} peso 6 a ogni singoletto. L'informazione fornita da Stefano \`{e} che si \`{e} verificato l'evento
\end{flushleft}


\begin{flushleft}
F = \{1, 3, 5\}. A questo punto possiamo usare la definizione per calcolare le quantit\`{a} richieste.
\end{flushleft}


41





\newpage
42





\begin{flushleft}
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





\begin{flushleft}
La probabilit\`{a} che sia uscito 3 \`{e}
\end{flushleft}


\begin{flushleft}
P(\{3\}∣ F) =
\end{flushleft}





\begin{flushleft}
P (\{3\} $\cap$ \{1, 3, 5\})
\end{flushleft}


\begin{flushleft}
P(\{3\})
\end{flushleft}


=


=


\begin{flushleft}
P(\{1, 3, 5\})
\end{flushleft}


\begin{flushleft}
P(\{1, 3, 5\})
\end{flushleft}





1


6


1


2





1


= .


3





\begin{flushleft}
La probabilit\`{a} che non sia uscito 1 \`{e}
\end{flushleft}


\begin{flushleft}
P(\{1\}c∣ F) =
\end{flushleft}





\begin{flushleft}
P (\{2, 3, 4, 5, 6\} $\cap$ \{1, 3, 5\})
\end{flushleft}


\begin{flushleft}
P(\{3, 5\})
\end{flushleft}


=


=


\begin{flushleft}
P(\{1, 3, 5\})
\end{flushleft}


\begin{flushleft}
P(\{1, 3, 5\})
\end{flushleft}





2


6


1


2





2


= .


3





\begin{flushleft}
Osservazione 3.3. Se fissiamo un evento F di probabilit\`{a} non nulla, allora la funzione PF : ℱ $\rightarrow$ ℝ
\end{flushleft}


\begin{flushleft}
definita per ogni E $\in$ ℱ da PF (E) = P(E∣ F) \`{e} una funzione di probabilit\`{a}, poich\'{e} soddisfa tutti
\end{flushleft}


\begin{flushleft}
gli assiomi visti. Abbiamo, infatti, che PF (E) ⩾ 0 per qualunque evento E in ℱ, dal momento
\end{flushleft}


\begin{flushleft}
che stiamo facendo il rapporto tra una quantit\`{a} non negativa e una positiva. Allo stesso tempo,
\end{flushleft}


\begin{flushleft}
P ($\Omega$ $\cap$ F)
\end{flushleft}


\begin{flushleft}
PF ($\Omega$) = P(F) = 1. Non resta che verificare che anche il terzo assioma sia soddisfatto: prendiamo una famiglia numerabile (Ei)+$\infty$
\end{flushleft}


\begin{flushleft}
i=1 di eventi a due a due disgiunti e scriviamone la probabilit\`{a}
\end{flushleft}


\begin{flushleft}
condizionata a F dell'unione,
\end{flushleft}


\begin{flushleft}
P(
\end{flushleft}


((





+$\infty$





\begin{flushleft}
F
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
(E $\cap$ F)]
\end{flushleft}


\begin{flushleft}
)) = P[(⋃ P(F)E ) $\cap$ F] = P[⋃ P(F)
\end{flushleft}


)


+$\infty$


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Ei
\end{flushleft}





=





+$\infty$


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





∑+$\infty$


\begin{flushleft}
i=1 P (E i $\cap$ F)
\end{flushleft}


=


\begin{flushleft}
P(F)
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





+$\infty$





\begin{flushleft}
PF (Ei),
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
in cui abbiamo usato la distributivit\`{a} dell'intersezione rispetto all'unione.
\end{flushleft}


\begin{flushleft}
Allora anche per PF valgono le propriet\`{a} viste per una qualunque misura di probabilit\`{a} P.
\end{flushleft}


\begin{flushleft}
Tutto questo non ci sorprende: abbiamo dato la definizione di probabilit\`{a} condizionata proprio
\end{flushleft}


\begin{flushleft}
con l'idea di avere alla fine una misura di probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Esempio 3.4. Edoardo ama molto correre in montagna quindi, se le previsioni sono buone, la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} che passi la domenica sui monti \`{e} del 70\%. Se le previsioni sono buone, con che probabilit\`{a} rimane a casa?
\end{flushleft}


\begin{flushleft}
Siano M l'evento ``correre in montagna'' e S l'evento ``buone previsioni'':
\end{flushleft}


\begin{flushleft}
P(M∣ S) + P(M c∣ S) = P (M $\cup$ M c∣ S) = P($\Omega$∣ S) = 1,
\end{flushleft}


\begin{flushleft}
quindi P(M c∣ S) = 1 $-$ P(M∣ S) = 30\%.
\end{flushleft}


\begin{flushleft}
Nel definire la probabilit\`{a} condizionata, il nostro scopo era quantificare l'effetto di un evento
\end{flushleft}


\begin{flushleft}
su un altro, in termini di probabilit\`{a}. Tuttavia, il bello delle identit\`{a} \`{e} che possiamo rigirarle un
\end{flushleft}


\begin{flushleft}
po' per mettere in evidenza altri aspetti. In particolare, dalla definizione di probabilit\`{a} condizionata possiamo ricavare un modo (anzi, due) per scrivere la probabilit\`{a} dell'intersezione tra due
\end{flushleft}


\begin{flushleft}
eventi:
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F) = P(E∣ F) ⋅ P(F) = P(F∣ E) ⋅ P(E).
\end{flushleft}





(3.1)





\begin{flushleft}
La doppia identit\`{a} (3.1) prende anche il nome di teorema (o regola) del prodotto. Osserviamo che
\end{flushleft}


\begin{flushleft}
nella (3.1) siamo stati un po' imprecisi: non abbiamo specificato che P(E) $\neq$ 0 $\neq$ P(F). Tuttavia, se
\end{flushleft}


\begin{flushleft}
anche P(E) o P(F) fossero nulli, avremmo che P(E $\cap$F) =0, perch\'{e} l'intersezione E $\cap$F \`{e} un evento
\end{flushleft}


\begin{flushleft}
contenuto in un evento di probabilit\`{a} nulla (E o F): qualunque valore (finito) assegniamo a P(E∣
\end{flushleft}


\begin{flushleft}
F) (o P(F∣ E)), lo annulleremo moltiplicandolo per 0.
\end{flushleft}


\begin{flushleft}
Potrebbe essere interessante caratterizzare quegli eventi che non interagiscono tra loro, quelli
\end{flushleft}


\begin{flushleft}
che intuitivamente chiameremmo eventi indipendenti. Come prossimo passo vogliamo quindi
\end{flushleft}


\begin{flushleft}
dare una definizione matematica di indipendenza tra eventi, per poi vedere come essa si sposi
\end{flushleft}


\begin{flushleft}
con l'idea intuitiva di eventi indipendenti.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 3.5. In uno spazio di probabilit\`{a} ($\Omega$, ℱ, P), due eventi E ed F in ℱ si dicono indipendenti
\end{flushleft}


\begin{flushleft}
se vale l'uguaglianza P (E $\cap$ F) = P(E) ⋅ P(F).
\end{flushleft}





\begin{flushleft}
\newpage
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





43





\begin{flushleft}
Questa definizione, a un primo sguardo, ci sorprende un po': com'\`{e} che parliamo di indipendenza tra eventi e ci ritroviamo con una {``}formula'' per la probabilit\`{a} dell'intersezione? In realt\`{a}
\end{flushleft}


\begin{flushleft}
grazie al legame tra probabilit\`{a} dell'intersezione e probabilit\`{a} condizionata possiamo dare un
\end{flushleft}


\begin{flushleft}
altro punto di vista sull'indipendenza appena definita. Infatti, se due eventi E ed F sono indipendenti, abbiamo
\end{flushleft}


\begin{flushleft}
P(E) ⋅ P(F) = P (E $\cap$ F) = P(E∣ F) ⋅ P(F)
\end{flushleft}





\begin{flushleft}
e P(E) ⋅ P(F) = P(F∣ E) ⋅ P(E),
\end{flushleft}





\begin{flushleft}
cio\`{e}, supponendo P(E) $\neq$ 0 e P(F) $\neq$ 0,
\end{flushleft}


\begin{flushleft}
P(E∣ F) = P(E)
\end{flushleft}





\begin{flushleft}
e P(F∣ E) = P(F).
\end{flushleft}





\begin{flushleft}
Quindi sapere che \`{e} accaduto F non cambia quello che sappiamo della probabilit\`{a} di E e, viceversa. Inoltre, avendo due catene di uguaglianze possiamo invertire il ragionamento: sapere che
\end{flushleft}


\begin{flushleft}
E non ci d\`{a} informazioni su F ed F non ci d\`{a} informazioni su E implica che E ed F sono indipendenti, per la definizione di indipendenza data sopra. La definizione data caratterizza proprio
\end{flushleft}


\begin{flushleft}
quello che ci aspettavamo e il termine usato \`{e} giustificato.
\end{flushleft}


\begin{flushleft}
Se siamo invece interessati alla probabilit\`{a} dell'intersezione di due eventi, sappiamo che essa
\end{flushleft}


\begin{flushleft}
\`{e} uguale al prodotto delle probabilit\`{a} dei due eventi se questi ultimi sono tra loro indipendenti.
\end{flushleft}


\begin{flushleft}
Se non abbiamo questa informazione, dobbiamo usare la regola del prodotto (3.1) vista sopra,
\end{flushleft}


\begin{flushleft}
oppure l'identit\`{a} incontrata in precedenza:
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F) = P(E) + P(F) $-$ P (E $\cup$ F).
\end{flushleft}


\begin{flushleft}
Esempio 3.6. Gaia sa che le sue professoresse di Storia e di Arte interrogano in ognuna delle due
\end{flushleft}


\begin{flushleft}
materie a sorteggio tra coloro che ancora non hanno un voto. Sapendo che nella classe, formata
\end{flushleft}


\begin{flushleft}
da 25 tra studentesse e studenti, nessuno \`{e} ancora stato interrogato in Storia e 6 persone (ma non
\end{flushleft}


\begin{flushleft}
Gaia) hanno un voto in Arte, con che probabilit\`{a} Gaia verr\`{a} interrogata domani?
\end{flushleft}


1


\begin{flushleft}
Gaia ha una probabilit\`{a} di essere interrogata in Storia uguale a P(S) = 25 , come tutte le sue
\end{flushleft}


1


\begin{flushleft}
compagne e i suoi compagni di classe, e P(A) = 19 di essere interrogata in Arte. Le due estrazioni
\end{flushleft}


\begin{flushleft}
vengono fatte da liste (o contenitori) diversi, quindi non si influenzano l'una con l'altra: possiamo
\end{flushleft}


\begin{flushleft}
allora considerare le due interrogazioni come indipendenti. La probabilit\`{a} di interrogazione di
\end{flushleft}


\begin{flushleft}
Gaia \`{e} allora
\end{flushleft}


1


1


1


43


\begin{flushleft}
P (S $\cup$ A) = P(S) + P(A) $-$ P (S $\cap$ A) = + $-$
\end{flushleft}


=


,


25 19 25 ⋅ 19 475


\begin{flushleft}
in cui abbiamo usato l'identit\`{a} per la probabilit\`{a} dell'unione vista nella Proposizione 2.30 e, per
\end{flushleft}


\begin{flushleft}
valutare P (S $\cap$ A), l'indipendenza.
\end{flushleft}


\begin{flushleft}
Esempio 3.7. Nicol\`{o} possiede un'auto sportiva gialla. Un giorno, in un parcheggio, vede che
\end{flushleft}


\begin{flushleft}
l'auto in sosta accanto alla sua \`{e} anch'essa una sportiva gialla. Mentre rientra verso casa, si chiede
\end{flushleft}


\begin{flushleft}
quanto sia probabile che un'auto sia una sportiva gialla. Da una rapida ricerca online scopre che
\end{flushleft}


\begin{flushleft}
solamente 1 auto ogni 100 \`{e} un'auto sportiva e che solo 1 auto su 200 \`{e} gialla. Ne conclude quindi
\end{flushleft}


1


\begin{flushleft}
che la probabilit\`{a} che un'auto sia una sportiva gialla \`{e} 20000 .
\end{flushleft}


\begin{flushleft}
In realt\`{a} questo ragionamento non \`{e} corretto, perch\'{e} nulla garantisce che i due eventi ``auto
\end{flushleft}


\begin{flushleft}
sportiva'' e ``auto gialla'' siano indipendenti. In effetti, con un po' di attenzione, Nicol\`{o} scopre
\end{flushleft}


\begin{flushleft}
poco dopo che tra le auto gialle, 1 su 3 \`{e} un'auto sportiva, quindi la probabilit\`{a} che un'auto a caso
\end{flushleft}


\begin{flushleft}
sia gialla e sportiva \`{e}
\end{flushleft}


1 1


1


1


\begin{flushleft}
P (S $\cap$ G) = P(S∣ G) ⋅ P(G) = ⋅
\end{flushleft}


=


$\neq$


\begin{flushleft}
= P(S) ⋅ P(G).
\end{flushleft}


3 200 600 20000


\begin{flushleft}
Qui l'errore non ha gravi conseguenze, ma una svista simile ha contribuito alla condanna, poi
\end{flushleft}


\begin{flushleft}
annullata, di Malcolm Ricardo Collins3.1.
\end{flushleft}


\begin{flushleft}
3.1. \`{E} un caso giudiziario realmente accaduto negli anni Sessanta in California. Una discussione più dettagliata di
\end{flushleft}


\begin{flushleft}
questo e di altri esempi reali di errori matematici in ambito processuale si trova nel libro Math on Trial.
\end{flushleft}





\newpage
44





\begin{flushleft}
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





\begin{flushleft}
Dalla riscrittura in termini di probabilit\`{a} condizionata dell'indipendenza, abbiamo che, se due
\end{flushleft}


\begin{flushleft}
eventi E ed F sono indipendenti, allora P(F∣ E) = P(F), ma anche P(F c∣ E) = P(F c). Ma che succede
\end{flushleft}


\begin{flushleft}
se abbiamo il complementare dall'altro lato del condizionamento?
\end{flushleft}


\begin{flushleft}
Esempio 3.8. Prendiamo, in uno spazio di probabilit\`{a} ($\Omega$, ℱ, P), due eventi E ed F tali che 0 $<$
\end{flushleft}


\begin{flushleft}
P(F) $<$ 1 e P(E∣ F) = P(E∣ F c). Possiamo dire che gli eventi E ed F sono indipendenti?
\end{flushleft}


\begin{flushleft}
Potremmo sospettare un trabocchetto, quindi andiamo a scriverci con attenzione le quantit\`{a}:
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F)
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F c) P (E $\cap$ F c)
\end{flushleft}


\begin{flushleft}
= P(E∣ F) = P(E∣ F c) =
\end{flushleft}


=


.


\begin{flushleft}
P(F)
\end{flushleft}


\begin{flushleft}
P(F c)
\end{flushleft}


\begin{flushleft}
1 $-$ P(F)
\end{flushleft}


\begin{flushleft}
Ora prendiamo il primo e l'ultimo termine e moltiplichiamoli per P(F) (1 $-$ P(F))
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F) (1 $-$ P(F)) = P (E $\cap$ F c) P(F)
\end{flushleft}


\begin{flushleft}
e continuiamo raccogliendo i termini moltiplicati per P(F) a secondo membro,
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F) = (P (E $\cap$ F) + P (E $\cap$ F c)) P(F).
\end{flushleft}


\begin{flushleft}
A questo punto possiamo osservare che i due eventi E $\cap$F ed E $\cap$F c sono disgiunti e la loro unione
\end{flushleft}


\begin{flushleft}
\`{e} E, quindi, siccome la probabilit\`{a} dell'unione disgiunta \`{e} la somma delle probabilit\`{a}, abbiamo
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F) = P(E) P(F), ossia l'indipendenza.
\end{flushleft}


\begin{flushleft}
Torniamo allora a guardare il testo iniziale e proviamo a rileggere quello che c'\`{e} scritto. La
\end{flushleft}


\begin{flushleft}
condizione P(E∣ F) = P(E∣ F c) ci dice che sapere che F sia accaduto o no non d\`{a} alcuna informazione su E; infatti non modifica la sua probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Lezione 4
\end{flushleft}





\begin{flushleft}
Nell'Esempio 3.8 abbiamo incontrato un'idea interessante: abbiamo scritto un evento dividendolo in due pezzi disgiunti, che per\`{o} esaurissero tutte le possibilit\`{a}. In realt\`{a} non c'\`{e} nulla di
\end{flushleft}


\begin{flushleft}
speciale nel fatto che siano due eventi complementari: le caratteristiche fondamentali sono che
\end{flushleft}


\begin{flushleft}
gli eventi siano tutti disgiunti, ma che allo stesso tempo coprano tutto lo spazio, cio\`{e} ne siano
\end{flushleft}


\begin{flushleft}
una partizione. Andare a riscrivere la probabilit\`{a} di un evento in termini delle sue probabilit\`{a}
\end{flushleft}


\begin{flushleft}
condizionate a una partizione di eventi \`{e} una tecnica molto importante che prende il nome di formula di fattorizzazione (o legge delle probabilit\`{a} totali). La sua validit\`{a} \`{e} garantita dal seguente
\end{flushleft}


\begin{flushleft}
teorema.
\end{flushleft}


\begin{flushleft}
TEOREMA 3.9. Dato uno spazio di probabilit\`{a} ($\Omega$, ℱ, P), consideriamo una famiglia al più numerabile di
\end{flushleft}


\begin{flushleft}
eventi disgiunti (Ei) i$\in$I che sia anche una partizione di $\Omega$. Supponiamo che ogni evento nella partizione
\end{flushleft}


\begin{flushleft}
abbia probabilit\`{a} non nulla. Allora per ogni evento F $\in$ ℱ,
\end{flushleft}


\begin{flushleft}
P(F) =
\end{flushleft}





\begin{flushleft}
P (F $\cap$ Ei) =
\end{flushleft}


\begin{flushleft}
i$\in$I
\end{flushleft}





\begin{flushleft}
P(F∣ Ei) ⋅ P(E i).
\end{flushleft}


\begin{flushleft}
i$\in$I
\end{flushleft}





\begin{flushleft}
Dimostrazione. Osserviamo che la seconda uguaglianza deriva, addendo per addendo, dalla
\end{flushleft}


\begin{flushleft}
definizione di probabilit\`{a} condizionata. Per quanto riguarda la prima, basta osservare che
\end{flushleft}





(( ((





\begin{flushleft}
P(F) = P (F $\cap$ $\Omega$) = P F $\cap$
\end{flushleft}





\begin{flushleft}
)))) = P((
\end{flushleft}





\begin{flushleft}
Ei
\end{flushleft}


\begin{flushleft}
i$\in$I
\end{flushleft}





\begin{flushleft}
i$\in$I
\end{flushleft}





))





\begin{flushleft}
(F $\cap$ E i)
\end{flushleft}





\begin{flushleft}
e che l'unione \`{e} necessariamente disgiunta, dal momento che per ogni i risulta F $\cap$ E i $\subset$ Ei.
\end{flushleft}





□





\begin{flushleft}
Osserviamo che in realt\`{a} la richiesta che gli eventi nella partizione non abbiano misura nulla
\end{flushleft}


\begin{flushleft}
non \`{e} cruciale: se \`{e} vero che non sappiamo determinare il valore di P(F∣ E i) per tali eventi, sappiamo che comunque \`{e} una probabilit\`{a}, quindi un numero compreso tra 0 e 1. Questo numero
\end{flushleft}


\begin{flushleft}
compare moltiplicato per P(E i), cio\`{e} per 0, e ci\`{o} risolve i nostri problemi.
\end{flushleft}





\begin{flushleft}
\newpage
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





45





\begin{flushleft}
La formula di fattorizzazione va a estendere al mondo della probabilit\`{a} quello che \`{e} il principio
\end{flushleft}


\begin{flushleft}
della somma nella combinatoria: ci permette di dividere il problema in sotto-problemi (auspicabilmente) più facili, dandoci un modo per combinarli alla fine. Di nuovo la strategia del divide
\end{flushleft}


\begin{flushleft}
et impera. Come accennato in precedenza, questo risultato \`{e} di grandissima utilit\`{a} pratica, perch\'{e}
\end{flushleft}


\begin{flushleft}
ci permette di spezzare il calcolo della probabilit\`{a} in più sotto-casi, scelti opportunamente, spesso
\end{flushleft}


\begin{flushleft}
semplificando enormemente i conti.
\end{flushleft}





\begin{flushleft}
Esempio 3.10. A un gruppo di studio per preparare l'esame di probabilit\`{a} e statistica partecipano
\end{flushleft}


\begin{flushleft}
solo tre studenti: Carlo, Anita e Francesca. Carlo \`{e} un esperto di problemi di combinatoria e ne
\end{flushleft}


\begin{flushleft}
risolve sei su sette, le altre due preferiscono entrambe la statistica e risolvono gli esercizi di combinatoria solo una volta su quattro. Oggi lavorano indipendentemente su tre problemi, assegnati
\end{flushleft}


\begin{flushleft}
a caso, di cui solo uno di combinatoria. Qual \`{e} la probabilit\`{a} che alla fine dell'incontro il gruppo
\end{flushleft}


\begin{flushleft}
abbia una soluzione per il problema di combinatoria?
\end{flushleft}


\begin{flushleft}
Cosa sappiamo? Chiamiamo C l'evento ``il problema di combinatoria viene assegnato a Carlo''
\end{flushleft}


\begin{flushleft}
e R l'evento ``il problema di combinatoria viene risolto''. Allora il testo ci dice che
\end{flushleft}


6


\begin{flushleft}
P(R∣ C) = ,
\end{flushleft}


7





1


\begin{flushleft}
P(R∣ C c) = ,
\end{flushleft}


4





1


\begin{flushleft}
P(C) = .
\end{flushleft}


3





\begin{flushleft}
Grazie alla formula di fattorizzazione possiamo riscrivere la probabilit\`{a} cercata come
\end{flushleft}


6 1 1 2 19


\begin{flushleft}
P(R) = P(R∣ C) ⋅ P(C) + P(R∣ C c) ⋅ P(C c) = ⋅ + ⋅ = .
\end{flushleft}


7 3 4 3 42


\begin{flushleft}
Esempio 3.11. Da un recente sondaggio svolto nell'Arcipelago delle Tre Isole \`{e} emerso che nell'isola
\end{flushleft}


\begin{flushleft}
di Idilos 2 abitanti su 15 sono matematici, nell'isola di Iremun \`{e} matematico 1 abitante su 5, mentre
\end{flushleft}


\begin{flushleft}
sulla terza isola, Erettel, sono 3 su 25. Qual \`{e} la probabilit\`{a} che un qualunque abitante dell'arcipelago sia un matematico, se il 30\% vive su Idilos, il 45\% su Iremun e il 25\% su Erettel?
\end{flushleft}


\begin{flushleft}
Indicando con M l'essere un matematico e con S, N ed E l'essere abitante dell'isola di Idilos,
\end{flushleft}


\begin{flushleft}
Iremun ed Erettel rispettivamente, abbiamo
\end{flushleft}





\begin{flushleft}
P(M) = P(M∣ S) ⋅ P(S) + P(M∣ N) ⋅ P(N) + P(M∣ E) ⋅ P(E)
\end{flushleft}


2 30 1 45


3 25


=


⋅


+ ⋅


+ ⋅


15 100 5 100 25 200


= 16\%


\begin{flushleft}
In pratica quello che stiamo facendo \`{e} prendere la media delle probabilit\`{a} dell'evento che ci interessa (essere matematici) condizionata ai casi disgiunti (vivere in una specifica isola), pesando
\end{flushleft}


\begin{flushleft}
questa media con le probabilit\`{a} dei casi stessi.
\end{flushleft}


\begin{flushleft}
Facciamo un passo indietro e torniamo all'indipendenza: l'abbiamo definita a partire dalla
\end{flushleft}


\begin{flushleft}
probabilit\`{a} dell'intersezione e siamo poi passati al legame con la probabilit\`{a} condizionata, che
\end{flushleft}


\begin{flushleft}
ci ha dato una caratterizzazione molto più intuitiva dell'indipendenza stessa. Perch\'{e} allora non
\end{flushleft}


\begin{flushleft}
abbiamo usato direttamente la probabilit\`{a} condizionata per dare la definizione?
\end{flushleft}


\begin{flushleft}
Torniamo per un momento alla questione, lasciata in sospeso, del caso in cui abbiamo un
\end{flushleft}


\begin{flushleft}
evento di probabilit\`{a} nulla. Cosa succede? Supponiamo che sia P(E) = 0. Allora, per monotonia,
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F) ⩽ P(E) = 0, cio\`{e} P (E $\cap$ F) = 0 = P(E) ⋅ P(F), ossia un evento di probabilit\`{a} nulla \`{e} indipendente rispetto a ogni evento, usando la definizione data. Cosa succede se andiamo a considerare
\end{flushleft}


\begin{flushleft}
le probabilit\`{a} condizionate?
\end{flushleft}


\begin{flushleft}
Quella che vogliamo guardare \`{e} P(F∣E), che per\`{o} non \`{e} definita: questo ci obbligherebbe a dare
\end{flushleft}


\begin{flushleft}
una definizione più macchinosa di indipendenza, specificando a parte il caso in cui un evento
\end{flushleft}


\begin{flushleft}
ha probabilit\`{a} nulla. Osserviamo che questo non \`{e} davvero influente, perch\'{e} P(F∣ E) compare
\end{flushleft}


\begin{flushleft}
moltiplicato per P(E): P(F∣ E) \`{e} una probabilit\`{a} e ha un valore compreso tra 0 e 1, quindi anche
\end{flushleft}


\begin{flushleft}
se non ne conosciamo il valore, sappiamo che il prodotto varr\`{a} zero.
\end{flushleft}





\newpage
46





\begin{flushleft}
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





\begin{flushleft}
A questo punto abbiamo la curiosit\`{a} di capire quanto possa valere P(F∣E) se P(E) =0. Quando
\end{flushleft}


\begin{flushleft}
andiamo ad analizzare i dettagli, per\`{o}, ci accorgiamo che non ha un valore univoco. Se E $\subset$ F,
\end{flushleft}


\begin{flushleft}
allora sapere che \`{e} avvenuto E ci dice automaticamente che \`{e} avvenuto F, con probabilit\`{a} 1. Matematicamente questo torna (con qualche equilibrismo), perch\'{e} E $\cap$ F = E e quindi abbiamo che i
\end{flushleft}


\begin{flushleft}
due termini uguali {``}si semplificano''. Se invece E $\cap$ F = $\emptyset$, cio\`{e} E $\subset$ F c, sapere che \`{e} avvenuto E
\end{flushleft}


\begin{flushleft}
assegna automaticamente probabilit\`{a} 0 a F, cosa che possiamo immaginare vedendo la probabilit\`{a} dell'evento nullo {``}più nulla'' di tutte le altre.
\end{flushleft}


\begin{flushleft}
Fin qui sembra andare tutto bene, a parte la seccatura di dover distinguere queste due possibilit\`{a}. Purtroppo per\`{o} questi non sono i soli casi possibili: infatti un evento di probabilit\`{a} nulla
\end{flushleft}


\begin{flushleft}
pu\`{o} avere intersezione non vuota e differenza non vuota con un altro evento e, in questo caso,
\end{flushleft}


\begin{flushleft}
non sappiamo assegnare un valore sensato alla probabilit\`{a} condizionata.
\end{flushleft}


\begin{flushleft}
Proseguiamo ora con altre propriet\`{a} interessanti del condizionamento.
\end{flushleft}


\begin{flushleft}
Esempio 3.12. Lanciamo per l'n-esima volta un dado a 6 facce. Lo spazio probabilizzabile che
\end{flushleft}


\begin{flushleft}
consideriamo \`{e} dunque $\Omega$ = \{1, 2, 3, 4, 5, 6\} e ℱ = 𝒫($\Omega$). Prendiamo i due eventi E = \{2, 4, 6\} ed
\end{flushleft}


\begin{flushleft}
F = \{3, 6\}.
\end{flushleft}


\begin{flushleft}
Supponiamo che il dado sia bilanciato, quindi ogni faccia del dado (ogni singoletto) ha proba1
\end{flushleft}


\begin{flushleft}
bilit\`{a} P(\{i\}) = 6 , per ogni i = 1, . . . , 6. Allora
\end{flushleft}


1


\begin{flushleft}
P(E) = ,
\end{flushleft}


2





\begin{flushleft}
P(F) =
\end{flushleft}





1


3





1


\begin{flushleft}
e P (E $\cap$ F) = P(\{6\}) = = P(E) ⋅ P(F),
\end{flushleft}


6





\begin{flushleft}
cio\`{e} i due eventi sono indipendenti.
\end{flushleft}


\begin{flushleft}
Supponiamo invece che il dado sia truccato: allora abbiamo una nuova probabilit\`{a} P̃ tale che
\end{flushleft}


\begin{flushleft}
P̃(\{1\}) = P̃(\{2\}) = P̃(\{3\}) = P̃(\{4\}) =
\end{flushleft}





1


,


12





1


\begin{flushleft}
P̃(\{5\}) = P̃(\{6\}) = .
\end{flushleft}


3





\begin{flushleft}
Dopo aver verificato che si tratta effettivamente di una probabilit\`{a}, andiamo a calcolare
\end{flushleft}


1


\begin{flushleft}
P̃(E) = ,
\end{flushleft}


2





\begin{flushleft}
P̃(F) =
\end{flushleft}





5


12





1 5


\begin{flushleft}
e P̃(E $\cap$ F) = P̃(\{6\}) = $\neq$ = P̃(E) ⋅ P̃(F),
\end{flushleft}


3 24





\begin{flushleft}
ossia sotto questa probabilit\`{a} i due eventi non sono indipendenti.
\end{flushleft}


\begin{flushleft}
Grazie a quest'ultimo esempio, notiamo che l'indipendenza tra due eventi non \`{e} una propriet\`{a}
\end{flushleft}


\begin{flushleft}
intrinseca degli eventi stessi, ma dipende dall'intero spazio di probabilit\`{a} scelto e, in particolare,
\end{flushleft}


\begin{flushleft}
dalla misura di probabilit\`{a}. Se consideriamo sullo stesso spazio probabilizzabile due probabilit\`{a}
\end{flushleft}


\begin{flushleft}
distinte, pu\`{o} succedere che con una di esse due eventi siano indipendenti e con l'altra no.
\end{flushleft}


\begin{flushleft}
C'\`{e} un caso particolare che ci interessa, arrivati a questo punto: mettiamo assieme il concetto
\end{flushleft}


\begin{flushleft}
di indipendenza e una particolare misura di probabilit\`{a}, la probabilit\`{a} condizionata. Se fissiamo
\end{flushleft}


\begin{flushleft}
nel nostro spazio di probabilit\`{a} ($\Omega$, ℱ, P) un evento F $\in$ ℱ di probabilit\`{a} non nulla, abbiamo visto
\end{flushleft}


\begin{flushleft}
che la funzione PF : ℱ $\rightarrow$ ℝ definita per ogni E $\in$ ℱ da PF (E) = P(E∣ F) \`{e} una probabilit\`{a} e possiamo
\end{flushleft}


\begin{flushleft}
quindi considerare l'indipendenza tra eventi rispetto a essa. Ne nasce la seguente definizione.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 3.13. In uno spazio di probabilit\`{a} ($\Omega$, ℱ, P), fissato un evento F tale che P(F) $\neq$ 0, due eventi
\end{flushleft}


\begin{flushleft}
E 1 ed E2 si dicono indipendenti condizionalmente a F se
\end{flushleft}


\begin{flushleft}
P (E1 $\cap$ E 2∣ F) = P(E 1∣ F) ⋅ P(E 2∣ F).
\end{flushleft}


\begin{flushleft}
L'indipendenza condizionale \`{e} distinta dall'indipendenza, come vediamo nei due esempi successivi.
\end{flushleft}


\begin{flushleft}
Esempio 3.14. Marko ha due cassetti nel suo armadio, nei quali tiene i suoi calzini. In uno ci
\end{flushleft}


\begin{flushleft}
sono solo calzini invernali lunghi, nell'altro ci sono calzini estivi sia lunghi sia corti (met\`{a} e met\`{a}).
\end{flushleft}


\begin{flushleft}
Marko pesca contemporaneamente due calzini da uno dei due cassetti.
\end{flushleft}





\begin{flushleft}
\newpage
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





47





\begin{flushleft}
Se chiamiamo S l'evento ``Marko pesca dal secondo cassetto'', gli eventi L1: ``il primo calzino
\end{flushleft}


\begin{flushleft}
pescato \`{e} lungo'' e C 2: ``il secondo calzino pescato \`{e} corto'' sono indipendenti condizionalmente
\end{flushleft}


\begin{flushleft}
a S. Infatti P(L1∣ S) = 0.5 = P(C2∣ S), quindi P (L 1 $\cap$ C2∣ S) = 0.25 = P(L1∣ S) P(C 2∣ S).
\end{flushleft}


\begin{flushleft}
In generale, tuttavia, se supponiamo che Marko scelga con uguale probabilit\`{a} dai due cassetti,
\end{flushleft}


\begin{flushleft}
i due eventi non sono indipendenti. Infatti abbiamo
\end{flushleft}


1 1 3


\begin{flushleft}
P(L 1) =P(L 1∣ S) P(S) + P(L1∣ S c) (1 $-$ P(S)) = + =
\end{flushleft}


4 2 4


1


1


\begin{flushleft}
c
\end{flushleft}


\begin{flushleft}
P(C 2) =P(C 2∣ S) P(S) + P(C2∣ S ) (1 $-$ P(S)) = + 0 =
\end{flushleft}


4


4


1


\begin{flushleft}
c
\end{flushleft}


\begin{flushleft}
P (L1 $\cap$ C 2) =P (L1 $\cap$ C 2∣ S) P(S) + P (L 1 $\cap$ C2∣ S ) (1 $-$ P(S)) =
\end{flushleft}


8


3 1


\begin{flushleft}
P(L1) ⋅ P(C 2) = $\neq$ .
\end{flushleft}


16 8


\begin{flushleft}
Esempio 3.15. Consideriamo ancora una volta il lancio di due dadi a 6 facce. I due eventi D2:
\end{flushleft}


\begin{flushleft}
``il primo dado ha come risultato 2'' ed E 5: ``il secondo dado ha come risultato 5'' sono tra loro
\end{flushleft}


\begin{flushleft}
indipendenti. Tuttavia se condizioniamo rispetto all'evento S8: ``la somma dei dadi \`{e} 8'', vediamo
\end{flushleft}


\begin{flushleft}
che D2 ed E5 non sono indipendenti condizionalmente a S 8. Infatti
\end{flushleft}


\begin{flushleft}
P (D2 $\cap$ E 5∣ S 8) = 0 $\neq$
\end{flushleft}





1


\begin{flushleft}
= P(D2∣ S8) ⋅ P(E 5∣ S 8),
\end{flushleft}


25





\begin{flushleft}
poich\'{e} per avere la somma dei due dadi uguale a 8, ciascuno dei due pu\`{o} prendere uno dei 5
\end{flushleft}


1


\begin{flushleft}
valori tra 2 e 6, quindi entrambi i fattori a ultimo membro sono 5 .
\end{flushleft}


\begin{flushleft}
Possiamo prendere una variante dell'esempio precedente e osservare un altro aspetto.
\end{flushleft}


\begin{flushleft}
Esempio 3.16. Siano D2, E5 come nell'esempio precedente e S 7: ``la somma dei dadi \`{e} 7''. Osserviamo che non solo D2 ed E 5 sono indipendenti tra loro, ma ciascuno di loro \`{e} anche indipendente
\end{flushleft}


\begin{flushleft}
da S 7:
\end{flushleft}


1


1


\begin{flushleft}
P(D2∣ S7) = = P(D2) P(S 7∣ D2) = = P(S7)
\end{flushleft}


6


6


1


1


\begin{flushleft}
P(E5∣ S7) = = P(E 5) P(S 7∣ E 5) = = P(S7).
\end{flushleft}


6


6


\begin{flushleft}
Questo per\`{o} non ci basta per dire che sono tutti e tre indipendenti tra loro, infatti
\end{flushleft}


\begin{flushleft}
P (D2 $\cap$ E5 $\cap$ S 7) =
\end{flushleft}





1


1


$\neq$


\begin{flushleft}
= P(D2) ⋅ P(E 5) ⋅ P(S7).
\end{flushleft}


36 216





\begin{flushleft}
Concludiamo queste divagazioni sull'indipendenza con un ultimo esempio, in cui abbiamo
\end{flushleft}


\begin{flushleft}
indipendenza condizionale rispetto a una partizione.
\end{flushleft}


\begin{flushleft}
Esempio 3.17. Prendiamo ora tre eventi D, E ed F sul nostro spazio di probabilit\`{a} ($\Omega$, ℱ, P), con
\end{flushleft}


\begin{flushleft}
0 $<$P(F)$<$ 1 e supponiamo che D ed E siano indipendenti tra loro condizionalmente a F, ma anche
\end{flushleft}


\begin{flushleft}
a F c. Possiamo dire che D ed E sono necessariamente indipendenti tra loro in senso stretto?
\end{flushleft}


\begin{flushleft}
Da un lato avremmo la tentazione di rispondere affermativamente: sono indipendenti in ciascuna delle due possibilit\`{a} determinate da F (sia con F vero, sia con F falso), quindi lo saranno
\end{flushleft}


\begin{flushleft}
anche globalmente. Allo stesso tempo, per\`{o}, gli esempi precedenti ci hanno insegnato un po' di
\end{flushleft}


\begin{flushleft}
prudenza.
\end{flushleft}


\begin{flushleft}
Proviamo allora a vedere se ci sono condizioni da soddisfare affinch\'{e} questa indipendenza sia
\end{flushleft}


\begin{flushleft}
vera e, allo stesso tempo, se possiamo costruire un controesempio.
\end{flushleft}


\begin{flushleft}
Dalla formula di fattorizzazione abbiamo le seguenti identit\`{a}:
\end{flushleft}


\begin{flushleft}
P(D) =P(D∣ F) ⋅ P(F) + P(D∣ F c) ⋅ (1 $-$ P(F))
\end{flushleft}


\begin{flushleft}
=(P(D∣ F) $-$ P(D∣ F c)) ⋅ P(F) + P(D∣ F c)
\end{flushleft}


\begin{flushleft}
P(E) =P(E∣ F) ⋅ P(F) + P(E∣ F c) ⋅ (1 $-$ P(F))
\end{flushleft}


\begin{flushleft}
=(P(E∣ F) $-$ P(E∣ F c)) ⋅ P(F) + P(E∣ F c),
\end{flushleft}





\newpage
48





\begin{flushleft}
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





\begin{flushleft}
cio\`{e}, chiamando per semplicit\`{a} d = P(D∣ F), d′ = P(D∣ F c), e = P(E∣ F), e′ = P(E∣ F c) e anche a = P(D),
\end{flushleft}


\begin{flushleft}
b = P(E), c = P(F),
\end{flushleft}


\begin{flushleft}
a =d c + d′ (1 $-$ c) = (d $-$ d′) c + d′
\end{flushleft}


\begin{flushleft}
b =e c + e′ (1 $-$ c) = (e $-$ e′) c + e′.
\end{flushleft}


\begin{flushleft}
Allo stesso tempo abbiamo anche, grazie all'indipendenza di D ed E condizionalmente a F ed F c,
\end{flushleft}


\begin{flushleft}
P (D $\cap$ E)=P (D $\cap$ E∣ F) ⋅ P(F) + P (D $\cap$ E∣ F c) ⋅ P(F c)
\end{flushleft}


\begin{flushleft}
=P(D∣ F) ⋅ P(E∣ F) ⋅ P(F) + P(D∣ F c) ⋅ P(E∣ F c) ⋅ P(F c)
\end{flushleft}


\begin{flushleft}
=d e c + d′ e′ (1 $-$ c).
\end{flushleft}


\begin{flushleft}
Avremmo l'indipendenza se valesse P (D $\cap$ E) = P(D) ⋅ P(E), cio\`{e}, con la nuova notazione, d e c +
\end{flushleft}


\begin{flushleft}
d′ e′ (1 $-$ c) = a b. Studiamo allora questa identit\`{a}.
\end{flushleft}


\begin{flushleft}
d e c + d′ e′ $-$ d′ e′ c=a b
\end{flushleft}


\begin{flushleft}
=(d c + d′ $-$ d′ c) (e c + e′ $-$ e′ c)
\end{flushleft}


\begin{flushleft}
=d e c 2 + d e′ c $-$ d e′ c 2 + d′ e c
\end{flushleft}


\begin{flushleft}
+ d′ e′ $-$ d′ e′ c $-$ d′ e c 2 $-$ d′ e′ c + d′ e′ c 2.
\end{flushleft}


\begin{flushleft}
Possiamo semplificare un po' di termini, arrivando a
\end{flushleft}


\begin{flushleft}
d e c 2 + d e′ c $-$ d e′ c 2 + d′ e c $-$ d′ e c 2 $-$ d′ e′ c + d′ e′ c 2 $-$ d e c = 0
\end{flushleft}


\begin{flushleft}
che possiamo riscrivere, raccogliendo più volte i fattori in comune, come
\end{flushleft}


\begin{flushleft}
c (c $-$ 1) (d $-$ d′) (e $-$ e′) = 0,
\end{flushleft}


\begin{flushleft}
o, tornando esplicitamente alle probabilit\`{a},
\end{flushleft}


\begin{flushleft}
P(F) ⋅ P(F c) ⋅ (P(D∣ F) $-$ P(D∣ F c)) ⋅ (P(E∣ F) $-$ P(E∣ F c)) = 0.
\end{flushleft}


\begin{flushleft}
I primi due fattori per ipotesi non possono essere 0 (altrimenti non potremmo parlare di probabilit\`{a} condizionali), quindi ci sono due possibilit\`{a}: o la probabilit\`{a} di D non cambia nelle due parti
\end{flushleft}


\begin{flushleft}
F ed F c, o quella di E non cambia.
\end{flushleft}





\begin{flushleft}
D
\end{flushleft}





\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
F
\end{flushleft}





\begin{flushleft}
Fc
\end{flushleft}





\begin{flushleft}
D$\cap$E
\end{flushleft}





\begin{flushleft}
Figura 3.2. Un controesempio
\end{flushleft}





\begin{flushleft}
Abbiamo allora tutti gli ingredienti per costruire un controesempio, rappresentato in Figura 3.2.
\end{flushleft}


1


\begin{flushleft}
In questo esempio abbiamo P(F) = P(F c) = 2 . La probabilit\`{a} di ciascun evento \`{e} data dalla sua
\end{flushleft}


1


\begin{flushleft}
area in quadratini divisa per l'area totale (sempre in quadratini). In F abbiamo P(D∣ F) = 3 , P(E∣
\end{flushleft}


1


1


1


1


\begin{flushleft}
F) = 1 e P (D $\cap$ E∣ F) = 3 , mentre in F c valgono P(D∣ F c) = 2 , P(E∣ F c) = 3 e P (D $\cap$ E∣ F c) = 6 . Allora,
\end{flushleft}


\begin{flushleft}
condizionalmente a F e F c, D ed E sono indipendenti.
\end{flushleft}





\begin{flushleft}
\newpage
3.1 TEOREMA DI BAYES
\end{flushleft}





49





\begin{flushleft}
Se guardiamo per\`{o} le probabilit\`{a} di D ed E, vediamo P(D) = 12 e P(E) = 3 , dunque P(D) ⋅
\end{flushleft}


5


1


\begin{flushleft}
P(E) = 18 , mentre P (D $\cap$ E) = 4 , quindi D ed E non sono indipendenti.
\end{flushleft}


5





2





\begin{flushleft}
3.1. TEOREMA DI BAYES
\end{flushleft}


\begin{flushleft}
La probabilit\`{a} condizionata non \`{e} simmetrica: in generale P(E∣ F) $\neq$ P(F∣ E). Da un punto di vista
\end{flushleft}


\begin{flushleft}
matematico la cosa \`{e} immediata: basta guardare la definizione e osservare che non \`{e} simmetrica
\end{flushleft}


\begin{flushleft}
nei due insiemi considerati. Tuttavia, se andiamo a considerare l'uso della probabilit\`{a} nella vita
\end{flushleft}


\begin{flushleft}
di tutti i giorni, ci accorgiamo che questo \`{e} uno degli errori (o fallacie) più frequenti.
\end{flushleft}


\begin{flushleft}
Esempio 3.18. Da una recente indagine3.2 sui vaccini per l'influenza stagionale, in Italia la copertura vaccinale per le persone di et\`{a} maggiore o uguale a 65 anni \`{e} del 53.1\%. Nella popolazione
\end{flushleft}


\begin{flushleft}
generale la copertura si riduce al 15.8\%. Questo non significa che, scegliendo un vaccinato a caso,
\end{flushleft}


\begin{flushleft}
la probabilit\`{a} che abbia almeno 65 anni sia il 53.1\%. Infatti gli italiani con almeno 65 anni sono
\end{flushleft}


\begin{flushleft}
circa 14 milioni, di cui circa 7.5 milioni sono vaccinati. Al tempo stesso la popolazione italiana
\end{flushleft}


\begin{flushleft}
\`{e} costituita da 60 milioni di persone circa, di cui 9.5 milioni vaccinati. Tra i vaccinati, gli over 65
\end{flushleft}


\begin{flushleft}
sono quasi il 79\%. In termini di probabilit\`{a} condizionate abbiamo
\end{flushleft}


\begin{flushleft}
P(vaccinato ∣ over 65) = 53.1\% $\neq$ P(over 65 ∣ vaccinato) = 78.9\%.
\end{flushleft}


\begin{flushleft}
Purtroppo nel momento in cui ci si allontana dal contesto esplicitamente matematico, capita
\end{flushleft}


\begin{flushleft}
spesso che le due probabilit\`{a} condizionate vengano confuse. Vediamo alcuni tipici esempi.
\end{flushleft}


\begin{flushleft}
$\bullet$ {``}Se la maggior parte dei criminali appartiene a un certo gruppo, allora \`{e} altamente probabile
\end{flushleft}


\begin{flushleft}
che un generico membro del gruppo sia un criminale.'' Falso: tra i condannati per omicidio
\end{flushleft}


\begin{flushleft}
in Italia, oltre il 95\% sono di sesso maschile, ma non ci verrebbe mai in mente di pensare che
\end{flushleft}


\begin{flushleft}
quasi tutti i maschi italiani siano assassini.
\end{flushleft}


\begin{flushleft}
$\bullet$ {``}Se la probabilit\`{a} che un imputato abbia indizi contro di lui pur essendo innocente \`{e} molto
\end{flushleft}


\begin{flushleft}
bassa, allora deve essere molto bassa anche la probabilit\`{a} che sia innocente se ci sono indizi
\end{flushleft}


\begin{flushleft}
contro di lui.'' Falso: questo argomento prende il nome di fallacia del procuratore ed \`{e} stato
\end{flushleft}


\begin{flushleft}
ingrediente di molti casi di cattiva giustizia, con condanne annullate in fase di revisione dei
\end{flushleft}


\begin{flushleft}
processi, ad esempio il gi\`{a} citato caso Collins, ma anche con assoluzioni forse non meritate,
\end{flushleft}


\begin{flushleft}
come nel caso O. J. Simpson.
\end{flushleft}


\begin{flushleft}
$\bullet$ {``}Se la maggior parte dei recenti attacchi terroristici in Europa \`{e} stata portata a termine da
\end{flushleft}


\begin{flushleft}
musulmani, allora la proporzione di musulmani che sono terroristi \`{e} molto alta.'' Falso anche
\end{flushleft}


\begin{flushleft}
questa volta: in realt\`{a} la probabilit\`{a} che un musulmano europeo sia un terrorista \`{e} dell'ordine
\end{flushleft}


\begin{flushleft}
di 4 ⋅ 10 $-$6, cento volte più piccola della probabilit\`{a} di essere colpiti da un fulmine nel corso
\end{flushleft}


\begin{flushleft}
della propria vita.
\end{flushleft}


\begin{flushleft}
Pur non essendoci simmetria, le due probabilit\`{a} condizionate P(E∣ F) e P(F∣ E) non sono completamente scollegate tra loro, come vediamo nel prossimo esempio.
\end{flushleft}


\begin{flushleft}
Esempio 3.19. Tra i concorrenti delle Olimpiadi della Matematica3.3, il 43\% \`{e} del biennio, il rimanente 57\% del triennio. Tra i concorrenti del biennio, il 51\% sono ragazze, tra quelli del triennio
\end{flushleft}


\begin{flushleft}
tale percentuale scende al 23\%. Se Giulietta \`{e} una concorrente, qual \`{e} la probabilit\`{a} che sia una
\end{flushleft}


\begin{flushleft}
studentessa del biennio?
\end{flushleft}


\begin{flushleft}
Indichiamo con B l'evento ``concorrente del biennio'' e con ♀ l'evento ``concorrente \`{e} una
\end{flushleft}


\begin{flushleft}
ragazza''. Allora dai dati del problema abbiamo:
\end{flushleft}


\begin{flushleft}
P(B) = 0.43,
\end{flushleft}





\begin{flushleft}
P(B c) = 0.57,
\end{flushleft}





\begin{flushleft}
P(♀∣ B) = 0.51,
\end{flushleft}





\begin{flushleft}
P(♀∣ B c) = 0.23.
\end{flushleft}





\begin{flushleft}
3.2. Fonte: Ministero della Salute-ISS per la stagione 2018/19.
\end{flushleft}


\begin{flushleft}
3.3. Un sottoinsieme ben determinato degli studenti di scuola secondaria di secondo grado.
\end{flushleft}





\newpage
50





\begin{flushleft}
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





\begin{flushleft}
Noi per\`{o} vorremmo calcolare P(B∣ ♀), poich\'{e} Giulietta \`{e} una ragazza. Cominciamo a calcolare
\end{flushleft}


\begin{flushleft}
qualcosa di diverso: P (B $\cap$ ♀), cio\`{e} la probabilit\`{a} che la persona presa sia del biennio e sia una
\end{flushleft}


\begin{flushleft}
P (B $\cap$ ♀)
\end{flushleft}


\begin{flushleft}
ragazza. Lo facciamo perch\'{e} per definizione P(B∣ ♀) = P(♀) e stiamo in questo modo calcolando
\end{flushleft}


\begin{flushleft}
il numeratore. Dalla definizione di probabilit\`{a} condizionata otteniamo che
\end{flushleft}


\begin{flushleft}
P (B $\cap$ ♀) = P(♀∣ B) ⋅ P(B)
\end{flushleft}


\begin{flushleft}
dove le due quantit\`{a} a secondo membro sono note. Possiamo allora calcolare esplicitamente
\end{flushleft}


\begin{flushleft}
P (B $\cap$ ♀) = 0.51 ⋅ 0.43 = 0.2193.
\end{flushleft}


\begin{flushleft}
Per calcolare P(B∣ ♀), la quantit\`{a} che cerchiamo, non resta che calcolare P(♀), cosa che possiamo fare aiutandoci con la formula di fattorizzazione,
\end{flushleft}


\begin{flushleft}
P(♀) = P(♀∣ B) ⋅ P(B) + P(♀∣ B c) ⋅ P(B c).
\end{flushleft}


\begin{flushleft}
Anche in questo caso tutte le quantit\`{a} sono note (e addirittura abbiamo gi\`{a} calcolato il primo
\end{flushleft}


\begin{flushleft}
prodotto), quindi abbiamo
\end{flushleft}


\begin{flushleft}
P(♀) = 0.2193 + 0.23 ⋅ 0.57 = 0.3504.
\end{flushleft}


\begin{flushleft}
Mettendo assieme il tutto, abbiamo che quanto cerchiamo, cio\`{e} la probabilit\`{a} che Giulietta sia del
\end{flushleft}


\begin{flushleft}
biennio, \`{e}
\end{flushleft}


\begin{flushleft}
P (B $\cap$ ♀) P(♀∣ B) ⋅ P(B) 0.2193
\end{flushleft}


\begin{flushleft}
P(B∣ ♀) =
\end{flushleft}


=


=


$\approx$ 0.6259.


\begin{flushleft}
P(♀)
\end{flushleft}


\begin{flushleft}
P(♀)
\end{flushleft}


0.3504


\begin{flushleft}
Nell'esempio precedente abbiamo fatto qualcosa di interessante, che va oltre la risoluzione del
\end{flushleft}


\begin{flushleft}
problema assegnato: abbiamo calcolato una probabilit\`{a} condizionata in funzione della sua speculare, ossia P(E∣ F) a partire da P(F∣ E). Possiamo fare la stessa cosa in generale, come mostrato
\end{flushleft}


\begin{flushleft}
dal seguente risultato.
\end{flushleft}


\begin{flushleft}
TEOREMA 3.20. (BAYES) Sia ($\Omega$, ℱ, P) uno spazio di probabilit\`{a} e siano E, F due eventi, entrambi di
\end{flushleft}


\begin{flushleft}
probabilit\`{a} non nulla. Allora
\end{flushleft}


\begin{flushleft}
P(F∣ E)
\end{flushleft}


\begin{flushleft}
P(E∣ F) =
\end{flushleft}


\begin{flushleft}
⋅ P(E).
\end{flushleft}


\begin{flushleft}
P(F)
\end{flushleft}





\begin{flushleft}
Dimostrazione. Dalla definizione di probabilit\`{a} condizionata abbiamo la seguente catena di
\end{flushleft}


\begin{flushleft}
uguaglianze:
\end{flushleft}


\begin{flushleft}
P (E $\cap$ F) P (E $\cap$ F) P(E) P(F∣ E) ⋅ P(E)
\end{flushleft}


\begin{flushleft}
P(E∣ F) =
\end{flushleft}


=


⋅


=


.


□


\begin{flushleft}
P(F)
\end{flushleft}


\begin{flushleft}
P(E)
\end{flushleft}


\begin{flushleft}
P(F)
\end{flushleft}


\begin{flushleft}
P(F)
\end{flushleft}


\begin{flushleft}
Possiamo poi combinare il Teorema di Bayes con il teorema delle probabilit\`{a} totali, ricavando
\end{flushleft}


\begin{flushleft}
il seguente risultato.
\end{flushleft}


\begin{flushleft}
COROLLARIO 3.21. Data una partizione di $\Omega$ in eventi disgiunti di probabilit\`{a} non nulla, se F \`{e} un evento
\end{flushleft}


\begin{flushleft}
in ℱ, allora per ogni evento E
\end{flushleft}


\begin{flushleft}
P(F∣ E) ⋅ P(E)
\end{flushleft}


\begin{flushleft}
P(E∣ F) =
\end{flushleft}


.


(3.2)


\begin{flushleft}
∑i$\in$I P(F∣ E i) ⋅ P(Ei)
\end{flushleft}


\begin{flushleft}
Un trucco di pigrizia: se scegliamo la partizione in modo che E ne faccia parte, il prodotto al
\end{flushleft}


\begin{flushleft}
numeratore sulla destra compare anche nella somma a denominatore, quindi dobbiamo calcolare
\end{flushleft}


\begin{flushleft}
il valore di un addendo in meno.
\end{flushleft}


\begin{flushleft}
Esempio 3.22. Un laboratorio propone un nuovo test per determinare la positivit\`{a} (o negativit\`{a})
\end{flushleft}


\begin{flushleft}
al virus SARS-CoV-2. La proporzione di infetti che risultano positivi al test (detta anche sensibilit\`{a}) \`{e} il 99.9\%, mentre la proporzione di sani che sono negativi al test (detta anche specificit\`{a}) \`{e} il
\end{flushleft}


\begin{flushleft}
99.7\%. In Italia il virus contagia 5 persone su 1000. Jacopo si sottopone a questo test. Se il test \`{e}
\end{flushleft}


\begin{flushleft}
positivo, con che probabilit\`{a} Jacopo \`{e} davvero infetto?
\end{flushleft}





\begin{flushleft}
\newpage
3.1 TEOREMA DI BAYES
\end{flushleft}





51





\begin{flushleft}
La prima tentazione \`{e} di rispondere 99.9\%. Tuttavia, avendo visto che il condizionamento
\end{flushleft}


\begin{flushleft}
non \`{e} simmetrico, sappiamo distinguere tra P (M∣ +) e P (+∣ M), dove M \`{e} l'evento ``Jacopo \`{e}
\end{flushleft}


\begin{flushleft}
malato'' e + l'evento ``Jacopo \`{e} positivo''. Il dato del problema sulla sensibilit\`{a} \`{e} P (+∣ M), mentre
\end{flushleft}


\begin{flushleft}
il problema ci chiede P (M∣ +). Il Teorema di Bayes, per\`{o}, ci suggerisce la strada da prendere:
\end{flushleft}


\begin{flushleft}
P (+∣ M) ⋅ P(M)
\end{flushleft}


\begin{flushleft}
P (M∣ +) =
\end{flushleft}


\begin{flushleft}
P (+)
\end{flushleft}


\begin{flushleft}
P (+∣ M) ⋅ P(M)
\end{flushleft}


=


,


(3.3)


\begin{flushleft}
P (+∣ M) ⋅ P(M) + P (+∣ M c) ⋅ P(M c)
\end{flushleft}


\begin{flushleft}
dove abbiamo usato anche l'identit\`{a} (3.2) e la formula di fattorizzazione. Sostituiamo i valori
\end{flushleft}


\begin{flushleft}
disponibili, che abbiamo gi\`{a} come dati o che ricaviamo facilmente:
\end{flushleft}


\begin{flushleft}
P(M) = 0.005,
\end{flushleft}





\begin{flushleft}
P(M c) = 1 $-$ P(M) = 0.995,
\end{flushleft}





\begin{flushleft}
P (+∣ M) = 0.999
\end{flushleft}





\begin{flushleft}
e anche
\end{flushleft}


\begin{flushleft}
P (+∣ M c) = 1 $-$ P ($-$∣ M c) = 0.003.
\end{flushleft}


\begin{flushleft}
Tornando alla (3.3), abbiamo allora
\end{flushleft}


0.999 ⋅ 0.005


0.999 ⋅ 0.005 + 0.003 ⋅ 0.995


0.004995


=


$\approx$ 63\%.


0.00798


\begin{flushleft}
Questa probabilit\`{a}, per quanto non trascurabile, \`{e} comunque inferiore rispetto a quella che ci
\end{flushleft}


\begin{flushleft}
aveva tentato inizialmente.
\end{flushleft}


\begin{flushleft}
Spendiamo due parole per spiegare, per quanto in modo non approfondito, il motivo di questa
\end{flushleft}


\begin{flushleft}
discrepanza. Concentriamoci su quello che sappiamo: Jacopo \`{e} positivo al test. Quando succede questo? Se una persona \`{e} veramente malata, nel 99.9\% dei casi il test sar\`{a} positivo, tuttavia
\end{flushleft}


\begin{flushleft}
l'incidenza della malattia, ossia la proporzione di persone effettivamente malate, \`{e} molto piccola. Allo stesso tempo, raramente (nello 0.3\% dei casi) il test segnaler\`{a} come positivo qualcuno
\end{flushleft}


\begin{flushleft}
che \`{e} sano. Tuttavia la proporzione di persone sane \`{e} molto alta, quindi tra i positivi al test i
\end{flushleft}


\begin{flushleft}
falsi positivi sono una parte non trascurabile: più di un terzo.
\end{flushleft}


\begin{flushleft}
P (M∣ +) =
\end{flushleft}





\begin{flushleft}
L'esempio precedente, oltre a essere un buon esercizio, ci mostra anche quanto sia importante
\end{flushleft}


\begin{flushleft}
il Teorema di Bayes nella vita reale. Il cervello umano non \`{e} portato intuitivamente al ragionamento probabilistico ed \`{e} quindi facile incappare in errori. Il Teorema di Bayes \`{e} uno degli
\end{flushleft}


\begin{flushleft}
strumenti che ci permettono di aggirare ed evitare questi errori. Una delle sue applicazioni, in
\end{flushleft}


\begin{flushleft}
sintonia con il metodo scientifico, consiste nello spingerci ad aggiornare le nostre convinzioni.
\end{flushleft}


\begin{flushleft}
Cosa vogliamo dire con questo? Ci aspettiamo di fare ipotesi e metterle alla prova con opportuni esperimenti. Facciamo entrare in gioco anche la probabilit\`{a}, usandola come misura del livello
\end{flushleft}


\begin{flushleft}
di convinzione nella nostra ipotesi.
\end{flushleft}


\begin{flushleft}
Ad esempio, Maestra Rita potrebbe supporre che la probabilit\`{a} che Pierino non abbia studiato
\end{flushleft}


\begin{flushleft}
la lezione sia del 70\%. In questo caso il fenomeno d'interesse \`{e} {``}lo studio da parte degli scolari''
\end{flushleft}


\begin{flushleft}
(in particolare da parte di Pierino) e abbiamo come ipotesi {``}Pierino non ha studiato''. Maestra
\end{flushleft}


\begin{flushleft}
Rita non \`{e} sicura di questa ipotesi: Pierino potrebbe finalmente aver capito ed essersi messo sui
\end{flushleft}


\begin{flushleft}
libri, ma se la maestra dovesse scommettere darebbe fiducia a Pierino solo al 30\%. Maestra Rita
\end{flushleft}


\begin{flushleft}
per\`{o} pu\`{o} mettere alla prova la sua ipotesi con un esperimento: interrogando Pierino ha modo di
\end{flushleft}


\begin{flushleft}
verificare se abbia studiato o no.
\end{flushleft}


\begin{flushleft}
Scriviamo queste cose con la notazione della probabilit\`{a}: H \`{e} la nostra ipotesi, (Pierino non
\end{flushleft}


\begin{flushleft}
ha studiato) che supponiamo vera con probabilit\`{a} P(H) (70\% nell'esempio). Con E indichiamo il
\end{flushleft}


\begin{flushleft}
risultato di un esperimento (Pierino non sa rispondere alla domanda).
\end{flushleft}


\begin{flushleft}
Prima di effettuare l'esperimento, possiamo assegnare le probabilit\`{a} relative all'esperimento:
\end{flushleft}


\begin{flushleft}
P(E∣ H) nel caso in cui H sia vera e P(E∣H c) nel caso in cui H sia falsa. Nel caso di Pierino, Maestra
\end{flushleft}


\begin{flushleft}
Rita stima che P(E∣ H) = 90\%: se Pierino non ha studiato \`{e} probabile che non sappia rispondere,
\end{flushleft}


\begin{flushleft}
ma potrebbe avere fortuna e azzeccare la risposta. Viceversa, valuta P(E∣ H c) = 5\%: se Pierino ha
\end{flushleft}


\begin{flushleft}
studiato, potrebbe comunque non rispondere correttamente, per qualche motivo, anche se \`{e} poco
\end{flushleft}


\begin{flushleft}
probabile.
\end{flushleft}





\newpage
52





\begin{flushleft}
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





\begin{flushleft}
Assegniamo queste probabilit\`{a} condizionate prima di vedere l'effettivo risultato dell'esperimento. Quando per\`{o} sappiamo cosa \`{e} successo, possiamo usare gli ingredienti che abbiamo
\end{flushleft}


\begin{flushleft}
preparato per vedere come cambia la nostra confidenza nell'ipotesi dopo aver visto il verificarsi
\end{flushleft}


\begin{flushleft}
di E. In altre parole siamo interessati a P(H∣ E): quanto \`{e} convinta Maestra Rita che Pierino non
\end{flushleft}


\begin{flushleft}
abbia studiato se non ha saputo rispondere alla domanda che gli ha fatto?
\end{flushleft}


\begin{flushleft}
Per il Teorema di Bayes,
\end{flushleft}


\begin{flushleft}
P(H∣ E) =
\end{flushleft}





\begin{flushleft}
P(E∣ H)
\end{flushleft}


\begin{flushleft}
⋅ P(H)
\end{flushleft}


\begin{flushleft}
P(E∣ H) P(H) + P(E∣ H c) P(H c)
\end{flushleft}





\begin{flushleft}
e Maestra Rita, che prima pensava che ci fosse un 30\% di possibilit\`{a} che Pierino per una volta
\end{flushleft}


\begin{flushleft}
avesse studiato la lezione, dopo la scena muta aggiorna questa sua convinzione,
\end{flushleft}


90


10000


70


⋅


⋅


$\approx$ 97.7\%


100 90 ⋅ 70 + 5 ⋅ 30 100


\begin{flushleft}
e ha quasi la certezza che Pierino non si sia preparato.
\end{flushleft}


\begin{flushleft}
Tornando al caso generale, P(H) \`{e} la probabilit\`{a} che diamo alla verit\`{a} di H prima di effettuare
\end{flushleft}


\begin{flushleft}
l'esperimento e prende quindi il nome di probabilit\`{a} a priori (o prior). D'altra parte, P(H∣ E) \`{e} la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} di H aggiornata dopo aver visto il risultato E dell'esperimento: prende il nome di
\end{flushleft}


\begin{flushleft}
probabilit\`{a} a posteriori o posterior.
\end{flushleft}


\begin{flushleft}
\`{E} allora più chiaro il parallelo col ragionamento scientifico. Nello studiare un fenomeno, facciamo un'ipotesi H di cui siamo convinti a un livello P(H), per precedenti osservazioni o per altri
\end{flushleft}


\begin{flushleft}
motivi. Pianifichiamo un esperimento e, prima di effettuarlo, valutiamo con cura quali sono i possibili risultati e quanto li riteniamo plausibili in un mondo in cui H \`{e} vera e in uno in cui H \`{e} falsa,
\end{flushleft}


\begin{flushleft}
dando dei valori a P(E∣ H) e P(E∣ H c), rispettivamente, per ogni possibile esito E dell'esperimento.
\end{flushleft}


\begin{flushleft}
A questo punto facciamo l'esperimento e ne osserviamo il risultato E. Possiamo poi aggiornare
\end{flushleft}


\begin{flushleft}
la nostra convinzione che H sia vera, con l'informazione in più raccolta con l'esperimento, calcolando P(H∣ E) col Teorema di Bayes.
\end{flushleft}


\begin{flushleft}
Nell'Esempio 3.22, prima di sottoporsi al test, Jacopo poteva stimare la probabilit\`{a} di essere
\end{flushleft}


\begin{flushleft}
malato allo 0.5\%; dopo il risultato positivo del test, rivaluta questa probabilit\`{a} al 63\%. Il modo
\end{flushleft}


\begin{flushleft}
in cui ha scelto la sua probabilit\`{a} a priori di essere malato \`{e} di considerarsi un individuo qualunque della popolazione, all'interno della quale l'incidenza \`{e} 5 su 1000. Chiaramente altri fattori
\end{flushleft}


\begin{flushleft}
sarebbero potuti entrare in gioco: ad esempio se avesse avuto sintomi, magari avrebbe valutato
\end{flushleft}


\begin{flushleft}
diversamente la probabilit\`{a} a priori.
\end{flushleft}


\begin{flushleft}
Ci sono pochi vincoli sulla prior: deve essere una probabilit\`{a}, quindi soddisfare le propriet\`{a}
\end{flushleft}


\begin{flushleft}
che ormai conosciamo (in particolare quella di monotonia). In più, se vogliamo poter usare il
\end{flushleft}


\begin{flushleft}
Teorema di Bayes in modo fruttuoso, non possiamo assegnare mai le probabilit\`{a} 0 e 1.
\end{flushleft}


\begin{flushleft}
Infatti se assegniamo a un evento probabilit\`{a} 1, diciamo P(H) = 1, per quanti esperimenti contrari facciamo non potremo mai discostarci da quel valore:
\end{flushleft}


\begin{flushleft}
P(H∣ E) =
\end{flushleft}





\begin{flushleft}
P(E∣ H) P(H)
\end{flushleft}


\begin{flushleft}
P(E∣ H)
\end{flushleft}


=


=1


\begin{flushleft}
c
\end{flushleft}


\begin{flushleft}
c
\end{flushleft}


\begin{flushleft}
P(E∣ H) P(H) + P(E∣ H ) P(H ) P(E∣ H)
\end{flushleft}





\begin{flushleft}
e analogamente per il caso P(H) = 0.
\end{flushleft}


\begin{flushleft}
Questo ha senso, da un punto di vista astratto: se siamo certi di qualcosa nulla ci far\`{a} cambiare
\end{flushleft}


\begin{flushleft}
idea. In generale, per\`{o}, quando dichiariamo di essere certi di qualcosa in un contesto sperimentale, questo significa che per cambiare idea avremo bisogno di una notevole quantit\`{a} di evidenza
\end{flushleft}


\begin{flushleft}
contraria alla nostra convinzione precedente. Questo almeno finch\'{e} vogliamo agire in modo
\end{flushleft}


\begin{flushleft}
razionale. I valori 0 e 1 sono quindi da evitare.
\end{flushleft}


\begin{flushleft}
Quanto appena detto vale anche per i risultati degli esperimenti: anche se possono sembrare
\end{flushleft}


\begin{flushleft}
controesempi alla nostra ipotesi, dobbiamo tenerci un po' di margine (da valutare) che tenga conto
\end{flushleft}


\begin{flushleft}
di possibili errori nell'esperimento, ad esempio una lettura sbagliata da parte dello strumento.
\end{flushleft}


\begin{flushleft}
Quindi non raggiungeremo mai certezze: per la gioia degli scienziati sperimentali possiamo continuare a fare esperimenti all'infinito!
\end{flushleft}





\begin{flushleft}
\newpage
3.1 TEOREMA DI BAYES
\end{flushleft}





53





\begin{flushleft}
3.1.1. Esperimenti ripetuti (divagazione)
\end{flushleft}


\begin{flushleft}
Se continuiamo a fare esperimenti, vorremo combinare i risultati osservati in ciascuno di essi per
\end{flushleft}


\begin{flushleft}
aggiornare la nostra P(H). Come primo passo, vediamo il caso di due esperimenti: abbiamo due
\end{flushleft}


\begin{flushleft}
esiti E1 ed E 2 e vogliamo capire quanto vale P (H∣ E 1 $\cap$ E 2), la probabilit\`{a} a posteriori della nostra
\end{flushleft}


\begin{flushleft}
ipotesi dopo entrambi gli esperimenti. Facciamo un esempio.
\end{flushleft}


\begin{flushleft}
Esempio 3.23. Torniamo al caso di Jacopo, incontrato all'Esempio 3.22. Se Jacopo si sottoponesse
\end{flushleft}


\begin{flushleft}
di nuovo al test e questo risultasse nuovamente positivo, quale sarebbe la probabilit\`{a} che sia
\end{flushleft}


\begin{flushleft}
effettivamente malato?
\end{flushleft}


\begin{flushleft}
L'impostazione del problema \`{e} simile a quella dell'Esempio 3.22, solo che ora abbiamo due
\end{flushleft}


\begin{flushleft}
eventi rispetto ai quali condizioniamo. Allora
\end{flushleft}


\begin{flushleft}
P(+2∣ M $\cap$ +1)P (M∣ + 1)
\end{flushleft}


\begin{flushleft}
P(+2∣ M $\cap$ +1)P(M∣ +1) + P(+ 2∣ M c $\cap$ + 1)P (M c∣ +1)
\end{flushleft}


\begin{flushleft}
P (+2∣ M $\cap$ +1)
\end{flushleft}


=


⋅


\begin{flushleft}
P(+2∣ M $\cap$ +1)P(M∣ +1) + P(+ 2∣ M c $\cap$ + 1)P (M c∣ +1)
\end{flushleft}


\begin{flushleft}
P (+1∣ M) P(M)
\end{flushleft}


⋅


,


\begin{flushleft}
P (+ 1∣ M) P(M) + P (+ 1∣ M c) P(M c)
\end{flushleft}





\begin{flushleft}
P (M∣ +2$\cap$+ 1) =
\end{flushleft}





(3.4)





\begin{flushleft}
in cui abbiamo messo in evidenza una specie di iterazione. Tuttavia non \`{e} facile semplificare
\end{flushleft}


\begin{flushleft}
ulteriormente questa espressione, a meno di non fare alcune ipotesi di indipendenza tra i due
\end{flushleft}


\begin{flushleft}
test. In particolare, prendiamo come ipotesi il fatto che i due test, ossia gli eventi +1 e + 2, siano
\end{flushleft}


\begin{flushleft}
indipendenti condizionatamente a M ed M c. In altre parole, quando sappiamo se Jacopo \`{e} malato
\end{flushleft}


\begin{flushleft}
o no, la positivit\`{a} dei due test \`{e} indipendente3.4.
\end{flushleft}


\begin{flushleft}
Se ora torniamo alla (3.4) abbiamo, sfruttando l'indipendenza condizionata,
\end{flushleft}


\begin{flushleft}
P (M∣ + 1$\cap$+2) =
\end{flushleft}





\begin{flushleft}
P (+2∣ M)
\end{flushleft}


\begin{flushleft}
P (+1∣ M) P(M)
\end{flushleft}


⋅


\begin{flushleft}
P (+ 2∣ M) P(M∣ + 1) + P (+ 2∣ M c) P (M c∣ +1) P (+ 1∣ M) P(M) + P (+ 1∣ M c) P(M c)
\end{flushleft}





\begin{flushleft}
in cui il secondo fattore nel membro di destra \`{e} esattamente P(M∣ +1). In sostanza stiamo facendo
\end{flushleft}


\begin{flushleft}
esattamente la medesima cosa vista all'Esempio 3.22, solo che al secondo passaggio \`{e} cambiata la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} di partenza: non \`{e} più P(M), bensì P(M∣ + 1), perch\'{e} dobbiamo tenere conto del primo
\end{flushleft}


\begin{flushleft}
test fatto.
\end{flushleft}


\begin{flushleft}
Possiamo a questo punto sostituire nell'espressione i valori che conosciamo e ricavare la probabilit\`{a} cercata: P (M ∣ +1$\cap$+ 2) $\approx$ 99.8\%. Avere un secondo test positivo ci ha portati (quasi) alla
\end{flushleft}


\begin{flushleft}
certezza, nonostante quanto osservato prima (Esempio 3.22) sul fatto che in prima battuta i falsi
\end{flushleft}


\begin{flushleft}
positivi non sono trascurabili.
\end{flushleft}


\begin{flushleft}
Pu\`{o} essere interessante notare, a margine di questo esempio, cosa succederebbe qualora il
\end{flushleft}


\begin{flushleft}
secondo test fosse negativo. La risposta di pancia potrebbe essere che il test positivo e quello
\end{flushleft}


\begin{flushleft}
negativo si ``annullano'' a vicenda, quindi che la probabilit\`{a} che Jacopo sia malato ritorni a essere
\end{flushleft}


\begin{flushleft}
il valore di base 0.005. Le cose per\`{o} non stanno proprio così: abbiamo
\end{flushleft}


\begin{flushleft}
P (M∣ + 1$\cap$$-$ 2) =
\end{flushleft}





\begin{flushleft}
P ($-$ 2∣ M)
\end{flushleft}


⋅


\begin{flushleft}
P ($-$ 2∣ M) P(M∣ +1) + P ($-$ 2∣ M c) P (M c∣ + 1)
\end{flushleft}


⋅





\begin{flushleft}
P (+ 1∣ M) P(M)
\end{flushleft}


\begin{flushleft}
P (+1∣ M) P(M) + P (+1∣ M c) P(M c)
\end{flushleft}





\begin{flushleft}
e, sostituendo i valori che conosciamo, otteniamo P (M∣ + 1$\cap$$-$ 2) $\approx$ 0.002. Come mai? Il motivo \`{e}
\end{flushleft}


\begin{flushleft}
questo: se da un lato i falsi positivi non sono infrequenti, i falsi negativi lo sono molto meno, dato
\end{flushleft}


\begin{flushleft}
che complessivamente gli infetti sono una piccola parte della popolazione.
\end{flushleft}


\begin{flushleft}
Ispirati dall'Esempio 3.23, possiamo fare alcune osservazioni generali.
\end{flushleft}


\begin{flushleft}
3.4. Questo non significa che i due test siano indipendenti tra loro, nonostante stiamo considerandoli indipendenti se
\end{flushleft}


\begin{flushleft}
condizionati a un evento e al suo complementare, come abbiamo visto nell'Esempio 3.17.
\end{flushleft}





\newpage
54





\begin{flushleft}
PROBABILIT\`{A} CONDIZIONATA
\end{flushleft}





\begin{flushleft}
Osservazione 3.24. Ripetere un esperimento non \`{e} inutile, nemmeno se d\`{a} nuovamente il medesimo risultato: la nostra valutazione della probabilit\`{a} cambier\`{a} ulteriormente dopo la seconda
\end{flushleft}


\begin{flushleft}
osservazione. Lo stesso vale per due esperimenti con risultato opposto: in generale vederne i
\end{flushleft}


\begin{flushleft}
risultati non ci riporta al punto di partenza, ma ci lascia comunque delle informazioni aggiuntive,
\end{flushleft}


\begin{flushleft}
codificate dentro la probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Osservazione 3.25. La grandezza dell'effetto delle due osservazioni sulla probabilit\`{a} non \`{e} la
\end{flushleft}


\begin{flushleft}
stessa. Nell'esempio, il risultato del primo test porta la probabilit\`{a} di malattia da 0.005 a 0.63,
\end{flushleft}


\begin{flushleft}
con un aumento di 0.625. Il secondo esperimento la fa crescere ``solo'' di 0.368. Questo potrebbe
\end{flushleft}


\begin{flushleft}
sorprenderci: la seconda osservazione non \`{e} in s\'{e} diversa dalla prima. Il fenomeno, che prende il
\end{flushleft}


\begin{flushleft}
nome di diminuzione dei ritorni marginali, \`{e} del tutto naturale: ogni successivo esperimento con il
\end{flushleft}


\begin{flushleft}
medesimo risultato ha un impatto sempre minore sulla probabilit\`{a}. Pu\`{o} sembrare contro-intuitivo, ma ci\`{o} accade solo perch\'{e} le informazioni che raccogliamo interagiscono con la probabilit\`{a}
\end{flushleft}


\begin{flushleft}
attraverso una moltiplicazione e non una somma, come il nostro cervello preferirebbe. Possiamo
\end{flushleft}


\begin{flushleft}
vedere una traccia di questo comportamento moltiplicativo nell'identit\`{a} (3.4).
\end{flushleft}





\begin{flushleft}
\newpage
CAPITOLO 4
\end{flushleft}


\begin{flushleft}
COSTRUIRE PROBABILIT\`{A}
\end{flushleft}


\begin{flushleft}
4.1. SPAZI FINITI O NUMERABILI
\end{flushleft}


\begin{flushleft}
Cominciamo esaminando un caso semplice. Supponiamo di aver individuato lo spazio degli esiti
\end{flushleft}


\begin{flushleft}
$\Omega$ e di aver visto che esso \`{e} un insieme finito o numerabile. Come prima cosa prendiamo ℱ =
\end{flushleft}


\begin{flushleft}
𝒫($\Omega$), cio\`{e} l'insieme delle parti di $\Omega$. In altre parole vogliamo che tutti i possibili sottoinsiemi di
\end{flushleft}


\begin{flushleft}
$\Omega$ siano eventi. Se siamo alla ricerca di un algoritmo generale, questa \`{e} una buona idea, perch\'{e}
\end{flushleft}


\begin{flushleft}
qualunque insieme ci capiti di avere in $\Omega$, esso potr\`{a} avere una probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Come abbiamo visto, la cardinalit\`{a} di ℱ \`{e} 2 \#$\Omega$. Nel caso finito non \`{e} un grave problema, ma
\end{flushleft}


\begin{flushleft}
nel caso numerabile dovremo andare ad assegnare una probabilit\`{a} a tanti eventi quanti sono i
\end{flushleft}


\begin{flushleft}
numeri reali (non solo infiniti, ma più che numerabili). Questo pu\`{o} sembrare un problema, dal
\end{flushleft}


\begin{flushleft}
momento che non lo possiamo fare ricorsivamente, a differenza di quanto accade nel caso di una
\end{flushleft}


\begin{flushleft}
quantit\`{a} numerabile di oggetti.
\end{flushleft}


\begin{flushleft}
Ma proprio qui sta il trucco: andiamo ad assegnare una probabilit\`{a} a ciascun singoletto in $\Omega$,
\end{flushleft}


\begin{flushleft}
in modo che per ogni 𝜔 $\in$ $\Omega$, P(\{𝜔\}) ⩾ 0 e ∑𝜔$\in$$\Omega$ P(\{𝜔\}) = 1.
\end{flushleft}


\begin{flushleft}
In pratica quello che facciamo \`{e} scegliere una funzione che soddisfi queste due propriet\`{a}, più
\end{flushleft}


\begin{flushleft}
eventuali altre condizioni imposte dal problema specifico, e a questo punto siamo a posto. Infatti
\end{flushleft}


\begin{flushleft}
per ogni E $\in$ ℱ
\end{flushleft}


\begin{flushleft}
P(E) ≔
\end{flushleft}





\begin{flushleft}
P(\{𝜔\}),
\end{flushleft}


\begin{flushleft}
𝜔$\in$E
\end{flushleft}





\begin{flushleft}
dove abbiamo usato una propriet\`{a} che volevamo soddisfare, ossia che la probabilit\`{a} di un'unione
\end{flushleft}


\begin{flushleft}
disgiunta sia la somma delle probabilit\`{a}. Inoltre possiamo osservare che la somma si svolge su
\end{flushleft}


\begin{flushleft}
una quantit\`{a} di indici al più numerabile, quindi non stiamo commettendo alcun abuso di notazione4.1.
\end{flushleft}


\begin{flushleft}
La difficolt\`{a} più grande in questo caso \`{e} individuare una funzione P definita su $\Omega$ che soddisfi
\end{flushleft}


\begin{flushleft}
le due propriet\`{a} enunciate sopra, cio\`{e} la non negativit\`{a} e la somma a 1, e che al contempo catturi
\end{flushleft}


\begin{flushleft}
le propriet\`{a} del particolare problema che stiamo considerando.
\end{flushleft}


\begin{flushleft}
Esempio 4.1. Tre amici si sfidano abitualmente nella corsa, sempre sullo stesso percorso. Prisca
\end{flushleft}


\begin{flushleft}
arriva per prima il doppio delle volte di Carlo, Daniele arriva primo la met\`{a} delle volte di Carlo.
\end{flushleft}


\begin{flushleft}
Qual \`{e} la probabilit\`{a} che, in un giorno qualunque, Carlo sia il più veloce?
\end{flushleft}


\begin{flushleft}
Indichiamo con d la frequenza con cui Daniele vince. Dai dati del problema sappiamo che
\end{flushleft}


\begin{flushleft}
Carlo vince con frequenza 2 d e Prisca con frequenza 2 ⋅2d =4 d. Sappiamo anche che, dal momento
\end{flushleft}


2


\begin{flushleft}
che i concorrenti sono solo loro tre, 1 = 4 d + 2 d + d = 7 d, cio\`{e} Carlo arriva primo con probabilit\`{a} 7 .
\end{flushleft}


\begin{flushleft}
Non sempre, per\`{o}, abbiamo le informazioni per dare una probabilit\`{a} esplicita a ogni esito,
\end{flushleft}


\begin{flushleft}
come vedremo nel prossimo esempio. In questo caso abbiamo due possibilit\`{a}: accontentarci di
\end{flushleft}


\begin{flushleft}
assegnare la probabilit\`{a} solo su una tribù di eventi, oppure cambiare l'insieme $\Omega$ in modo che gli
\end{flushleft}


\begin{flushleft}
{``}eventi indivisibili'' diventino esiti nella nuova rappresentazione.
\end{flushleft}


\begin{flushleft}
4.1. Un vero abuso che si vede spesso \`{e} il seguente: si lasciano cadere le parentesi graffe e si identifica il singoletto di
\end{flushleft}


\begin{flushleft}
𝜔, un evento, con 𝜔 stesso, un esito. Anche se il desiderio di alleggerire la notazione \`{e} condivisibile, si tratta di una scelta
\end{flushleft}


\begin{flushleft}
pericolosa, perch\'{e} genera ambiguit\`{a}.
\end{flushleft}





55





\newpage
56





\begin{flushleft}
COSTRUIRE PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Esempio 4.2. Sull'isola dei matematici applicati c'\`{e} una particolare lotteria, in cui viene estratto
\end{flushleft}


\begin{flushleft}
un numero naturale a caso. Tuttavia, non tutti i numeri hanno la medesima probabilit\`{a} di uscire:
\end{flushleft}


1


\begin{flushleft}
ciascun numero pari ha la stessa probabilit\`{a} di uscire, il 7 esce con probabilit\`{a} 2 , l'evento \{1, 2, 3,
\end{flushleft}


1


\begin{flushleft}
5\} ha probabilit\`{a} 3 , mentre gli eventi \{9\}, \{9, 11\} e \{n: n ⩾ 9\} hanno la stessa probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Possiamo iniziare osservando che i numeri pari possono avere solamente probabilit\`{a} 0: se
\end{flushleft}


\begin{flushleft}
così non fosse, avremmo una probabilit\`{a} totale maggiore di 1, dal momento che i numeri naturali
\end{flushleft}


1


\begin{flushleft}
soddisfano la propriet\`{a} archimedea. Questo ci dice anche che P(\{1, 2, 3, 5\}) = P(\{1, 3, 5\}) = 3 . Con
\end{flushleft}


\begin{flushleft}
le stesse idee possiamo anche mostrare che ogni numero naturale strettamente maggiore di 9 ha
\end{flushleft}


\begin{flushleft}
probabilit\`{a} 0. A questo punto sappiamo che
\end{flushleft}


\begin{flushleft}
1 = P($\Omega$) = P(\{1, 3, 5\}) + P(7) + P(9) + P(\{0, 2, 4, 6, 8\}) + P(\{n: n $>$ 9\}),
\end{flushleft}


\begin{flushleft}
quindi P(\{9\}) = 6 . Osserviamo che, con i dati forniti, non siamo in grado di dire quali siano le
\end{flushleft}


\begin{flushleft}
probabilit\`{a} degli eventi \{1\}, \{3\}, \{5\}, \{1, 3\}, \{1, 5\}, \{1, 7\}... Possiamo considerare solo eventi in cui
\end{flushleft}


\begin{flushleft}
\{1, 3, 5\} sia un blocco unico.
\end{flushleft}


\begin{flushleft}
Un modo per ricondursi a quanto visto prima \`{e} scegliere un $\Omega$ diverso. In questo caso prendiamo, per esempio, $\Omega$ che ha per elementi l'insieme dei naturali pari, l'insieme dei naturali dispari
\end{flushleft}


\begin{flushleft}
maggiori di 5 e l'insieme \{1, 3, 5\}.
\end{flushleft}


1





\begin{flushleft}
Nel caso numerabile, dato che ci sono infiniti singoletti, potremmo aspettarci che un numero
\end{flushleft}


\begin{flushleft}
infinito di essi dovr\`{a} necessariamente avere probabilit\`{a} zero. Questo \`{e} falso, come possiamo
\end{flushleft}


\begin{flushleft}
vedere nel seguente esempio.
\end{flushleft}


\begin{flushleft}
Esempio 4.3. Anche sull'isola dei matematici puri c'\`{e} una lotteria infinita, su tutti i numeri naturali, in cui ogni numero ha il doppio della probabilit\`{a} di essere estratto rispetto al suo successore.
\end{flushleft}


\begin{flushleft}
In questo caso abbiamo bisogno di sfruttare la serie geometrica. Sappiamo infatti che, posta z
\end{flushleft}


\begin{flushleft}
la probabilit\`{a} di estrarre 0, la probabilit\`{a} di estrarre n \`{e} 2 $-$n ⋅ z, ma anche che
\end{flushleft}


+$\infty$





1=





\begin{flushleft}
2 $-$n ⋅ z = z ⋅
\end{flushleft}





\begin{flushleft}
n=0
\end{flushleft}





+$\infty$





\begin{flushleft}
2 $-$n = z ⋅ 2,
\end{flushleft}





\begin{flushleft}
n=0
\end{flushleft}





\begin{flushleft}
da cui abbiamo che lo zero esce con probabilit\`{a} e che in generale un numero naturale n esce con
\end{flushleft}


\begin{flushleft}
probabilit\`{a} 2 $-$(n+1). In particolare, nessun numero naturale ha probabilit\`{a} 0 di uscire.
\end{flushleft}


1


2





\begin{flushleft}
4.2. LO SPAZIO DEI NUMERI REALI
\end{flushleft}


\begin{flushleft}
Consideriamo ora il caso in cui $\Omega$ \`{e} l'intervallo di numeri reali [0, 1]. Dobbiamo scegliere la tribù
\end{flushleft}


\begin{flushleft}
e valutare come definire una misura di probabilit\`{a}. Cominciamo dalla tribù.
\end{flushleft}


\begin{flushleft}
Come gi\`{a} accennato in precedenza, potremmo prendere come tribù l'insieme delle parti di
\end{flushleft}


\begin{flushleft}
$\aleph$0
\end{flushleft}


\begin{flushleft}
[0, 1], ma questo ha cardinalit\`{a} pari all'insieme potenza di ℝ, cio\`{e} 2(2 ), che \`{e} un po' grande
\end{flushleft}


\begin{flushleft}
per i nostri gusti, visto che poi a ogni elemento della tribù andr\`{a} assegnata una probabilit\`{a}4.2.
\end{flushleft}


\begin{flushleft}
Consideriamo insiemi di numeri reali. Quelli che ci possono venire in mente di solito4.3 sono
\end{flushleft}


\begin{flushleft}
punti singoli, segmenti, semirette e loro combinazioni (unioni finite o numerabili, differenze e
\end{flushleft}


\begin{flushleft}
così via). Dato che per il momento ci stiamo interessando solamente all'intervallo [0, 1], intersecheremo quest'ultimo con gli insiemi visti sopra. Dentro alla nostra tribù dovranno esserci
\end{flushleft}


\begin{flushleft}
insiemi di questo tipo, perch\'{e} \`{e} di questi che vogliamo calcolare la probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
4.2. Ci sono anche altri motivi per non scegliere l'insieme delle parti: non possiamo farlo, se vogliamo definire una
\end{flushleft}


\begin{flushleft}
probabilit\`{a} che soddisfi alcune ragionevoli condizioni. Discutere di questo, per\`{o}, ci porterebbe un po' troppo fuori strada,
\end{flushleft}


\begin{flushleft}
verso la teoria della misura.
\end{flushleft}


\begin{flushleft}
4.3. Qualcuno potrebbe pensare immediatamente a casi patologici come l'insieme di Vitali (Giuseppe Vitali, 1875 --
\end{flushleft}


1932).





\begin{flushleft}
\newpage
4.2 LO SPAZIO DEI NUMERI REALI
\end{flushleft}





57





\begin{flushleft}
In altre parole, vogliamo la tribù generata da punti isolati, intervalli (aperti, chiusi, semiaperti
\end{flushleft}


\begin{flushleft}
a destra e a sinistra) e loro unioni numerabili, cio\`{e} la più piccola tribù che contiene tutti questi
\end{flushleft}


\begin{flushleft}
insiemi. Con un po' di teoria degli insiemi possiamo osservare che a partire dai soli intervalli
\end{flushleft}


\begin{flushleft}
chiusi in [0, 1] possiamo ottenere, attraverso il passaggio al complementare e all'unione numerabile:
\end{flushleft}


\begin{flushleft}
$\bullet$ gli intervalli aperti (a, b), definendo per ogni n $\in$ ℕ ∖ \{0\}, I n = a + n , b $-$ n , intervallo chiuso, e
\end{flushleft}


\begin{flushleft}
prendendone l'unione ⋃ n$\in$ℕ In = (a, b);
\end{flushleft}


1





1





\begin{flushleft}
$\bullet$ gli intervalli semiaperti della forma [a, b) e (a, b], in maniera analoga;
\end{flushleft}


\begin{flushleft}
$\bullet$ i singoletti;
\end{flushleft}


\begin{flushleft}
$\bullet$ le intersezioni...
\end{flushleft}


\begin{flushleft}
Quindi se vogliamo avere una tribù che contenga tutti questi insiemi, possiamo generarla a partire dai soli intervalli chiusi, dal momento che unioni numerabili e complementari di elementi di
\end{flushleft}


\begin{flushleft}
una tribù sono essi stessi nella tribù.
\end{flushleft}


\begin{flushleft}
In realt\`{a} \`{e} possibile usare come generatori gli intervalli semiaperti a sinistra, ossia della forma
\end{flushleft}


\begin{flushleft}
(a, b]. Come vedremo tra poco, questo modo di procedere \`{e} anche più comodo. In modo analogo a quanto fatto sopra, a partire dagli intervalli semiaperti a sinistra possiamo ottenere (con
\end{flushleft}


\begin{flushleft}
unioni numerabili e passaggi al complementare) gli intervalli chiusi e, di conseguenza, tutti gli
\end{flushleft}


\begin{flushleft}
altri insiemi che ci interessano.
\end{flushleft}


\begin{flushleft}
Insomma, sia usando gli intervalli chiusi, sia usando gli intervalli semichiusi a destra (cio\`{e}
\end{flushleft}


\begin{flushleft}
semiaperti a sinistra), generiamo una tribù che soddisfa le nostre richieste, poich\'{e} contiene gli
\end{flushleft}


\begin{flushleft}
insiemi che consideriamo interessanti. Essa prende il nome di tribù dei Boreliani4.4 (su [0, 1]) e
\end{flushleft}


\begin{flushleft}
viene indicata con ℬ([0, 1]). La sua cardinalit\`{a} \`{e} quella del continuo, cosa che non dimostreremo
\end{flushleft}


\begin{flushleft}
qui (si fa per induzione transfinita).
\end{flushleft}


\begin{flushleft}
Ora che abbiamo $\Omega$ e ℱ, dobbiamo solo scegliere una misura di probabilit\`{a}. Anche in questo
\end{flushleft}


\begin{flushleft}
caso, come in quello degli spazi finiti o numerabili, non esiste un'unica scelta: il modo in cui definiamo la probabilit\`{a} dipende dal problema che stiamo considerando. Tuttavia possiamo stabilire
\end{flushleft}


\begin{flushleft}
una procedura per definire misure di probabilit\`{a} valide: dal momento che dobbiamo assegnare
\end{flushleft}


\begin{flushleft}
una probabilit\`{a} a ciascun evento, cio\`{e} a ciascun elemento della tribù dei Boreliani, cominciamo
\end{flushleft}


\begin{flushleft}
assegnando una probabilit\`{a} a ciascun intervallo utilizzato per generare la tribù4.5. Vogliamo farlo
\end{flushleft}


\begin{flushleft}
in modo che la probabilit\`{a} dipenda solo dai due estremi dell'intervallo, senza dimenticare che
\end{flushleft}


\begin{flushleft}
anche le altre propriet\`{a} devono essere soddisfatte.
\end{flushleft}





\begin{flushleft}
Esempio 4.4. Una possibile scelta di misura di probabilit\`{a} sull'intervallo unitario [0, 1] \`{e} la
\end{flushleft}


\begin{flushleft}
seguente: interpretiamo ogni intervallo [a, b] contenuto in [0, 1] come un segmento e gli assegniamo come probabilit\`{a} la sua lunghezza. Abbiamo allora P([a, b]) = b $-$ a.
\end{flushleft}


\begin{flushleft}
A partire da questo, possiamo calcolare le probabilit\`{a} degli altri elementi della tribù, anche
\end{flushleft}


\begin{flushleft}
di forma diversa da [a, b], come ad esempio [a, b), sfruttando gli assiomi di Kolmogorov. Infatti,
\end{flushleft}


\begin{flushleft}
preso c tale che b ⩽ c ⩽ 1, abbiamo [a, c] = [a, b) $\cup$ [b, c], in cui l'unione \`{e} disgiunta. Allora
\end{flushleft}


\begin{flushleft}
c $-$ a = P([a, c]) = P([a, b)) + P([b, c]) = P([a, b)) + (c $-$ b),
\end{flushleft}


\begin{flushleft}
da cui P([a, b)) = c $-$ a $-$ (c $-$ b) = b $-$ a. In modo analogo possiamo calcolare la probabilit\`{a} degli altri
\end{flushleft}


\begin{flushleft}
elementi della tribù, ad esempio quella dei singoletti.
\end{flushleft}


\begin{flushleft}
Questa \`{e} una possibile scelta di probabilit\`{a} sull'intervallo [0, 1], che prende anche il nome di
\end{flushleft}


\begin{flushleft}
probabilit\`{a} uniforme o misura di Lebesgue 4.6, ma non \`{e} l'unica.
\end{flushleft}


\begin{flushleft}
4.4. \'{E}mile Borel (1871 -- 1956).
\end{flushleft}


\begin{flushleft}
4.5. Il fatto che questo sia sufficiente a definire una probabilit\`{a} su tutta la tribù dei Boreliani, anche se \`{e} intuitivo, non
\end{flushleft}


\begin{flushleft}
\`{e} un fatto banale. Esiste per\`{o} un risultato, il Teorema di Carath\'{e}odory (Constantin Carath\'{e}odory, 1873 -- 1950), che ce lo
\end{flushleft}


\begin{flushleft}
garantisce, ne vediamo l'enunciato poco oltre.
\end{flushleft}


\begin{flushleft}
4.6. Henri L\'{e}on Lebesgue (1875 -- 1941).
\end{flushleft}





\newpage
58





\begin{flushleft}
COSTRUIRE PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Se vogliamo che la probabilit\`{a} di un intervallo dipenda solo dai suoi estremi, possiamo considerare una funzione F: [0, 1] $\rightarrow$ ℝ, tale che P((a, b]) = F(b) $-$ F(a). Da questo punto di vista la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} nell'Esempio 4.4 \`{e} stata ottenuta scegliendo F(x) = x (la funzione identit\`{a}) nell'intervallo [0, 1]. Chiaramente ci sono altre scelte possibili, come vedremo ora.
\end{flushleft}


\begin{flushleft}
Esempio 4.5. Prendiamo la funzione F: [0, 1] $\rightarrow$ ℝ definita da
\end{flushleft}


1


\begin{flushleft}
\{\{\{ x
\end{flushleft}


\begin{flushleft}
0⩽x$<$
\end{flushleft}


2.


\begin{flushleft}
F(x) = \{
\end{flushleft}


\begin{flushleft}
\{\{ 12 (x + 1) 12 ⩽ x ⩽ 1
\end{flushleft}


\begin{flushleft}
La probabilit\`{a} definita sulla tribù dei Boreliani a partire da P((a, b]) = F(b) $-$ F(a) non \`{e} più quella
\end{flushleft}


\begin{flushleft}
uniforme vista nell'Esempio 4.4. Per certi intervalli (e quindi per certi eventi) le due probabilit\`{a}
\end{flushleft}


1 3


\begin{flushleft}
coincidono, ma possiamo vedere facilmente che su alcuni intervalli, come ad esempio 4 , 4 , esse
\end{flushleft}


\begin{flushleft}
assumono valori diversi. Inoltre, in questo caso, non \`{e} sempre vero che P((a, b]) =P((a, b)). Infatti
\end{flushleft}


1 1


3


1


1


\begin{flushleft}
P 4 , 2 = 4 $-$ 4 = 2 , mentre
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





1 1


,


4 2





\begin{flushleft}
=P
\end{flushleft}





((





1 1


,


4 2





\begin{flushleft}
n$\in$ℕ
\end{flushleft}





1





))





1 1


1


\begin{flushleft}
, $-$n
\end{flushleft}


4 2


1


1


1


\begin{flushleft}
$-$ n $-$F 4
\end{flushleft}


2





\begin{flushleft}
= lim P
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
= lim F
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


1


1





\begin{flushleft}
$-$n
\end{flushleft}





=2 $-$ 4 = 4,


1





\begin{flushleft}
in cui abbiamo dovuto scomodare il passaggio al limite per n che tende a +$\infty$.
\end{flushleft}


\begin{flushleft}
Di conseguenza abbiamo anche che P
\end{flushleft}





1


2





\begin{flushleft}
=P
\end{flushleft}





1 1


,


4 2





\begin{flushleft}
$-$P
\end{flushleft}





1 1


,


4 2





\begin{flushleft}
= 2 $-$ 4 = 4 , mentre si pu\`{o}
\end{flushleft}


1





1





1





\begin{flushleft}
verificare (con l'ausilio dei limiti) che per ogni x $\neq$ 2 in [0, 1], P(\{x\}) = 0.
\end{flushleft}


1





\begin{flushleft}
Non tutte le funzioni F vanno bene, per\`{o}: non dobbiamo dimenticare che stiamo cercando
\end{flushleft}


\begin{flushleft}
delle probabilit\`{a}, quindi gli assiomi dovranno essere soddisfatti. Abbiamo visto, nell'Esempio 4.5,
\end{flushleft}


\begin{flushleft}
che F non deve necessariamente essere continua. Tuttavia deve essere monotona debolmente
\end{flushleft}


\begin{flushleft}
crescente, poich\'{e} per 0 ⩽ a $<$ b $<$ c ⩽ 1,
\end{flushleft}


\begin{flushleft}
F(b) $-$ F(a) = P((a, b]) ⩽ P((a, c]) = F(c) $-$ F(a),
\end{flushleft}


\begin{flushleft}
per la Proposizione 2.28, quindi F(c) ⩾ F(b). Questo ancora non basta: per vedere le altre propriet\`{a} di queste funzioni, conviene per\`{o} passare al caso in cui $\Omega$ \`{e} l'intera retta reale e considerare
\end{flushleft}


\begin{flushleft}
[0, 1] come un caso speciale.
\end{flushleft}


\begin{flushleft}
Se vogliamo lavorare sull'intera retta dei numeri reali ℝ, dobbiamo come prima cosa definire
\end{flushleft}


\begin{flushleft}
nuovamente la tribù che consideriamo. I Boreliani su [0, 1] non sono più sufficienti, ma baster\`{a}
\end{flushleft}


\begin{flushleft}
modificarli un po' per estenderli a tutto ℝ.
\end{flushleft}


\begin{flushleft}
Quali sono queste modifiche? Per comodit\`{a}, al posto dei segmenti prenderemo le semirette
\end{flushleft}


\begin{flushleft}
come mattoni base della nostra costruzione. In particolare, sostituiamo gli intervalli semiaperti
\end{flushleft}


\begin{flushleft}
(a, b] con le semirette sinistre chiuse, cio\`{e} della forma ($-$$\infty$, b], con b $\in$ℝ (e non più limitato al solo
\end{flushleft}


\begin{flushleft}
intervallo [0, 1]).
\end{flushleft}


\begin{flushleft}
A partire da queste semirette possiamo generare, con le solite operazioni di unione numerabile e passaggio al complementare, gli intervalli (aperti, chiusi e semiaperti), i singoletti, le semirette sinistre aperte e le semirette destre aperte e chiuse, nonch\'{e} tutte le loro unioni: abbiamo
\end{flushleft}


\begin{flushleft}
quindi dei buoni generatori. La tribù generata dalle semirette sinistre chiuse prende il nome di
\end{flushleft}


\begin{flushleft}
tribù dei Boreliani (su ℝ) e viene indicata con ℬ(ℝ) (o brevemente con ℬ)4.7. La sua cardinalit\`{a} \`{e} anche in questo caso quella del continuo.
\end{flushleft}


\begin{flushleft}
4.7. Si pu\`{o} ottenere la stessa tribù anche usando altri generatori, ma come vedremo questa scelta \`{e} particolarmente
\end{flushleft}


\begin{flushleft}
comoda per definire le probabilit\`{a}.
\end{flushleft}





\begin{flushleft}
\newpage
4.2 LO SPAZIO DEI NUMERI REALI
\end{flushleft}





59





\begin{flushleft}
Per definire una probabilit\`{a} sullo spazio probabilizzabile (ℝ,ℬ), sfruttiamo la medesima idea
\end{flushleft}


\begin{flushleft}
vista per l'intervallo unitario: la faremo dipendere solamente dagli estremi. In questo caso per\`{o}
\end{flushleft}


\begin{flushleft}
abbiamo un solo estremo {``}agibile'': il secondo. Allora definiamo la probabilit\`{a} della semiretta
\end{flushleft}


\begin{flushleft}
($-$$\infty$, b] come funzione del solo estremo b, mediante un'opportuna funzione F definita su tutti i
\end{flushleft}


\begin{flushleft}
reali: P(($-$$\infty$, b]) = F(b). Questo \`{e} del tutto compatibile con quanto visto prima: per differenza di
\end{flushleft}


\begin{flushleft}
insiemi abbiamo infatti che P((a, b]) = P(($-$$\infty$, b]) $-$ P(($-$$\infty$, a]) = F(b) $-$ F(a).
\end{flushleft}


\begin{flushleft}
Non tutte le funzioni F vanno bene, tuttavia. Abbiamo gi\`{a} visto che F deve essere monotona
\end{flushleft}


\begin{flushleft}
non decrescente, ma ora non possiamo più avere come probabilit\`{a} la lunghezza dei segmenti,
\end{flushleft}


\begin{flushleft}
ossia F uguale all'identit\`{a}: dal momento che le semirette hanno lunghezza infinita, non potremmo
\end{flushleft}


\begin{flushleft}
più rispettare gli assiomi di Kolmogorov4.8.
\end{flushleft}


\begin{flushleft}
Abbiamo per\`{o} una buona caratterizzazione delle funzioni ammesse: sono quelle funzioni F:
\end{flushleft}


\begin{flushleft}
ℝ $\rightarrow$ ℝ tali che
\end{flushleft}


\begin{flushleft}
$\bullet$ F \`{e} non decrescente (o debolmente crescente);
\end{flushleft}


\begin{flushleft}
$\bullet$ esiste il limite di F(x) per x che tende a +$\infty$ e vale lim F(x) = 1;
\end{flushleft}


\begin{flushleft}
x$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
$\bullet$ esiste il limite di F(x) per x che tende a $-$$\infty$ e vale lim F(x) = 0;
\end{flushleft}


\begin{flushleft}
x$\rightarrow$$-$$\infty$
\end{flushleft}





\begin{flushleft}
$\bullet$ in ogni punto x 0 la funzione F \`{e} continua a destra, cio\`{e} lim+ F(x) = F(x0) e limitata a sinistra,
\end{flushleft}


\begin{flushleft}
x$\rightarrow$x 0
\end{flushleft}


\begin{flushleft}
ossia lim$-$ F(x) ⩽ F(x0).
\end{flushleft}


\begin{flushleft}
x$\rightarrow$x 0
\end{flushleft}





\begin{flushleft}
La prima di queste propriet\`{a} ci \`{e} familiare e segue dalla monotonia della probabilit\`{a}. Le due
\end{flushleft}


\begin{flushleft}
successive seguono dal fatto che P($\Omega$) = P(ℝ) = 1. L'ultima propriet\`{a} (o meglio, le due propriet\`{a}
\end{flushleft}


\begin{flushleft}
all'ultimo punto) possono apparire più sorprendenti. In realt\`{a} servono per darci la possibilit\`{a} di
\end{flushleft}


\begin{flushleft}
assegnare a un punto una probabilit\`{a} diversa da 0:
\end{flushleft}


\begin{flushleft}
P(\{x0\})=P(($-$$\infty$, x0]) $-$ P
\end{flushleft}





(((





\begin{flushleft}
$-$$\infty$, x 0 $-$ n
\end{flushleft}


1





\begin{flushleft}
n$\in$ℕ
\end{flushleft}


1


\begin{flushleft}
x0 $-$ n
\end{flushleft}





\begin{flushleft}
=F(x 0) $-$ lim F
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
=F(x 0) $-$ lim$-$ F(x).
\end{flushleft}





)))





\begin{flushleft}
x$\rightarrow$x0
\end{flushleft}





\begin{flushleft}
Allo stesso tempo ci garantiscono che la probabilit\`{a} si comporta bene anche in tali punti e, in
\end{flushleft}


\begin{flushleft}
particolare,
\end{flushleft}


\begin{flushleft}
lim F b + n $-$ F(a) = lim P
\end{flushleft}


1





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
a, b + n
\end{flushleft}


1





\begin{flushleft}
= P((a, b]) = F(b) $-$ F(a).
\end{flushleft}





\begin{flushleft}
Insomma, ci basta definire una funzione F di questo tipo per avere una probabilit\`{a} sulla retta
\end{flushleft}


\begin{flushleft}
reale4.9.
\end{flushleft}


\begin{flushleft}
Esempio 4.6. Consideriamo la funzione F: ℝ $\rightarrow$ ℝ definita da
\end{flushleft}


\begin{flushleft}
F(x) =
\end{flushleft}





\begin{flushleft}
\{\{ 01 $-$ e
\end{flushleft}





\begin{flushleft}
$-$x
\end{flushleft}





\begin{flushleft}
x$<$0
\end{flushleft}


.


\begin{flushleft}
x⩾0
\end{flushleft}





\begin{flushleft}
Questa funzione soddisfa le propriet\`{a} viste sopra (\`{e} addirittura continua in ogni punto), quindi
\end{flushleft}


\begin{flushleft}
definisce una probabilit\`{a}. Possiamo in particolare vedere che ogni intervallo non vuoto nei reali
\end{flushleft}


\begin{flushleft}
positivi ha una probabilit\`{a} strettamente positiva:
\end{flushleft}


\begin{flushleft}
P((a, b]) = F(b) $-$ F(a) = 1 $-$ e $-$b $-$ 1 + e $-$a = e $-$a $-$ e $-$b,
\end{flushleft}


\begin{flushleft}
mentre ogni singoletto ha probabilit\`{a} 0 (conseguenza del fatto che F \`{e} continua).
\end{flushleft}


\begin{flushleft}
4.8. Non possiamo nemmeno prendere una funzione che sia proporzionale alla lunghezza dei segmenti, perch\'{e}
\end{flushleft}


\begin{flushleft}
avremmo il medesimo problema.
\end{flushleft}


\begin{flushleft}
4.9. Stiamo ancora imbrogliando, perch\'{e} stiamo sfruttando in silenzio il Teorema di Carath\'{e}odory gi\`{a} nominato in
\end{flushleft}


\begin{flushleft}
precedenza.
\end{flushleft}





\newpage
60





\begin{flushleft}
COSTRUIRE PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Non possiamo davvero apprezzarlo qui, ma imparare a costruire una misura di probabilit\`{a} (e
\end{flushleft}


\begin{flushleft}
quindi uno spazio di probabilit\`{a}) sui reali \`{e} un ottimo investimento, se non addirittura il migliore
\end{flushleft}


\begin{flushleft}
che possiamo fare. \`{E} infatti possibile trasformare ogni esperimento aleatorio in uno equivalente
\end{flushleft}


\begin{flushleft}
in cui lo spazio probabilizzabile sia (ℝ, ℬ) e tutte le caratteristiche peculiari del problema siano
\end{flushleft}


\begin{flushleft}
codificate dalla probabilit\`{a} P (cio\`{e} dalla funzione F, che come vedremo prende il nome di funzione
\end{flushleft}


\begin{flushleft}
di ripartizione). Questo \`{e} reso possibile dalla nozione di variabile aleatoria o casuale4.10.
\end{flushleft}





\begin{flushleft}
4.2.1. Il teorema di Carath\'{e}odory
\end{flushleft}


\begin{flushleft}
Il Teorema di Carath\'{e}odory \`{e} lo strumento che permette di definire la probabilit\`{a} su $\Omega$ dandone
\end{flushleft}


\begin{flushleft}
il valore su una piccola parte degli eventi e non su tutti quelli che stanno nella tribù. Per poter
\end{flushleft}


\begin{flushleft}
fare ci\`{o}, per\`{o}, non possiamo prendere una famiglia qualunque di eventi, ma dobbiamo prenderne
\end{flushleft}


\begin{flushleft}
una abbastanza ricca. Una possibilit\`{a} \`{e} quella di prendere un'algebra: se abbiamo una funzione
\end{flushleft}


\begin{flushleft}
su quest'algebra che si comporta come una probabilit\`{a}, allora la possiamo estendere a una probabilit\`{a} vera e propria definita sulla tribù generata da 𝒜.
\end{flushleft}


\begin{flushleft}
TEOREMA 4.7. (CARATH\'{E}ODORY) Dati un insieme $\Omega$, un'algebra 𝒜 di sottoinsiemi di $\Omega$ e una funzione
\end{flushleft}


\begin{flushleft}
P0: 𝒜 $\rightarrow$ [0, 1] che ha le propriet\`{a} di una probabilit\`{a}, allora esiste un'unica probabilit\`{a} P su ($\Omega$, 𝜎(𝒜)) che
\end{flushleft}


\begin{flushleft}
coincide con P0 su 𝒜.
\end{flushleft}





\begin{flushleft}
4.3. SPAZI PRODOTTO
\end{flushleft}


\begin{flushleft}
In probabilit\`{a} succede spesso che qualcosa possa essere visto come una combinazione di più fenomeni aleatori. Quando questi sono distinti e non si influenzano a vicenda (sono indipendenti,
\end{flushleft}


\begin{flushleft}
come visto nel Capitolo 3), possiamo descriverli tutti assieme come spazio prodotto, portandoci
\end{flushleft}


\begin{flushleft}
dietro quello che sappiamo sulle varie componenti. Per farci un'idea, vediamo qualche esempio.
\end{flushleft}


\begin{flushleft}
Esempio 4.8. Se lanciamo un dado a 4 facce e una moneta, possiamo scrivere gli esiti come coppie
\end{flushleft}


\begin{flushleft}
ordinate in cui la prima componente \`{e} l'esito del lancio del dado e la seconda l'esito del lancio
\end{flushleft}


\begin{flushleft}
della moneta. In altre parole, $\Omega$ = \{(1, T), (2, T), (3, T), (4, T), (1, C), (2, C), (3, C), (4, C)\}. Come
\end{flushleft}


\begin{flushleft}
insieme, questo \`{e} il prodotto cartesiano dei due insiemi universo $\Omega$ 1 = \{1, 2, 3, 4\} e $\Omega$ 2 = \{T, C\}, cio\`{e}
\end{flushleft}


\begin{flushleft}
$\Omega$ = $\Omega$ 1 × $\Omega$ 2. Se assumiamo che il dado e la moneta non si influenzino, possiamo definire una
\end{flushleft}


\begin{flushleft}
probabilit\`{a} su questo spazio a partire dalle probabilit\`{a} del dado e della moneta, ovviamente su
\end{flushleft}


\begin{flushleft}
un'opportuna tribù.
\end{flushleft}


\begin{flushleft}
Esempio 4.9. Prendiamo ora n monete tutte uguali tra loro e lanciamole (o in alternativa prendiamo una sola moneta e lanciamola n volte). In questo caso uno spazio naturale per descrivere
\end{flushleft}


\begin{flushleft}
il fenomeno \`{e} quello delle n-uple ordinate di elementi di $\Omega$ 1 = \{T, C\}, cio\`{e} $\Omega$ = ($\Omega$ 1) n. E se pensassimo di lanciare la moneta infinite volte? Avremmo che un esito \`{e} una successione di elementi
\end{flushleft}


\begin{flushleft}
di $\Omega$ 1, cio\`{e} avremmo $\Omega$ = ($\Omega$ 1)ℕ. In entrambi i casi, per\`{o}, per poter calcolare probabilit\`{a} di eventi
\end{flushleft}


\begin{flushleft}
abbiamo bisogno di definire una tribù ℱ e una funzione di probabilit\`{a} P. Nel secondo caso possiamo identificare $\Omega$ con \{0, 1\}ℕ, che a sua volta possiamo identificare coi numeri reali in [0, 1]:
\end{flushleft}


\begin{flushleft}
potremmo allora usare quanto visto nella Sezione 4.2. Questo maschererebbe per\`{o} la struttura
\end{flushleft}


\begin{flushleft}
di ``esperimento ripetuto'' che invece \`{e} più facilmente riconoscibile nella rappresentazione come
\end{flushleft}


\begin{flushleft}
prodotto (infinito).
\end{flushleft}


\begin{flushleft}
Come primo caso, consideriamo il prodotto di due esperimenti aleatori descritti rispettivamente dagli spazi di probabilit\`{a} ($\Omega$ 1, ℱ 1, P1) e ($\Omega$ 2, ℱ 2, P2). Vogliamo costruire uno spazio di
\end{flushleft}


\begin{flushleft}
probabilit\`{a} ($\Omega$, ℱ,P) che descriva la coppia di esperimenti. Iniziamo dallo spazio degli esiti: come
\end{flushleft}


\begin{flushleft}
abbiamo gi\`{a} detto nell'Esempio 4.8, \`{e} ragionevole prendere il prodotto cartesiano $\Omega$ = $\Omega$ 1 × $\Omega$ 2.
\end{flushleft}


\begin{flushleft}
4.10. Incontreremo di nuovo le variabili aleatorie nel Capitolo 5.
\end{flushleft}





\begin{flushleft}
\newpage
4.3 SPAZI PRODOTTO
\end{flushleft}





61





\begin{flushleft}
Passiamo allora alla tribù: ℱ sar\`{a} generata dai prodotti di elementi delle due tribù ℱ 1 e ℱ 2,
\end{flushleft}


\begin{flushleft}
quindi
\end{flushleft}


\begin{flushleft}
ℱ = ℱ 1 $\otimes$ ℱ 2 = 𝜎(\{E1 × E 2 : E1 $\in$ ℱ 1, E 2 $\in$ ℱ 2\}),
\end{flushleft}


\begin{flushleft}
cio\`{e} ℱ \`{e} la tribù generata dai rettangoli in cui la prima coordinata \`{e} data dal primo esperimento
\end{flushleft}


\begin{flushleft}
e la seconda coordinata dal secondo. Non ci fermiamo alla famiglia dei rettangoli, ma ne prendiamo la tribù generata perch\'{e} vogliamo essere sicuri di avere una famiglia di insiemi che sia una
\end{flushleft}


\begin{flushleft}
tribù. Usando l'analogia geometrica, vogliamo che nella tribù ci siano anche altre figure (triangoli, cerchi...), che costruiamo come unione numerabile di rettangoli (o complementari).
\end{flushleft}


\begin{flushleft}
Come ultimo passo, dobbiamo parlare della probabilit\`{a} P. Ancora una volta vogliamo mettere
\end{flushleft}


\begin{flushleft}
in evidenza che si tratta di una combinazione di esperimenti, quindi vorremmo che la proiezione
\end{flushleft}


\begin{flushleft}
su ogni coordinata fosse la probabilit\`{a} del corrispondente esperimento singolo, cio\`{e} che la probabilit\`{a} di ogni esperimento di $\Omega$ 1 fosse inalterata nel prodotto con $\Omega$ 2 e viceversa.
\end{flushleft}


\begin{flushleft}
Possiamo ottenere una probabilit\`{a} P con le propriet\`{a} richieste se la definiamo, per ogni rettangolo E 1 × E2 in ℱ = ℱ 1 $\otimes$ ℱ 2, come
\end{flushleft}


\begin{flushleft}
P (E1 × E 2) = P1(E 1) ⋅ P2(E2).
\end{flushleft}





(4.1)





\begin{flushleft}
Questo giustifica anche la notazione P = P1 $\otimes$ P2. Si pu\`{o} obiettare che la (4.1) non definisce da sola
\end{flushleft}


\begin{flushleft}
una probabilit\`{a} per ogni elemento di ℱ se, come abbiamo detto, non ogni elemento di ℱ \`{e} un rettangolo. Tuttavia, potendo scrivere ogni elemento di ℱ a partire da rettangoli, mediante unione
\end{flushleft}


\begin{flushleft}
e complementare, e sapendo come si comporta la probabilit\`{a} rispetto all'unione (disgiunta) e al
\end{flushleft}


\begin{flushleft}
complementare, possiamo limitarci a definirla sui rettangoli e l'estensione sar\`{a} unica4.11.
\end{flushleft}


\begin{flushleft}
Esempio 4.10. Tornando all'Esempio 4.8, osserviamo che nella tribù ℱ non ci sono solo i prodotti
\end{flushleft}


\begin{flushleft}
di elementi delle due tribù ℱ 1 e ℱ 2: infatti il complementare di \{1\} × \{C\} non pu\`{o} essere scritto
\end{flushleft}


\begin{flushleft}
come prodotto (in particolare non \`{e} \{2, 3, 4\} × \{T\}, che non contiene la coppia (1, T), che appartiene al complementare di \{1\} × \{C\}). Dobbiamo prendere la tribù generata, che contiene anche
\end{flushleft}


\begin{flushleft}
tutti i complementari e le unioni di rettangoli (cio\`{e} di prodotti di elementi di ℱ 1 e ℱ 2).
\end{flushleft}


\begin{flushleft}
La probabilit\`{a} dell'evento \{(1, T)\}, supponendo il dado equilibrato e la moneta non truccata,
\end{flushleft}


1


\begin{flushleft}
sar\`{a} P(\{(1, T)\}) = P1(\{1\}) ⋅ P2(\{T\}) = 8 , mentre quella dell'evento (\{1, 2\} × \{C\}) c sar\`{a}
\end{flushleft}


1 3


\begin{flushleft}
P((\{1, 2\} × \{C\})c) = 1 $-$ P (\{1, 2\} × \{C\}) = 1 $-$ P1(\{1, 2\}) ⋅ P2(\{C\}) = 1 $-$ = .
\end{flushleft}


4 4


\begin{flushleft}
In modo analogo possiamo fare per un numero finito di esperimenti distinti quello che abbiamo
\end{flushleft}


\begin{flushleft}
mostrato per due esperimenti. Possiamo anche passare a una quantit\`{a} numerabile, ma vedremo
\end{flushleft}


\begin{flushleft}
i dettagli solamente in un caso speciale: quello degli esperimenti ripetuti.
\end{flushleft}


\begin{flushleft}
Parliamo di esperimenti ripetuti quando tutti gli esperimenti sono copie identiche del medesimo esperimento, cio\`{e} possono essere tutti descritti con lo stesso spazio di probabilit\`{a} ($\Omega$ S, ℱ S,
\end{flushleft}


\begin{flushleft}
PS). Ne abbiamo visti due nell'Esempio 4.9: il lancio di n monete uguali o quello di infinite (numerabili) monete uguali.
\end{flushleft}


\begin{flushleft}
Nel caso di un numero finito di ripetizioni, abbiamo una versione semplificata di quanto visto
\end{flushleft}


\begin{flushleft}
per il prodotto di esperimenti qualunque: abbiamo infatti (considerando ad esempio due sole
\end{flushleft}


\begin{flushleft}
ripetizioni) che $\Omega$ = $\Omega$ 1 × $\Omega$ 2 = $\Omega$ S2, perch\'{e} i due spazi dei singoli elementi coincidono; abbiamo
\end{flushleft}


\begin{flushleft}
inoltre che la tribù
\end{flushleft}





\begin{flushleft}
ℱ = ℱ S $\otimes$ ℱ S = ℱ S2 = 𝜎(\{E1 × E 2 : E 1 $\in$ ℱ S, E 2 $\in$ ℱ S\})
\end{flushleft}


\begin{flushleft}
e che la probabilit\`{a} P = PS2.
\end{flushleft}


\begin{flushleft}
Esempio 4.11. Francesco lancia 6 volte una moneta truccata (o una volta sei monete truccate
\end{flushleft}


\begin{flushleft}
identiche tra loro), che d\`{a} testa con probabilit\`{a} p e croce con probabilit\`{a} 1 $-$ p. Con che probabilit\`{a}
\end{flushleft}


\begin{flushleft}
i primi due lanci sono entrambi testa? Con che probabilit\`{a} i primi tre lanci non sono tutti uguali
\end{flushleft}


\begin{flushleft}
tra loro?
\end{flushleft}


\begin{flushleft}
4.11. Ancora una volta stiamo facendo le cose più facili di quanto non siano in realt\`{a}: anche qui viene in aiuto il
\end{flushleft}


\begin{flushleft}
Teorema di Carath\'{e}odory, che garantisce che tale estensione \`{e} unica.
\end{flushleft}





\newpage
62





\begin{flushleft}
COSTRUIRE PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Come spazio $\Omega$ abbiamo \{T, C\}6 o \{0, 1\}6. La tribù \`{e} quella generata dai rettangoli, mentre la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} su ciascuna componente vale 0 sull'insieme vuoto, p su \{T\}, 1 $-$ p su \{C\} e 1 su $\Omega$ S = \{T,
\end{flushleft}


\begin{flushleft}
C\}. Il primo evento cui siamo interessati, ``i primi due lanci sono entrambi testa'', \`{e} \{T\} × \{T\} × $\Omega$ S4,
\end{flushleft}


\begin{flushleft}
la cui probabilit\`{a} \`{e}
\end{flushleft}


\begin{flushleft}
P (\{T\} × \{T\} × $\Omega$ S4) = P(\{T\})2 P($\Omega$ S)4 = p 2 14 = p 2.
\end{flushleft}


\begin{flushleft}
Il secondo evento \`{e} un po' più complicato: lo possiamo scrivere come unione di rettangoli, oppure
\end{flushleft}


\begin{flushleft}
in modo più semplice come complementare di unione di rettangoli,
\end{flushleft}


\begin{flushleft}
E = (\{T\} × \{T\} × \{T\} × $\Omega$ S3 $\cup$ \{C\} × \{C\} × \{C\} × $\Omega$ S3)c.
\end{flushleft}


\begin{flushleft}
Per quanto riguarda la probabilit\`{a} abbiamo allora
\end{flushleft}


\begin{flushleft}
P(E)=1 $-$ P (\{T\} × \{T\} × \{T\} × $\Omega$ S3 $\cup$ \{C\} × \{C\} × \{C\} × $\Omega$ S3)
\end{flushleft}


\begin{flushleft}
=1 $-$ P (\{T\} × \{T\} × \{T\} × $\Omega$ S3) $-$ P (\{C\} × \{C\} × \{C\} × $\Omega$ S3)
\end{flushleft}


\begin{flushleft}
=1 $-$ p 3 $-$ (1 $-$ p) 3
\end{flushleft}


\begin{flushleft}
=3 p $-$ 3 p 2,
\end{flushleft}


\begin{flushleft}
dove nel secondo passaggio abbiamo usato che i due eventi \{T\} × \{T\} × \{T\} × $\Omega$ S3 e \{C\} × \{C\} × \{C\} ×
\end{flushleft}


\begin{flushleft}
$\Omega$ S3 sono disgiunti, dal momento che le sestuple nei due insiemi hanno sicuramente le prime tre
\end{flushleft}


\begin{flushleft}
coordinate distinte e sono quindi diverse.
\end{flushleft}


\begin{flushleft}
Passiamo al caso di infinite ripetizioni di uno stesso esperimento ($\Omega$ S,ℱ S,PS): siamo alla ricerca
\end{flushleft}


\begin{flushleft}
di un unico spazio ($\Omega$, ℱ,P) che le descriva tutte assieme. Cominciamo come sempre dallo spazio
\end{flushleft}


\begin{flushleft}
$\Omega$: esso sar\`{a} costituito da successioni di elementi di $\Omega$ S, quindi $\Omega$ = $\Omega$ℕ
\end{flushleft}


\begin{flushleft}
S . Fin qui nulla di difficile.
\end{flushleft}


\begin{flushleft}
Ci dedichiamo ora alla tribù ℱ. Qui, almeno in apparenza, quando le ripetizioni sono infinite
\end{flushleft}


\begin{flushleft}
le cose si complicano: ci sono troppe componenti da controllare. Proviamo dunque a sfruttare le
\end{flushleft}


\begin{flushleft}
idee viste prima e a concentrarci solo sulla ricerca dei generatori della tribù. Non solo, cerchiamo
\end{flushleft}


\begin{flushleft}
anche di imparare da quanto visto nella Sezione 4.2 per ℝ.
\end{flushleft}


\begin{flushleft}
Una cosa che possiamo fare \`{e} fissare un numero naturale n e mettere in un unico insieme tutti
\end{flushleft}


\begin{flushleft}
gli elementi 𝜔 $\in$ $\Omega$ che hanno in comune le prime n coordinate. Possiamo farlo per ogni numero
\end{flushleft}


\begin{flushleft}
naturale n, considerando per ciascun n tutte le possibili n-uple di elementi di $\Omega$ S. Questi insiemi,
\end{flushleft}


\begin{flushleft}
al variare di n, prendono il nome di n-cilindri, perch\'{e} come i cilindri geometrici sono caratterizzati
\end{flushleft}


\begin{flushleft}
dall'avere una sezione fissata (le prime n componenti).
\end{flushleft}


\begin{flushleft}
Prendiamo allora la collezione 𝒞 di tutti gli n-cilindri al variare di n: la chiamiamo famiglia degli
\end{flushleft}


\begin{flushleft}
insiemi cilindrici. Analogamente a quanto abbiamo visto per i rettangoli, la famiglia dei cilindri
\end{flushleft}


\begin{flushleft}
in generale non \`{e} una tribù. Possiamo per\`{o} usarla per generarne una: ℱ = 𝜎(𝒞), che \`{e} una tribù
\end{flushleft}


\begin{flushleft}
su $\Omega$ℕ.
\end{flushleft}


\begin{flushleft}
Avendo costruito spazio e tribù, non resta che l'ultimo passo, la probabilit\`{a}. Per definirla
\end{flushleft}


\begin{flushleft}
usiamo la forma dei cilindri che generano la tribù ℱ e il fatto che stiamo parlando di esperimenti ripetuti: su ogni cilindro definiamo la probabilit\`{a} come il prodotto della probabilit\`{a} PS su
\end{flushleft}


\begin{flushleft}
ciascuna delle n componenti del cilindro e di fattori 1 per tutte le altre (in sostanza le stiamo
\end{flushleft}


\begin{flushleft}
ignorando). In questo modo abbiamo una probabilit\`{a} che generalizza al caso infinito quanto gi\`{a}
\end{flushleft}


\begin{flushleft}
visto per il caso del prodotto finito: per una successione di eventi E i $\in$ ℱ S abbiamo che la probabilit\`{a} dell'evento ⨂+$\infty$
\end{flushleft}


\begin{flushleft}
i=1 E i $\in$ ℱ \`{e}
\end{flushleft}


\begin{flushleft}
P(
\end{flushleft}


(





+$\infty$


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
E)
\end{flushleft}


)=





+$\infty$





\begin{flushleft}
PS(E i).
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
In realt\`{a}, stiamo tacendo molti dettagli: non abbiamo la pretesa di essere precisi e nemmeno lo
\end{flushleft}


\begin{flushleft}
spazio o i prerequisiti per poterlo fare, ma vogliamo solo farci un'idea. Per vedere a fondo tutti i
\end{flushleft}


\begin{flushleft}
dettagli, ancora una volta, \`{e} necessario prendere in mano un libro di testo avanzato o seguire un
\end{flushleft}


\begin{flushleft}
corso universitario di probabilit\`{a} o di teoria della misura.
\end{flushleft}





\begin{flushleft}
\newpage
4.4 FARSI LE OSSA
\end{flushleft}





63





\begin{flushleft}
Un'ultima osservazione, prima di passare a qualche esempio: quello che abbiamo fatto per la
\end{flushleft}


\begin{flushleft}
ripetizione infinita di un esperimento pu\`{o} essere adattato al caso del prodotto infinito di esperimenti non necessariamente uguali tra loro. Anche in tal caso possiamo definire dei cilindri,
\end{flushleft}


\begin{flushleft}
in cui per\`{o} le componenti devono essere {``}pescate'' dagli spazi corrispondenti alla coordinata in
\end{flushleft}


\begin{flushleft}
questione. Questo appesantisce la notazione, ma non cambia la sostanza.
\end{flushleft}


\begin{flushleft}
Esempio 4.12. Federico ha infinite monete identiche tra loro, ciascuna delle quali d\`{a} testa con
\end{flushleft}


\begin{flushleft}
probabilit\`{a} p e croce con probabilit\`{a} 1 $-$ p. Come sempre possiamo pensare che in realt\`{a} ne abbia
\end{flushleft}


\begin{flushleft}
una sola e la lanci infinite volte. Con che probabilit\`{a} Federico ottiene la prima testa al k-esimo
\end{flushleft}


\begin{flushleft}
lancio?
\end{flushleft}


\begin{flushleft}
Osserviamo che in questo esempio non possiamo fissare a priori un numero massimo di lanci
\end{flushleft}


\begin{flushleft}
(o di monete), perch\'{e} qualunque sia questo numero, potremmo avere croci in tutti questi lanci
\end{flushleft}


\begin{flushleft}
(improbabile, al crescere del numero dei lanci, ma mai con probabilit\`{a} identicamente zero). Ha
\end{flushleft}


\begin{flushleft}
allora senso considerare una ripetizione infinita dell'esperimento ``lancio di una moneta''4.12. Qual
\end{flushleft}


\begin{flushleft}
\`{e} l'evento del quale vogliamo calcolare la probabilit\`{a}? \`{E} un k-cilindro le cui prime k $-$ 1 componenti sono C e la cui k-esima componente \`{e} T. Delle successive non ci interessa. Sappiamo
\end{flushleft}


\begin{flushleft}
che i cilindri stanno nella tribù, dal momento che ne sono i generatori. La probabilit\`{a} di questo
\end{flushleft}


\begin{flushleft}
cilindro \`{e}
\end{flushleft}


\begin{flushleft}
PS(\{C\})k $-$1 PS(\{T\})
\end{flushleft}





+$\infty$





\begin{flushleft}
1 = (1 $-$ p) k $-$1 p.
\end{flushleft}





\begin{flushleft}
i=k +1
\end{flushleft}





\begin{flushleft}
4.4. FARSI LE OSSA
\end{flushleft}


\begin{flushleft}
Nelle sezioni precedenti abbiamo visto alcuni modi per costruire spazi di probabilit\`{a}. Non \`{e} per\`{o}
\end{flushleft}


\begin{flushleft}
garantito che siano i migliori per i particolari problemi che incontreremo, n\'{e} che in ogni problema
\end{flushleft}


\begin{flushleft}
avremo tutte le informazioni necessarie per costruirli nei modi visti, pur avendo magari tutto
\end{flushleft}


\begin{flushleft}
quello che ci serve per arrivare a una soluzione.
\end{flushleft}


\begin{flushleft}
Esempio 4.13. Supponiamo di avere un dado a 6 facce, di cui sappiamo che P(1)= 6 . Se volessimo
\end{flushleft}


\begin{flushleft}
procedere come visto nella Sezione 4.1 e ci concentrassimo su $\Omega$ = \{1,..., 6\}, dovremmo assegnare
\end{flushleft}


\begin{flushleft}
una probabilit\`{a} a tutte le facce del dado. Per\`{o} non possiamo farlo, perch\'{e} non abbiamo alcuna
\end{flushleft}


\begin{flushleft}
informazione sulle altre facce. Potremmo assumere che il dado sia bilanciato e che quindi tutte
\end{flushleft}


\begin{flushleft}
le facce escano con la medesima probabilit\`{a}, ma il risultato che otterremmo sarebbe vero solo se
\end{flushleft}


\begin{flushleft}
questa ipotesi fosse soddisfatta, cosa che non abbiamo la possibilit\`{a} di controllare.
\end{flushleft}


1





\begin{flushleft}
Alle volte la formulazione del problema ci suggerisce una costruzione diversa da quella standard. Come possiamo accorgercene? \`{E} un'attivit\`{a} creativa e non meccanica: dobbiamo fare
\end{flushleft}


\begin{flushleft}
apprendistato, il solo modo di allenare l'occhio e la mano \`{e} fare tanti esercizi. Dobbiamo cercare soluzioni diverse alle quali ispirarci in futuro per affrontare altri problemi, in particolare
\end{flushleft}


\begin{flushleft}
quelli in cui i metodi standard non funzioneranno. Per questo stesso motivo, uno dei metodi
\end{flushleft}


\begin{flushleft}
migliori per allenarsi a risolvere problemi \`{e} risolvere altri problemi e confrontare le proprie soluzioni con quelle altrui. P\'{o}lya4.13 nel suo libro Come risolvere i problemi di matematica indica tra
\end{flushleft}


\begin{flushleft}
le diverse euristiche per trovare una soluzione a un problema quella di cercare un altro problema,
\end{flushleft}


\begin{flushleft}
analogo o simile, del quale ci sia nota una soluzione, per poi cercare di adattare quest'ultima
\end{flushleft}


\begin{flushleft}
al problema corrente. Parla per\`{o} di euristiche, non di teoremi, perch\'{e} questa somiglianza non
\end{flushleft}


\begin{flushleft}
\`{e} definita in modo formale, poich\'{e} esula dagli scopi del testo: sta a noi individuarla e sfruttarla.
\end{flushleft}


\begin{flushleft}
4.12. Questo esperimento costituito da una ripetizione infinita del lancio di una moneta si chiama anche processo (o
\end{flushleft}


\begin{flushleft}
schema) di Bernoulli (Jakob Bernoulli 1654 -- 1705). Il modello che descrive il primo istante di successo in un processo di
\end{flushleft}


\begin{flushleft}
Bernoulli si chiama, per alcuni, geometrico. Lo rivedremo più avanti, nel Capitolo 8.
\end{flushleft}


\begin{flushleft}
4.13. Gy\"{o}rgy P\'{o}lya (1887 -- 1985).
\end{flushleft}





\newpage
64





\begin{flushleft}
COSTRUIRE PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Nel caso dei problemi di probabilit\`{a}, dobbiamo imparare a estrarre gli oggetti giusti dal testo
\end{flushleft}


\begin{flushleft}
che abbiamo: non solo la probabilit\`{a}, ma prima di essa lo spazio degli esiti e la tribù. In particolare
\end{flushleft}


\begin{flushleft}
\`{e} un ottimo esercizio, soprattutto all'inizio, essere molto precisi (quasi noiosi) nello scrivere esplicitamente cosa scegliamo come spazio degli esiti e come tribù, perch\'{e} quest'accortezza ci eviter\`{a}
\end{flushleft}


\begin{flushleft}
di prendere dei granchi, come ad esempio definire una probabilit\`{a} su coppie ordinate, quando gli
\end{flushleft}


\begin{flushleft}
oggetti su cui stiamo lavorando magari sono coppie non ordinate.
\end{flushleft}


\begin{flushleft}
Esempio 4.14. In una noiosa serata di lockdown, due amici si danno appuntamento su Zoom per
\end{flushleft}


\begin{flushleft}
passare assieme la serata. Per rendere più elettrizzante l'appuntamento, si mettono d'accordo
\end{flushleft}


\begin{flushleft}
nel modo seguente: ciascuno di loro si impegna a connettersi in un orario compreso tra le 22 e
\end{flushleft}


\begin{flushleft}
le 23 e a restare online in attesa per 5 minuti. Passati questi 5 minuti (o allo scoccare delle 23) si
\end{flushleft}


\begin{flushleft}
disconnetter\`{a}. Con che probabilit\`{a} i due amici si incontreranno su Zoom?
\end{flushleft}


\begin{flushleft}
La prima volta che si affronta un problema di questo tipo, la tentazione più forte \`{e} quella
\end{flushleft}


\begin{flushleft}
di discretizzare in minuti o secondi. In questo caso, per\`{o}, il tempo va considerato una quantit\`{a}
\end{flushleft}


\begin{flushleft}
continua. Concentriamoci allora su uno dei due amici. Con che probabilit\`{a} arriver\`{a} nei primi
\end{flushleft}


1


\begin{flushleft}
dieci minuti dell'ora? Il segmento favorevole \`{e} lungo 6 del segmento totale (10 minuti su 60),
\end{flushleft}


1


\begin{flushleft}
quindi la probabilit\`{a} che arrivi in quei dieci minuti \`{e} proprio 6 . Analogamente, la probabilit\`{a}
\end{flushleft}


1


\begin{flushleft}
che il secondo amico arrivi tra le 22.21 e le 22.41 \`{e} 3 , poich\'{e} c'\`{e} un intervallo lungo 20 (minuti)
\end{flushleft}


\begin{flushleft}
favorevole su un intervallo totale lungo 60 (minuti).
\end{flushleft}


\begin{flushleft}
In questo ragionamento, per\`{o}, stiamo considerando i due amici separatamente e stiamo trascurando il fatto che sono disposti ad aspettare. Se sapessimo che il primo amico arriva alle 22.13,
\end{flushleft}


\begin{flushleft}
allora la probabilit\`{a} che i due si incontrino sarebbe uguale alla probabilit\`{a} che il secondo arrivi
\end{flushleft}


1


\begin{flushleft}
nei 5 minuti precedenti alle 22.13 o nei 5 minuti successivi, cio\`{e} 6 .
\end{flushleft}


\begin{flushleft}
\`{E} arrivato il momento di passare dai segmenti ai quadrati. Mettiamo sull'asse delle ascisse
\end{flushleft}


\begin{flushleft}
l'orario di arrivo del primo amico e su quello delle ordinate quello del secondo. Le coordinate
\end{flushleft}


\begin{flushleft}
interne al quadrato rappresentano le combinazioni di arrivi dei due amici. I due si incontrano se
\end{flushleft}


\begin{flushleft}
le due coordinate non differiscono più di 5. Ma geometricamente questo cosa significa?
\end{flushleft}


\begin{flushleft}
Se arrivano insieme, si incontrano. Questi punti sono la diagonale del quadrato. Ma non sono,
\end{flushleft}


\begin{flushleft}
come detto, la loro unica possibilit\`{a} di incontrarsi4.14. Possiamo spostarci orizzontalmente o verticalmente di 5 minuti, rispetto alla diagonale, cio\`{e} considerare la diagonale ingrassata, colorata
\end{flushleft}


\begin{flushleft}
in grigio chiaro nella Figura 4.1. Questa superficie rappresenta tutte le coppie di orario d'arrivo
\end{flushleft}


\begin{flushleft}
per cui i due amici si incontrano. Per calcolare la probabilit\`{a} richiesta dobbiamo considerare il
\end{flushleft}


\begin{flushleft}
rapporto tra quest'area e quella totale, che rappresenta tutte le possibili coppie di tempi d'arrivo
\end{flushleft}


11


\begin{flushleft}
dei due amici. Questo rapporto \`{e} 36 .
\end{flushleft}


23.00





22.30





22.00





22.30





23.00





\begin{flushleft}
Figura 4.1. Incontro sotto il Grattacielo
\end{flushleft}


\begin{flushleft}
4.14. In realt\`{a} la probabilit\`{a} che arrivino insieme \`{e} 0, come possiamo vedere calcolando il rapporto tra l'area della
\end{flushleft}


\begin{flushleft}
diagonale (nulla) e quella del quadrato.
\end{flushleft}





\begin{flushleft}
\newpage
4.4 FARSI LE OSSA
\end{flushleft}





65





\begin{flushleft}
Possiamo esaminare questo stesso esercizio sotto la lente più formale introdotta nella prima
\end{flushleft}


\begin{flushleft}
parte di questo capitolo. Quello che cambia \`{e} solamente il linguaggio, non l'idea sottostante,
\end{flushleft}


\begin{flushleft}
n\'{e} tanto meno il risultato. Giusto per dare uno spunto: abbiamo considerato per ciascuno dei
\end{flushleft}


\begin{flushleft}
due amici uno spazio di probabilit\`{a} in cui $\Omega$ = [0, 60] e ℱ = ℬ([0, 60]) (cio\`{e} la tribù dei Boreliani generata dagli intervalli semiaperti in [0, 60], il che equivale a prendere la tribù dei Boreliani
\end{flushleft}


\begin{flushleft}
su ℝ intersecata con l'intervallo che ci interessa). Per quanto riguarda P stiamo prendendo la
\end{flushleft}


\begin{flushleft}
b$-$a
\end{flushleft}


\begin{flushleft}
lunghezza dei segmenti riscalata (in modo che P([0,60])=1), cio\`{e} P([a,b])= 60 . Possiamo vedere
\end{flushleft}


\begin{flushleft}
la stessa probabilit\`{a} come generata dalla funzione
\end{flushleft}





\begin{flushleft}
\{\{ 0x
\end{flushleft}


\begin{flushleft}
F(x) = \{
\end{flushleft}


\{\{ 60


1





\begin{flushleft}
x$<$0
\end{flushleft}


\begin{flushleft}
0 ⩽ x ⩽ 60 .
\end{flushleft}


\begin{flushleft}
x $>$ 60
\end{flushleft}





\begin{flushleft}
Quando poi passiamo a considerare insieme i due amici, siamo in uno spazio prodotto (in realt\`{a}
\end{flushleft}


\begin{flushleft}
il quadrato dello stesso spazio), con la misura prodotto, che \`{e} l'area delle porzioni del quadrato
\end{flushleft}


\begin{flushleft}
(il nostro $\Omega$ 2), rinormalizzata dividendo per 60 ⋅ 60 = 3600, in modo da avere una probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Osservazione 4.15. Un dettaglio interessante, anche se non necessario per il problema appena
\end{flushleft}


\begin{flushleft}
esaminato, \`{e} il seguente: possiamo calcolare la probabilit\`{a} anche di eventi che nello spazio bidimensionale non sono rettangoli, ma che si ottengono come unione (eventualmente numerabile)
\end{flushleft}


\begin{flushleft}
di rettangoli, come ad esempio triangoli, poligoni, cerchi o altre figure convesse.
\end{flushleft}


\begin{flushleft}
Esempio 4.16. Prendendo a caso due punti su un segmento, lo si divide in tre parti. Con che
\end{flushleft}


\begin{flushleft}
probabilit\`{a} questi tre segmenti possono formare un triangolo?
\end{flushleft}


\begin{flushleft}
Come prima cosa, fissiamo uguale a 1 la lunghezza del segmento iniziale4.15. Consideriamo
\end{flushleft}


\begin{flushleft}
questo segmento unitario in un sistema cartesiano dove l'origine coincide con il primo estremo e
\end{flushleft}


\begin{flushleft}
chiamiamo P e Q i due punti presi a caso su di esso. Ciascuno di essi \`{e} univocamente identificato
\end{flushleft}


\begin{flushleft}
dalla sua distanza dall'origine, che indichiamo rispettivamente con p e q.
\end{flushleft}


\begin{flushleft}
Osserviamo che l'evento in cui P e Q coincidono (e dunque p = q) \`{e} un punto e ha quindi
\end{flushleft}


\begin{flushleft}
probabilit\`{a} nulla4.16 di accadere, per le propriet\`{a} della probabilit\`{a} uniforme sul segmento [0, 1].
\end{flushleft}


\begin{flushleft}
Possiamo quindi trascurarlo e abbiamo così due casi possibili: p $<$ q e p $>$ q. Data la simmetria del
\end{flushleft}


\begin{flushleft}
problema, possiamo studiare solamente uno dei due casi (a patto di ricordarcene nel momento in
\end{flushleft}


\begin{flushleft}
cui consideriamo $\Omega$ o di moltiplicare per 2 il risultato, se $\Omega$ non tiene conto della simmetria).
\end{flushleft}


\begin{flushleft}
Se p $<$ q, allora i tre segmenti hanno lunghezza p, q $-$ p e 1 $-$ q (quello che resta a destra del
\end{flushleft}


\begin{flushleft}
secondo punto). Affinch\'{e} possano essere le lunghezze dei lati di un triangolo, devono soddisfare
\end{flushleft}


\begin{flushleft}
le disuguaglianze triangolari, cio\`{e} ogni lunghezza deve essere minore della somma delle altre
\end{flushleft}


\begin{flushleft}
due:
\end{flushleft}


\begin{flushleft}
p$<$q$-$p+1$-$q=1$-$p
\end{flushleft}


\begin{flushleft}
q$-$p$<$p+1$-$q
\end{flushleft}


\begin{flushleft}
1 $-$ q $<$ p + q $-$ p = q.
\end{flushleft}





\{\{


\{\{\{





\begin{flushleft}
In ciascuna di queste disuguaglianze sommiamo a entrambi i membri quanto compare a primo
\end{flushleft}


\begin{flushleft}
membro, ottenendo
\end{flushleft}


\begin{flushleft}
2p$<$1
\end{flushleft}


\begin{flushleft}
2 (q $-$ p) $<$ 1
\end{flushleft}


\begin{flushleft}
2 (1 $-$ q) $<$ 1,
\end{flushleft}





\{\{\{


\{





\begin{flushleft}
da cui risulta che le tre lunghezze p, q $-$ p e 1 $-$ q devono tutte essere minori di 2 .
\end{flushleft}


1





\begin{flushleft}
4.15. In sostanza stiamo assumendo come unit\`{a} di misura ``la lunghezza di questo segmento''.
\end{flushleft}


\begin{flushleft}
4.16. Abbiamo gi\`{a} visto un fenomeno simile nell'Esempio 4.14: in entrambi i casi abbiamo che, con una distribuzione
\end{flushleft}


\begin{flushleft}
uniforme di probabilit\`{a}, oggetti geometrici di dimensione più bassa (come i punti in un segmento o i segmenti in una
\end{flushleft}


\begin{flushleft}
superficie) hanno misura nulla.
\end{flushleft}





\newpage
66





\begin{flushleft}
COSTRUIRE PROBABILIT\`{A}
\end{flushleft}





\begin{flushleft}
Anche in questo problema, come nel precedente, abbiamo per\`{o} un continuo di valori possibili
\end{flushleft}


\begin{flushleft}
per p e q. Rappresentiamoli anche in questo caso in due dimensioni: siccome abbiamo assunto
\end{flushleft}


\begin{flushleft}
p $<$ q, il nostro $\Omega$ sar\`{a} il solo triangolo sopra la diagonale, colorato in grigio chiaro. Quali sono in
\end{flushleft}


1


\begin{flushleft}
questo triangolo le coppie (p,q) che vanno bene? Cominciamo scartando tutti i punti in cui p $>$ 2 o
\end{flushleft}


1


1


\begin{flushleft}
q $<$ 2 . Rimane solamente un vincolo da considerare: q $-$ p $<$ 2 , cio\`{e} scartiamo i punti che distano più
\end{flushleft}


\begin{flushleft}
di 2 dalla diagonale. Rimane il triangolo colorato in grigio scuro nella Figura 4.2, che \`{e} rettangolo
\end{flushleft}


1


1


\begin{flushleft}
isoscele di cateto 2 e area 8 . La probabilit\`{a} cercata \`{e} il rapporto tra quest'area e l'area dell'intero
\end{flushleft}


1


1


\begin{flushleft}
triangolo sopra la diagonale, che vale 2 . La probabilit\`{a} cercata \`{e} allora 4 .
\end{flushleft}


1





\begin{flushleft}
q
\end{flushleft}


1





1


2





1


2





1





\begin{flushleft}
p
\end{flushleft}





\begin{flushleft}
Figura 4.2. Spezzare un segmento per avere triangoli, prima soluzione
\end{flushleft}





\begin{flushleft}
Per evitare di calcolare le aree, possiamo osservare che il triangolo più grande \`{e} diviso in
\end{flushleft}


\begin{flushleft}
quattro triangolini equivalenti dalle linee che abbiamo tracciato, di cui solo uno, quello più scuro,
\end{flushleft}


\begin{flushleft}
\`{e} costituito da punti che rappresentano casi favorevoli.
\end{flushleft}


\begin{flushleft}
Se non siamo convinti che sia sufficiente considerare solo il caso p $<$ q, possiamo guardare i
\end{flushleft}


\begin{flushleft}
casi favorevoli all'interno dell'intero quadrato, considerando anche il caso simmetrico in cui p $>$q.
\end{flushleft}


\begin{flushleft}
Vediamo ora una seconda soluzione. Mettiamoci in un sistema di riferimento cartesiano tridimensionale, con i tre assi che rappresentano le lunghezze dei tre segmenti. Le terne possibili
\end{flushleft}


\begin{flushleft}
(cio\`{e} quelle nel primo ottante in cui la somma delle tre coordinate \`{e} uguale a 1) giacciono tutte su
\end{flushleft}


\begin{flushleft}
un piano e, in particolare, sulla superficie di un triangolo (all'interno del cubo unitario) di vertici
\end{flushleft}


\begin{flushleft}
(1, 0, 0), (0, 1, 0), (0, 0, 1), colorato in grigio nella Figura 4.3 a sinistra.
\end{flushleft}





\begin{flushleft}
H
\end{flushleft}





\begin{flushleft}
V
\end{flushleft}





\begin{flushleft}
O
\end{flushleft}





\begin{flushleft}
Figura 4.3. Spezzare un segmento per avere triangoli, seconda soluzione
\end{flushleft}





\begin{flushleft}
Possiamo proiettare i tre assi cartesiani sul triangolo, in modo che siano le altezze rispetto
\end{flushleft}


\begin{flushleft}
ai tre lati (ad esempio, nella Figura 4.3 a sinistra proiettiamo l'asse O V sull'altezza V H): in altre
\end{flushleft}


\begin{flushleft}
parole, possiamo scegliere di rappresentare le lunghezze dei tre segmenti come le tre altezze del
\end{flushleft}


\begin{flushleft}
triangolo, che consideriamo dunque tutte di lunghezza 1. Il Teorema di Viviani4.17 ci dice che i
\end{flushleft}


\begin{flushleft}
punti del triangolo sono precisamente i punti in cui la somma delle distanze dai lati \`{e} uguale alla
\end{flushleft}


\begin{flushleft}
lunghezza di una delle altezze e quindi a 1. I punti interni al triangolo sono quindi tutti i modi
\end{flushleft}


\begin{flushleft}
possibili in cui un segmento unitario pu\`{o} essere spezzato in tre parti, il nostro $\Omega$.
\end{flushleft}


\begin{flushleft}
4.17. Vincenzo Viviani (1622 -- 1703).
\end{flushleft}





\begin{flushleft}
\newpage
4.4 FARSI LE OSSA
\end{flushleft}





67





\begin{flushleft}
Ora dobbiamo rappresentare le altre condizioni, gi\`{a} viste nella prima soluzione: nessuno dei
\end{flushleft}


1


\begin{flushleft}
tre segmenti pu\`{o} essere più lungo di 2 . L'intersezione di queste tre condizioni \`{e} il triangolino
\end{flushleft}


1


\begin{flushleft}
centrale in Figura 4.3 a destra, la cui superficie \`{e} 4 della superficie totale.
\end{flushleft}


\begin{flushleft}
Qualche commento prima di proseguire. Nella seconda soluzione dell'Esempio 4.16 abbiamo
\end{flushleft}


\begin{flushleft}
trasformato il nostro problema di probabilit\`{a} in un problema di geometria. E in un certo senso
\end{flushleft}


\begin{flushleft}
avevamo fatto la stessa cosa anche nella prima soluzione e in quella dell'Esempio 4.14. Ci\`{o} accade
\end{flushleft}


\begin{flushleft}
perch\'{e}, se proviamo a suddividere la matematica in compartimenti stagni risolvendo problemi di
\end{flushleft}


\begin{flushleft}
probabilit\`{a} o di geometria o di teoria dei numeri, la matematica si mostrer\`{a} comunque come un
\end{flushleft}


\begin{flushleft}
tutt'uno, in cui lo stesso problema pu\`{o} (e alle volte deve) essere affrontato con tecniche diverse
\end{flushleft}


\begin{flushleft}
che arrivano da ambiti apparentemente distinti.
\end{flushleft}


\begin{flushleft}
Inoltre sembra che ci siano spesso più strade che portano al medesimo risultato. Anche questa
\end{flushleft}


\begin{flushleft}
\`{e} una verit\`{a} più generale della matematica e non solo dei problemi di probabilit\`{a}. Questa osservazione, per\`{o}, ci suggerisce un buon esercizio: cercare nuove soluzioni a un problema gi\`{a} visto,
\end{flushleft}


\begin{flushleft}
che magari potranno tornare utili per altri problemi che incontreremo in futuro.
\end{flushleft}


\begin{flushleft}
\`{E} importante che le diverse soluzioni portino davvero al medesimo risultato: guadagneremo
\end{flushleft}


\begin{flushleft}
così un po' di confidenza nella correttezza di quanto abbiamo ottenuto. Se i risultati invece saranno
\end{flushleft}


\begin{flushleft}
tutti diversi, avremo la certezza che almeno uno di quelli trovati sia sbagliato. Infatti in probabilit\`{a} pu\`{o} capitare, se non si fa attenzione a scrivere tutto nei dettagli, di trovarsi in situazioni
\end{flushleft}


\begin{flushleft}
paradossali.
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
CAPITOLO 5
\end{flushleft}


\begin{flushleft}
VARIABILI ALEATORIE
\end{flushleft}


\begin{flushleft}
Lezione 7
\end{flushleft}





\begin{flushleft}
Cominciamo con un esempio gi\`{a} visto.
\end{flushleft}


\begin{flushleft}
Esempio 5.1. Lanciamo due dadi bilanciati a 6 facce e ne consideriamo la somma. Quali sono le
\end{flushleft}


\begin{flushleft}
probabilit\`{a} dei vari risultati possibili della somma?
\end{flushleft}


\begin{flushleft}
Abbiamo gi\`{a} visto questo esempio: avevamo scelto come spazio degli esiti l'insieme delle
\end{flushleft}


\begin{flushleft}
coppie ordinate in cui ciascuno degli elementi \`{e} un numero naturale compreso tra 1 e 6. Per
\end{flushleft}


\begin{flushleft}
i vari risultati della somma, che indichiamo con S abbiamo le seguenti probabilit\`{a}:
\end{flushleft}


\begin{flushleft}
S
\end{flushleft}


\begin{flushleft}
S=0
\end{flushleft}


\begin{flushleft}
S=1
\end{flushleft}





\begin{flushleft}
elementi
\end{flushleft}


$\emptyset$


$\emptyset$





\begin{flushleft}
S=2
\end{flushleft}





\{(1, 1)\}





\begin{flushleft}
S=3
\end{flushleft}





\{(1, 2), (2, 1)\}





\begin{flushleft}
S=4
\end{flushleft}





\{(1, 3), (2, 2), (3, 1)\}





\begin{flushleft}
S=5
\end{flushleft}





\{(1, 4), (2, 3), (3, 2), (4, 1)\}





\begin{flushleft}
S=6
\end{flushleft}





\{(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)\}





\begin{flushleft}
S=7
\end{flushleft}





\{(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)\}





\begin{flushleft}
S=8
\end{flushleft}





\{(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)\}





\begin{flushleft}
S=9
\end{flushleft}





\{(3, 6), (4, 5), (5, 4), (6, 3)\}





\begin{flushleft}
P
\end{flushleft}


0


0





\begin{flushleft}
S = 10 \{(4, 6), (5, 5), (6, 4)\}
\end{flushleft}


\begin{flushleft}
S = 11 \{(5, 6), (6, 5)\}
\end{flushleft}


\begin{flushleft}
S = 12 \{(6, 6)\}
\end{flushleft}


\begin{flushleft}
S ⩾ 13 $\emptyset$
\end{flushleft}





1


36


2


36


3


36


4


36


5


36


6


36


5


36


4


36


3


36


2


36


1


36





0





\begin{flushleft}
Tabella 5.1. Somma di due dadi.
\end{flushleft}





\begin{flushleft}
Ciascuna riga della tabella corrisponde a un evento: con \{S = 11\}, \{S = 6\} stiamo indicando
\end{flushleft}


\begin{flushleft}
degli eventi. La scrittura \{S = x\} un modo compatto per indicare quello che sta nella seconda
\end{flushleft}


\begin{flushleft}
colonna della tabella, che sarebbe l'evento vero e proprio, ossia il sottoinsieme di $\Omega$. Per\`{o} sottolinea un dettaglio importante: in questo caso non ci interessa il risultato dell'esperimento, ma una
\end{flushleft}


\begin{flushleft}
sua funzione. Ci \`{e} indifferente che la somma uguale a 4 sia stata ottenuta come (1, 3) o (2, 2). Se
\end{flushleft}


\begin{flushleft}
pensiamo al lavoro fatto per completare la tabella, molto di quel lavoro \`{e} stato inutile, abbiamo
\end{flushleft}


\begin{flushleft}
esplicitato molte informazioni che, per risolvere il problema in questione, non ci occorrono.
\end{flushleft}


\begin{flushleft}
Continuiamo con un secondo esempio.
\end{flushleft}


\begin{flushleft}
Esempio 5.2. Un'azienda produce calcolatori. Il costo di produzione di un singolo calcolatore \`{e}
\end{flushleft}


\begin{flushleft}
pari a 1000 \euro, mentre il prezzo di vendita \`{e} 2000 \euro. La probabilit\`{a} che ci siano guasti irreparabili
\end{flushleft}


\begin{flushleft}
durante la produzione di un calcolatore \`{e} del 10\%. I calcolatori con guasti non vengono venduti.
\end{flushleft}


\begin{flushleft}
1. Con un ordine di un calcolatore, qual \`{e} la probabilit\`{a} per l'azienda di avere un guadagno?
\end{flushleft}


\begin{flushleft}
2. Con un ordine di tre calcolatori, qual \`{e} la probabilit\`{a} per l'azienda di avere un guadagno?
\end{flushleft}


69





\newpage
70





\begin{flushleft}
VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Per avere un calcolatore funzionante, l'azienda deve continuare a produrne finch\'{e} non ne esce
\end{flushleft}


\begin{flushleft}
uno senza guasti (e quindi vendibile). Con che probabilit\`{a} accade questo?
\end{flushleft}


\begin{flushleft}
Pu\`{o} succedere al primo tentativo: viene prodotto un solo calcolatore e questo non ha difetti.
\end{flushleft}


\begin{flushleft}
La probabilit\`{a} che questo accada \`{e} 1 $-$ p = 0.9, dove con p indichiamo la probabilit\`{a} che il calcolatore prodotto sia guasto.
\end{flushleft}


\begin{flushleft}
Pu\`{o} succedere al secondo tentativo: viene prodotto un primo calcolatore, ma \`{e} guasto, dopodich\'{e} ne viene prodotto un secondo, funzionante. La probabilit\`{a} che questo accada \`{e} p ⋅ (1 $-$ p) =
\end{flushleft}


\begin{flushleft}
0.09. \`{E} importante l'ordine: se il primo fosse funzionante, non ci sarebbe bisogno di produrre il
\end{flushleft}


\begin{flushleft}
secondo. (Vale la pena osservare che stiamo assumendo l'indipendenza della presenza di errori
\end{flushleft}


\begin{flushleft}
tra calcolatori diversi.)
\end{flushleft}


\begin{flushleft}
Pu\`{o} succedere al terzo tentativo, al quarto e così via. In generale la probabilit\`{a} che il primo
\end{flushleft}


\begin{flushleft}
calcolatore vendibile sia prodotto all'n-simo tentativo \`{e} p n$-$1 ⋅ (1 $-$ p).
\end{flushleft}


\begin{flushleft}
La domanda del problema, per\`{o}, \`{e} molto specifica: richiede la probabilit\`{a} che l'azienda abbia
\end{flushleft}


\begin{flushleft}
un guadagno, cosa che avviene se vengono prodotti n calcolatori con 2000 $-$ 1000 n $>$ 0, ossia
\end{flushleft}


\begin{flushleft}
l'azienda guadagna solo se n = 1, nel caso n = 2 va in pari e per n ⩾ 3 va in perdita. Quindi la probabilit\`{a} di guadagno \`{e} 0.9, quella di non perderci \`{e} 0.99 e quella di andare in rosso \`{e} 0.009̄ = 0.01.
\end{flushleft}


\begin{flushleft}
Non abbiamo scritto esplicitamente chi fosse $\Omega$, ma possiamo usare $\Omega$ = ℕ ∖ \{0\} pensando
\end{flushleft}


\begin{flushleft}
come esiti il numero di calcolatori prodotti fino al primo calcolatore funzionante.
\end{flushleft}


\begin{flushleft}
Passiamo ora alla seconda domanda: l'ordine \`{e} ora di 3 calcolatori. Abbiamo un successo
\end{flushleft}


\begin{flushleft}
quando sono stati prodotti 3 calcolatori funzionanti, quindi $\Omega$ = ℕ ∖ \{0, 1, 2\}, perch\'{e} l'azienda ne
\end{flushleft}


\begin{flushleft}
dovr\`{a} produrre almeno 3.
\end{flushleft}


\begin{flushleft}
L'ordine pu\`{o} essere evaso non appena vengono prodotti 3 calcolatori, se tutti e tre sono funzionanti, cosa che avviene con probabilit\`{a} (1 $-$ p)3 = 0.729.
\end{flushleft}


\begin{flushleft}
Alternativamente l'ordine pu\`{o} essere evaso con la produzione di 4 calcolatori, purch\'{e} ce ne
\end{flushleft}


\begin{flushleft}
sia esattamente uno tra i primi tre che \`{e} guasto. L'ultimo non pu\`{o} essere guasto, altrimenti non
\end{flushleft}


\begin{flushleft}
sarebbe nemmeno stato prodotto. La probabilit\`{a} che questo avvenga \`{e} 31 p (1 $-$ p)3 = 0.2187. Il
\end{flushleft}


\begin{flushleft}
ruolo del coefficiente binomiale \`{e} quello di contare tutti i casi in cui possiamo avere un calcolatore
\end{flushleft}


\begin{flushleft}
guasto tra i primi 3.
\end{flushleft}


\begin{flushleft}
Similmente potrebbero occorrere 5 calcolatori prodotti, se 2 dei primi 4 sono guasti. La probabilit\`{a} di questo evento \`{e} 42 p 2 (1 $-$ p)3 = 0.04374.
\end{flushleft}


\begin{flushleft}
In generale occorreranno n calcolatori prodotti per averne 3 funzionanti (di cui l'ultimo prodotto) con probabilit\`{a} nn $-$$-$ 13 p n$-$3 (1 $-$ p)3.
\end{flushleft}


\begin{flushleft}
Anche in questo caso dobbiamo calcolare la probabilit\`{a} che l'azienda ci guadagni. Questo
\end{flushleft}


\begin{flushleft}
avviene per quegli n tali che 3 ⋅ 2000 $-$ n ⋅ 1000 $>$ 0, ossia n $<$ 6 (anche in questo caso per n = 6 c'\`{e}
\end{flushleft}


\begin{flushleft}
pareggio di bilancio). La probabilit\`{a} che l'azienda guadagni, quindi, \`{e} la somma delle probabilit\`{a}
\end{flushleft}


\begin{flushleft}
che debba produrre 3, 4 o 5 calcolatori:
\end{flushleft}


5





\begin{flushleft}
P=
\end{flushleft}


\begin{flushleft}
n=3
\end{flushleft}





\begin{flushleft}
n $-$ 1 n$-$3
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)3 = 0.729 + 0.2187 + 0.04374 = 0.99144.
\end{flushleft}


\begin{flushleft}
n$-$3
\end{flushleft}





\begin{flushleft}
Possiamo osservare che abbiamo prestato molta poca attenzione a ($\Omega$,ℱ,P). Inoltre in $\Omega$ non c'era
\end{flushleft}


\begin{flushleft}
nulla che descrivesse il guadagno: abbiamo solo contato quanti calcolatori era necessario costruire
\end{flushleft}


\begin{flushleft}
per averne 1 (o 3) non guasti. Possiamo per\`{o} scrivere un $\Omega$ diverso per i guadagni, ora:
\end{flushleft}


\begin{flushleft}
$\Omega$ G1 = \{1000, 0, $-$1000, $-$2000, . . . \},
\end{flushleft}





\begin{flushleft}
$\Omega$ G3 = \{3000, 2000, 1000, 0, $-$1000, . . . \}
\end{flushleft}





\begin{flushleft}
dove consideriamo rispettivamente la vendita di un calcolatore e di tre. Possiamo anche definire
\end{flushleft}


\begin{flushleft}
una probabilit\`{a} direttamente su questi $\Omega$ (che hanno cardinalit\`{a} sempre numerabile) {``}sfruttando''
\end{flushleft}


\begin{flushleft}
quanto calcolato nello spazio di probabilit\`{a} precedente:
\end{flushleft}


\begin{flushleft}
PG1 (1000) = 0.9, PG1 (0) = 0.99, . . .
\end{flushleft}


\begin{flushleft}
e (nel caso dei 3 calcolatori)
\end{flushleft}


\begin{flushleft}
PG3 (3000) = 0.729, PG3 (2000) = 0.2187, PG3 (1000) = 0.04374, . . .
\end{flushleft}





\begin{flushleft}
\newpage
VARIABILI ALEATORIE
\end{flushleft}





71





\begin{flushleft}
Anche in questo esempio, come nel precedente abbiamo considerato una funzione del risultato
\end{flushleft}


\begin{flushleft}
dell'esperimento aleatorio di partenza,.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 5.3. Dato uno spazio probabilizzabile ($\Omega$,ℱ), si dice variabile aleatoria o variabile casuale
\end{flushleft}


\begin{flushleft}
ogni funzione X : $\Omega$ $\rightarrow$ ℝ tale che per ogni x $\in$ ℝ, l'insieme \{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ x\} $\in$ ℱ.
\end{flushleft}


\begin{flushleft}
Esempio 5.4. La funzione S dell'Esempio 5.1 che calcola la somma dei risultati dei due dadi (cio\`{e}
\end{flushleft}


\begin{flushleft}
delle due componenti di ogni elemento 𝜔) \`{e} una variabile aleatoria.
\end{flushleft}


\begin{flushleft}
Osservazione 5.5. Proviamo a leggere più a fondo questa definizione.
\end{flushleft}


\begin{flushleft}
1. Chiamiamo queste funzioni {``}variabili aleatorie'' perch\'{e} il valore della funzione dipende dal
\end{flushleft}


\begin{flushleft}
risultato 𝜔 di un esperimento casuale.
\end{flushleft}


\begin{flushleft}
2. Siamo partiti da uno spazio probabilizzabile, non di probabilit\`{a}. Pu\`{o} sembrare strano, visto che
\end{flushleft}


\begin{flushleft}
siamo partiti dall'idea di assegnare una probabilit\`{a} a funzioni di esiti, ma la definizione che
\end{flushleft}


\begin{flushleft}
abbiamo dato non dipende da una particolare probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
3. Chiediamo che \{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ x\} $\in$ ℱ perch\'{e} vorremmo assegnare una probabilit\`{a} a questi
\end{flushleft}


\begin{flushleft}
insiemi. Qualunque probabilit\`{a} abbiamo sullo spazio ($\Omega$,ℱ), la possiamo {``}esportare'' a questi
\end{flushleft}


\begin{flushleft}
insiemi.
\end{flushleft}


\begin{flushleft}
4. Come mai consideriamo proprio gli insiemi di questa forma? Cosa ci ricorda la condizione
\end{flushleft}


\begin{flushleft}
X(𝜔)⩽x? Lo spazio di arrivo \`{e} lo spazio ℝ dei numeri reali, se vogliamo avere una probabilit\`{a}
\end{flushleft}


\begin{flushleft}
ci serve come prima cosa una tribù e, per ℝ, abbiamo visto la tribù ℬ dei Boreliani, che ha
\end{flushleft}


\begin{flushleft}
come possibili generatori le semirette ($-$$\infty$, x].
\end{flushleft}


\begin{flushleft}
5. Cominciamo a vedere dove vogliamo arrivare. Resta per\`{o} una domanda: come mai stiamo
\end{flushleft}


\begin{flushleft}
procedendo {``}al contrario''? Perch\'{e} {``}portiamo indietro'' gli insiemi misurabili da ℬ a ℱ e non
\end{flushleft}


\begin{flushleft}
viceversa?
\end{flushleft}


\begin{flushleft}
Esempio 5.6. Siano $\Omega$ = \{1, 2, 3\}, ℱ = \{$\emptyset$, \{1\}, \{2, 3\}, \{1, 2, 3\}\} e sia $\Omega$̃ = \{1, 2\}. Se prendiamo la funzione f : $\Omega$$\rightarrow$ $\Omega$̃ tale che f (1) = f (2) = 1 e f (3) =2, la famiglia di insiemi ℱ̃ = \{ f (E) : E $\in$ ℱ\} non \`{e} una
\end{flushleft}


\begin{flushleft}
tribù, infatti ℱ̃ = \{ f ($\emptyset$), f (\{1\}), f (\{2, 3\}), f (\{1, 2, 3\})\} = \{$\emptyset$, \{1\}, \{1, 2\}\}, cui manca \{2\} per essere una
\end{flushleft}


\begin{flushleft}
tribù.
\end{flushleft}


\begin{flushleft}
Nota 5.7. Nell'enunciato precedente E \`{e} un insieme e con f (E) ne stiamo prendendo l'immagine,
\end{flushleft}


\begin{flushleft}
ossia l'insieme f (E) = \{𝜔˜ $\in$ $\Omega$̃ : $\exists$𝜔 $\in$ E $\subseteq$ $\Omega$ : 𝜔˜ = f (𝜔)\}. Osserviamo che f ($\Omega$) $\subseteq$ $\Omega$̃, ma non necessariamente vale l'uguaglianza: per averla f deve essere suriettiva.
\end{flushleft}


\begin{flushleft}
In modo analogo possiamo definire la preimmagine di un insieme di $\Omega$̃ mediante f : essa \`{e}
\end{flushleft}


\begin{flushleft}
l'insieme
\end{flushleft}


\begin{flushleft}
f $-$1(Ẽ) = \{𝜔 $\in$ $\Omega$ : f (𝜔) $\in$ Ẽ\},
\end{flushleft}


\begin{flushleft}
definito per ogni sottoinsieme Ẽ di $\Omega$̃. In questo caso f $-$1 non \`{e} la funzione inversa, che potrebbe
\end{flushleft}


\begin{flushleft}
anche non esistere, dal momento che non abbiamo fatto ipotesi sull'invertibilit\`{a} di f . Non la
\end{flushleft}


\begin{flushleft}
stiamo vedendo come funzione degli elementi di $\Omega$̃, bensì come mappa di insiemi. In particolare,
\end{flushleft}


\begin{flushleft}
siccome f \`{e} una funzione, f $-$1($\Omega$̃) = $\Omega$, non occorre che f sia iniettiva n\'{e} suriettiva.
\end{flushleft}


\begin{flushleft}
D'altra parte, la scelta di tornare indietro funziona, come ci garantisce il seguente risultato.
\end{flushleft}


\begin{flushleft}
TEOREMA 5.8. Sia ($\Omega$̃, ℱ̃) uno spazio probabilizzabile. Siano inoltre $\Omega$ un insieme e X: $\Omega$ $\rightarrow$ $\Omega$̃ una funzione. Allora ℱ = \{X $-$1(Ẽ) : Ẽ $\in$ ℱ̃\} \`{e} una tribù su $\Omega$.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Controlliamo che siano soddisfatte le tre propriet\`{a} che caratterizzano una tribù:
\end{flushleft}


\begin{flushleft}
i. X $-$1($\Omega$̃) = $\Omega$, quindi $\Omega$ $\in$ ℱ;
\end{flushleft}


\begin{flushleft}
ii. X $-$1(Ẽ c) = X $-$1($\Omega$̃ ∖ Ẽ) = $\Omega$ ∖ X $-$1(Ẽ) = (X $-$1(Ẽ))c, quindi (X $-$1(Ẽ))c $\in$ ℱ;
\end{flushleft}


$\infty$


$-$1


\begin{flushleft}
iii. X $-$1(⋃ $\infty$
\end{flushleft}


\begin{flushleft}
i=1 Ẽ i) = ⋃ i=1 X (Ẽ i), quindi ℱ \`{e} chiusa rispetto all'unione numerabile.
\end{flushleft}





□





\newpage
72





\begin{flushleft}
VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Non solo, possiamo anche usare questa stessa idea per {``}portare avanti'' una tribù.
\end{flushleft}


\begin{flushleft}
TEOREMA 5.9. Sia ($\Omega$, ℱ) uno spazio probabilizzabile. Siano inoltre $\Omega$̃ un insieme e X: $\Omega$ $\rightarrow$ $\Omega$̃ una funzione. Allora ℱ̃ = \{Ẽ $\subseteq$ $\Omega$̃ : X $-$1(Ẽ) $\in$ ℱ\} \`{e} una tribù.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Controlliamo che siano soddisfatte le tre propriet\`{a} che caratterizzano una tribù:
\end{flushleft}


\begin{flushleft}
i. X $-$1($\Omega$̃) = $\Omega$ $\in$ ℱ, quindi $\Omega$̃ $\in$ ℱ̃;
\end{flushleft}


\begin{flushleft}
ii. se Ẽ $\in$ ℱ̃, allora X $-$1(Ẽ) $\in$ ℱ, quindi (X $-$1(Ẽ c)) = $\Omega$ ∖ X $-$1(Ẽ) = (X $-$1(Ẽ))c $\in$ ℱ, dunque Ẽ c $\in$ ℱ̃;
\end{flushleft}


\begin{flushleft}
iii. se abbiamo una successione (Ẽi)i $\subseteq$ ℱ̃, allora la successione (X $-$1(Ẽi))i $\subseteq$ ℱ, di conseguenza
\end{flushleft}


$\infty$


$\infty$


$-$1


$-$1


\begin{flushleft}
ℱ $\ni$ ⋃$\infty$
\end{flushleft}


□


\begin{flushleft}
i=1 X (Ẽ i) = X (⋃ i=1 Ẽ i) e ⋃ i=1 Ẽ i $\in$ ℱ̃.
\end{flushleft}


\begin{flushleft}
Osservazione 5.10. Noi siamo interessati a un caso speciale, in cui $\Omega$̃ = ℝ e ℱ̃ = ℬ e X : $\Omega$ $\rightarrow$ ℝ \`{e}
\end{flushleft}


\begin{flushleft}
una variabile aleatoria. In questo contesto la famiglia di insiemi
\end{flushleft}


\begin{flushleft}
𝜎(X) ≔ \{X $-$1(B) : B $\in$ ℬ\}
\end{flushleft}


\begin{flushleft}
\`{e} una tribù, detta tribù generata da X. Inoltre 𝜎(X) $\subseteq$ ℱ, con l'inclusione invece dell'uguaglianza,
\end{flushleft}


\begin{flushleft}
perch\'{e} non \`{e} detto che tutti gli elementi di ℱ siano controimmagine di qualche Boreliano B.
\end{flushleft}


\begin{flushleft}
Gli eventi in ℱ sono quelli per cui abbiamo un valore della funzione probabilit\`{a}, nel momento
\end{flushleft}


\begin{flushleft}
in cui ne definiamo una su ($\Omega$, ℱ). Gli eventi in 𝜎(X) sono tutti gli eventi che {``}hanno a che fare''
\end{flushleft}


\begin{flushleft}
con X. Dal momento che 𝜎(X) \`{e} un sottoinsieme di ℱ, abbiamo automaticamente una probabilit\`{a}
\end{flushleft}


\begin{flushleft}
anche per tutti gli eventi in 𝜎(X).
\end{flushleft}





\begin{flushleft}
Esempio 5.11. Nel momento in cui abbiamo una probabilit\`{a} sui risultati dei due dadi
\end{flushleft}


\begin{flushleft}
nell'Esempio 5.1 (quella dei dadi bilanciati, ad esempio, ma anche qualche probabilit\`{a} diversa,
\end{flushleft}


\begin{flushleft}
che descriva dadi truccati), attraverso S abbiamo immediatamente una probabilit\`{a} sui numeri
\end{flushleft}


\begin{flushleft}
reali che descrive la probabilit\`{a} della somma dei due dadi.
\end{flushleft}


\begin{flushleft}
Osservazione 5.12. Non sempre \`{e} facile capire se una funzione sia o meno una variabile aleatoria:
\end{flushleft}


\begin{flushleft}
c'\`{e} una branca della matematica che si occupa (anche) di questo, chiamata Teoria della misura.
\end{flushleft}


\begin{flushleft}
Tuttavia ci viene in aiuto, nel caso $\Omega$ = ℝ e ℱ = ℬ, il seguente teorema.
\end{flushleft}


\begin{flushleft}
TEOREMA 5.13. Sia X : (ℝ, ℬ(ℝ)) $\rightarrow$ (ℝ, ℬ(ℝ)) una funzione continua o monotona crescente o monotona decrescente. Allora X \`{e} una variabile aleatoria.
\end{flushleft}


\begin{flushleft}
Osservazione 5.14. La notazione X:(ℝ, ℬ(ℝ))$\rightarrow$ (ℝ, ℬ(ℝ)) nell'enunciato precedente sottolinea
\end{flushleft}


\begin{flushleft}
il fatto che siamo interessati non solo agli insiemi di partenza e arrivo della funzione X, ma che
\end{flushleft}


\begin{flushleft}
essi ci interessano come spazi probabilizzabili, in particolare entrambi con la tribù dei Boreliani.
\end{flushleft}


\begin{flushleft}
Pu\`{o} sembrare che stiamo introducendo molta notazione e che, sotto sotto, ci stiamo complicando la vita: in fondo che male c'\`{e} ad avere tanti spazi probabilizzabili diversi per descrivere
\end{flushleft}


\begin{flushleft}
esperimenti aleatori diversi? In realt\`{a} sapere che possiamo riscrivere un esperimento aleatorio
\end{flushleft}


\begin{flushleft}
sullo spazio (ℝ, ℬ) ci dice che possiamo concentrarci a definire probabilit\`{a} su quello spazio e
\end{flushleft}


\begin{flushleft}
abbiamo visto che per farlo abbiamo bisogno di funzioni F sui reali (con un po' di caratteristiche,
\end{flushleft}


\begin{flushleft}
che abbiamo visto nella Definizione XXX).
\end{flushleft}


\begin{flushleft}
Ora mettiamo alla prova il nostro strumento, le variabili aleatorie, per descrivere un particolare esperimento aleatorio.
\end{flushleft}


\begin{flushleft}
Esempio 5.15. Lanciamo una moneta, ancora una volta. Questa volta siamo interessati a una
\end{flushleft}


\begin{flushleft}
successione di lanci di una moneta bilanciata. Vogliamo calcolare la probabilit\`{a} di ottenere testa
\end{flushleft}


\begin{flushleft}
per la prima volta in un lancio dispari (ad esempio perch\'{e} stiamo giocando in due, lanciando
\end{flushleft}


\begin{flushleft}
alternatamente, col primo a ottenere testa che vince).
\end{flushleft}


\begin{flushleft}
Lo spazio di probabilit\`{a} che descrive questo esperimento \`{e} ($\Omega$, ℱ, P), con $\Omega$ = \{T, C\}ℕ∖\{0\} lo
\end{flushleft}


\begin{flushleft}
spazio prodotto delle successioni di teste e croci, ℱ la tribù generata dai cilindri, cio\`{e} quegli eventi
\end{flushleft}


\begin{flushleft}
in cui fissiamo un numero finito di indici, e P \`{e} la probabilit\`{a} prodotto.
\end{flushleft}





\begin{flushleft}
\newpage
VARIABILI ALEATORIE
\end{flushleft}





73





\begin{flushleft}
Siamo interessati a calcolare la probabilit\`{a} che testa esca la prima volta a un lancio dispari.
\end{flushleft}


\begin{flushleft}
Consideriamo allora come variabile aleatoria X la funzione che ci dice qual \`{e} il primo lancio in
\end{flushleft}


\begin{flushleft}
cui esce testa. In questo modo quello che vogliamo calcolare \`{e} P(X $\in$ \{2 k + 1, k $\in$ ℕ\}). Com'\`{e} fatta
\end{flushleft}


\begin{flushleft}
questa funzione? Possiamo scriverla come X(𝜔) = inf \{i ⩾ 1 : 𝜔 i = T\}.
\end{flushleft}


\begin{flushleft}
Ora che abbiamo X, possiamo ricavarci la tribù generata da X, 𝜎(X). Cominciamo a vedere
\end{flushleft}


\begin{flushleft}
come sono fatte le controimmagini dei singoletti di numeri naturali positivi (anche perch\'{e} ci
\end{flushleft}


\begin{flushleft}
aspettiamo che siano gli eventi in cui la probabilit\`{a} sar\`{a} non nulla). Abbiamo
\end{flushleft}


\begin{flushleft}
X $-$1(\{4\}) = \{𝜔 $\in$ $\Omega$ : 𝜔1 = 𝜔 2 = 𝜔3 = C, 𝜔4 = T\}
\end{flushleft}


\begin{flushleft}
cio\`{e} il cilindro le cui prime 3 componenti sono C e la quarta \`{e} T. Più in generale, 𝜎(X) \`{e} formata
\end{flushleft}


\begin{flushleft}
da unioni finite o numerabili di cilindri della forma
\end{flushleft}


\begin{flushleft}
Hk ≔ \{𝜔 $\in$ $\Omega$ : 𝜔 i = C, i $<$ k, 𝜔k = T\}.
\end{flushleft}


\begin{flushleft}
Quindi
\end{flushleft}


$\infty$





\begin{flushleft}
P(X \`{e} dispari) =
\end{flushleft}





\begin{flushleft}
P(𝜔 $\in$ H2i+1)
\end{flushleft}


\begin{flushleft}
i=0
\end{flushleft}


$\infty$





=


\begin{flushleft}
i=0
\end{flushleft}





1





1


=


\begin{flushleft}
2 2i+1 2
\end{flushleft}





$\infty$


\begin{flushleft}
i=0
\end{flushleft}





1 1


2


\begin{flushleft}
4$-$i = ⋅
\end{flushleft}


= .


2 1$-$ 1 3


4





\begin{flushleft}
Potevamo arrivare allo stesso risultato osservando che P(X pari) + P(X dispari) = 1 e che
\end{flushleft}


1


\begin{flushleft}
P(X pari) = P(X dispari),
\end{flushleft}


2


\begin{flushleft}
perch\'{e} \`{e} la probabilit\`{a} che il primo lancio sia C e che poi contiamo i lanci a partire dal primo del
\end{flushleft}


1


2


\begin{flushleft}
secondo giocatore. Quindi, ponendo x = P(X dispari), x + 2 x = 1 e x = 3 .
\end{flushleft}


\begin{flushleft}
Lezione 8
\end{flushleft}





\begin{flushleft}
Abbiamo introdotto le variabili aleatorie, funzioni dall'insieme degli esiti di un esperimento
\end{flushleft}


\begin{flushleft}
aleatorio all'insieme dei numeri reali, gi\`{a} dotato della tribù dei Boreliani. Pensarle come funzioni
\end{flushleft}


\begin{flushleft}
pu\`{o} aiutare a capirle meglio: non pensiamo tanto al valore della funzione in un punto, cio\`{e} al
\end{flushleft}


\begin{flushleft}
valore della funzione per un particolare esito 𝜔, ma alla funzione in s\'{e}, in senso globale. Ci interessano di più i valori che pu\`{o} assumere e con quale probabilit\`{a} li pu\`{o} assumere.
\end{flushleft}


\begin{flushleft}
Vediamo alcuni esempi di variabili aleatorie molto semplici. Fissiamo, per tutti gli esempi
\end{flushleft}


\begin{flushleft}
seguenti, uno spazio di probabilit\`{a} ($\Omega$, ℱ, P).
\end{flushleft}


\begin{flushleft}
Esempio 5.16. (Variabili aleatorie degeneri) Per ogni c $\in$ ℝ la funzione costante X(𝜔) $\equiv$ c, per
\end{flushleft}


\begin{flushleft}
ogni 𝜔 $\in$ $\Omega$, \`{e} una variabile aleatoria, detta variabile aleatoria degenere. Una volta fissato c (e quindi
\end{flushleft}


\begin{flushleft}
una particolare funzione costante, cio\`{e} una particolare variabile aleatoria X), possiamo chiederci
\end{flushleft}


\begin{flushleft}
quale sia la probabilit\`{a} che la funzione X assuma un certo valore a. Ci aspettiamo che questa
\end{flushleft}


\begin{flushleft}
probabilit\`{a} sia 1 se a = c e 0 altrimenti e così \`{e}:
\end{flushleft}


\begin{flushleft}
P(X = a) =
\end{flushleft}





\begin{flushleft}
\{\{ 10 aa =$\neq$ cc
\end{flushleft}





\begin{flushleft}
Più in generale vorremo calcolare la probabilit\`{a} di un evento, ossia di un insieme, cio\`{e} con la
\end{flushleft}


\begin{flushleft}
terminologia delle variabili aleatorie, P(X $\in$ A). Questo possiamo farlo se A $\in$ ℬ, grazie alle propriet\`{a} delle tribù, in particolare dei Boreliani, e della preimmagine nella definizione di variabile
\end{flushleft}


\begin{flushleft}
aleatoria:
\end{flushleft}


\begin{flushleft}
P(X $\in$ A) = P(\{𝜔 $\in$ $\Omega$ : X(𝜔) $\in$ A\}) = P(X $-$1(A)),
\end{flushleft}


\begin{flushleft}
in cui X $-$1(A) $\in$ ℱ e quindi l'ultima probabilit\`{a} \`{e} ben definita.
\end{flushleft}


\begin{flushleft}
Nel caso particolare della variabile aleatoria degenere X $\equiv$ c, se A $\in$ ℬ,
\end{flushleft}


\begin{flushleft}
P(X $\in$ A) =
\end{flushleft}





\begin{flushleft}
c$\in$A
\end{flushleft}


\begin{flushleft}
\{\{ 10 sealtrimenti.
\end{flushleft}





\begin{flushleft}
Qual \`{e} la tribù generata da X? Abbiamo in questo caso 𝜎(X) = \{$\emptyset$, $\Omega$\}: la preimmagine di un
\end{flushleft}


\begin{flushleft}
insieme A in ℬ \`{e} tutto $\Omega$ se c $\in$ A ed \`{e} l'insieme vuoto altrimenti.
\end{flushleft}





\newpage
74





\begin{flushleft}
VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Esempio 5.17. (Variabili aleatorie indicatrici) In questo caso partiamo con un evento nello spazio
\end{flushleft}


\begin{flushleft}
di partenza ($\Omega$, ℱ, P): E $\in$ ℱ. La variabile aleatoria indicatrice di E \`{e} definita come
\end{flushleft}


\begin{flushleft}
IE(𝜔) = 1E(𝜔) =
\end{flushleft}





\begin{flushleft}
\{\{ 10 sese 𝜔𝜔 $\in$$\in$ EE .
\end{flushleft}


\begin{flushleft}
c
\end{flushleft}





\begin{flushleft}
Quindi la variabile aleatoria IE pu\`{o} assumere due valori, 0 oppure 1. Com'\`{e} fatta allora 𝜎(IE)?
\end{flushleft}


\begin{flushleft}
Dobbiamo vedere chi sono gli insieme pre-immagine dei Boreliani. Abbiamo sicuramente $\emptyset$ e
\end{flushleft}


\begin{flushleft}
$\Omega$, ma anche E = IE$-$1(\{1\}) ed E c = IE$-$1(\{0\}). Inoltre ogni insieme A $\in$ ℬ che contiene 1 ma non 0
\end{flushleft}


\begin{flushleft}
ha come preimmagine E, ogni insieme B $\in$ ℬ che contiene 0 ma non 1 ha come preimmagine E c.
\end{flushleft}


\begin{flushleft}
Se un insieme di ℬ non contiene alcuno tra 0 e 1, la sua preimmagine \`{e} $\emptyset$, mentre se li contiene
\end{flushleft}


\begin{flushleft}
entrambi la sua preimmagine \`{e} $\Omega$.
\end{flushleft}


\begin{flushleft}
Per quanto riguarda la probabilit\`{a}, abbiamo, per A $\in$ ℬ
\end{flushleft}


\begin{flushleft}
se 1 $\in$ A e 0 $\notin$ A
\end{flushleft}


\begin{flushleft}
\{\{\{ P(E)
\end{flushleft}


\begin{flushleft}
P(E ) se 1 $\notin$ A e 0 $\in$ A
\end{flushleft}


\begin{flushleft}
P(I $\in$ A) = \{
\end{flushleft}


\begin{flushleft}
\{\{ 1 se 1 $\in$ A e 0 $\in$ A
\end{flushleft}


0


\begin{flushleft}
se 1 $\notin$ A e 0 $\notin$ A.
\end{flushleft}


\begin{flushleft}
c
\end{flushleft}





\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
Questa funzione \`{e} proprio la funzione indicatrice dell'insieme E, ma la sua probabilit\`{a} non \`{e} una
\end{flushleft}


\begin{flushleft}
funzione indicatrice.
\end{flushleft}


\begin{flushleft}
Esempio 5.18. (Variabili aleatorie semplici) Una volta che abbiamo le variabili aleatorie indicatrici, ne possiamo considerare delle combinazioni lineari5.1. Per esempio, dati E, F $\in$ ℱ, possiamo
\end{flushleft}


\begin{flushleft}
prendere X = IE $-$ 3 IF .
\end{flushleft}


\begin{flushleft}
In analogia all'esempio delle variabili aleatorie indicatrici, come prima cosa ci chiediamo quali
\end{flushleft}


\begin{flushleft}
siano i possibili valori di X e quali siano, di conseguenza, gli elementi di 𝜎(X). Abbiamo
\end{flushleft}





\begin{flushleft}
\{\{ 01 𝜔𝜔 $\notin$$\in$ EE $\cup$∖ FF
\end{flushleft}


\begin{flushleft}
X(𝜔) = \{
\end{flushleft}


\begin{flushleft}
\{\{ $-$3 𝜔 $\in$ F ∖ E
\end{flushleft}


\begin{flushleft}
\{\{ $-$2 𝜔 $\in$ E $\cap$ F.
\end{flushleft}


\begin{flushleft}
Quindi abbiamo che la tribù generata da X \`{e} la tribù generata da E ed F:
\end{flushleft}


\begin{flushleft}
𝜎(X) = 𝜎(E, F)
\end{flushleft}


\begin{flushleft}
= \{$\emptyset$, E, F, E c, F c, E $\cap$ F, (E $\cap$ F)c = E c $\cup$ F c, E $\cup$ F, (E $\cup$ F)c = E c $\cap$ F c, E ∖ F = E $\cap$ F c,
\end{flushleft}


\begin{flushleft}
(E ∖ F)c = E c $\cup$ F, F ∖ E = F $\cap$ E c, (F ∖ E)c = F c $\cup$ E, E$\Delta$F = (E $\cap$ F c) $\cup$ (E c $\cap$ F),
\end{flushleft}


\begin{flushleft}
(E$\Delta$F)c = (E c $\cup$ F) $\cap$ (F c $\cup$ E) = (E c $\cap$ F c) $\cup$ (E $\cap$ F), $\Omega$\}.
\end{flushleft}


\begin{flushleft}
A questo punto, in modo del tutto analogo a quanto visto prima, possiamo assegnare, per A $\in$ ℬ,
\end{flushleft}


\begin{flushleft}
dei valori di probabilit\`{a} P(X $\in$ A). Quanti sono questi valori? Quali sono? Quanti ne dobbiamo
\end{flushleft}


\begin{flushleft}
calcolare?
\end{flushleft}


\begin{flushleft}
∘ Soluzione:
\end{flushleft}


\begin{flushleft}
Negli esempi precedenti abbiamo parlato di probabilit\`{a} della variabile aleatoria, ma prima
\end{flushleft}


\begin{flushleft}
di continuare andiamo a formalizzare quanto gi\`{a} fatto. Sia ($\Omega$, ℱ, P) uno spazio di probabilit\`{a},
\end{flushleft}


\begin{flushleft}
X : $\Omega$ $\rightarrow$ ℝ una variabile aleatoria e A $\in$ ℬ. Allora
\end{flushleft}


\begin{flushleft}
P(X $\in$ A) = P(\{𝜔 $\in$ $\Omega$ : X(𝜔) $\in$ A\}) = P(X $-$1(A))
\end{flushleft}


\begin{flushleft}
e questa quantit\`{a} \`{e} ben definita, infatti A \`{e} un Boreliano, quindi pu\`{o} essere scritto mediante
\end{flushleft}


\begin{flushleft}
unione (numerabile) e complementare di semirette della forma ($-$$\infty$,a] e, per definizione di variabile aleatoria, ogni preimmagine di semiretta (e quindi ogni preimmagine di Boreliani) \`{e} in ℱ
\end{flushleft}


\begin{flushleft}
e, per concludere, per ogni elemento di ℱ la probabilit\`{a} P \`{e} ben definita.
\end{flushleft}


\begin{flushleft}
In questo senso, quindi, la funzione X : ($\Omega$, ℱ) $\rightarrow$ (ℝ, ℬ) {``}trasporta'' su (ℝ, ℬ) una qualunque
\end{flushleft}


\begin{flushleft}
probabilit\`{a} P definita sullo spazio probabilizzabile ($\Omega$, ℱ). Possiamo chiamare PX questa probabilit\`{a} su (ℝ, ℬ).
\end{flushleft}


\begin{flushleft}
5.1. Questo dovrebbe richiamare memorie del corso di Analisi.
\end{flushleft}





\begin{flushleft}
\newpage
VARIABILI ALEATORIE
\end{flushleft}





75





\begin{flushleft}
DEFINIZIONE 5.19. Dati uno spazio di probabilit\`{a} ($\Omega$, ℱ, P) e una variabile aleatoria X : ($\Omega$, ℱ) $\rightarrow$ (ℝ, ℬ),
\end{flushleft}


\begin{flushleft}
si dice legge o distribuzione di X la funzione di probabilit\`{a} PX definita su (ℝ, ℬ) per ogni A $\in$ ℬ da
\end{flushleft}


\begin{flushleft}
PX (A) ≔ P(X $\in$ A) = P(X $-$1(A)).
\end{flushleft}


\begin{flushleft}
Esempio 5.20. Tornando alla situazione descritta nell'Esempio 5.1, cio\`{e} la somma delle facce di
\end{flushleft}


\begin{flushleft}
due dadi bilanciati indipendenti, possiamo ora scrivere PS(\{7\}) per indicare P(S $\in$ \{7\}).
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 5.21. Siano X e Y due variabili aleatorie definite su due spazi di probabilit\`{a}, ($\Omega$, ℱ, P) e
\end{flushleft}


\begin{flushleft}
($\Omega$̃, ℱ̃, P̃) rispettivamente:
\end{flushleft}


\begin{flushleft}
X : ($\Omega$, ℱ, P) $\rightarrow$ (ℝ, ℬ)
\end{flushleft}


\begin{flushleft}
Y : ($\Omega$̃, ℱ̃, P̃) $\rightarrow$ (ℝ, ℬ).
\end{flushleft}


\begin{flushleft}
Chiamiamo PX e PY le loro leggi, cio\`{e} funzioni di probabilit\`{a} definite su (ℝ, ℬ) come
\end{flushleft}


\begin{flushleft}
PX (⋅) = P(X $-$1(⋅));
\end{flushleft}





\begin{flushleft}
PY(⋅) = P̃(Y $-$1(⋅)).
\end{flushleft}





\begin{flushleft}
Se le due funzioni di probabilit\`{a} PX e PY sono uguali, cio\`{e} se assegnano la medesima probabilit\`{a} ad ogni
\end{flushleft}


\begin{flushleft}
elemento di ℬ, diciamo che le variabili aleatorie X e Y sono identicamente distribuite e scriviamo X $\sim$ Y.
\end{flushleft}


\begin{flushleft}
Se leggiamo meglio la definizione appena data, dire che X $\sim$ Y equivale ad affermare che sono
\end{flushleft}


\begin{flushleft}
due copie dello stesso esperimento, almeno dal punto di vista della probabilit\`{a}. Notiamo che
\end{flushleft}


\begin{flushleft}
non \`{e} necessario che X e Y siano definite sullo stesso spazio di probabilit\`{a}. In altre parole stiamo
\end{flushleft}


\begin{flushleft}
dicendo che possiamo rappresentare esperimenti aleatori equivalenti in spazi diversi senza che
\end{flushleft}


\begin{flushleft}
questo abbia effetti sulla probabilit\`{a}. Allo stesso tempo \`{e} anche possibile che esperimenti aleatori
\end{flushleft}


\begin{flushleft}
a priori diversi tra loro siano descritti da variabili aleatorie identicamente distribuite e che quindi,
\end{flushleft}


\begin{flushleft}
dal punto di vista della probabilit\`{a}, siano essenzialmente lo stesso esperimento.
\end{flushleft}


\begin{flushleft}
Esempio 5.22. Non importa se per descrivere il lancio di un dado a 6 facce scegliamo $\Omega$ = \{1, 2, 3,
\end{flushleft}


\begin{flushleft}
4, 5, 6\}, $\Omega$ = \{uno, due, tre, quattro, cinque, sei\}, $\Omega$ = \{U, D, T, Q, C, S\}: anche se formalmente sono
\end{flushleft}


\begin{flushleft}
spazi degli esiti distinti (e quindi ne derivano spazi di probabilit\`{a} diversi), possiamo in tutti i
\end{flushleft}


\begin{flushleft}
casi scrivere una codifica dell'esperimento in ℝ attraverso un'opportuna variabile aleatoria (il
\end{flushleft}


\begin{flushleft}
risultato del lancio), in modo che ciascuna di esse sia identicamente distribuita rispetto alle altre
\end{flushleft}


\begin{flushleft}
e quindi equivalente dal punto di vista della probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Esempio 5.23. Consideriamo un'urna con 50 biglie bianche e 50 biglie nere, da cui estraiamo una
\end{flushleft}


\begin{flushleft}
biglia. Sia X la variabile aleatoria indicatrice dell'evento {``}\`{e} uscita una biglia bianca''. Allora, per
\end{flushleft}


\begin{flushleft}
A $\in$ ℬ,
\end{flushleft}


\begin{flushleft}
1 se \{0, 1\} $\subseteq$ A
\end{flushleft}


\begin{flushleft}
PX (A) =
\end{flushleft}





\{\{


\begin{flushleft}
\{\{ se \#\{\{0, 1\} $\cap$ A\} = 1
\end{flushleft}


\begin{flushleft}
\{ 0 se \{0, 1\} $\cap$ A = $\emptyset$.
\end{flushleft}


1


2





\begin{flushleft}
Prendiamo ora una moneta bilanciata, che lanciamo una sola volta, e definiamo Y la variabile
\end{flushleft}


\begin{flushleft}
aleatoria indicatrice dell'evento {``}\`{e} uscita croce''. Per B $\in$ ℬ abbiamo
\end{flushleft}





\begin{flushleft}
\{\{\{ 1 se \{0, 1\} $\subseteq$ B
\end{flushleft}


\begin{flushleft}
P (B) = \{ se \#\{\{0, 1\} $\cap$ B\} = 1
\end{flushleft}


\begin{flushleft}
\{\{ 0 se \{0, 1\} $\cap$ B = $\emptyset$.
\end{flushleft}


\begin{flushleft}
Y
\end{flushleft}





1


2





\begin{flushleft}
Allo stesso modo, consideriamo una sfida tra due giocatori, Cassandra e Daniele, in cui ciascuno
\end{flushleft}


\begin{flushleft}
abbia la medesima probabilit\`{a} di vincere (e non sia possibile pareggiare) e chiamiamo Z la variabile indicatrice dell'evento {``}vince Cassandra''. Per C $\in$ ℬ vale ancora una volta
\end{flushleft}





\begin{flushleft}
\{\{ 1 se \{0, 1\} $\subseteq$ C
\end{flushleft}


\begin{flushleft}
P (C) = \{ se \#\{\{0, 1\} $\cap$ C\} = 1
\end{flushleft}


\begin{flushleft}
\{\{ 0 se \{0, 1\} $\cap$ C = $\emptyset$.
\end{flushleft}


\begin{flushleft}
Z
\end{flushleft}





1


2





\newpage
76





\begin{flushleft}
VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Astraendo i tre esperimenti alle sole propriet\`{a} o caratteristiche che riguardano la probabilit\`{a}, possiamo osservare che essi sono lo stesso esperimento, fatto codificato dalla notazione X $\sim$ Y $\sim$ Z.
\end{flushleft}


\begin{flushleft}
Questo \`{e} uno dei motivi per cui monete, dadi e urne sono così comuni negli esempi di probabilit\`{a}: permettono di rappresentare in termini molto semplici e vicini all'esperienza comune
\end{flushleft}


\begin{flushleft}
esperimenti aleatori magari molto complicati ma che, dal punto di vista della probabilit\`{a}, non
\end{flushleft}


\begin{flushleft}
aggiungono nulla. Un esempio classico \`{e} quello della descrizione della diffusione di un'infezione
\end{flushleft}


\begin{flushleft}
mediante urne.
\end{flushleft}


\begin{flushleft}
Osservazione 5.24. Nel momento in cui assegniamo una legge a una variabile aleatoria, non \`{e}
\end{flushleft}


\begin{flushleft}
più necessario specificare lo spazio di probabilit\`{a} sottostante. Le variabili aleatorie ci permettono
\end{flushleft}


\begin{flushleft}
di riprodurre nello spazio probabilizzabile (ℝ, ℬ) gli esperimenti aleatori, mediante la scelta di
\end{flushleft}


\begin{flushleft}
un'opportuna probabilit\`{a}, la legge della variabile aleatoria. In questo modo abbiamo semplificato
\end{flushleft}


\begin{flushleft}
la portata della teoria che dobbiamo sviluppare: non occorre farlo per tutti i possibili spazi probabilizzabili, ma per il solo (ℝ, ℬ).
\end{flushleft}


\begin{flushleft}
Insomma, ci basta parlare di funzioni di probabilit\`{a} sullo spazio (ℝ, ℬ). Abbiamo gi\`{a} visto
\end{flushleft}


\begin{flushleft}
come definirle: ci basta assegnarle su una particolare famiglia di generatori della tribù ℬ dei
\end{flushleft}


\begin{flushleft}
Boreliani, le semirette di forma ($-$$\infty$, a], al variare di a $\in$ ℝ. Quindi, tornando al contesto delle
\end{flushleft}


\begin{flushleft}
leggi delle variabili aleatorie, \`{e} sufficiente specificare il valore di una legge PX sulle semirette
\end{flushleft}


\begin{flushleft}
per averne una definizione univoca su tutta la tribù ℬ. Questo ci permette di lavorare con una
\end{flushleft}


\begin{flushleft}
funzione su ℝ, dal momento che le semirette sono in relazione biunivoca con i numeri reali,
\end{flushleft}


\begin{flushleft}
invece che con una funzione su ℬ, cio\`{e} con una funzione su numeri invece che su insiemi di
\end{flushleft}


\begin{flushleft}
numeri, qualcosa cui siamo più abituati.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 5.25. Data una variabile aleatoria X sullo spazio di probabilit\`{a} ($\Omega$, ℱ, P), la funzione di
\end{flushleft}


\begin{flushleft}
ripartizione o funzione cumulativa5.2 di X \`{e} la funzione F X : ℝ $\rightarrow$ ℝ definita per ogni y $\in$ ℝ da
\end{flushleft}


\begin{flushleft}
FX (y) ≔
\end{flushleft}


=


=


=





\begin{flushleft}
PX (($-$$\infty$, y])
\end{flushleft}


\begin{flushleft}
P(X $\in$ ($-$$\infty$, y])
\end{flushleft}


\begin{flushleft}
P(\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ y\})
\end{flushleft}


\begin{flushleft}
P(X ⩽ y).
\end{flushleft}





\begin{flushleft}
Con un leggero abuso di notazione si scrive X $\sim$ FX per dire che la variabile aleatoria X ha funzione di
\end{flushleft}


\begin{flushleft}
ripartizione F X.
\end{flushleft}


\begin{flushleft}
Esempio 5.26. Consideriamo una variabile aleatoria degenere X $\equiv$ c. La sua funzione di ripartizione \`{e}
\end{flushleft}


\begin{flushleft}
1 se y ⩾ c
\end{flushleft}


\begin{flushleft}
FX (y) = P(X ⩽ y) =
\end{flushleft}


\begin{flushleft}
0 se y $<$ c
\end{flushleft}





\{





\begin{flushleft}
FX
\end{flushleft}


1





0





\begin{flushleft}
y
\end{flushleft}





\begin{flushleft}
c
\end{flushleft}





\begin{flushleft}
Figura 5.1. Funzione di ripartizione della v.a. degenere X $\equiv$ c
\end{flushleft}





\begin{flushleft}
Esempio 5.27. Consideriamo ora una variabile aleatoria indicatrice. Per far ci\`{o} fissiamo un evento
\end{flushleft}


\begin{flushleft}
E $\in$ ℱ: la variabile aleatoria indicatrice associata a E, indicata con IE o 1E \`{e} la funzione
\end{flushleft}


\begin{flushleft}
IE(𝜔) = 1E(𝜔) =
\end{flushleft}





\begin{flushleft}
\{\{ 10 sese 𝜔𝜔 $\in$$\in$ EE .
\end{flushleft}


\begin{flushleft}
c
\end{flushleft}





\begin{flushleft}
5.2. Ci sono anche altre varianti, che nascono dal termine inglese, cumulative distribution function, da cui viene anche
\end{flushleft}


\begin{flushleft}
l'abbreviazione cdf .
\end{flushleft}





\begin{flushleft}
\newpage
VARIABILI ALEATORIE
\end{flushleft}





77





\begin{flushleft}
La funzione di ripartizione di questa variabile aleatoria \`{e}
\end{flushleft}


0


\begin{flushleft}
se y $<$ 0
\end{flushleft}


\begin{flushleft}
FIE(y) = P(IE ⩽ y) = P(E c) se 0 ⩽ y $<$ 1
\end{flushleft}


1


\begin{flushleft}
se y ⩾ 1
\end{flushleft}





\{\{


\{\{





\begin{flushleft}
FIE
\end{flushleft}


1


\begin{flushleft}
P (E c )
\end{flushleft}


0





\begin{flushleft}
y
\end{flushleft}





1





\begin{flushleft}
Figura 5.2. Funzione di ripartizione della v.a. indicatrice IE
\end{flushleft}





\begin{flushleft}
Esempio 5.28. Prendiamo ora il lancio di un dado bilanciato a 4 facce: lo rappresentiamo con la
\end{flushleft}


\begin{flushleft}
variabile aleatoria D4, la cui funzione di ripartizione \`{e}
\end{flushleft}





\{\{\{ 0/


\begin{flushleft}
(y) = P(D ⩽ y) = \{
\end{flushleft}


\{\{ //


\{\{ 1


1





\begin{flushleft}
FD4
\end{flushleft}





2





4





3





4


4


4





\begin{flushleft}
se y $<$ 1
\end{flushleft}


\begin{flushleft}
se 1 ⩽ y $<$ 2
\end{flushleft}


\begin{flushleft}
se 2 ⩽ y $<$ 3
\end{flushleft}


\begin{flushleft}
se 3 ⩽ y $<$ 4
\end{flushleft}


\begin{flushleft}
se y ⩾ 4
\end{flushleft}





\begin{flushleft}
FD4
\end{flushleft}


1


3


4


1


2


1


4





0





1





2





3





4





\begin{flushleft}
y
\end{flushleft}





\begin{flushleft}
Figura 5.3. Funzione di ripartizione della v.a. di un dado a 4 facce D4
\end{flushleft}





\begin{flushleft}
Esempio 5.29. Consideriamo ora lo spazio di probabilit\`{a} ($\Omega$, ℱ, P) in cui $\Omega$ = [0, 1] \`{e} l'intervallo
\end{flushleft}


\begin{flushleft}
unitario dei numeri reali, ℱ = ℬ([0, 1]) \`{e} la tribù dei Boreliani ristretta all'intervallo [0, 1] e come
\end{flushleft}


\begin{flushleft}
probabilit\`{a} abbiamo P([a, b]) = b $-$ a, la lunghezza dei segmenti (detta anche misura di Lebesgue).
\end{flushleft}


\begin{flushleft}
Prendiamo la variabile aleatoria X = Id : [0, 1] $\rightarrow$ ℝ. Vogliamo determinarne la funzione di ripartizione:
\end{flushleft}


\begin{flushleft}
FX (y) = P(X ⩽ y)
\end{flushleft}


\begin{flushleft}
= P(\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ y\})
\end{flushleft}


\begin{flushleft}
P($\emptyset$) = 0
\end{flushleft}


\begin{flushleft}
se y $<$ 0
\end{flushleft}


\begin{flushleft}
= P([0, y]) = y se 0 ⩽ y $<$ 1
\end{flushleft}


\begin{flushleft}
P([0, 1]) = 1 se y ⩾ 1
\end{flushleft}





\{\{


\{\{





\begin{flushleft}
In questo caso possiamo osservare che la funzione di ripartizione di questa variabile aleatoria,
\end{flushleft}


\begin{flushleft}
diversamente da quanto visto negli esempi precedenti, \`{e} una funzione continua. Questa particolare variabile aleatoria \`{e} molto importante e prende il nome di variabile aleatoria uniforme su [0, 1].
\end{flushleft}


\begin{flushleft}
FX
\end{flushleft}


1





0





1





\begin{flushleft}
y
\end{flushleft}





\begin{flushleft}
Figura 5.4. Funzione di ripartizione della v.a. uniforme su [0, 1]
\end{flushleft}





\newpage
78





\begin{flushleft}
VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Ripartiamo dagli ultimi esempi visti e richiamiamo alcune propriet\`{a} gi\`{a} viste. Abbiamo visto
\end{flushleft}


\begin{flushleft}
che, per assegnare una legge a una variabile aleatoria, \`{e} sufficiente assegnare una funzione di
\end{flushleft}


\begin{flushleft}
probabilit\`{a} su ℝ, cosa che possiamo fare in particolare attraverso una funzione di ripartizione.
\end{flushleft}


\begin{flushleft}
Osservazione 5.30. Se abbiamo assegnato una funzione di ripartizione F X su ℝ, possiamo calcolare non solo la probabilit\`{a} PX di una semiretta ($-$$\infty$,y], ma anche di tutti gli altri insiemi Boreliani
\end{flushleft}


\begin{flushleft}
su ℝ. In particolare, la probabilit\`{a} dell'intervallo (a, b], con a $<$ b, \`{e}
\end{flushleft}


\begin{flushleft}
PX ((a, b]) = P(($-$$\infty$, b]) $-$ P(($-$$\infty$, a]) = FX (b) $-$ F X (a),
\end{flushleft}


\begin{flushleft}
grazie alle propriet\`{a} delle funzioni di probabilit\`{a} e alle definizioni date. Possiamo allora recuperare dalla discussione fatta precedentemente le propriet\`{a} della funzione di ripartizione F X .
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 5.31. Data una variabile aleatoria X, la sua funzione di ripartizione F X soddisfa le seguenti
\end{flushleft}


\begin{flushleft}
propriet\`{a}:
\end{flushleft}


\begin{flushleft}
i. \`{e} non decrescente
\end{flushleft}


\begin{flushleft}
ii. lim x$\rightarrow$$-$$\infty$ FX (x) = 0 e lim x$\rightarrow$+$\infty$ FX (x) = 1
\end{flushleft}


\begin{flushleft}
iii. \`{e} cadlag, ossia continua a destra (lim x$\rightarrow$x+0 F X (x) = F X (x0)) e limitata a sinistra (lim x$\rightarrow$x0$-$ FX (x) =
\end{flushleft}


\begin{flushleft}
F X (x0) $-$ P(X = x 0)).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Mostriamo, in ordine, le varie propriet\`{a}. Per s ⩽ t abbiamo
\end{flushleft}


\begin{flushleft}
F X (s) = P(X ⩽ s) = P(\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ s\})
\end{flushleft}


\begin{flushleft}
⩽ P(\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ t\}) = P(X ⩽ t) = FX (t)
\end{flushleft}


\begin{flushleft}
in cui, per la disuguaglianza abbiamo usato la monotonia delle funzioni di probabilit\`{a} e l'inclusione
\end{flushleft}


\begin{flushleft}
\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ s\} $\subseteq$ \{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ t\}.
\end{flushleft}


\begin{flushleft}
Per quanto riguarda i limiti agli estremi,
\end{flushleft}


\begin{flushleft}
lim F X (x) = lim P(X ⩽ x)
\end{flushleft}





\begin{flushleft}
x$\rightarrow$$-$$\infty$
\end{flushleft}





\begin{flushleft}
x$\rightarrow$$-$$\infty$
\end{flushleft}





\begin{flushleft}
= lim P(\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ x\})
\end{flushleft}


\begin{flushleft}
x$\rightarrow$$-$$\infty$
\end{flushleft}





\begin{flushleft}
= P
\end{flushleft}





((





\begin{flushleft}
\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ $-$n\}
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
= P($\emptyset$) = 0
\end{flushleft}





))





\begin{flushleft}
e, in modo del tutto analogo,
\end{flushleft}


\begin{flushleft}
lim F X (x) = lim P(X ⩽ x)
\end{flushleft}





\begin{flushleft}
x$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
x$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
= lim P(\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ x\})
\end{flushleft}


\begin{flushleft}
x$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
= P
\end{flushleft}





((





\begin{flushleft}
\{𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ n\}
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


$-$1





))





\begin{flushleft}
= P(X (ℝ)) = P($\Omega$) = 1.
\end{flushleft}


\begin{flushleft}
In un generico punto interno x 0 $\in$ ℝ abbiamo, per il limite da destra,
\end{flushleft}


\begin{flushleft}
lim F X (x) = lim+ P(X ⩽ x)
\end{flushleft}





\begin{flushleft}
x$\rightarrow$x0+
\end{flushleft}





\begin{flushleft}
x$\rightarrow$x 0
\end{flushleft}





\begin{flushleft}
= P
\end{flushleft}





(((





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ x 0 +
\end{flushleft}





\begin{flushleft}
= P(X ⩽ x0) = F X (x0)
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





)))





\begin{flushleft}
\newpage
5.1 VARIABILI ALEATORIE DISCRETE E CONTINUE
\end{flushleft}





79





\begin{flushleft}
e per quello da sinistra
\end{flushleft}


\begin{flushleft}
lim FX (x) = lim$-$ P(X ⩽ x)
\end{flushleft}





\begin{flushleft}
x$\rightarrow$x 0$-$
\end{flushleft}





\begin{flushleft}
x$\rightarrow$x 0
\end{flushleft}





\begin{flushleft}
= P
\end{flushleft}





((





\begin{flushleft}
𝜔 $\in$ $\Omega$ : X(𝜔) ⩽ x0 $-$
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
= P(X $<$ x 0)
\end{flushleft}


\begin{flushleft}
= P(X ⩽ x 0) $-$ P(X = x0)
\end{flushleft}


\begin{flushleft}
= F X (x0) $-$ P(X = x 0)
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





))





\begin{flushleft}
in cui abbiamo usato la seguente osservazione: se 𝜔 $\in$ ⋃ n$\rightarrow$+$\infty$ X(𝜔) ⩽ x 0 $-$ n , allora X(𝜔) ⩽ x per
\end{flushleft}


\begin{flushleft}
qualche x $<$ x 0 e dunque X(𝜔) $<$ x0.
\end{flushleft}


□


1





\begin{flushleft}
Osservazione 5.32. Fissato un qualunque punto x 0 $\in$ ℝ, chiedere che la funzione di ripartizione
\end{flushleft}


\begin{flushleft}
F X sia continua in x 0, cio\`{e} chiedere che lim x$\rightarrow$x0+ F X (x) = lim x$\rightarrow$x0$-$ F X (x) \`{e} equivalente a chiedere che
\end{flushleft}


\begin{flushleft}
la probabilit\`{a} che X assuma il valore x 0 sia nulla, cio\`{e} P(X = x0) = 0.
\end{flushleft}


\begin{flushleft}
Osservazione 5.33. Come gi\`{a} osservato in precedenza, a partire da una funzione di ripartizione
\end{flushleft}


\begin{flushleft}
F X possiamo calcolare la probabilit\`{a} in un qualunque Boreliano. Ad esempio:
\end{flushleft}


\begin{flushleft}
$-$ P(X $\in$ (a, b]) = FX (b) $-$ F X (a)
\end{flushleft}


\begin{flushleft}
$-$ P(X $\in$ [a, b]) = FX (b) $-$ F X (a) + P(X = a) = FX (b) $-$ lim x$\rightarrow$a $-$ FX (x)
\end{flushleft}


\begin{flushleft}
$-$ P(X $<$ a) = lim x$\rightarrow$a $-$ FX (x)
\end{flushleft}


\begin{flushleft}
$-$ P(X $>$ b) = 1 $-$ F X (b)
\end{flushleft}


\begin{flushleft}
e così via.
\end{flushleft}





\begin{flushleft}
5.1. VARIABILI ALEATORIE DISCRETE E CONTINUE
\end{flushleft}


\begin{flushleft}
Le variabili aleatorie si possono dividere in tre classi:
\end{flushleft}


\begin{flushleft}
$-$ variabili aleatorie discrete
\end{flushleft}


\begin{flushleft}
$-$ variabili aleatorie (assolutamente) continue
\end{flushleft}


\begin{flushleft}
$-$ variabili aleatorie miste.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 5.34. Una variabile aleatoria che pu\`{o} assumere al più un numero finito o numerabile di valori
\end{flushleft}


\begin{flushleft}
si dice variabile aleatoria discreta.
\end{flushleft}


\begin{flushleft}
Osservazione 5.35. Una caratterizzazione equivalente di variabile aleatoria discreta pu\`{o} essere
\end{flushleft}


\begin{flushleft}
data in termini della funzione di ripartizione. Una variabile aleatoria \`{e} discreta se e solo se la sua
\end{flushleft}


\begin{flushleft}
funzione di ripartizione \`{e} discontinua e costante a tratti, con un numero finito o numerabile di
\end{flushleft}


\begin{flushleft}
discontinuit\`{a}. I punti di discontinuit\`{a} sono i valori che la variabile aleatoria pu\`{o} assumere.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 5.36. Una variabile aleatoria X si dice continua se la sua funzione di ripartizione FX \`{e}
\end{flushleft}


\begin{flushleft}
continua. Se, inoltre, esiste una funzione non negativa fX : ℝ $\rightarrow$ ℝ tale che, per ogni x $\in$ ℝ,
\end{flushleft}


\begin{flushleft}
FX (x) =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


$-$$\infty$





\begin{flushleft}
fX (y) dy
\end{flushleft}





\begin{flushleft}
allora X si dice assolutamente continua.
\end{flushleft}


\begin{flushleft}
Osservazione 5.37. Al momento il motivo di questa richiesta addizionale per la funzione di ripartizione non \`{e} chiarissima, ma ne capiremo il motivo tra qualche pagina.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 5.38. Una variabile aleatoria che non sia n\'{e} discreta n\'{e} (assolutamente) continua5.3 di dice
\end{flushleft}


\begin{flushleft}
variabile aleatoria mista.
\end{flushleft}


\begin{flushleft}
5.3. Il fatto che si escludano tutte le continue o solo le assolutamente continue dipende dai casi. Noi escluderemo le
\end{flushleft}


\begin{flushleft}
assolutamente continue.
\end{flushleft}





\newpage
80





\begin{flushleft}
VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Osservazione 5.39. La famiglia delle variabili aleatorie miste \`{e} la classe più grande, ma anche
\end{flushleft}


\begin{flushleft}
quella di cui possiamo dire di meno, in particolare in un corso introduttivo come questo. Nel
\end{flushleft}


\begin{flushleft}
seguito non le tratteremo quasi mai.
\end{flushleft}


\begin{flushleft}
Esempio 5.40. Vediamo come costruire un'interessante variabile aleatoria mista. Per farlo, partiamo da una variabile aleatoria uniforme sull'intervallo [0, 1], scrivendone i possibili valori in
\end{flushleft}


\begin{flushleft}
binario. A questo punto, sostituiamo, nella rappresentazione come allineamento dei valori, ogni
\end{flushleft}


\begin{flushleft}
1 con un 2 e leggiamo i valori risultanti come se fossero in base 3.
\end{flushleft}


\begin{flushleft}
La funzione di ripartizione di questa variabile aleatoria \`{e} continua e costante a tratti, ma non
\end{flushleft}


\begin{flushleft}
ammette primitiva.
\end{flushleft}


\begin{flushleft}
∘ Codice R per generare la figura
\end{flushleft}


1.00





0.75





\begin{flushleft}
FX
\end{flushleft}





\begin{flushleft}
Lezione 9
\end{flushleft}





0.50





0.25





0.00


0.00





0.25





0.50





0.75





1.00





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 5.5. La funzione di ripartizione della variabile aleatoria di Cantor
\end{flushleft}





\begin{flushleft}
Esempio 5.41. Un altro esempio, meno drammatico, di variabile aleatoria mista \`{e} il seguente:
\end{flushleft}


\begin{flushleft}
0 se x $<$ 0
\end{flushleft}


\begin{flushleft}
F X (x) = x se 0 ⩽ x $<$ 1/2
\end{flushleft}


\begin{flushleft}
1 se 1/2 ⩽ x
\end{flushleft}





\{\{


\{\{\{





\begin{flushleft}
Questa variabile aleatoria non pu\`{o} essere continua, perch\'{e} ha una discontinuit\`{a} in 2 , ma allo
\end{flushleft}


\begin{flushleft}
stesso tempo non \`{e} discreta, poich\'{e}, pur avendo un numero finito di discontinuit\`{a}, non \`{e} costante
\end{flushleft}


\begin{flushleft}
a tratti.
\end{flushleft}


1





\begin{flushleft}
FX
\end{flushleft}


1





0





1


2





\begin{flushleft}
y
\end{flushleft}





\begin{flushleft}
Figura 5.6. Funzione di ripartizione di una variabile aleatoria mista
\end{flushleft}





\begin{flushleft}
5.1.1. Variabili aleatorie discrete
\end{flushleft}


\begin{flushleft}
Ci concentriamo ora sulle variabili aleatorie discrete.
\end{flushleft}





\begin{flushleft}
DEFINIZIONE 5.42. Sia X una variabile aleatoria discreta. Chiamiamo densit\`{a} discreta o funzione
\end{flushleft}


\begin{flushleft}
di massa di probabilit\`{a} (a volte abbreviata con pmf) la funzione 𝜑 X : ℝ $\rightarrow$ [0, 1], 𝜑 X (x) ≔ P(X = x).
\end{flushleft}


\begin{flushleft}
L'insieme ℛ X = \{x i\}i$\in$I, al più numerabile, dei possibili valori assunti da X (e quindi punti in cui 𝜑 X
\end{flushleft}


\begin{flushleft}
\`{e} non nulla) prende il nome di supporto di X o di 𝜑 X.
\end{flushleft}


\begin{flushleft}
TEOREMA 5.43. (PROPRIET\`{A} DELLA PMF) Sia X una variabile aleatoria discreta e sia 𝜑 X la sua densit\`{a}
\end{flushleft}


\begin{flushleft}
discreta. Allora:
\end{flushleft}


\begin{flushleft}
i. per ogni x $\in$ ℝ, 𝜑 X (x) ⩾ 0
\end{flushleft}





\begin{flushleft}
\newpage
5.1 VARIABILI ALEATORIE DISCRETE E CONTINUE
\end{flushleft}





81





\begin{flushleft}
ii. per ogni x $\in$ ℛ Xc, 𝜑 X (x) = 0
\end{flushleft}


\begin{flushleft}
iii. ∑ x$\in$ℛ X 𝜑X (x) = 1
\end{flushleft}





\begin{flushleft}
iv. se E $\in$ ℬ, allora PX (E) = ∑x$\in$ℛ X$\cap$E 𝜑 X (x) = ∑x$\in$ℛ X 1E(x) 𝜑X (x).
\end{flushleft}





\begin{flushleft}
Dimostrazione. Come prima cosa osserviamo che le propriet\`{a} i e ii sono immediate dalla Definizione 5.42. Inoltre, le somme in iii e iv sono ben definite, perch\'{e} ℛ X \`{e} al più numerabile.
\end{flushleft}


\begin{flushleft}
Mostriamo la iv e la iii seguir\`{a} come caso particolare. Abbiamo
\end{flushleft}


\begin{flushleft}
PX (E) = P(X $\in$ E) = P(\{𝜔 $\in$ $\Omega$ : X(𝜔) $\in$ E\} $\cap$ $\Omega$)
\end{flushleft}





(((


\begin{flushleft}
= P(
\end{flushleft}


(





\begin{flushleft}
= P \{𝜔 $\in$ $\Omega$ : X(𝜔) $\in$ E\} $\cap$
\end{flushleft}





\begin{flushleft}
\{𝜔 $\in$ $\Omega$ : X(𝜔) = x\}
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





)))


))





\begin{flushleft}
(\{𝜔 $\in$ $\Omega$ : X(𝜔) $\in$ E\} $\cap$ \{𝜔 $\in$ $\Omega$ : X(𝜔) = x\})
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
P((X $\in$ E) $\cap$ (X = x))
\end{flushleft}





=


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
1E(x) 𝜑 X (x).
\end{flushleft}





=


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
Come detto, la iii si ottiene nel caso particolare E = $\Omega$.
\end{flushleft}





□





\begin{flushleft}
Osservazione 5.44. Se X \`{e} una variabile aleatoria discreta di densit\`{a} discreta 𝜑 X , allora la sua
\end{flushleft}


\begin{flushleft}
funzione di ripartizione F X \`{e} tale che
\end{flushleft}


\begin{flushleft}
F X (y) =
\end{flushleft}





\begin{flushleft}
1($-$$\infty$,y](x) 𝜑X (x).
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
In particolare questo ripete quanto osservato in precedenza: la funzione di ripartizione \`{e} costante
\end{flushleft}


\begin{flushleft}
a tratti con salti nei punti in ℛ X . L'ampiezza dei salti, inoltre, \`{e} proprio la probabilit\`{a} che la
\end{flushleft}


\begin{flushleft}
variabile aleatoria assuma quel valore.
\end{flushleft}





\begin{flushleft}
5.1.2. Variabili aleatorie assolutamente continue
\end{flushleft}


\begin{flushleft}
Nel caso delle variabili aleatorie continue, e a maggior ragione nel caso di quelle assolutamente
\end{flushleft}


\begin{flushleft}
continue, non possiamo aspettarci una funzione come la densit\`{a} discreta. Infatti, poich\'{e} per definizione F X \`{e} continua, in ogni punto P(X = x) = 0 e quindi 𝜑X sarebbe identicamente nulla.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 5.45. Sia X una variabile aleatoria assolutamente continua. La funzione non negativa f X :
\end{flushleft}


\begin{flushleft}
x
\end{flushleft}


\begin{flushleft}
ℝ $\rightarrow$ ℝ tale che F X (x) = ∫$-$$\infty$ fX (y) dy prende il nome di funzione di densit\`{a} di probabilit\`{a} (o più semplicemente densit\`{a}) di X, a volte abbreviata con pdf. Per una variabile aleatoria assolutamente continua,
\end{flushleft}


\begin{flushleft}
ℛ X = \{x $\in$ ℝ : f X (x) $\neq$ 0\}.
\end{flushleft}


\begin{flushleft}
TEOREMA 5.46. (PROPRIET\`{A} DELLA PDF) Sia X una variabile aleatoria assolutamente continua e sia f X la
\end{flushleft}


\begin{flushleft}
sua densit\`{a}. Allora:
\end{flushleft}


\begin{flushleft}
i. ∫$-$$\infty$ fX (x) dx = 1
\end{flushleft}


+$\infty$


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
ii. ∫a fX (x) dx = FX (b) $-$ F X (a).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Entrambe le propriet\`{a} seguono direttamente dalla definizione. Infatti
\end{flushleft}


+$\infty$


$-$$\infty$





\begin{flushleft}
fX (x) dx = lim F X (x) = 1
\end{flushleft}


\begin{flushleft}
x$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
per le propriet\`{a} della funzione di ripartizione e
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
f X (x) dx =
\end{flushleft}





\begin{flushleft}
b
\end{flushleft}


$-$$\infty$





\begin{flushleft}
f X (x) dx $-$
\end{flushleft}





\begin{flushleft}
a
\end{flushleft}


$-$$\infty$





\begin{flushleft}
f X (x) dx = F X (b) $-$ FX (a)
\end{flushleft}





\begin{flushleft}
riconducendoci alla definizione di funzione di ripartizione.
\end{flushleft}





□





\newpage
82





\begin{flushleft}
VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Osservazione 5.47. A differenza della funzione di densit\`{a} discreta, la funzione di densit\`{a} non \`{e}
\end{flushleft}


\begin{flushleft}
necessariamente limitata all'intervallo [0, 1]. \`{E} non negativa, per definizione, ma pu\`{o} assumere
\end{flushleft}


\begin{flushleft}
valori maggiori di 1, purch\'{e} l'integrale su ℝ sia uguale a 1.
\end{flushleft}


\begin{flushleft}
Osservazione 5.48. Nei punti in cui la funzione di ripartizione FX \`{e} differenziabile, il teorema
\end{flushleft}


\begin{flushleft}
fondamentale del calcolo ci dice che F X′ (x) = f X (x), cio\`{e} la densit\`{a} \`{e} la derivata della funzione di
\end{flushleft}


\begin{flushleft}
ripartizione, ossia la {``}velocit\`{a}'' con cui sta cambiando la probabilit\`{a} in quel punto.
\end{flushleft}


\begin{flushleft}
Possiamo vedere la stessa cosa anche nel modo seguente, sfruttando il teorema del valor
\end{flushleft}


\begin{flushleft}
medio:
\end{flushleft}


\begin{flushleft}
P(x $-$ 𝜀 ⩽ X ⩽ x + 𝜀) =
\end{flushleft}





\begin{flushleft}
x+𝜀
\end{flushleft}





\begin{flushleft}
x$-$𝜀
\end{flushleft}





\begin{flushleft}
f X (y) dy $\approx$ 2 𝜀 ⋅ fX (x),
\end{flushleft}





\begin{flushleft}
in cui 2 𝜀 \`{e} l'ampiezza dell'intervallo. Al tendere di 𝜀 a 0 abbiamo così la probabilit\`{a} di un 𝜀-intorno
\end{flushleft}


\begin{flushleft}
di x, cio\`{e} una palla di raggio 𝜀 centrata in x.
\end{flushleft}


\begin{flushleft}
Ci possono essere punti in cui F X non \`{e} differenziabile e, quindi, non possiamo ricavare in
\end{flushleft}


\begin{flushleft}
modo univoco fX da F X . Questo non \`{e} un problema se questi punti sono in numero al più numerabile, perch\'{e} l'integrale ignora questi punti e quindi non hanno influsso sulla probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
Esempio 5.49. (Variabile aleatoria uniforme in [0, 1]) Abbiamo gi\`{a} visto la funzione di ripartizione della variabile aleatoria uniforme sull'intervallo [0, 1]:
\end{flushleft}


\begin{flushleft}
0 se x $<$ 0
\end{flushleft}


\begin{flushleft}
FX (x) = x se 0 ⩽ x $<$ 1
\end{flushleft}


\begin{flushleft}
1 se x ⩾ 1.
\end{flushleft}





\{\{


\{\{





\begin{flushleft}
Questa funzione \`{e} derivabile in ogni punto, tranne 0 e 1, quindi potremo definire fX su ℝ ∖ \{0, 1\}:
\end{flushleft}


\begin{flushleft}
0 se x $<$ 0
\end{flushleft}


\begin{flushleft}
f X (x) = 1 se 0 $<$ x $<$ 1
\end{flushleft}


\begin{flushleft}
0 se x $>$ 1
\end{flushleft}





\{\{


\{\{





\begin{flushleft}
FX fX
\end{flushleft}


1





0





1





\begin{flushleft}
y
\end{flushleft}





\begin{flushleft}
Figura 5.7. Funzione di ripartizione e densit\`{a} della v.a. uniforme su [0, 1]
\end{flushleft}





\begin{flushleft}
Osservazione 5.50. Come la funzione di massa di probabilit\`{a} 𝜑 X non ha senso per una variabile
\end{flushleft}


\begin{flushleft}
aleatoria assolutamente continua, così la densit\`{a} fX non ha senso per le variabili aleatorie discrete.
\end{flushleft}





\begin{flushleft}
\newpage
CAPITOLO 6
\end{flushleft}


\begin{flushleft}
TRASFORMAZIONI DI VARIABILI ALEATORIE
\end{flushleft}


\begin{flushleft}
Abbiamo caratterizzato le variabili aleatorie come funzioni, quindi \`{e} naturale chiedersi quale sia
\end{flushleft}


\begin{flushleft}
il loro comportamento quando le trasformiamo. Ci interessa in particolare il modo in cui una
\end{flushleft}


\begin{flushleft}
trasformazione influenza la legge della variabile aleatoria.
\end{flushleft}





\begin{flushleft}
6.1. TRASFORMAZIONI LINEARI
\end{flushleft}


\begin{flushleft}
Cominciamo dal caso più semplice: data una variabile aleatoria X, prendiamone una trasformazione lineare, ad esempio 2 X + 3. Com'\`{e} fatta questa nuova variabile aleatoria? Vediamolo in un
\end{flushleft}


\begin{flushleft}
esempio.
\end{flushleft}


\begin{flushleft}
Esempio 6.1. Consideriamo il lancio di un dado a 4 facce, rappresentato dalla variabile aleatoria
\end{flushleft}


\begin{flushleft}
D4. La funzione di ripartizione, come abbiamo gi\`{a} visto, \`{e}
\end{flushleft}





\{\{ 0/


\begin{flushleft}
(x) = P(D ⩽ x) = \{
\end{flushleft}


\{\{ //


\{\{ 1


1





\begin{flushleft}
FD4
\end{flushleft}





2





4





3





4


4


4





\begin{flushleft}
se x $<$ 1
\end{flushleft}


\begin{flushleft}
se 1 ⩽ x $<$ 2
\end{flushleft}


\begin{flushleft}
se 2 ⩽ x $<$ 3
\end{flushleft}


\begin{flushleft}
se 3 ⩽ x $<$ 4
\end{flushleft}


\begin{flushleft}
se x ⩾ 4
\end{flushleft}





\begin{flushleft}
e la sua funzione di densit\`{a} discreta 𝜑D4 \`{e}
\end{flushleft}


\begin{flushleft}
𝜑D4(x) =
\end{flushleft}





\begin{flushleft}
\{\{ se x $\in$ \{1, 2, 3, 4\}
\end{flushleft}


\begin{flushleft}
\{ 0 altrimenti.
\end{flushleft}


1


4





\begin{flushleft}
FD4 ϕD4
\end{flushleft}


1


3


4


1


2


1


4





0





1





2





3





4





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 6.1. Cdf e pmf della v.a. di un dado a 4 facce D4
\end{flushleft}





\begin{flushleft}
Sia ora Y = 2 D4 + 3, quali sono i valori che pu\`{o} assumere6.1?
\end{flushleft}


\begin{flushleft}
D4 1 2 3 4
\end{flushleft}


\begin{flushleft}
Y 5 7 9 11
\end{flushleft}


\begin{flushleft}
e sia la densit\`{a} sia la funzione di ripartizione sono traslate e dilatate in ascissa ma non in ordinata.
\end{flushleft}


\begin{flushleft}
6.1. Attenzione in questo caso 2 D4 non \`{e} da intendersi uguale al lancio di due dadi a 4 facce (cosa che sarebbe D4 + D4),
\end{flushleft}


\begin{flushleft}
\`{e} un solo dado il cui risultato viene raddoppiato.
\end{flushleft}





83





\newpage
84





\begin{flushleft}
TRASFORMAZIONI DI VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
FY ϕY
\end{flushleft}


1


3


4


1


2


1


4





0





5





7





9





\begin{flushleft}
11 y
\end{flushleft}





\begin{flushleft}
Figura 6.2. Cdf e pmf della v.a. Y = 2 D4 + 3
\end{flushleft}





\begin{flushleft}
Possiamo infatti osservare che per la funzione di densit\`{a} discreta
\end{flushleft}


\begin{flushleft}
𝜑Y(y) = P(Y = y) = P(2 D4 + 3 = y) = P D4 =
\end{flushleft}





\begin{flushleft}
y$-$3
\end{flushleft}


\begin{flushleft}
y $-$3
\end{flushleft}


\begin{flushleft}
= 𝜑D4
\end{flushleft}


2


2





\begin{flushleft}
e, per la funzione di ripartizione
\end{flushleft}


\begin{flushleft}
FY(y) = P(Y ⩽ y) = P(2 D4 + 3 ⩽ y) = P D4 ⩽
\end{flushleft}





\begin{flushleft}
y$-$3
\end{flushleft}


\begin{flushleft}
y $-$3
\end{flushleft}


\begin{flushleft}
= FD4
\end{flushleft}


.


2


2





\begin{flushleft}
Continuiamo con un secondo esempio, questa volta usando una variabile aleatoria assolutamente continua (la sola che abbiamo incontrato finora).
\end{flushleft}


\begin{flushleft}
Esempio 6.2. Sia X la variabile aleatoria uniforme sull'intervallo [0, 1]. Ne conosciamo gi\`{a} sia la
\end{flushleft}


\begin{flushleft}
funzione di ripartizione F X , sia la densit\`{a} fX .
\end{flushleft}


\begin{flushleft}
Sia Y = 2 X + 3. Non possiamo andarci a calcolare come prima i valori possibili, prendendo
\end{flushleft}


\begin{flushleft}
gli elementi (in numero finito) di ℛ X e calcolandone il valore trasformato, perch\'{e} questa volta la
\end{flushleft}


\begin{flushleft}
cardinalit\`{a} di ℛ X \`{e} quella del continuo. Tuttavia possiamo declinare la stessa idea: cerchiamo il
\end{flushleft}


\begin{flushleft}
supporto della densit\`{a} fY a partire dal supporto della densit\`{a} fX . Abbiamo visto che ℛ X = (0, 1).
\end{flushleft}


\begin{flushleft}
Inoltre, per definizione, il supporto ℛ Y di Y \`{e} l'insieme dei numeri reali y tali che fY(y) $\neq$ 0 o,
\end{flushleft}


\begin{flushleft}
equivalentemente, tali che f 2X+3(y) $\neq$ 0, o anche l'insieme dei numeri reali x tali che fY(2 x + 3) $\neq$0.
\end{flushleft}


\begin{flushleft}
Possiamo allora convincerci (vedremo i dettagli per assicurarcene in seguito) che il supporto
\end{flushleft}


\begin{flushleft}
di Y sia il supporto di X dilatato e traslato: ℛ Y = 2 ℛ X + 3, ogni numero x in (0, 1) viene trasformato in un numero y $\in$ (3, 5).
\end{flushleft}


\begin{flushleft}
Come cambia la funzione di densit\`{a}? Ci aspettiamo, essendo una trasformazione lineare, che
\end{flushleft}


\begin{flushleft}
sia qualcosa della stessa forma, quindi una costante c non nulla in (3, 5) e costantemente nulla
\end{flushleft}


\begin{flushleft}
altrove. La tentazione di dire c = 1 \`{e} forte: per le variabili aleatorie discrete abbiamo visto che la
\end{flushleft}


\begin{flushleft}
densit\`{a} discreta era trasformata in ascissa ma non in ordinata. Tuttavia questo non pu\`{o} essere il
\end{flushleft}


\begin{flushleft}
caso, infatti deve essere, per ogni densit\`{a},
\end{flushleft}


+$\infty$


$-$$\infty$





\begin{flushleft}
e se fosse c = 1 avremmo
\end{flushleft}





\begin{flushleft}
fX (x) dx =
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
ℛX
\end{flushleft}





\begin{flushleft}
f Y(y) dy =
\end{flushleft}





\begin{flushleft}
f X (x) dx = 1
\end{flushleft}


5





3





\begin{flushleft}
1 dy = 2.
\end{flushleft}





\begin{flushleft}
Proviamo allora a passare dalla funzione di ripartizione: come vedremo \`{e} quella la via maestra.
\end{flushleft}


\begin{flushleft}
Abbiamo infatti
\end{flushleft}


\begin{flushleft}
y$-$3
\end{flushleft}


\begin{flushleft}
y$-$3
\end{flushleft}


\begin{flushleft}
F Y(y) = P(Y ⩽ y) = P(2 X + 3 ⩽ y) = P X ⩽
\end{flushleft}


\begin{flushleft}
= FX
\end{flushleft}


2


2


\begin{flushleft}
che nel caso specifico diventa
\end{flushleft}





\{\{ 0


\begin{flushleft}
F (y) = \{
\end{flushleft}


\{\{


\{\{ 1


\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
y$-$3
\end{flushleft}


2





\begin{flushleft}
se
\end{flushleft}





\begin{flushleft}
y $-$3
\end{flushleft}


2





\begin{flushleft}
se 0 ⩽
\end{flushleft}


\begin{flushleft}
se
\end{flushleft}





\begin{flushleft}
y $-$3
\end{flushleft}


2





\begin{flushleft}
$<$ 0, cio\`{e} y $<$ 3
\end{flushleft}


\begin{flushleft}
y $-$3
\end{flushleft}


2





\begin{flushleft}
$<$ 1, cio\`{e} 3 ⩽ y $<$ 5
\end{flushleft}





\begin{flushleft}
⩾ 1, cio\`{e} y ⩾ 5.
\end{flushleft}





\begin{flushleft}
\newpage
6.1 TRASFORMAZIONI LINEARI
\end{flushleft}





85





\begin{flushleft}
Possiamo ora ricavarci per derivazione la densit\`{a} f Y, ottenendo
\end{flushleft}


\begin{flushleft}
fY(y) =
\end{flushleft}





\begin{flushleft}
\{\{ y $\in$ (3, 5)
\end{flushleft}


\begin{flushleft}
\{ 0 y $\in$ [3, 5]
\end{flushleft}


1


2





\begin{flushleft}
c
\end{flushleft}





\begin{flushleft}
confermando quindi che il supporto di Y \`{e} la trasformazione del supporto di X, come ipotizzato.
\end{flushleft}


\begin{flushleft}
Inoltre,
\end{flushleft}


1


\begin{flushleft}
y$-$3
\end{flushleft}


\begin{flushleft}
f Y(y) = fX
\end{flushleft}


,


2


2


\begin{flushleft}
rispetto al caso discreto compare un coefficiente.
\end{flushleft}


\begin{flushleft}
FY fY
\end{flushleft}


1


1


2





0





\begin{flushleft}
5 y
\end{flushleft}





3





\begin{flushleft}
Figura 6.3. Cdf e pdf di una trasformazione lineare della v.a. uniforme su [0, 1]
\end{flushleft}





\begin{flushleft}
In generale vale il seguente risultato.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 6.3. Sia X una variabile aleatoria e sia Y = a X + b con a $\neq$ 0, b $\in$ ℝ una sua trasformazione
\end{flushleft}


\begin{flushleft}
y$-$b
\end{flushleft}


\begin{flushleft}
lineare. Allora se a $>$ 0, FY(y) = F X a , mentre se a$<$0
\end{flushleft}


\begin{flushleft}
F Y(y) =
\end{flushleft}


\begin{flushleft}
Inoltre, se X \`{e} continua
\end{flushleft}





\begin{flushleft}
\{\{ 1 $-$ F
\end{flushleft}


\begin{flushleft}
\{\{ 1 $-$ F
\end{flushleft}





\begin{flushleft}
y$-$b
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
y$-$b
\end{flushleft}


\begin{flushleft}
X
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
se X \`{e} ass. continua
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
fY(y) =
\end{flushleft}


\begin{flushleft}
mentre se \`{e} discreta
\end{flushleft}





\begin{flushleft}
y $-$b
\end{flushleft}


\begin{flushleft}
𝜑 Y = 𝜑X a
\end{flushleft}





\begin{flushleft}
y $-$b
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
+ 𝜑X
\end{flushleft}





.





\begin{flushleft}
se X \`{e} discreta.
\end{flushleft}





1


\begin{flushleft}
y$-$b
\end{flushleft}


\begin{flushleft}
fX
\end{flushleft}


,


\begin{flushleft}
|a|
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





(





)





\begin{flushleft}
Dimostrazione. Cominciamo dalla funzione di ripartizione. Dalla definizione abbiamo
\end{flushleft}


\begin{flushleft}
FY(y) = P(Y ⩽ y) = P(a X + b ⩽ y) = P(a X ⩽ y $-$ b).
\end{flushleft}


\begin{flushleft}
Ora dobbiamo scindere in due casi in base al segno di a. Se \`{e} positivo
\end{flushleft}





((





\begin{flushleft}
FY(y) = P(a X ⩽ y $-$ b) = P X ⩽
\end{flushleft}


\begin{flushleft}
Se invece a \`{e} negativo,
\end{flushleft}





(





\begin{flushleft}
FY(y) = P(a X ⩽ y $-$ b) = P X ⩾
\end{flushleft}


\begin{flushleft}
che per X (e dunque F X ) continua d\`{a}
\end{flushleft}





\begin{flushleft}
y$-$b
\end{flushleft}


\begin{flushleft}
y$-$b
\end{flushleft}


\begin{flushleft}
= FX
\end{flushleft}


.


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





))





((





))





\begin{flushleft}
y $-$b
\end{flushleft}


\begin{flushleft}
y $-$b
\end{flushleft}


\begin{flushleft}
=1$-$P X$<$
\end{flushleft}


\begin{flushleft}
= 1 $-$ lim $-$ FX (x)
\end{flushleft}


\begin{flushleft}
y$-$b
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
x$\rightarrow$
\end{flushleft}





)





(





\begin{flushleft}
y$-$b
\end{flushleft}


\begin{flushleft}
FY(y) = 1 $-$ F X a
\end{flushleft}





\begin{flushleft}
FY(y) = 1 $-$ F X
\end{flushleft}





)





\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
, mentre per X discreta
\end{flushleft}





\begin{flushleft}
(( y $-$a b )) + 𝜑 (( y $-$a b )).
\end{flushleft}


\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
Per la densit\`{a} f Y, nel caso assolutamente continuo, \`{e} sufficiente usare la regola della catena,
\end{flushleft}


\begin{flushleft}
facendo attenzione ai segni: se a $>$ 0,
\end{flushleft}


\begin{flushleft}
f Y(y) =
\end{flushleft}





\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
y$-$b
\end{flushleft}


1


\begin{flushleft}
y$-$b
\end{flushleft}


1


\begin{flushleft}
y $-$b
\end{flushleft}


\begin{flushleft}
F (y) =
\end{flushleft}


\begin{flushleft}
F
\end{flushleft}


\begin{flushleft}
= FX′
\end{flushleft}


\begin{flushleft}
= fX
\end{flushleft}


.


\begin{flushleft}
dy Y
\end{flushleft}


\begin{flushleft}
dy X a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





(





)





(





)





(





)





\newpage
86





\begin{flushleft}
TRASFORMAZIONI DI VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Se invece a $<$ 0,
\end{flushleft}


\begin{flushleft}
f Y(y) =
\end{flushleft}





\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
y $-$b
\end{flushleft}


\begin{flushleft}
F (y) =
\end{flushleft}


\begin{flushleft}
1 $-$ FX
\end{flushleft}


\begin{flushleft}
dy Y
\end{flushleft}


\begin{flushleft}
dy
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





(





(





\begin{flushleft}
)) = $-$ dyd F ( y $-$a b ) = $-$ 1a f ( y $-$a b ),
\end{flushleft}


\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
y$-$b
\end{flushleft}





\begin{flushleft}
da cui f Y(y) = |a| fX a .
\end{flushleft}


\begin{flushleft}
Per la densit\`{a} discreta, infine,
\end{flushleft}


1





(





\begin{flushleft}
𝜑 Y(y) = P(Y = y) = P(a X + b = y) = P X =
\end{flushleft}





\begin{flushleft}
y $-$b
\end{flushleft}


\begin{flushleft}
y $-$b
\end{flushleft}


\begin{flushleft}
= 𝜑X
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





)





(





)





\begin{flushleft}
in cui il fatto che ci sia l'uguaglianza rende insignificante il segno di a.
\end{flushleft}





□





\begin{flushleft}
6.1.1. La costante di rinormalizzazione
\end{flushleft}


\begin{flushleft}
Ispirandoci a quanto abbiamo appena visto per la funzione di densit\`{a} trasformata, consideriamo
\end{flushleft}


\begin{flushleft}
un problema più generale. Supponiamo di avere una funzione, quand'\`{e} che essa \`{e} la densit\`{a}
\end{flushleft}


\begin{flushleft}
di una variabile aleatoria? Innanzitutto dobbiamo controllare che sia non negativa, dopodich\'{e}
\end{flushleft}


\begin{flushleft}
passiamo alla condizione sull'integrale.
\end{flushleft}


\begin{flushleft}
Se abbiamo una funzione f ⩾ 0 il cui integrale su ℝ \`{e} finito e positivo ma diverso da 1, possiamo ricavare da f una funzione di densit\`{a} prendendo la funzione c⋅ f , per un'opportuna costante
\end{flushleft}


\begin{flushleft}
(positiva) c. Come facciamo a determinare questa costante? Deve essere
\end{flushleft}


1=


\begin{flushleft}
quindi la scelta di c \`{e} obbligata:
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
c f (x) dx = c
\end{flushleft}





\begin{flushleft}
c=
\end{flushleft}





+$\infty$


$-$$\infty$





+$\infty$


$-$$\infty$





\begin{flushleft}
f (x) dx
\end{flushleft}





\begin{flushleft}
f (x) dx,
\end{flushleft}





$-$1





.





\begin{flushleft}
Il nome costante di rinormalizzazione viene dal fatto che stiamo riscalando la funzione f in modo
\end{flushleft}


\begin{flushleft}
che il suo integrale su ℝ sia 1.
\end{flushleft}


\begin{flushleft}
Esempio 6.4. Consideriamo la funzione f (x) = e $-$x per x $\in$ (0, 1) e costantemente nulla sul resto di
\end{flushleft}


\begin{flushleft}
ℝ. Possiamo trasformarla nella densit\`{a} di una variabile aleatoria moltiplicandola per un'opportuna costante, visto che \`{e} una funzione non negativa, purch\'{e} il suo integrale sia positivo.
\end{flushleft}


\begin{flushleft}
Cominciamo allora con il calcolo di
\end{flushleft}


+$\infty$





\begin{flushleft}
Allora la funzione
\end{flushleft}





$-$$\infty$





\begin{flushleft}
f (x) dx =
\end{flushleft}





\begin{flushleft}
f X (x) =
\end{flushleft}


\begin{flushleft}
\`{e} una densit\`{a} di probabilit\`{a}.
\end{flushleft}





\begin{flushleft}
\{\{ (10 $-$ e
\end{flushleft}





1


0





\begin{flushleft}
e $-$x dx = 1 $-$ e $-$1 $<$ 1.
\end{flushleft}





\begin{flushleft}
$-$1 $-$1 $-$x
\end{flushleft}





\begin{flushleft}
) e
\end{flushleft}





\begin{flushleft}
x $\in$ (0, 1)
\end{flushleft}


\begin{flushleft}
altrimenti
\end{flushleft}





\begin{flushleft}
fX
\end{flushleft}


\begin{flushleft}
(1 $-$ e$-$1 )$-$1
\end{flushleft}





\begin{flushleft}
e$-$1 (1 $-$ e$-$1 )$-$1
\end{flushleft}





0





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 6.4. Densit\`{a} di una trasformazione lineare della v.a. uniforme su [0, 1]
\end{flushleft}





\begin{flushleft}
Esempio 6.5. Sia f (x) = c nell'intervallo (0, 𝜋) e identicamente nulla altrimenti. Esistono (e se sì,
\end{flushleft}


\begin{flushleft}
quali sono) valori di c tali che f sia una densit\`{a} di probabilit\`{a}?
\end{flushleft}





\begin{flushleft}
\newpage
6.2 TRASFORMAZIONI NON LINEARI
\end{flushleft}





87





\begin{flushleft}
La funzione f \`{e} non negativa a patto che c ⩾ 0, restringendo quindi i potenziali valori di c.
\end{flushleft}


\begin{flushleft}
Inoltre deve essere
\end{flushleft}


1=





+$\infty$


$-$$\infty$





\begin{flushleft}
𝜋
\end{flushleft}





\begin{flushleft}
f (x) dx =
\end{flushleft}





0





\begin{flushleft}
c dx = c ⋅ 𝜋,
\end{flushleft}





\begin{flushleft}
da cui abbiamo c = 1/𝜋. Questa \`{e} la variabile aleatoria uniforme sull'intervallo [0, 𝜋], la cui funzione di ripartizione (che possiamo ricavare integrando f ) \`{e}
\end{flushleft}


\begin{flushleft}
F(x) =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


$-$$\infty$





\begin{flushleft}
\{\{ 0 x $<$ 0
\end{flushleft}


\begin{flushleft}
f (t) dt = \{ x 0 ⩽ x $<$ 𝜋
\end{flushleft}


\begin{flushleft}
\{\{ 1 x $>$ 𝜋.
\end{flushleft}


1


\begin{flushleft}
𝜋
\end{flushleft}





\begin{flushleft}
F f
\end{flushleft}


1


1


\begin{flushleft}
$\pi$
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
$\pi$
\end{flushleft}





0





\begin{flushleft}
Figura 6.5. Funzione di ripartizione e densit\`{a} della v.a. uniforme su [0, 𝜋]
\end{flushleft}





\begin{flushleft}
Esempio 6.6. Sia ora f (x) = c e $-$|x| una funzione definita su ℝ. Per quali valori (eventualmente
\end{flushleft}


\begin{flushleft}
anche nessuno) di c \`{e} la densit\`{a} di una variabile aleatoria?
\end{flushleft}


\begin{flushleft}
Anche in questo caso osserviamo che necessariamente c ⩾ 0 per garantire la non negativit\`{a}
\end{flushleft}


\begin{flushleft}
di f . Passiamo poi alla condizione sull'integrale,
\end{flushleft}


1=





+$\infty$


$-$$\infty$





\begin{flushleft}
f (x) dx =
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
c e $-$|x| dx = c
\end{flushleft}





0


$-$$\infty$





\begin{flushleft}
e x dx +
\end{flushleft}





+$\infty$


0





\begin{flushleft}
e $-$x dx = c [e x]0$-$$\infty$ + c [$-$e $-$x]+$\infty$
\end{flushleft}


\begin{flushleft}
0 = 2 c,
\end{flushleft}





\begin{flushleft}
da cui c = 1/2, quindi f (x) = 2 e $-$|x| \`{e} una densit\`{a} di probabilit\`{a}. La corrispondente funzione di
\end{flushleft}


\begin{flushleft}
ripartizione \`{e}
\end{flushleft}


1





\begin{flushleft}
F(x) =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


$-$$\infty$





\begin{flushleft}
f (t) dt =
\end{flushleft}





1


2





\begin{flushleft}
x
\end{flushleft}


$-$$\infty$





\begin{flushleft}
e $-$|t| dt =
\end{flushleft}





\{\{


\{





1


2


1


2





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
∫$-$$\infty$ e $-$t dt = 2 e x
\end{flushleft}


1





\begin{flushleft}
x$<$0
\end{flushleft}





1


0


\begin{flushleft}
∫$-$$\infty$ e t dt + 2
\end{flushleft}





1


\begin{flushleft}
x
\end{flushleft}


\begin{flushleft}
∫0 e $-$t dt = 1 $-$ 2 e $-$x
\end{flushleft}





\begin{flushleft}
x $>$ 0.
\end{flushleft}





\begin{flushleft}
F f
\end{flushleft}


1


1


2





0





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 6.6. Densit\`{a} di una trasformazione lineare della v.a. uniforme su [0, 1]
\end{flushleft}





\begin{flushleft}
Lezione 10
\end{flushleft}





\begin{flushleft}
6.2. TRASFORMAZIONI NON LINEARI
\end{flushleft}


\begin{flushleft}
Anche in questo caso abbiamo una variabile aleatoria X, di cui conosciamo la legge, ossia la funzione di ripartizione F X . Questo \`{e} essenzialmente equivalente al conoscerne la densit\`{a} fX , nel
\end{flushleft}


\begin{flushleft}
caso di variabili aleatorie assolutamente continue, o la densit\`{a} discreta 𝜑 X , nel caso di variabili
\end{flushleft}


\begin{flushleft}
aleatorie discrete.
\end{flushleft}


\begin{flushleft}
Ora, per\`{o}, invece di una trasformazione lineare abbiamo una funzione g : ℝ $\rightarrow$ ℝ, che supponiamo nonlineare (se fosse lineare ricadremmo nel caso precedente), ad esempio g(x) = |x| o
\end{flushleft}


\begin{flushleft}
g(x) =
\end{flushleft}





\begin{flushleft}
\{\{ 30 x + log(x) xx $>$⩽ 00.
\end{flushleft}


2





\begin{flushleft}
L'obiettivo \`{e} il medesimo di prima: determinare la legge della variabile aleatoria Y = g(X).
\end{flushleft}





\newpage
88





\begin{flushleft}
TRASFORMAZIONI DI VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Per le variabili aleatorie discrete le cose sono anche in questo caso molto semplici: dobbiamo
\end{flushleft}


\begin{flushleft}
solamente fare attenzione al fatto che g non \`{e} necessariamente iniettiva o suriettiva, quindi ogni
\end{flushleft}


\begin{flushleft}
valore di y pu\`{o} avere nessuna, una o più di una preimmagine rispetto a g. Ogni y che \`{e} immagine
\end{flushleft}


\begin{flushleft}
di almeno un punto x $\in$ ℛ X eredita da ogni sua preimmagine la corrispondente probabilit\`{a}:
\end{flushleft}


\begin{flushleft}
𝜑 Y(y) =
\end{flushleft}





\begin{flushleft}
𝜑X (x).
\end{flushleft}


\begin{flushleft}
x$\in$g $-$1(\{y\})
\end{flushleft}





\begin{flushleft}
Il supporto di Y \`{e} l'immagine mediante g del supporto di X, ℛ Y = g(ℛ X ) e la funzione di ripartizione si ricava dalla densit\`{a} discreta.
\end{flushleft}


\begin{flushleft}
Se invece X \`{e} assolutamente continua abbiamo in questo caso più generale rispetto a quello
\end{flushleft}


\begin{flushleft}
lineare almeno due modi di farlo, ciascuno coi suoi pro e i suoi contro6.2:
\end{flushleft}


\begin{flushleft}
1. Possiamo ricavare la legge di Y sfruttando la forma della variabile aleatoria X (in particolare
\end{flushleft}


\begin{flushleft}
la forma della sua funzione di ripartizione F X ) e della funzione g. Questa \`{e} una strategia che
\end{flushleft}


\begin{flushleft}
richiede di adattarsi alla specifica coppia (X, g) che consideriamo. Spesso \`{e} facile, ma \`{e} anche
\end{flushleft}


\begin{flushleft}
facile sbagliare.
\end{flushleft}


\begin{flushleft}
2. Possiamo usare un teorema generale. Purtroppo le ipotesi del teorema non sono sempre soddisfatte e, anche quando lo sono, l'applicazione del teorema pu\`{o} essere difficile.
\end{flushleft}


\begin{flushleft}
Vediamo la prima strategia, necessariamente, con due esempi.
\end{flushleft}


\begin{flushleft}
Esempio 6.7. Sia X una variabile aleatoria (assolutamente continua) di densit\`{a}
\end{flushleft}


\begin{flushleft}
fX (x) =
\end{flushleft}





\begin{flushleft}
$-$x
\end{flushleft}





\begin{flushleft}
\{ e0
\end{flushleft}





\begin{flushleft}
x$>$0
\end{flushleft}


\begin{flushleft}
x⩽0
\end{flushleft}





\begin{flushleft}
e sia g : ℝ $\rightarrow$ ℝ la funzione g(x) = e $-$x. Vogliamo determinare la legge della variabile aleatoria
\end{flushleft}


\begin{flushleft}
Y = e $-$X .
\end{flushleft}


\begin{flushleft}
Cominciamo dalla definizione:
\end{flushleft}


\begin{flushleft}
FY(y) = P(Y ⩽ y) = P(e $-$X ⩽ y) =
\end{flushleft}





\begin{flushleft}
⩽ log y) = P(X ⩾ $-$log y) y $>$ 0
\end{flushleft}


\begin{flushleft}
\{\{ P($-$X
\end{flushleft}


0


\begin{flushleft}
y⩽0
\end{flushleft}





\begin{flushleft}
dove abbiamo usato, oltre alle definizioni, la monotonia crescente del logaritmo.
\end{flushleft}


\begin{flushleft}
Ora per proseguire ci occorre la funzione di ripartizione di X, che possiamo ricavare da f X :
\end{flushleft}


\begin{flushleft}
F X (x) =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


$-$$\infty$





\begin{flushleft}
fX (t) dt =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


0





\begin{flushleft}
e $-$t dt = 1 $-$ e $-$x,
\end{flushleft}





\begin{flushleft}
x$>$0
\end{flushleft}





\begin{flushleft}
e identicamente nulla altrimenti. Allora
\end{flushleft}


0


\{


\{


\{


\begin{flushleft}
F (y) = 1 $-$ (1 $-$ e
\end{flushleft}


\{\{ 1


\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
y ⩽0
\end{flushleft}


\begin{flushleft}
$-$($-$log y)
\end{flushleft}





\begin{flushleft}
)=y 0$<$y $<$1
\end{flushleft}


\begin{flushleft}
y ⩾1
\end{flushleft}





\begin{flushleft}
in cui l'ultimo caso si verifica quando y $>$ 0 e $-$log y ⩽ 0. Quindi in questo caso Y \`{e} la variabile
\end{flushleft}


\begin{flushleft}
aleatoria uniforme su [0, 1].
\end{flushleft}


\begin{flushleft}
Se volessimo avere anche f Y, potremmo farlo derivando F Y, oppure, se non avessimo calcolato
\end{flushleft}


\begin{flushleft}
F Y derivandola in astratto. In questo secondo caso abbiamo (per y $>$ 0)
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
(1 $-$ FX ($-$log y))
\end{flushleft}


\begin{flushleft}
dy
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


1


\begin{flushleft}
= $-$F X′ ($-$log y)
\end{flushleft}


\begin{flushleft}
($-$log y) = $-$ fX ($-$log y) $-$
\end{flushleft}


\begin{flushleft}
dy
\end{flushleft}


\begin{flushleft}
y
\end{flushleft}


1


\begin{flushleft}
= f X ($-$log y)
\end{flushleft}


\begin{flushleft}
y
\end{flushleft}


1


\begin{flushleft}
per $-$log y $>$ 0 $\Leftrightarrow$ y $<$ 1 = e $-$($-$log y) = 1.
\end{flushleft}


\begin{flushleft}
y
\end{flushleft}


\begin{flushleft}
fY(y) = F Y′ (y) =
\end{flushleft}





(( ))





\begin{flushleft}
6.2. Contrariamente a quanto si pensa, raramente in matematica esiste una sola ricetta per risolvere problemi.
\end{flushleft}





\begin{flushleft}
\newpage
6.2 TRASFORMAZIONI NON LINEARI
\end{flushleft}





89





\begin{flushleft}
Riassumendo abbiamo
\end{flushleft}





\begin{flushleft}
0 y $<$0
\end{flushleft}


\begin{flushleft}
f Y(y) = 1 0 $<$ y $<$ 1
\end{flushleft}


\begin{flushleft}
0 y $>$ 1.
\end{flushleft}





\{\{\{


\{





\begin{flushleft}
Esempio 6.8. Sia X una variabile aleatoria (assolutamente continua) di densit\`{a}
\end{flushleft}


\begin{flushleft}
fX (x) =
\end{flushleft}





\begin{flushleft}
$-$x
\end{flushleft}





\begin{flushleft}
\{\{ e0
\end{flushleft}





\begin{flushleft}
x$>$0
\end{flushleft}


\begin{flushleft}
x⩽0
\end{flushleft}





\begin{flushleft}
e sia Z = (1 $-$ X)2, cio\`{e} g(x) = (1 $-$ x)2. Vogliamo determinare la legge di Z.
\end{flushleft}


\begin{flushleft}
Come prima cosa, consideriamo la funzione di ripartizione F Z,
\end{flushleft}


\begin{flushleft}
F Z(z) = P(Z ⩽ z) = P((1 $-$ X)2 ⩽ z) =
\end{flushleft}





\begin{flushleft}
$-$ X| ⩽ $\surd$z ) z $>$ 0
\end{flushleft}


\begin{flushleft}
\{\{ P(|1
\end{flushleft}


0


\begin{flushleft}
z⩽0
\end{flushleft}





\begin{flushleft}
in cui z = 0 pu\`{o} stare equivalentemente sopra o sotto, tanto la probabilit\`{a} di un punto \`{e} nulla,
\end{flushleft}


\begin{flushleft}
siccome la variabile \`{e} continua. Proseguendo, nel caso z $>$ 0, abbiamo
\end{flushleft}


\begin{flushleft}
P(|1 $-$ X| ⩽ $\surd$z ) =
\end{flushleft}


=


=


=





\begin{flushleft}
P($-$$\surd$z ⩽ 1 $-$ X ⩽ $\surd$z )
\end{flushleft}


\begin{flushleft}
P(1 + $\surd$z ⩾ X ⩾ 1 $-$ $\surd$z )
\end{flushleft}


\begin{flushleft}
FX (1 + $\surd$z ) $-$ F X (1 $-$ $\surd$z )
\end{flushleft}


\begin{flushleft}
(1 $-$ e $-$(1+$\surd$z )) 1\{1+$\surd$z $>$0\} $-$ (1 $-$ e $-$(1$-$$\surd$z )) 1\{1$-$$\surd$z $>$0\}
\end{flushleft}





\begin{flushleft}
e, riassumendo,
\end{flushleft}


0


\{


\{


\{


\begin{flushleft}
F (z) = e
\end{flushleft}


\begin{flushleft}
\{\{ 1 $-$ e
\end{flushleft}





\begin{flushleft}
$-$(1$-$$\surd$z )
\end{flushleft}





\begin{flushleft}
Z
\end{flushleft}





\begin{flushleft}
$-$e
\end{flushleft}





\begin{flushleft}
$-$(1+$\surd$z )
\end{flushleft}





\begin{flushleft}
$-$(1+$\surd$z )
\end{flushleft}





\begin{flushleft}
z⩽0
\end{flushleft}


\begin{flushleft}
0$<$z$<$1
\end{flushleft}


\begin{flushleft}
z ⩾ 1.
\end{flushleft}





\begin{flushleft}
Passiamo alla densit\`{a} f Z. Avendo la forma esplicita di FZ possiamo ricavarla derivando direttamente quest'ultima, ma se non l'avessimo gi\`{a} calcolata potremmo ricondurci a f X nel modo
\end{flushleft}


\begin{flushleft}
seguente, per z $>$ 0,
\end{flushleft}


\begin{flushleft}
f Z(z) = fX (1 + $\surd$z )
\end{flushleft}


=





\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
(1 + $\surd$z ) $-$ fX (1 $-$ $\surd$z ) (1 $-$ $\surd$z )
\end{flushleft}


\begin{flushleft}
dz
\end{flushleft}


\begin{flushleft}
dz
\end{flushleft}





1


\begin{flushleft}
( f (1 + $\surd$z ) + f X (1 $-$ $\surd$z )).
\end{flushleft}


\begin{flushleft}
2 $\surd$z X
\end{flushleft}





\begin{flushleft}
Ora possiamo andare a inserire la forma esplicita di f X , facendo attenzione al suo dominio, in
\end{flushleft}


\begin{flushleft}
particolare nel secondo addendo. Abbiamo
\end{flushleft}





\{\{ 0


\begin{flushleft}
f (z) = \{
\end{flushleft}


\{\{


\{


\begin{flushleft}
Z
\end{flushleft}





\begin{flushleft}
z$<$0
\end{flushleft}


\begin{flushleft}
$-$(1+$\surd$z )
\end{flushleft}





1


\begin{flushleft}
2 $\surd$z
\end{flushleft}





\begin{flushleft}
(e
\end{flushleft}





1


\begin{flushleft}
2 $\surd$z
\end{flushleft}





\begin{flushleft}
e $-$(1+$\surd$z )
\end{flushleft}





\begin{flushleft}
+e
\end{flushleft}





\begin{flushleft}
$-$(1$-$$\surd$z )
\end{flushleft}





\begin{flushleft}
) 0$<$z$<$1
\end{flushleft}


\begin{flushleft}
z $>$ 1.
\end{flushleft}





\begin{flushleft}
Anche in questo caso il valore della densit\`{a} in 0 e 1 non \`{e} rilevante. \`{E} invece un esercizio di
\end{flushleft}


\begin{flushleft}
Analisi verificare che la funzione fZ appena scritta sia una densit\`{a} di probabilit\`{a}, cio\`{e} che sia non
\end{flushleft}


\begin{flushleft}
negativa e abbia integrale uguale a 1.
\end{flushleft}


\begin{flushleft}
Passiamo ora alla seconda strategia. Essa si basa sul seguente risultato.
\end{flushleft}


\begin{flushleft}
TEOREMA 6.9. (CAMBIO DI VARIABILE) Sia X una variabile aleatoria assolutamente continua, di densit\`{a} f X. Sia inoltre Y = g(X), con g : ℝ $\rightarrow$ ℝ funzione 𝒞 1 a tratti e tale che P(g′(X) = 0) = 0. Allora
\end{flushleft}


\begin{flushleft}
f Y(y) =
\end{flushleft}


\begin{flushleft}
\{x$\in$g $-$1(\{y\})\}
\end{flushleft}





\begin{flushleft}
fX (x)
\end{flushleft}


.


\begin{flushleft}
|g′(x)|
\end{flushleft}





\newpage
90





\begin{flushleft}
TRASFORMAZIONI DI VARIABILI ALEATORIE
\end{flushleft}





\begin{flushleft}
Osservazione 6.10. Cerchiamo di capire cosa significa la condizione P(g′(X) = 0) = 0 nel Teorema 6.9. La scrittura g′(X) = 0 rappresenta un insieme, in particolare
\end{flushleft}


\begin{flushleft}
\{𝜔 $\in$ $\Omega$ : 𝜔 $\in$ X $-$1(\{x\})\}
\end{flushleft}





\begin{flushleft}
\{g′(X) = 0\} = \{𝜔 $\in$ $\Omega$ : g′(X(𝜔)) = 0\} =
\end{flushleft}


\begin{flushleft}
x:g′(x)=0
\end{flushleft}





\begin{flushleft}
sono quindi tutti quegli esiti che finiscono, attraverso X, nei punti in cui si annulla la derivata di g.
\end{flushleft}


\begin{flushleft}
Stiamo quindi chiedendo che g′ si annulli su insiemi di ℝ in cui X ha valore con probabilit\`{a} 0.
\end{flushleft}


\begin{flushleft}
Possono essere punti, dunque, anche in quantit\`{a} numerabile, ma in genere non intervallini. In
\end{flushleft}


\begin{flushleft}
particolare, nella somma possiamo trascurare eventuali punti x in cui il denominatore si annulla.
\end{flushleft}


\begin{flushleft}
Inoltre possiamo osservare che l'insieme \{x $\in$ g $-$1(\{y\})\} = \{x : g(x) = y\}, grazie a questa ipotesi
\end{flushleft}


\begin{flushleft}
sugli zeri di g′, ha un numero finito di elementi, quindi la somma \`{e} ben definita.
\end{flushleft}


\begin{flushleft}
Vediamo come usare il Teorema 6.9 in un esempio.
\end{flushleft}


\begin{flushleft}
Esempio 6.11. Rimettiamoci nello stesso caso dell'Esempio 6.8. La funzione g : ℝ $\rightarrow$ ℝ \`{e} una funzione 𝒞 1 e la sua derivata g′(x) = 2 x $-$ 2 si annulla solamente in x = 1, ma per la forma della
\end{flushleft}


\begin{flushleft}
variabile aleatoria X la probabilit\`{a} che X = 1 \`{e} nulla.
\end{flushleft}


\begin{flushleft}
Siamo allora nelle ipotesi del Teorema 6.9. Per usarne il risultato, come prima cosa andiamo
\end{flushleft}


\begin{flushleft}
a studiare come sono fatti gli insiemi g $-$1(\{z\}) al variare di z $\in$ ℝ. Abbiamo
\end{flushleft}


$\emptyset$


\begin{flushleft}
z$<$0
\end{flushleft}


\begin{flushleft}
g $-$1(\{z\}) = \{1\}
\end{flushleft}


\begin{flushleft}
z=0
\end{flushleft}


\begin{flushleft}
\{1 $-$ $\surd$z , 1 + $\surd$z \} z $>$ 0.
\end{flushleft}





\{\{


\{\{





\begin{flushleft}
Se ora passiamo a f Z abbiamo, dal Teorema 6.9
\end{flushleft}


\begin{flushleft}
z$<$0
\end{flushleft}





\{\{ 0


\begin{flushleft}
f (z) = \{
\end{flushleft}


\{\{


\{





\begin{flushleft}
fX(1)
\end{flushleft}


\begin{flushleft}
|g′(1)|
\end{flushleft}





\begin{flushleft}
Z
\end{flushleft}





\begin{flushleft}
z=0
\end{flushleft}





= +$\infty$





\begin{flushleft}
fX(1 $-$ $\surd$z )
\end{flushleft}


\begin{flushleft}
|g′(1 $-$ $\surd$z )|
\end{flushleft}





\begin{flushleft}
f (1 + $\surd$z )
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}


\begin{flushleft}
+ |g′(1
\end{flushleft}


\begin{flushleft}
z $>$ 0.
\end{flushleft}


\begin{flushleft}
+ $\surd$z )|
\end{flushleft}





\begin{flushleft}
La prima parte, per z $<$ 0, \`{e} a posto. Per z = 0 abbiamo un momento di fastidio, ma poi pensiamo
\end{flushleft}


\begin{flushleft}
al fatto che non ci interessa il valore in un singolo punto, per f Z: possiamo non definirla in z = 0.
\end{flushleft}


\begin{flushleft}
Resta da sistemare l'ultimo caso, z $>$ 0. In tal caso
\end{flushleft}


\begin{flushleft}
f (1 $-$ $\surd$z )
\end{flushleft}


\begin{flushleft}
f (1 + $\surd$z ) \{
\end{flushleft}


\begin{flushleft}
f (z) =
\end{flushleft}


+


=\{


\{


\begin{flushleft}
|g′(1 $-$ $\surd$z )| |g′(1 + $\surd$z )| \{
\end{flushleft}


\{


\begin{flushleft}
Z
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
e $-$(1$-$$\surd$z )
\end{flushleft}


\begin{flushleft}
2 |1 $-$ $\surd$z $-$ 1|
\end{flushleft}





\begin{flushleft}
+ 2 |1 + $\surd$z $-$ 1| 1 $-$ $\surd$z $>$ 0
\end{flushleft}





\begin{flushleft}
e $-$(1+$\surd$z )
\end{flushleft}





\begin{flushleft}
e $-$(1+$\surd$z )
\end{flushleft}


\begin{flushleft}
2 |1 + $\surd$z $-$ 1|
\end{flushleft}





\begin{flushleft}
1 $-$ $\surd$z $<$ 0
\end{flushleft}





\begin{flushleft}
e, mettendo assieme tutti i pezzi, otteniamo che
\end{flushleft}





\{\{\{ 0


\begin{flushleft}
f (z) = \{
\end{flushleft}


\{\{


\{





\begin{flushleft}
z$<$0
\end{flushleft}





\begin{flushleft}
e $-$(1$-$$\surd$z )
\end{flushleft}


\begin{flushleft}
2 $\surd$z
\end{flushleft}





\begin{flushleft}
Z
\end{flushleft}





\begin{flushleft}
e
\end{flushleft}





\begin{flushleft}
$-$(1+ $\surd$z )
\end{flushleft}





\begin{flushleft}
2 $\surd$z
\end{flushleft}





+





\begin{flushleft}
e $-$(1+ $\surd$z )
\end{flushleft}


\begin{flushleft}
2 $\surd$z
\end{flushleft}





\begin{flushleft}
0$<$z$<$1
\end{flushleft}


\begin{flushleft}
z $>$ 1.
\end{flushleft}





\begin{flushleft}
fZ
\end{flushleft}





1


2 (1





\begin{flushleft}
+ e$-$2 )
\end{flushleft}


\begin{flushleft}
e$-$2 /2
\end{flushleft}


0





1





\begin{flushleft}
Figura 6.7. Densit\`{a} della variabile aleatoria Z
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}





\begin{flushleft}
\newpage
CAPITOLO 7
\end{flushleft}


\begin{flushleft}
VETTORI ALEATORI
\end{flushleft}


\begin{flushleft}
Finora abbiamo considerato le variabili aleatorie una per volta. Tuttavia potremmo avere, sullo
\end{flushleft}


\begin{flushleft}
spazio di probabilit\`{a} ($\Omega$, ℱ, P) due variabili aleatorie X, Y che vogliamo trattare assieme, ad
\end{flushleft}


\begin{flushleft}
esempio perch\'{e} ci interessa conoscere la probabilit\`{a} che X $<$ Y, oppure che |X + Y| $>$ 1. Se ci pensiamo questo non \`{e} molto diverso dal cercare la probabilit\`{a} di g(X) $<$ 𝛼, per qualche funzione
\end{flushleft}


\begin{flushleft}
g e qualche valore 𝛼.
\end{flushleft}


\begin{flushleft}
Ad esempio, possiamo prendere g(x) = |x| e 𝛼 = 1 e riscrivere P(g(X) ⩽ 𝛼) = P(|X| ⩽ 1) come
\end{flushleft}


\begin{flushleft}
P(|X| ⩽ 1) = P($-$1 ⩽ X ⩽ 1) = F X (1) $-$ FX ($-$1) + P(X = $-$1).
\end{flushleft}


\begin{flushleft}
Abbiamo calcolato la probabilit\`{a} di tutti gli 𝜔 in $\Omega$ tali che X(𝜔) sia nell'intervallo chiuso [$-$1, 1].
\end{flushleft}


\begin{flushleft}
In maniera del tutto analoga, calcolare P(X $<$ Y) significher\`{a} trovare la probabilit\`{a} di tutti quegli
\end{flushleft}


\begin{flushleft}
𝜔 tali che X(𝜔)$<$ Y(𝜔). Gli esiti 𝜔 per\`{o} devono essere gli stessi in contemporanea in X e Y, quindi
\end{flushleft}


\begin{flushleft}
a priori non possiamo usare separatamente le leggi di X e Y. Procediamo per passi.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 7.1. Dati uno spazio di probabilit\`{a} ($\Omega$, ℱ, P) e due variabili aleatorie X e Y su di esso, si
\end{flushleft}


\begin{flushleft}
chiama coppia di variabili aleatorie o variabile aleatoria doppia o vettore aleatorio di dimensione 2
\end{flushleft}


\begin{flushleft}
la funzione V : $\Omega$ $\rightarrow$ ℝ2 definita da V(𝜔) = (X(𝜔), Y(𝜔)). Il vettore aleatorio V ha supporto
\end{flushleft}


\begin{flushleft}
ℛ V = ℛ X,Y = ℛ X × ℛ Y = \{(x, y) $\in$ ℝ2 : x $\in$ ℛ X , y $\in$ ℛ Y\}.
\end{flushleft}


\begin{flushleft}
Osservazione 7.2. Possiamo pensare a una vettore aleatorio di dimensione 2 come a una variabile
\end{flushleft}


\begin{flushleft}
aleatoria a valori sul piano ℝ2 invece che sulla retta ℝ. Un singolo esito 𝜔 viene mandato dal
\end{flushleft}


\begin{flushleft}
vettore in un punto del piano.
\end{flushleft}


\begin{flushleft}
In modo del tutto analogo possiamo definire e studiare vettori aleatori di dimensione d ⩾ 1.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 7.3. Data una variabile aleatoria doppia (X, Y), la sua funzione di ripartizione \`{e}
\end{flushleft}


\begin{flushleft}
FX,Y((x, y)) = FX,Y(x, y) = P(X ⩽ x, Y ⩽ y).
\end{flushleft}


\begin{flushleft}
Tale funzione F X,Y si dice anche funzione di ripartizione congiunta di X e Y.
\end{flushleft}


\begin{flushleft}
In maniera del tutto analoga possiamo definire la funzione di ripartizione congiunta per vettori aleatori
\end{flushleft}


\begin{flushleft}
d-dimensionali.
\end{flushleft}


\begin{flushleft}
Osservazione 7.4. In generale non \`{e} sufficiente conoscere le funzioni di ripartizione F X ed F Y per
\end{flushleft}


\begin{flushleft}
conoscere la funzione di ripartizione congiunta FX,Y. Viceversa, nota F X,Y possiamo ricavare da
\end{flushleft}


\begin{flushleft}
essa F X ed FY, che in questo caso prendono il nome di funzioni di ripartizione marginali. Infatti
\end{flushleft}


\begin{flushleft}
F X (x) = P(X ⩽ x, $\forall$Y)
\end{flushleft}


\begin{flushleft}
= P(X ⩽ x, Y $<$ +$\infty$)
\end{flushleft}


\begin{flushleft}
= lim F X,Y(x, y)
\end{flushleft}


\begin{flushleft}
y$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
e analogamente F Y(y) = lim x$\rightarrow$+$\infty$ F X,Y(x, y).
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 7.5. Data una variabile aleatoria doppia (X, Y) si dice funzione di ripartizione di X conFX,Y (x, y)
\end{flushleft}


\begin{flushleft}
dizionata a Y la funzione F X∣Y(x ∣ y) ≔ F (y) .
\end{flushleft}


\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
Questa funzione \`{e} la probabilit\`{a} dell'evento che immaginiamo: F X∣Y(x ∣ y) = P(X ⩽ x ∣ Y ⩽ y).
\end{flushleft}


\begin{flushleft}
Non ci sorprende dunque la prossima definizione.
\end{flushleft}


91





\newpage
92





\begin{flushleft}
VETTORI ALEATORI
\end{flushleft}





\begin{flushleft}
DEFINIZIONE 7.6. Dati uno spazio di probabilit\`{a} ($\Omega$, ℱ, P) e due sottotribù ℱ 1 ed ℱ 2 di ℱ, diciamo che
\end{flushleft}


\begin{flushleft}
ℱ 1 ed ℱ 2 sono indipendenti se ogni evento in ℱ 1 \`{e} indipendente da ogni evento di ℱ 2, ossia se per ogni
\end{flushleft}


\begin{flushleft}
E 1 $\in$ ℱ 1 ed E2 $\in$ ℱ 2, P(E1 $\cap$ E 2) = P(E1) ⋅ P(E 2).
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 7.7. Dati uno spazio di probabilit\`{a} ($\Omega$, ℱ, P) e due variabili aleatorie X e Y su di esso, tali
\end{flushleft}


\begin{flushleft}
variabili aleatorie sono indipendenti se lo sono le tribù 𝜎(X) e 𝜎(Y) da esse generate.
\end{flushleft}


\begin{flushleft}
La definizione di indipendenza tra variabili aleatorie ha lo svantaggio di non essere molto
\end{flushleft}


\begin{flushleft}
pratica nelle applicazioni, perch\'{e} per essere verificata richiede di controllare che tutte le coppie
\end{flushleft}


\begin{flushleft}
di eventi nel prodotto delle tribù generate siano indipendenti. Esistono per\`{o} delle condizioni
\end{flushleft}


\begin{flushleft}
equivalenti, di più facile uso.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 7.8. Due variabili aleatorie X e Y sullo stesso spazio di probabilit\`{a} sono indipendenti se e
\end{flushleft}


\begin{flushleft}
solo se per ogni (x, y) $\in$ ℝ2, FX,Y(x, y) = FX (x) ⋅ F Y(y).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Mostriamo l'implicazione diretta $\Rightarrow$. Abbiamo
\end{flushleft}


\begin{flushleft}
F X,Y(x, y) = P(\{X ⩽ x\} $\cap$ \{Y ⩽ y\}) = P(X ⩽ x) P(Y ⩽ y) = FX (x) F Y(y),
\end{flushleft}


\begin{flushleft}
in cui nella seconda uguaglianza abbiamo usato che \{X ⩽ x\} $\in$ 𝜎(X), \{Y ⩽ y\} $\in$ 𝜎(Y) e che, per
\end{flushleft}


\begin{flushleft}
definizione di indipendenza, le tribù generate sono equivalenti.
\end{flushleft}


\begin{flushleft}
L'implicazione inversa $\Leftarrow$ \`{e} una conseguenza non banale del teorema di Carath\'{e}odory e non
\end{flushleft}


\begin{flushleft}
viene affrontata in questo corso.
\end{flushleft}


□


\begin{flushleft}
PROPOSIZIONE 7.9. Due variabili aleatorie X e Y sullo stesso spazio di probabilit\`{a} sono indipendenti se e
\end{flushleft}


\begin{flushleft}
solo se per ogni (x, y) $\in$ ℝ2, FX (x) = F X∣Y(x ∣ y) e F Y(y) = FY∣X (y ∣ x).
\end{flushleft}


\begin{flushleft}
Osservazione 7.10. Se abbiamo più variabili aleatorie, cio\`{e} se abbiamo un vettore aleatorio di
\end{flushleft}


\begin{flushleft}
dimensione d ⩾ 3, per avere l'indipendenza dobbiamo considerare tutti i raggruppamenti possibili (a 2 a 2, a 3 a 3 e così via) come gi\`{a} visto per gli eventi.
\end{flushleft}





\begin{flushleft}
7.1. VETTORI ALEATORI DISCRETI
\end{flushleft}


\begin{flushleft}
Quanto detto finora sulle coppie di variabili aleatorie riguardava solamente le funzioni di ripartizione, quindi vale tanto per le variabili aleatorie discrete quanto per quelle assolutamente continue
\end{flushleft}


\begin{flushleft}
(e anche per quelle miste). Nel caso in cui entrambe le variabili aleatorie X e Y siano discrete,
\end{flushleft}


\begin{flushleft}
possiamo indagare più a fondo, facendo entrare in gioco le densit\`{a} discrete.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 7.11. Siano X e Y due variabili aleatorie discrete sullo stesso spazio di probabilit\`{a} ($\Omega$, ℱ, P).
\end{flushleft}


\begin{flushleft}
Si dice densit\`{a} discreta congiunta di X e Y la funzione 𝜑 X,Y : ℝ2 $\rightarrow$ [0, 1] definita da
\end{flushleft}


\begin{flushleft}
𝜑X,Y(x, y) = P(X = x, Y = y).
\end{flushleft}


\begin{flushleft}
Si dice inoltre densit\`{a} condizionale di X data Y la funzione
\end{flushleft}


\begin{flushleft}
𝜑X∣Y(x ∣ y) =
\end{flushleft}





\begin{flushleft}
= x ∣ Y = y) y $\in$ ℛ
\end{flushleft}


\begin{flushleft}
\{\{ P(X
\end{flushleft}


0


\begin{flushleft}
y$\in$ℛ .
\end{flushleft}


\begin{flushleft}
Y
\end{flushleft}


\begin{flushleft}
c
\end{flushleft}


\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
Osservazione 7.12. Dalla definizione di densit\`{a} discreta congiunta ricaviamo immediatamente le
\end{flushleft}


\begin{flushleft}
seguenti propriet\`{a}:
\end{flushleft}


\begin{flushleft}
$-$ per ogni (x, y) in ℝ2, 0 ⩽ 𝜑X,Y(x, y) ⩽ 1
\end{flushleft}


\begin{flushleft}
$-$ 𝜑 X,Y(x, y) = 0 sui valori impossibili, cio\`{e} se x $\in$ ℛ Xc o y $\in$ ℛ Yc
\end{flushleft}


\begin{flushleft}
$-$ vale l'identit\`{a}
\end{flushleft}


\begin{flushleft}
𝜑 X,Y(x, y) = 1.
\end{flushleft}


\begin{flushleft}
(x,y)$\in$ℝ2
\end{flushleft}





\begin{flushleft}
\newpage
7.1 VETTORI ALEATORI DISCRETI
\end{flushleft}





93





\begin{flushleft}
Forse la sola cosa che ci pu\`{o} sorprendere \`{e} il fatto che abbiamo scritto una somma su tutte le
\end{flushleft}


\begin{flushleft}
coppie in ℝ2, nell'ultima identit\`{a}. Ma questo abuso di notazione \`{e} innocuo, dal momento che
\end{flushleft}


\begin{flushleft}
tranne che per un numero finito o numerabile di valori di x e di y e dunque di coppie (x, y), la
\end{flushleft}


\begin{flushleft}
funzione 𝜑 X,Y \`{e} identicamente nulla. In effetti possiamo scrivere
\end{flushleft}


\begin{flushleft}
𝜑 X,Y(x, y) =
\end{flushleft}





\begin{flushleft}
𝜑 X,Y(x, y) = 1.
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X,y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
(x,y)$\in$ℝ2
\end{flushleft}





\begin{flushleft}
Vediamo ora alcune propriet\`{a} delle coppie di variabili aleatorie discrete.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 7.13. Sia (X, Y) una coppia di variabili aleatorie. Valgono le seguenti uguaglianze:
\end{flushleft}


\begin{flushleft}
i. per ogni (x, y) $\in$ ℝ2,
\end{flushleft}


\begin{flushleft}
F X,Y(x, y) =
\end{flushleft}





\begin{flushleft}
1\{𝜉 ⩽x\} 1\{𝜂⩽y\} 𝜑 X,Y(𝜉, 𝜂)
\end{flushleft}


\begin{flushleft}
(𝜉 ,𝜂)$\in$ℛ X,Y
\end{flushleft}





\begin{flushleft}
ii. per ogni (x, y) $\in$ ℝ2, 𝜑X,Y(x, y) = 𝜑X∣Y(x ∣ y) 𝜑 Y(y)
\end{flushleft}


\begin{flushleft}
iii. per ogni x $\in$ ℝ, 𝜑 X (x) = ∑y$\in$ℛ Y 𝜑 X,Y(x, y)
\end{flushleft}





\begin{flushleft}
iv. le variabili aleatorie X e Y sono indipendenti se e solo se, per ogni (x,y ) $\in$ℛ X,Y, 𝜑X,Y(x, y ) =𝜑X (x) 𝜑Y(y )
\end{flushleft}


\begin{flushleft}
v. le variabili aleatorie X e Y sono indipendenti se e solo se, per ogni (x, y) $\in$ ℛ X,Y, 𝜑 X (x) = 𝜑 X∣Y(x ∣ y) e
\end{flushleft}


\begin{flushleft}
𝜑 Y(y) = 𝜑Y∣X (y ∣ x).
\end{flushleft}





\begin{flushleft}
Lezione 11
\end{flushleft}





\begin{flushleft}
Dimostrazione. Procediamo in ordine.
\end{flushleft}


\begin{flushleft}
i. Segue immediatamente dalle definizioni.
\end{flushleft}


\begin{flushleft}
ii. Se y $\in$ ℛ Yc l'identit\`{a} \`{e} immediata, se y $\in$ ℛ Y abbiamo
\end{flushleft}


\begin{flushleft}
𝜑 X∣Y(x ∣ y) 𝜑 Y(y) = P(X = x ∣ Y = y) P(Y = y)
\end{flushleft}


\begin{flushleft}
P(X = x, Y = y)
\end{flushleft}


=


\begin{flushleft}
P(Y = y)
\end{flushleft}


\begin{flushleft}
P(Y = y)
\end{flushleft}


\begin{flushleft}
= 𝜑X,Y(x, y).
\end{flushleft}


\begin{flushleft}
iii. Iniziamo riscrivendo il secondo membro, sfruttando l'identit\`{a} appena mostrata:
\end{flushleft}


\begin{flushleft}
𝜑 X,Y(x, y) =
\end{flushleft}


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
𝜑X∣Y(x ∣ y) 𝜑X (x)
\end{flushleft}


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
𝜑X∣Y(x ∣ y)
\end{flushleft}





\begin{flushleft}
= 𝜑 X (x)
\end{flushleft}


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
P(Y = y ∣ X = x)
\end{flushleft}





\begin{flushleft}
= 𝜑 X (x)
\end{flushleft}


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
= 𝜑 X (x),
\end{flushleft}


\begin{flushleft}
poich\'{e} P(⋅ ∣ X = x) \`{e} una probabilit\`{a} e stiamo sommando su tutti i possibili eventi disgiunti.
\end{flushleft}


\begin{flushleft}
iv. L'implicazione $\Rightarrow$ \`{e} immediata dalle definizioni. Viceversa, l'implicazione $\Leftarrow$ si ottiene usando
\end{flushleft}


\begin{flushleft}
la prima propriet\`{a} e l'analogo risultato visto per le funzioni di ripartizione.
\end{flushleft}


\begin{flushleft}
v. Segue dalla iv. e dalla ii.
\end{flushleft}





□





\begin{flushleft}
Osservazione 7.14. Vale la pena osservare che, se \`{e} nota 𝜑 X,Y, la propriet\`{a} iv. \`{e} molto pratica per
\end{flushleft}


\begin{flushleft}
verificare (o confutare) l'indipendenza di X e Y.
\end{flushleft}


\begin{flushleft}
Esempio 7.15. Abbiamo due variabili aleatorie X e Y, entrambe discrete. La variabile X descrive
\end{flushleft}


\begin{flushleft}
il lancio di una moneta bilanciata, mentre Y \`{e} il lancio di un dado a 6 facce se X = 0 e il lancio di
\end{flushleft}


\begin{flushleft}
un dado a 8 facce se X = 1. Vogliamo ottenere la legge di Y.
\end{flushleft}


\begin{flushleft}
Come prima cosa vogliamo scrivere in modo preciso i dati del problema:
\end{flushleft}


\begin{flushleft}
1/ y $\in$ \{1, . . . , 6\}
\end{flushleft}


\begin{flushleft}
1/ y $\in$ \{1, . . . , 8\}
\end{flushleft}


6


8


\begin{flushleft}
𝜑Y∣X (y ∣ 0) =
\end{flushleft}


\begin{flushleft}
𝜑Y∣X (y ∣ 1) =
\end{flushleft}


\begin{flushleft}
0 altrimenti
\end{flushleft}


\begin{flushleft}
0 altrimenti,
\end{flushleft}





\{\{





\{\{





\newpage
94





\begin{flushleft}
VETTORI ALEATORI
\end{flushleft}





\begin{flushleft}
che potremmo anche scrivere in modo più compatto come
\end{flushleft}





\{\{ //


\begin{flushleft}
(y ∣ x) = \{
\end{flushleft}


\{0


1





\begin{flushleft}
𝜑 Y∣X
\end{flushleft}





6





1





8





\begin{flushleft}
x = 0, y $\in$ \{1, . . . , 6\}
\end{flushleft}


\begin{flushleft}
x = 1, y $\in$ \{1, . . . , 8\}
\end{flushleft}


\begin{flushleft}
altrimenti.
\end{flushleft}





\begin{flushleft}
Poi andiamo a ricavarci la densit\`{a} discreta congiunta, ricordando che 𝜑X,Y(x,y) =𝜑 Y∣X (y ∣ x)𝜑 X (x):
\end{flushleft}





\{\{ //


\begin{flushleft}
(x, y) = \{
\end{flushleft}


\{0


1





\begin{flushleft}
𝜑X,Y
\end{flushleft}





1





12


16





\begin{flushleft}
x = 0, y $\in$ \{1, . . . , 6\}
\end{flushleft}


\begin{flushleft}
x = 1, y $\in$ \{1, . . . , 8\}
\end{flushleft}


\begin{flushleft}
altrimenti.
\end{flushleft}





\begin{flushleft}
A questo punto abbiamo tutti gli ingredienti necessari per calcolare la densit\`{a} discreta di Y,
\end{flushleft}


\begin{flushleft}
sommando su tutti i possibili valori di X:
\end{flushleft}





\{\{ //


\begin{flushleft}
(x, y) = \{
\end{flushleft}


\{\{ 0


7





\begin{flushleft}
𝜑Y(y) =
\end{flushleft}





\begin{flushleft}
𝜑X,Y
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





1





48


16





\begin{flushleft}
y $\in$ \{1, . . . , 6\}
\end{flushleft}


\begin{flushleft}
y $\in$ \{7, 8\}
\end{flushleft}


\begin{flushleft}
altrimenti.
\end{flushleft}





\begin{flushleft}
A questo punto possiamo anche chiederci se le variabili aleatorie X e Y siano o meno indipendenti. Dal momento che conosciamo la densit\`{a} discreta congiunta ed entrambe le densit\`{a}
\end{flushleft}


\begin{flushleft}
marginali, \`{e} sufficiente verificare se 𝜑 X,Y(x, y) = 𝜑 X (x) 𝜑 Y(y), ma
\end{flushleft}





\{\{ //


\begin{flushleft}
𝜑 (x) 𝜑 (y) = \{
\end{flushleft}


\{\{ /


\{\{ 0


7


7





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
Y
\end{flushleft}





1





96


96


32





\begin{flushleft}
x = 0, y $\in$ \{1, . . . , 6\}
\end{flushleft}


\begin{flushleft}
x = 1, y $\in$ \{1, . . . , 6\}
\end{flushleft}


\begin{flushleft}
$\neq$ 𝜑 X,Y(x, y),
\end{flushleft}


\begin{flushleft}
x = 1, y $\in$ \{7, 8\}
\end{flushleft}


\begin{flushleft}
altrimenti
\end{flushleft}





\begin{flushleft}
quindi (come potevamo aspettarci, vista la definizione di Y) X e Y non sono indipendenti tra loro.
\end{flushleft}


\begin{flushleft}
Data una coppia di variabili aleatorie, in molti casi siamo interessati a qualche loro funzione.
\end{flushleft}


\begin{flushleft}
Un esempio, semplice ma molto utile, \`{e} la somma di due variabili aleatorie, che vediamo, nel caso
\end{flushleft}


\begin{flushleft}
discreto, nel seguente risultato.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 7.16. (SOMMA DI VARIABILI ALEATORIE DISCRETE) Siano X e Y due variabili aleatorie
\end{flushleft}


\begin{flushleft}
sullo stesso spazio di probabilit\`{a} ($\Omega$, ℱ, P) con densit\`{a} congiunta 𝜑 X,Y. La loro somma ha densit\`{a} discreta
\end{flushleft}


\begin{flushleft}
𝜑 X,Y(x, z $-$ x).
\end{flushleft}





\begin{flushleft}
𝜑 X+Y(z) =
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
Dimostrazione. Dalle definizioni abbiamo
\end{flushleft}


\begin{flushleft}
𝜑 X+Y(z) = P(X + Y = z)
\end{flushleft}





((


\begin{flushleft}
= P(
\end{flushleft}


((


\begin{flushleft}
= P
\end{flushleft}





))


\begin{flushleft}
\{X = x, Y = z $-$ x\})
\end{flushleft}


))


\begin{flushleft}
\{X = x, X + Y = z\}
\end{flushleft}





\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
P(X = x, Y = z $-$ x)
\end{flushleft}





=


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
𝜑X,Y(x, z $-$ x)
\end{flushleft}





=


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
e abbiamo così la densit\`{a} discreta della variabile aleatoria Z = X + Y.
\end{flushleft}


\begin{flushleft}
Osservazione 7.17. Se le variabili aleatorie X e Y sono indipendenti, allora
\end{flushleft}


\begin{flushleft}
𝜑 X (x) 𝜑 Y(z $-$ x).
\end{flushleft}





\begin{flushleft}
𝜑X+Y(z) =
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





□





\begin{flushleft}
\newpage
7.2 VETTORI ALEATORI ASSOLUTAMENTE CONTINUI
\end{flushleft}





95





\begin{flushleft}
Esempio 7.18. Siano X e Y due variabili aleatorie (indipendenti) che descrivono ciascuna il lancio
\end{flushleft}


\begin{flushleft}
di un dado a 10 facce. Indichiamo con S = X + Y la loro variabile aleatoria somma. Vogliamo
\end{flushleft}


\begin{flushleft}
scrivere la densit\`{a} discreta congiunta di S e X, 𝜑S,X (s, x) e la densit\`{a} discreta condizionata di S
\end{flushleft}


\begin{flushleft}
data X, 𝜑S∣X (s ∣ x).
\end{flushleft}


\begin{flushleft}
Partendo dalla definizione,
\end{flushleft}


\begin{flushleft}
𝜑S,X (s, x) = P(S = s, X = x) = P(X + Y = s, X = x)
\end{flushleft}


\begin{flushleft}
= P(Y = s $-$ x, X = x) = 𝜑 X,Y(x, s $-$ x) = 𝜑 X (x) 𝜑 Y(s $-$ x),
\end{flushleft}


\begin{flushleft}
dove nell'ultimo passaggio abbiamo sfruttato il fatto che X e Y siano indipendenti.
\end{flushleft}


\begin{flushleft}
Passiamo alla densit\`{a} discreta condizionata,
\end{flushleft}


\begin{flushleft}
𝜑S∣X (s ∣ x) =
\end{flushleft}





\begin{flushleft}
𝜑S,X (s, x)
\end{flushleft}


\begin{flushleft}
= 𝜑 Y(s $-$ x).
\end{flushleft}


\begin{flushleft}
𝜑X (x)
\end{flushleft}





\begin{flushleft}
Finora non abbiamo usato la particolare forma delle densit\`{a} discrete di X e Y:
\end{flushleft}


\begin{flushleft}
𝜑X (x) = 𝜑 Y(x) =
\end{flushleft}





\begin{flushleft}
x $\in$ \{1, . . . , 10\}
\end{flushleft}


\begin{flushleft}
altrimenti,
\end{flushleft}





\{\{ 0/


1





10





\begin{flushleft}
se andiamo a scriverle nelle identit\`{a} ottenute sopra, abbiamo
\end{flushleft}





\{\{ 0/


1





\begin{flushleft}
𝜑S,X (s, x) =
\end{flushleft}





100





\begin{flushleft}
s $\in$ \{2, . . . , 20\}, x $\in$ \{1, . . . , s $-$ 1\}
\end{flushleft}


\begin{flushleft}
altrimenti
\end{flushleft}





\begin{flushleft}
in cui la prima riga cattura tutti i possibili risultati della somma in cui x sia un addendo ammissibile. Per la densit\`{a} discreta condizionata di S data X,
\end{flushleft}


\begin{flushleft}
𝜑S∣X (s ∣ x) =
\end{flushleft}





\{\{ 0/


1





10





\begin{flushleft}
x $\in$ \{1, . . . , 10\}, s $\in$ \{x + 1, . . . , x + 10\}
\end{flushleft}


\begin{flushleft}
altrimenti.
\end{flushleft}





\begin{flushleft}
Per quanto riguarda la densit\`{a} discreta di S abbiamo
\end{flushleft}





\{\{ //


\{\{ ⋅⋅


\{ /⋅


\begin{flushleft}
(s, x) = \{
\end{flushleft}


\{\{ ⋅⋅


\{\{ / ⋅


\{\{ 0


1


2





10





\begin{flushleft}
𝜑S(s) =
\end{flushleft}





\begin{flushleft}
𝜑S,X
\end{flushleft}


\begin{flushleft}
x=1
\end{flushleft}





100


100





10





1





100





100





\begin{flushleft}
s=2
\end{flushleft}


\begin{flushleft}
s=3
\end{flushleft}


\begin{flushleft}
s = 11
\end{flushleft}





⋅⋅


⋅


⋅⋅


⋅





\begin{flushleft}
s = 20
\end{flushleft}


\begin{flushleft}
s $\in$ \{2, . . . , 20\}c.
\end{flushleft}





\begin{flushleft}
7.2. VETTORI ALEATORI ASSOLUTAMENTE CONTINUI
\end{flushleft}


\begin{flushleft}
Dopo aver visto il caso particolare di coppie di variabili aleatorie discrete, consideriamo ora le
\end{flushleft}


\begin{flushleft}
coppie di variabili aleatorie assolutamente continue. Come osservato, per le funzioni di ripartizione la teoria non dipende dal particolare tipo di variabile aleatoria considerato, quindi quello
\end{flushleft}


\begin{flushleft}
che vedremo, specifico per le assolutamente continue, sar\`{a} legato alle densit\`{a} di probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 7.19. Siano X e Y due variabili aleatorie assolutamente continue sullo stesso spazio di probabilit\`{a} ($\Omega$,ℱ, P). Chiamiamo densit\`{a} congiunta di X e Y la funzione fX,Y : ℝ2 $\rightarrow$ ℝ tale che per ogni evento
\end{flushleft}


\begin{flushleft}
E nella tribù prodotto ℬ $\otimes$ ℬ
\end{flushleft}


\begin{flushleft}
P((X, Y) $\in$ E) =
\end{flushleft}





\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
f X,Y(s, t) ds dt.
\end{flushleft}





\begin{flushleft}
Osservazione 7.20. C'\`{e} una sola probabilit\`{a} e non una probabilit\`{a} prodotto perch\'{e} non stiamo
\end{flushleft}


\begin{flushleft}
considerando coppie di esiti, ma un solo esito, sul quale costruiamo la coppia (X(𝜔), Y(𝜔)):
\end{flushleft}


\begin{flushleft}
P((X, Y) $\in$ E) = P(\{𝜔 $\in$ $\Omega$ : (X(𝜔), Y(𝜔)) $\in$ E\}).
\end{flushleft}


\begin{flushleft}
In effetti la tribù prodotto \`{e} in ℝ2, non in $\Omega$ × $\Omega$.
\end{flushleft}





\newpage
96





\begin{flushleft}
VETTORI ALEATORI
\end{flushleft}





\begin{flushleft}
PROPOSIZIONE 7.21. Siano X e Y due variabili aleatorie assolutamente continue sullo stesso spazio di
\end{flushleft}


\begin{flushleft}
probabilit\`{a} ($\Omega$, ℱ, P). Allora:
\end{flushleft}


\begin{flushleft}
i. per ogni (x, y) $\in$ ℝ2,
\end{flushleft}


\begin{flushleft}
F X,Y(x, y) =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
y
\end{flushleft}





$-$$\infty$





$-$$\infty$





\begin{flushleft}
fX,Y(s, t) dt ds
\end{flushleft}





\begin{flushleft}
ii. per ogni x, y $\in$ ℝ possiamo scrivere le densit\`{a} marginali di X e Y come
\end{flushleft}


\begin{flushleft}
f X (x) =
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
fX,Y(x, t) dt
\end{flushleft}





+$\infty$





\begin{flushleft}
fY(y) =
\end{flushleft}





$-$$\infty$





\begin{flushleft}
f X,Y(s, y) ds
\end{flushleft}





\begin{flushleft}
iii. X e Y sono indipendenti se e solo se per ogni (x, y) $\in$ ℝ2, fX,Y(x, y) = fX (x) fY(y).
\end{flushleft}


\begin{flushleft}
Dimostrazione. La prima uguaglianza, che possiamo anche scrivere in forma differenziale come
\end{flushleft}


\begin{flushleft}
f X,Y(x, y) =
\end{flushleft}





\begin{flushleft}
$\partial$2F X,Y
\end{flushleft}


\begin{flushleft}
(x, y)
\end{flushleft}


\begin{flushleft}
$\partial$x $\partial$y
\end{flushleft}





\begin{flushleft}
segue immediatamente dalla definizione di densit\`{a} congiunta e di funzione di ripartizione. La
\end{flushleft}


\begin{flushleft}
seconda coppia di uguaglianze \`{e} un'applicazione del teorema del calcolo integrale. Per quanto
\end{flushleft}


\begin{flushleft}
riguarda la terza propriet\`{a}, l'implicazione diretta $\Rightarrow$ segue dalla definizione, mentre quella inversa
\end{flushleft}


\begin{flushleft}
$\Leftarrow$ si mostra passando dalle corrispondenti propriet\`{a} della funzione di ripartizione.
\end{flushleft}


□





\begin{flushleft}
Osservazione 7.22. Anche nel caso assolutamente continuo abbiamo l'analogo dell'Osservazione 7.12, cio\`{e} alcune propriet\`{a} immediate della funzione di densit\`{a} congiunta. Abbiamo infatti,
\end{flushleft}


\begin{flushleft}
per ogni (x, y) $\in$ ℝ2, che f X,Y(x, y) ⩾ 0. Osserviamo per\`{o} che, a differenza di 𝜑X,Y, non abbiamo
\end{flushleft}


\begin{flushleft}
un limite dall'alto del valore della densit\`{a} congiunta, in analogia a quanto visto per la densit\`{a}
\end{flushleft}


\begin{flushleft}
di una variabile aleatoria assolutamente continua (anch'essa non negativa) e la densit\`{a} discreta
\end{flushleft}


\begin{flushleft}
di una discreta (la cui immagine \`{e} contenuta in [0, 1]).
\end{flushleft}


\begin{flushleft}
Inoltre, vale l'identit\`{a}
\end{flushleft}


\begin{flushleft}
f X,Y(x, y) dx dy = 1,
\end{flushleft}





\begin{flushleft}
ℝ2
\end{flushleft}





\begin{flushleft}
da cui possiamo sviluppare un discorso sulle costanti di rinormalizzazione analogo a quello fatto
\end{flushleft}


\begin{flushleft}
in precedenza.
\end{flushleft}


\begin{flushleft}
Esempio 7.23. Sia fX,Y(x, y) = e $-$x per 0 ⩽ y ⩽ x e nulla altrimenti. Vogliamo la densit\`{a} marginale
\end{flushleft}


\begin{flushleft}
f X di X.
\end{flushleft}


\begin{flushleft}
Per ottenerla ci basta integrare la densit\`{a} congiunta su tutti i possibili valori di y,
\end{flushleft}


\begin{flushleft}
f X (x) =
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
fX,Y(x, y) dy =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


0





\begin{flushleft}
e $-$x dy = x e $-$x.
\end{flushleft}





\begin{flushleft}
Se vogliamo anche la funzione di ripartizione di X, possiamo ottenerla come
\end{flushleft}


\begin{flushleft}
F X (x) =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


$-$$\infty$





\begin{flushleft}
fX (t) dt = 1 $-$ (x + 1) e $-$x
\end{flushleft}





\begin{flushleft}
per x $>$ 0 (e 0 altrimenti), oppure direttamente dalla densit\`{a} congiunta,
\end{flushleft}


\begin{flushleft}
FX (x) = lim FX,Y(x, y) = lim
\end{flushleft}


\begin{flushleft}
y$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
y$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
y
\end{flushleft}





$-$$\infty$





$-$$\infty$





\begin{flushleft}
f X,Y(s, t) dt ds =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





+$\infty$





$-$$\infty$





$-$$\infty$





\begin{flushleft}
fX,Y(s, t) dt ds.
\end{flushleft}





\begin{flushleft}
DEFINIZIONE 7.24. Siano X e Y due variabili aleatorie assolutamente continue sullo stesso spazio probabilit\`{a} ($\Omega$, ℱ, P). Chiamiamo densit\`{a} condizionale di X rispetto a Y la funzione fX∣Y definita come
\end{flushleft}


\begin{flushleft}
f X∣Y(x ∣ y) =
\end{flushleft}





\begin{flushleft}
fX,Y(x, y)
\end{flushleft}


,


\begin{flushleft}
f Y(y)
\end{flushleft}





\begin{flushleft}
per y $\in$ ℛ Y e identicamente nulla altrimenti.
\end{flushleft}


\begin{flushleft}
Osservazione 7.25. Anche in questo caso possiamo ricavare dalla densit\`{a} condizionale e dalla
\end{flushleft}


\begin{flushleft}
densit\`{a} marginale di Y la densit\`{a} congiunta:
\end{flushleft}


\begin{flushleft}
f X,Y(x, y) = f X∣Y(x ∣ y) fY(y).
\end{flushleft}





\begin{flushleft}
\newpage
7.2 VETTORI ALEATORI ASSOLUTAMENTE CONTINUI
\end{flushleft}





97





\begin{flushleft}
Osservazione 7.26. Se guardiamo fX∣Y come funzione della sola x, per y fissato, abbiamo che
\end{flushleft}


\begin{flushleft}
f X∣Y(x ∣ y) \`{e} la densit\`{a} di X {``}condizionata'' all'evento \{Y = y\}. Le virgolette sono necessarie perch\'{e},
\end{flushleft}


\begin{flushleft}
avendo preso Y assolutamente continua, l'evento \{Y = y\} ha probabilit\`{a} 0 e non pu\`{o} essere usato
\end{flushleft}


\begin{flushleft}
in un condizionamento.
\end{flushleft}


\begin{flushleft}
Esempio 7.27. Due variabili aleatorie X e Y, assolutamente continue, hanno densit\`{a} congiunta
\end{flushleft}


\begin{flushleft}
f X,Y(x, y) = 6 e $-$2x e $-$3y
\end{flushleft}


\begin{flushleft}
per x $>$ 0 e y $>$ 0 e nulla altrimenti. Vogliamo determinare se X e Y sono indipendenti.
\end{flushleft}


\begin{flushleft}
Come prima cosa ci ricaviamo, dalla densit\`{a} congiunta, le densit\`{a} marginali. Per X,
\end{flushleft}


\begin{flushleft}
f X (x) =
\end{flushleft}


\begin{flushleft}
e per Y
\end{flushleft}


\begin{flushleft}
f Y(y) =
\end{flushleft}





+$\infty$


$-$$\infty$





+$\infty$


$-$$\infty$





\begin{flushleft}
fX,Y(x, y) dy =
\end{flushleft}


\begin{flushleft}
fX,Y(x, y) dx =
\end{flushleft}





+$\infty$


\begin{flushleft}
6 e $-$2x e $-$3y dy = 2 e $-$2x
\end{flushleft}


0





\begin{flushleft}
x$>$0
\end{flushleft}


\begin{flushleft}
x⩽0
\end{flushleft}





+$\infty$


\begin{flushleft}
6 e $-$2x e $-$3y dx = 3 e $-$3y
\end{flushleft}


0





\begin{flushleft}
y $>$0
\end{flushleft}


\begin{flushleft}
y ⩽ 0.
\end{flushleft}





\{\{\{ ∫


0





\{\{\{ ∫


0





\begin{flushleft}
A questo punto non ci resta che verificare l'indipendenza confrontando il prodotto delle densit\`{a} marginali con la densit\`{a} congiunta:
\end{flushleft}


\begin{flushleft}
fX (x) fY(y) = 2 e $-$2x 3 e $-$3y = 6 e $-$2x e $-$3y = f X,Y(x, y).
\end{flushleft}


\begin{flushleft}
Le due variabili aleatorie sono allora indipendenti tra loro.
\end{flushleft}


\begin{flushleft}
Come per le variabili aleatorie discrete, ci interessiamo a un problema particolare: la somma
\end{flushleft}


\begin{flushleft}
di una coppia di variabili aleatorie assolutamente continue.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 7.28. Siano X e Y due variabili aleatorie assolutamente continue sullo stesso spazio probabilit\`{a} ($\Omega$, ℱ, P), con densit\`{a} congiunta f X,Y. La densit\`{a} della loro somma \`{e}
\end{flushleft}


\begin{flushleft}
fX+Y(z) =
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
f X,Y(x, z $-$ x) dx.
\end{flushleft}





\begin{flushleft}
Dimostrazione. Cominciamo considerando la funzione di ripartizione, FX+Y(z) = P(X + Y ⩽ z).
\end{flushleft}


\begin{flushleft}
Possiamo vedere questa probabilit\`{a} come P((X, Y) $\in$ E) per qualche E $\in$ ℬ $\otimes$ ℬ: infatti
\end{flushleft}


\begin{flushleft}
X+Y ⩽z
\end{flushleft}





⟺





\begin{flushleft}
Y ⩽ z $-$ X.
\end{flushleft}





\begin{flushleft}
Se lo vediamo nel piano cartesiano ℝ2, sono i punti al di sotto della retta y = $-$x + z, quindi
\end{flushleft}


\begin{flushleft}
P((X, Y) $\in$ E) =
\end{flushleft}





\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
f X,Y(x, y) dy dx =
\end{flushleft}





+$\infty$





\begin{flushleft}
z$-$x
\end{flushleft}





$-$$\infty$





$-$$\infty$





\begin{flushleft}
f X,Y(x, y) dy dx.
\end{flushleft}





\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
Figura 7.1. L'evento E \`{e} quello in grigio in figura
\end{flushleft}





\newpage
98





\begin{flushleft}
VETTORI ALEATORI
\end{flushleft}





\begin{flushleft}
Infine, visto che siamo interessati alla densit\`{a}, deriviamo in z e abbiamo concluso.
\end{flushleft}





□





\begin{flushleft}
Esempio 7.29. Siano X e Y variabili aleatorie assolutamente continue tali che fX,Y(x, y) = e $-$x per
\end{flushleft}


\begin{flushleft}
0 ⩽ y ⩽ x e nulla altrimenti. Qual \`{e} la legge della somma X + Y?
\end{flushleft}


\begin{flushleft}
Come prima cosa determiniamo in quali punti del piano ℝ2 \`{e} supportata (cio\`{e} \`{e} diversa da 0)
\end{flushleft}


\begin{flushleft}
la funzione f X,Y: dalla definizione abbiamo che fX,Y = 0 se y ⩽ 0 o se y $>$ x.
\end{flushleft}





\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}


\begin{flushleft}
Figura 7.2. In grigio il supporto di f X,Y
\end{flushleft}





\begin{flushleft}
Sappiamo, dalla Proposizione 7.28, che
\end{flushleft}


\begin{flushleft}
F X+Y(z) =
\end{flushleft}





\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
f X,Y(x, y) dy dx
\end{flushleft}





\begin{flushleft}
con E =\{(x, y): x +y ⩽z\} (rappresentato in Figura 7.1). Ma possiamo mettere assieme questa informazione col supporto di fX,Y, perch\'{e} al di fuori di quest'ultimo l'integrale \`{e} identicamente nullo.
\end{flushleft}


\begin{flushleft}
Quindi possiamo integrare sul dominio E′, dato dall'intersezione di E col supporto di fX,Y e rappresentato in Figura 7.3.
\end{flushleft}





\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}


\begin{flushleft}
Figura 7.3. In grigio il dominio di integrazione di f X,Y
\end{flushleft}





\begin{flushleft}
Ora non ci resta che calcolare l'integrale, ma come possiamo farlo? L'integrale ha forma
\end{flushleft}


□





□





□





□





\begin{flushleft}
e $-$x dx dy
\end{flushleft}





\begin{flushleft}
in cui dobbiamo per\`{o} determinare gli estremi di integrazione. Possiamo osservare che y varia tra
\end{flushleft}


\begin{flushleft}
0 e z/2 e che, per y fissato, x varia tra y e z $-$ y. Allora
\end{flushleft}


\begin{flushleft}
F X+Y(z) =
\end{flushleft}


=





\begin{flushleft}
z
\end{flushleft}


2


0


\begin{flushleft}
z
\end{flushleft}


2





0





\begin{flushleft}
z$-$y
\end{flushleft}


\begin{flushleft}
y
\end{flushleft}





\begin{flushleft}
e $-$x dx dy =
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}


2





0





\begin{flushleft}
z$-$y
\end{flushleft}





\begin{flushleft}
[$-$e $-$x]y dy
\end{flushleft}


\begin{flushleft}
z/
\end{flushleft}





\begin{flushleft}
z/
\end{flushleft}





\begin{flushleft}
e $-$y $-$ e $-$(z$-$y) dy = [$-$e $-$y]02 $-$ e $-$z [e y]0 2
\end{flushleft}





\begin{flushleft}
= 1$-$e
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}





$-$2





\begin{flushleft}
$-$e
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}





$-$2





\begin{flushleft}
+ e $-$z = 1 $-$ e
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}





$-$2 2





\begin{flushleft}
\newpage
7.3 VETTORI ALEATORI MISTI
\end{flushleft}





99





\begin{flushleft}
per ogni z ⩾ 0. A questo punto, per avere fX+Y possiamo derivare in z.
\end{flushleft}


\begin{flushleft}
Esempio 7.30. Siano X, Y due variabili aleatorie indipendenti e identicamente distribuite con
\end{flushleft}


\begin{flushleft}
densit\`{a} f (t) = e $-$t per t $>$ 0 e 0 altrimenti. Sia S = X + Y la loro somma. Qual \`{e} la densit\`{a} di X
\end{flushleft}


\begin{flushleft}
condizionata a S?
\end{flushleft}


\begin{flushleft}
Determiniamo come prima cosa la densit\`{a} congiunta. Grazie all'ipotesi di indipendenza tra le
\end{flushleft}


\begin{flushleft}
variabili aleatorie abbiamo
\end{flushleft}


\begin{flushleft}
f X,Y(x, y) = e $-$x e $-$y
\end{flushleft}


\begin{flushleft}
per x, y $>$ 0, nel primo quadrante, e 0 altrove.
\end{flushleft}


\begin{flushleft}
Ora vogliamo determinare la legge congiunta di X e S. Per farlo, passiamo dalla funzione di
\end{flushleft}


\begin{flushleft}
ripartizione F X,S:
\end{flushleft}


\begin{flushleft}
F X,S(x, z) = P(X ⩽ x, S ⩽ z) = P(X ⩽ x, Y ⩽ z $-$ X)
\end{flushleft}


\begin{flushleft}
= P((X, Y) $\in$ E) =
\end{flushleft}


\begin{flushleft}
f X,Y(x, y) dx dy
\end{flushleft}


\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
dove il dominio E cambia a seconda che x $<$ z o x ⩾ z, come illustrato nella Figura 7.4.
\end{flushleft}


\begin{flushleft}
Y
\end{flushleft}


\begin{flushleft}
z
\end{flushleft}





\begin{flushleft}
Y
\end{flushleft}


\begin{flushleft}
z
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
Figura 7.4. Il dominio di integrazione E in grigio, a sinistra se 0 $<$ x $<$ z, a destra se x ⩾ z
\end{flushleft}





\begin{flushleft}
Allora, se x ⩾ z,
\end{flushleft}


\begin{flushleft}
F X,S(x, z) =
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}


0





\begin{flushleft}
e $-$t
\end{flushleft}





\begin{flushleft}
z$-$t
\end{flushleft}


0





\begin{flushleft}
e $-$u du dt =
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}


0





\begin{flushleft}
e $-$t (1 $-$ e $-$z e t) dt = 1 $-$ e $-$z $-$ z e $-$z.
\end{flushleft}





\begin{flushleft}
Se invece 0 $<$ x $<$ z,
\end{flushleft}


\begin{flushleft}
F X,S(x, z) =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


0





\begin{flushleft}
e $-$t
\end{flushleft}





\begin{flushleft}
z$-$t
\end{flushleft}


0





\begin{flushleft}
e $-$u du dt =
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


0





\begin{flushleft}
e $-$t (1 $-$ e $-$z e t) dt = 1 $-$ e $-$x $-$ x e $-$z.
\end{flushleft}





\begin{flushleft}
Ora possiamo ricavare la densit\`{a} congiunta derivando in x e z:
\end{flushleft}


\begin{flushleft}
fX,S(x, z) =
\end{flushleft}


\begin{flushleft}
Vogliamo determinare f X∣S(x ∣ z) =
\end{flushleft}





\begin{flushleft}
f X,S(x, z)
\end{flushleft}


,


\begin{flushleft}
fS(z)
\end{flushleft}





\begin{flushleft}
fS(z) =
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
$\partial$2FX,S
\end{flushleft}


\begin{flushleft}
e $-$z 0 $<$ x $<$ z
\end{flushleft}


=


\begin{flushleft}
0 x ⩾ z.
\end{flushleft}


\begin{flushleft}
$\partial$x $\partial$z
\end{flushleft}





\begin{flushleft}
ma ci occorre ancora fS,
\end{flushleft}





\begin{flushleft}
f X,S(x, z) dx =
\end{flushleft}





\begin{flushleft}
Quindi abbiamo, per 0 $<$ x $<$ z,
\end{flushleft}


\begin{flushleft}
f X∣S(x ∣ z) =
\end{flushleft}





\begin{flushleft}
Lezione 12
\end{flushleft}





\{\{





\begin{flushleft}
z
\end{flushleft}


0





\begin{flushleft}
e $-$z dx = z e $-$z.
\end{flushleft}





\begin{flushleft}
e $-$z 1
\end{flushleft}


= .


\begin{flushleft}
z e $-$z z
\end{flushleft}





\begin{flushleft}
7.3. VETTORI ALEATORI MISTI
\end{flushleft}


\begin{flushleft}
Nelle sezioni precedenti abbiamo considerato coppie aleatorie omogenee, in cui entrambe le variabili aleatorie sono dello stesso tipo, o discrete o assolutamente continue. Vediamo ora, in un
\end{flushleft}


\begin{flushleft}
esempio, cosa succede se le due variabili aleatorie in una coppia sono una discreta e una assolutamente continua.
\end{flushleft}





\newpage
100





\begin{flushleft}
VETTORI ALEATORI
\end{flushleft}





\begin{flushleft}
Esempio 7.31. Tra gli studenti dell'Universit\`{a} di Otnert, il 52\% studiano materie umanistiche e
\end{flushleft}


\begin{flushleft}
il 48\% studiano materie scientifiche. Il tempo di studio al giorno per gli studenti delle materie
\end{flushleft}


\begin{flushleft}
scientifiche \`{e} distribuito in modo uniforme tra 155 e 180 minuti, mentre per gli studenti delle
\end{flushleft}


\begin{flushleft}
materie umanistiche \`{e} distribuito in modo uniforme tra 143 e 166 minuti. Ci chiediamo:
\end{flushleft}


\begin{flushleft}
1. Qual \`{e}, se esiste, la legge congiunta delle variabili aleatorie X (indirizzo di studio) e Y (tempo
\end{flushleft}


\begin{flushleft}
di studio quotidiano).
\end{flushleft}


\begin{flushleft}
2. Qual \`{e} la probabilit\`{a} che un generico studente dell'universit\`{a} studi al più 160 minuti.
\end{flushleft}


\begin{flushleft}
3. Come sono suddivisi tra i due indirizzi gli studenti che passano sui libri meno di 160 minuti.
\end{flushleft}


\begin{flushleft}
4. Come sono suddivisi tra i due indirizzi gli studenti che passano sui libri esattamente 160
\end{flushleft}


\begin{flushleft}
minuti.
\end{flushleft}


\begin{flushleft}
Cominciamo con lo scrivere formalmente i dati del nostro problema. La variabile aleatoria X \`{e}
\end{flushleft}


\begin{flushleft}
discreta e, in particolare, identicamente distribuita a una moneta sbilanciata: se codifichiamo con
\end{flushleft}


\begin{flushleft}
0 l'indirizzo scientifico e con 1 l'indirizzo umanistico abbiamo
\end{flushleft}


\begin{flushleft}
0.48 x = 0
\end{flushleft}


\begin{flushleft}
𝜑X (x) = 0.52 x = 1
\end{flushleft}


0


\begin{flushleft}
x $\in$ \{0, 1\}c.
\end{flushleft}





\{\{\{


\{





\begin{flushleft}
Abbiamo poi per Y le seguenti densit\`{a} condizionate:
\end{flushleft}


\begin{flushleft}
c y $\in$ [155, 180]
\end{flushleft}


\begin{flushleft}
c y $\in$ [143, 166]
\end{flushleft}


\begin{flushleft}
fY∣X (y ∣ 0) = S
\end{flushleft}


\begin{flushleft}
f Y∣X (y ∣ 1) = U
\end{flushleft}


\begin{flushleft}
0 altrimenti
\end{flushleft}


\begin{flushleft}
0 altrimenti
\end{flushleft}


\begin{flushleft}
dove cS e cU sono due costanti positive che dobbiamo determinare, in modo che le densit\`{a} condizionate siano effettivamente delle densit\`{a}, cio\`{e} abbiano integrale 1,
\end{flushleft}


1


1


\begin{flushleft}
cS (180 $-$ 155) = 1 $\Rightarrow$ cS =
\end{flushleft}


\begin{flushleft}
c U (166 $-$ 143) = 1 $\Rightarrow$ cS = .
\end{flushleft}


25


23


\begin{flushleft}
In realt\`{a} dovremmo scrivere la legge condizionata per ogni (x, y) $\in$ ℝ2,
\end{flushleft}





\{





\{





\{ //


\begin{flushleft}
(y ∣ x) = \{
\end{flushleft}


\{\{\{ 0


1





\begin{flushleft}
f Y∣X
\end{flushleft}





1





1/23





25


23





\begin{flushleft}
y $\in$ [155, 180], x = 0
\end{flushleft}


\begin{flushleft}
y $\in$ [143, 166], x = 1
\end{flushleft}


\begin{flushleft}
altrimenti.
\end{flushleft}





\begin{flushleft}
fY |X
\end{flushleft}





1/25


143





166





0


155





180





\begin{flushleft}
Y
\end{flushleft}





1


\begin{flushleft}
X
\end{flushleft}


\begin{flushleft}
Figura 7.5. Densit\`{a} condizionale di Y data X. Entrambi i rettangolini hanno area 1
\end{flushleft}





\begin{flushleft}
Per avere la legge congiunta, dobbiamo passare attraverso le funzioni di ripartizione, per
\end{flushleft}


\begin{flushleft}
vedere che succede. Quello che otteniamo \`{e} FX,Y(x,y) =F Y∣X (y ∣x) FX (x), che ci suggerisce la forma
\end{flushleft}


\begin{flushleft}
seguente per la {``}densit\`{a}'',
\end{flushleft}


\begin{flushleft}
f X,Y(x, y) = fY∣X (y ∣ x) 𝜑X (x),
\end{flushleft}


\begin{flushleft}
un ibrido tra una densit\`{a} congiunta e una densit\`{a} discreta congiunta,
\end{flushleft}


\begin{flushleft}
fX,Y
\end{flushleft}





\begin{flushleft}
\{\{ ⋅ 0.48 = 0.0192 y $\in$ [155, 180], x = 0
\end{flushleft}


\begin{flushleft}
(x, y) = \{
\end{flushleft}


\begin{flushleft}
\{\{ ⋅ 0.52 = 0.0226087 y $\in$ [143, 166], x = 1
\end{flushleft}


\{\{ 0


\begin{flushleft}
altrimenti.
\end{flushleft}


1


25


1


23





\begin{flushleft}
\newpage
7.3 VETTORI ALEATORI MISTI
\end{flushleft}





101





\begin{flushleft}
fY |X
\end{flushleft}


0.02261


0.0192


143





166





0


155





180





\begin{flushleft}
Y
\end{flushleft}





1


\begin{flushleft}
X
\end{flushleft}


\begin{flushleft}
Figura 7.6. Densit\`{a} congiunta di X e Y. La somma delle aree dei rettangolini \`{e} 1
\end{flushleft}





\begin{flushleft}
Per trovare la legge di Y dobbiamo marginalizzare la legge congiunta, sommando su tutti i
\end{flushleft}


\begin{flushleft}
valori possibili di X, che sono solo due:
\end{flushleft}


\begin{flushleft}
fY(y) = f X,Y(0, y) + f X,Y
\end{flushleft}





\begin{flushleft}
143 $<$ y $<$ 155
\end{flushleft}


\{\{\{ 0.0226087


\begin{flushleft}
0.0418087 155 $<$ y $<$ 166
\end{flushleft}


\begin{flushleft}
(1, y) = \{
\end{flushleft}


\begin{flushleft}
\{\{ 0.0192 166 $<$ y $<$ 180
\end{flushleft}


0


\begin{flushleft}
altrimenti.
\end{flushleft}





\begin{flushleft}
Siccome vogliamo sapere la probabilit\`{a} che uno studente passi al più 160 minuti sui libri, dobbiamo ricavare F Y(y), integrando fY,
\end{flushleft}


\begin{flushleft}
y $<$ 143
\end{flushleft}


\begin{flushleft}
\{\{ 00.0226087 (y $-$ 143)
\end{flushleft}


\begin{flushleft}
143 ⩽ y $<$ 155
\end{flushleft}


\{


\begin{flushleft}
F (y) = \{ 0.2713044 + 0.0418087 (y $-$ 155) 155 ⩽ y $<$ 166
\end{flushleft}


\begin{flushleft}
\{\{ 0.7312001 + 0.0192 (y $-$ 166) 166 ⩽ y $<$ 180
\end{flushleft}


\{1


\begin{flushleft}
y ⩾ 180,
\end{flushleft}


\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
quindi la probabilit\`{a} cercata \`{e} F Y(160) = 0.4803479.
\end{flushleft}


\begin{flushleft}
Chiedere come sono distribuiti tra i due indirizzi gli studenti che passano meno di 160 minuti
\end{flushleft}


\begin{flushleft}
sui libri equivale a calcolare, per x = 0, 1, le probabilit\`{a}
\end{flushleft}


\begin{flushleft}
P(X = x ∣ Y $<$ 160) =
\end{flushleft}





\begin{flushleft}
P(X = x, Y $<$ 160) ∫143 f X,Y(x, y) dy
\end{flushleft}


\begin{flushleft}
0.2 x = 0
\end{flushleft}


=


$\approx$


\begin{flushleft}
0.8 x = 1.
\end{flushleft}


\begin{flushleft}
P(Y $<$ 160)
\end{flushleft}


\begin{flushleft}
FY(160)
\end{flushleft}


160





\{





\begin{flushleft}
Se invece siamo interessati alla probabilit\`{a} di appartenenza ai due indirizzi di uno studente
\end{flushleft}


\begin{flushleft}
che studia esattamente 160 minuti, non possiamo fare allo stesso modo, perch\'{e} l'evento Y = 160
\end{flushleft}


\begin{flushleft}
ha probabilit\`{a} nulla7.1. Tuttavia possiamo usare la densit\`{a} condizionata ibrida
\end{flushleft}


\begin{flushleft}
fX∣Y(x ∣ 160) =
\end{flushleft}





\begin{flushleft}
fX,Y(x, 160) f X,Y(x, 160)
\end{flushleft}


\begin{flushleft}
0.46 x = 0
\end{flushleft}


=


$\approx$


\begin{flushleft}
0.54 x = 1.
\end{flushleft}


\begin{flushleft}
fY(160)
\end{flushleft}


0.0418087





\{\{





\begin{flushleft}
Quello che otteniamo \`{e} una densit\`{a} discreta, ossia la probabilit\`{a} che uno studente appartenga a
\end{flushleft}


\begin{flushleft}
uno dei due indirizzi. Questo non ci dovrebbe sorprendere, perch\'{e} nel momento in cui ci restringiamo a un valore specifico di Y, geometricamente stiamo sezionando la legge congiunta, restringendola al piano y = 160. Su questo piano abbiamo una funzione (in x) costantemente uguale
\end{flushleft}


\begin{flushleft}
a 0, tranne in 0 e 1. A questo punto (modulo un riscalamento per f Y(160)) abbiamo una funzione che soddisfa tutte le propriet\`{a} di una densit\`{a} discreta.
\end{flushleft}


\begin{flushleft}
7.1. Se un evento \`{e} impossibile, allora ha probabilit\`{a} nulla, ma non \`{e} vero il viceversa: se abbiamo una variabile
\end{flushleft}


\begin{flushleft}
aleatoria continua, ciascun suo valore a priori ha probabilit\`{a} 0 di uscire, eppure uno di essi esce, quindi, a posteriori, non
\end{flushleft}


\begin{flushleft}
possiamo dire che fosse impossibile.
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
CAPITOLO 8
\end{flushleft}


\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}


\begin{flushleft}
Come abbiamo visto in molti degli esempi, ci sono alcune variabili aleatorie che ricorrono abbastanza spesso. In parte questo \`{e} dovuto al fatto che finora non abbiamo introdotto moltissimi
\end{flushleft}


\begin{flushleft}
esempi di variabili aleatori, ma in parte \`{e} anche legato all'esistenza di un certo numero di variabili
\end{flushleft}


\begin{flushleft}
aleatorie ben conosciute che vengono usate per descrivere esperimenti aleatori con certe caratteristiche.
\end{flushleft}


\begin{flushleft}
Parleremo indifferentemente di variabili aleatorie o di distribuzioni (ad esempio, una variabile aleatoria Bernoulliana o a distribuzione Bernoulliana o distribuita come una Bernoulliana)
\end{flushleft}


\begin{flushleft}
perch\'{e} siamo interessati alla legge, alla distribuzione, appunto, perch\'{e} \`{e} questa a caratterizzare il
\end{flushleft}


\begin{flushleft}
comportamento probabilistico della variabile aleatoria, indipendentemente dallo spazio di partenza.
\end{flushleft}





\begin{flushleft}
8.1. BERNOULLIANE
\end{flushleft}


\begin{flushleft}
Cominciamo dall'esperimento più semplice (ma non banale) che possiamo immaginare: qualcosa
\end{flushleft}


\begin{flushleft}
il cui esito \`{e} binario, pu\`{o} essere {``}sì'' o {``}no'', positivo o negativo e così via, con una certa probabilit\`{a}. Dovrebbe ricordarci qualcosa...
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 8.1. Una variabile aleatoria discreta X si dice Bernoulliana (o variabile aleatoria di Bernoulli8.1) di parametro p, con p $\in$ [0, 1] se ha densit\`{a} discreta
\end{flushleft}


\begin{flushleft}
p
\end{flushleft}


\begin{flushleft}
x=1
\end{flushleft}


\begin{flushleft}
𝜑X (x) = 1 $-$ p x = 0
\end{flushleft}


0


\begin{flushleft}
altrimenti,
\end{flushleft}





\{\{


\{\{





\begin{flushleft}
o equivalentemente se ha funzione di ripartizione
\end{flushleft}


0


\begin{flushleft}
x$<$0
\end{flushleft}


\begin{flushleft}
F X (x) = 1 $-$ p 0 ⩽ x $<$ 1
\end{flushleft}


1


\begin{flushleft}
x ⩾ 1.
\end{flushleft}





\{\{\{


\{\{





\begin{flushleft}
Se X \`{e} una Bernoulliana, scriviamo X $\sim$ bin(1, p).
\end{flushleft}


\begin{flushleft}
Se guardiamo la funzione di ripartizione (o la densit\`{a} discreta) possiamo riconoscere in questa
\end{flushleft}


\begin{flushleft}
una variabile aleatoria che abbiamo gi\`{a} incontrato in precedenza: \`{e} la variabile aleatoria indicatrice, vista negli Esempi 5.17 e 5.27, in questo caso indicatrice dell'evento {``}successo'', che ha
\end{flushleft}


\begin{flushleft}
probabilit\`{a} p. Nello scrivere l'esperimento aleatorio come variabile casuale abbiamo codificato il
\end{flushleft}


\begin{flushleft}
successo con 1 e l'insuccesso con 0. In realt\`{a} l'abbiamo incontrata altre volte, spesso con p = 0.5: \`{e}
\end{flushleft}


\begin{flushleft}
il lancio di una moneta. Se p = 0.5, la moneta \`{e} equa, altrimenti \`{e} non bilanciata.
\end{flushleft}


\begin{flushleft}
A questo punto sappiamo facilmente proporre un candidato per lo spazio di probabilit\`{a} su
\end{flushleft}


\begin{flushleft}
cui \`{e} definita: $\Omega$ = \{0, 1\}, ℱ = 𝒫($\Omega$) = \{$\emptyset$, \{0\}, \{1\}, $\Omega$\} e P definita sui singoletti come P(\{0\}) = 1 $-$ p e
\end{flushleft}


\begin{flushleft}
P(\{1\}) = p.
\end{flushleft}


\begin{flushleft}
8.1. Jakob Bernoulli (1655 -- 1705) uno dei molti matematici della famiglia. \`{E} legato alla probabilit\`{a} dalla sua opera Ars
\end{flushleft}


\begin{flushleft}
Conjectandi, pubblicata postuma nel 1713.
\end{flushleft}





103





\newpage
104





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
8.2. BINOMIALI
\end{flushleft}


\begin{flushleft}
Consideriamo ora il caso in cui abbiamo n variabili aleatorie Bernoulliane, indipendenti e identicamente distribuite (i.i.d.); ne prendiamo la somma S. Se riguardiamo alla caratterizzazione
\end{flushleft}


\begin{flushleft}
che abbiamo dato poco sopra delle Bernoulliane, S \`{e} la variabile aleatoria che conta il numero di
\end{flushleft}


\begin{flushleft}
successi in n lanci di una moneta (cio\`{e} in n ripetizioni di un esperimento Bernoulliano).
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 8.2. Diciamo che una variabile aleatoria discreta X \`{e} una binomiale di parametri n e p,
\end{flushleft}


\begin{flushleft}
con n $\in$ ℕ ∖ \{0\} e p $\in$ [0, 1], se \`{e} la somma di n variabili aleatorie di Bernoulli indipendenti e identicamente
\end{flushleft}


\begin{flushleft}
distribuite di parametro p. In questo caso scriviamo X $\sim$ bin(n, p).
\end{flushleft}


\begin{flushleft}
Osservazione 8.3. Come suggerito dalla notazione, una Bernoulliana \`{e} una binomiale di parametri n = 1 e p, cio\`{e} la somma di una sola Bernoulliana di parametro p.
\end{flushleft}


\begin{flushleft}
Mentre nella definizione delle variabili aleatorie Bernoulliane avevamo identificato queste
\end{flushleft}


\begin{flushleft}
ultime mediante la loro legge, ossia la loro densit\`{a} discreta o funzione di ripartizione, nel caso
\end{flushleft}


\begin{flushleft}
delle binomiali le abbiamo caratterizzate a partire da altre variabili aleatorie. Come prima cosa,
\end{flushleft}


\begin{flushleft}
quindi, andiamo a ricavare la legge di una binomiale di parametri n e p.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 8.4. Se X $\sim$ bin(n, p) con n $\in$ ℕ\ensuremath{\backslash}\{0\} e p $\in$ [0, 1], allora
\end{flushleft}


\begin{flushleft}
𝜑 X (k) =
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\{\{\{


0





\begin{flushleft}
p k (1 $-$ p)n$-$k k $\in$ \{0, . . . , n\}
\end{flushleft}





\begin{flushleft}
⌊x⌋
\end{flushleft}





\begin{flushleft}
FX (x) =
\end{flushleft}





\begin{flushleft}
altrimenti
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)n$-$k .
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
Dimostrazione. Se X $\sim$ bin(n, p), allora il suo supporto, ossia l'insieme dei valori che pu\`{o} assumere, \`{e} l'insieme ℛ X = \{0, 1, . . . , n\}, dal momento che tra le n Bernoulliane considerate possiamo
\end{flushleft}


\begin{flushleft}
non avere alcun successo, averne uno solo e così via fino a n successi.
\end{flushleft}


\begin{flushleft}
Prendiamo ora k $\in$ \{0, . . . , n\}, vogliamo calcolare 𝜑X (k). Ricordiamo che, dalle definizioni,
\end{flushleft}


\begin{flushleft}
𝜑 (k) = P(X = k) = P(
\end{flushleft}


((





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Xi = k
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





))


)





\begin{flushleft}
con X i $\sim$ bin(1,p) per i $\in$ \{1,..., n\}. Chiamiamo N = \{1,...,n\} l'insieme degli indici delle Bernoulliane
\end{flushleft}


\begin{flushleft}
e indichiamo con ℐ k $\subseteq$𝒫(N) la famiglia degli insiemi I k tali che I k $\subseteq$N e \#I k =k. Per ciascun insieme
\end{flushleft}


\begin{flushleft}
(di indici) I k definiamo l'evento
\end{flushleft}


\begin{flushleft}
E Ik =
\end{flushleft}





\begin{flushleft}
\{Xi = 1\} $\cap$
\end{flushleft}


\begin{flushleft}
i$\in$Ik
\end{flushleft}





\begin{flushleft}
\{X i = 0\}
\end{flushleft}


\begin{flushleft}
i$\in$N\ensuremath{\backslash}Ik
\end{flushleft}





\begin{flushleft}
che contiene gli esiti per cui tutti e soli i successi sono nelle Bernoulliane i cui indici sono in I k .
\end{flushleft}


\begin{flushleft}
Possiamo ora scrivere l'evento \{X=k\} di tutti gli esiti che danno luogo a esattamente k successi
\end{flushleft}


\begin{flushleft}
come
\end{flushleft}


\begin{flushleft}
\{X = k\} =
\end{flushleft}





\begin{flushleft}
E Ik.
\end{flushleft}


\begin{flushleft}
Ik $\in$ℐ k
\end{flushleft}





\begin{flushleft}
Per come sono costruiti questi sono tutti e soli i modi di avere esattamente k successi negli n
\end{flushleft}


\begin{flushleft}
tentativi. Non solo, per come abbiamo definito gli Ek , essi sono eventi tra loro disgiunti, quindi
\end{flushleft}


\begin{flushleft}
𝜑 X (k) = P(X = k) = P
\end{flushleft}





(((





)))





\begin{flushleft}
E Ik =
\end{flushleft}





\begin{flushleft}
Ik $\in$ℐ k
\end{flushleft}





\begin{flushleft}
P(EIk).
\end{flushleft}


\begin{flushleft}
Ik $\in$ℐ k
\end{flushleft}





\begin{flushleft}
Il passo successivo \`{e} quindi calcolare P(E Ik) per ogni I k $\in$ ℐ k :
\end{flushleft}


\begin{flushleft}
P(EIk) = P
\end{flushleft}





((





\begin{flushleft}
\{Xi = 1\} $\cap$
\end{flushleft}


\begin{flushleft}
i$\in$Ik
\end{flushleft}





\begin{flushleft}
P(Xi = 1)
\end{flushleft}





=


\begin{flushleft}
i$\in$Ik
\end{flushleft}


\begin{flushleft}
\#Ik
\end{flushleft}





\begin{flushleft}
= p
\end{flushleft}





\begin{flushleft}
\{Xi = 0\}
\end{flushleft}


\begin{flushleft}
i$\in$N\ensuremath{\backslash}Ik
\end{flushleft}





\begin{flushleft}
P(X i = 0)
\end{flushleft}





\begin{flushleft}
i$\in$N\ensuremath{\backslash}Ik
\end{flushleft}


\begin{flushleft}
\#(N\ensuremath{\backslash}Ik)
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
(1 $-$ p)
\end{flushleft}





))





\begin{flushleft}
= p (1 $-$ p)n$-$k ,
\end{flushleft}





\begin{flushleft}
\newpage
8.2 BINOMIALI
\end{flushleft}





105





\begin{flushleft}
in cui abbiamo sfruttato l'indipendenza delle Bernoulliane nella seconda identit\`{a} e il fatto che
\end{flushleft}


\begin{flushleft}
siano identicamente distribuite nella terza.
\end{flushleft}


\begin{flushleft}
Osserviamo che la probabilit\`{a} P(EIk) così trovata \`{e} uguale per tutti gli insiemi I k $\in$ ℐ k , dal
\end{flushleft}


\begin{flushleft}
momento che dipende solamente dalla cardinalit\`{a} di I k . Allora
\end{flushleft}


\begin{flushleft}
P(EIk) = p k (1 $-$ p)n$-$k
\end{flushleft}





\begin{flushleft}
𝜑X (k) =
\end{flushleft}


\begin{flushleft}
Ik $\in$ℐ k
\end{flushleft}





1


\begin{flushleft}
Ik $\in$ℐ k
\end{flushleft}





\begin{flushleft}
e, per concludere, non ci resta che contare quanti elementi ha la famiglia di insiemi ℐ k . Ci siamo
\end{flushleft}


\begin{flushleft}
ricondotti al problema, gi\`{a} visto, di contare in quanti modi diversi possiamo scegliere k indici
\end{flushleft}


\begin{flushleft}
tra n, cio\`{e} nk . In conclusione, per k $\in$ \{0, . . . , n\}, 𝜑 X (k) = nk p k (1 $-$ p)n$-$k .
\end{flushleft}


\begin{flushleft}
Per ricavare la funzione di ripartizione F X (x) dobbiamo sommare, per tutti gli interi non negativi minori di x, la probabilit\`{a} di assumere tali valori, ossia la densit\`{a} discreta:
\end{flushleft}


\begin{flushleft}
⌊x⌋
\end{flushleft}





\begin{flushleft}
FX (x) =
\end{flushleft}


\begin{flushleft}
concludendo così la dimostrazione.
\end{flushleft}





\begin{flushleft}
⌊x⌋
\end{flushleft}





\begin{flushleft}
𝜑X (k) =
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)n$-$k ,
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


□





\begin{flushleft}
Osservazione 8.5. Nella dimostrazione abbiamo osservato che per una variabile aleatoria binon
\end{flushleft}


\begin{flushleft}
miale X, 𝜑 X (k) = P(∑i=1 X i = k), con le Xi $\sim$ bin(1, p). Queste ultime sono tutte variabili aleatorie
\end{flushleft}


\begin{flushleft}
discrete, quindi potremmo farne ricorsivamente la somma, come visto nel Capitolo 7. Tuttavia
\end{flushleft}


\begin{flushleft}
questa strategia si presta più facilmente a errori e, nella sostanza, \`{e} analoga a quanto visto nella
\end{flushleft}


\begin{flushleft}
dimostrazione.
\end{flushleft}


\begin{flushleft}
Osservazione 8.6. Possiamo controllare immediatamente che, per una variabile aleatoria binomiale X $\sim$ bin(n, p), F X (x) = 1 per ogni x ⩾ n: basta leggere la somma come binomio di Newton di
\end{flushleft}


\begin{flushleft}
esponente n,
\end{flushleft}


\begin{flushleft}
⌊x⌋
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
F X (x) =
\end{flushleft}


\begin{flushleft}
𝜑 X (k) =
\end{flushleft}


\begin{flushleft}
𝜑X (k) =
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)n$-$k = (p + (1 $-$ p))n = 1.
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
Esempio 8.7. (Ross 5.1.1) Un'azienda produce pennette USB che sono difettose, indipendentemente l'una dall'altra, con probabilit\`{a} p =0.02. Vende questi oggetti in confezioni da 15 e rimborsa
\end{flushleft}


\begin{flushleft}
i propri clienti se c'\`{e} più di una pennetta difettosa nella confezione. Quale percentuale di confezioni viene rimborsata? Comprando 4 confezioni, con che probabilit\`{a} esattamente una di queste
\end{flushleft}


\begin{flushleft}
sar\`{a} rimborsabile?
\end{flushleft}


\begin{flushleft}
Cominciamo a descrivere la situazione in questo problema in termini di variabili aleatorie.
\end{flushleft}


\begin{flushleft}
Chiamiamo O la variabile aleatoria che descrive, per una singola pennetta, il suo essere o meno
\end{flushleft}


\begin{flushleft}
difettosa e con N il numero di pennette difettose in una confezione. La variabile aleatoria O \`{e} una
\end{flushleft}


\begin{flushleft}
Bernoulliana di parametro p =0.02, cio\`{e} O $\sim$ bin(1, 0.02). La variabile aleatoria N \`{e} la somma di 15
\end{flushleft}


\begin{flushleft}
variabili aleatorie indipendenti e distribuite come O, quindi \`{e} una binomiale di parametri n = 15
\end{flushleft}


\begin{flushleft}
e p = 0.02, N $\sim$ bin(15, 0.02).
\end{flushleft}


\begin{flushleft}
Possiamo a questo punto riformulare la prima domanda come la probabilit\`{a} che N $>$ 1,
\end{flushleft}


15





\begin{flushleft}
P(N = k) = 1 $-$ P(N = 0) $-$ P(N = 1)
\end{flushleft}





\begin{flushleft}
P(N $>$ 1) =
\end{flushleft}


\begin{flushleft}
k=2
\end{flushleft}





\begin{flushleft}
= 1 $-$ 𝜑N (0) $-$ 𝜑N (1)
\end{flushleft}


15


15


= 1$-$


(1 $-$ 0.02)15 $-$


0.02 (1 $-$ 0.02)14 $\approx$ 3.5\%


0


1


\begin{flushleft}
Osserviamo che avremmo potuto equivalentemente scrivere P(N $>$ 1) = 1 $-$ FN (1).
\end{flushleft}


\begin{flushleft}
Per rispondere alla seconda domanda introduciamo una nuova variabile aleatoria S che dice
\end{flushleft}


\begin{flushleft}
se una scatola \`{e} rimborsabile o meno: S $\sim$ bin(1, 0.035). A noi per\`{o} interessa il totale di scatole da
\end{flushleft}


\begin{flushleft}
rimborsare tra le 4 comprate: questa \`{e} una variabile aleatoria R $\sim$ bin(4, 0.035). La risposta alla
\end{flushleft}


\begin{flushleft}
seconda domanda, ossia la probabilit\`{a} di farsi rimborsare esattamente una scatola tra 4 acquistate, \`{e}
\end{flushleft}


4


\begin{flushleft}
𝜑R(1) =
\end{flushleft}


0.035 (1 $-$ 0.035)3 $\approx$ 12.7\%.


1





\newpage
106





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
8.2.1. Bernoulliane e binomiali in R
\end{flushleft}


\begin{flushleft}
Uno dei motivi per cui usiamo R a supporto degli esercizi \`{e} il suo essere orientato alla probabilit\`{a}
\end{flushleft}


\begin{flushleft}
e alla statistica. In particolare contiene gi\`{a} le leggi delle principali variabili aleatorie. Cominciamo
\end{flushleft}


\begin{flushleft}
a vedere cosa offre per la binomiale (e per la Bernoulliana).
\end{flushleft}


\begin{flushleft}
Densit\`{a} discreta La funzione di densit\`{a} discreta per una binomiale \`{e} la funzione dbinom(x,
\end{flushleft}


\begin{flushleft}
size, prob)che ha come parametri il punto x in cui vogliamo calcolare la densit\`{a} 𝜑, il numero
\end{flushleft}


\begin{flushleft}
size di tentativi (quello che nella Definizione 8.2 abbiamo indicato con n) e la probabilit\`{a} prob
\end{flushleft}


\begin{flushleft}
di successo di ogni tentativo (quella che nella Definizione 8.2 abbiamo indicato con p).
\end{flushleft}


\begin{flushleft}
Per calcolare la densit\`{a} discreta 𝜑X (11) di una variabile aleatoria X $\sim$ bin(44, 0.2) in R useremo
\end{flushleft}


\begin{flushleft}
il comando dbinom(x = 11, size = 44, prob = 0.2). Se nominiamo i parametri,
\end{flushleft}


\begin{flushleft}
possiamo anche passarli in ordine diverso (ad esempio dbinom(size = 44, prob =
\end{flushleft}


\begin{flushleft}
0.2, x = 11)), in alternativa possiamo passarli anche senza nominarli, ma in questo caso
\end{flushleft}


\begin{flushleft}
devono essere nell'ordine predefinito: dbinom(11,44,0.2).
\end{flushleft}


\begin{flushleft}
Funzione di ripartizione La funzione di ripartizione per una binomiale \`{e} la funzione pbinom(q, size, prob, lower.tail = TRUE), i cui parametri size e prob sono esattamente come sopra, mentre q \`{e} il punto8.2 in cui vogliamo calcolare la funzione di ripartizione
\end{flushleft}


\begin{flushleft}
F e lower.tail \`{e} un parametro logico (posto vero di default) che determina se calcoliamo
\end{flushleft}


\begin{flushleft}
la funzione di ripartizione FX nel punto q (ossia P(X ⩽ q), la coda inferiore), in corrispondenza
\end{flushleft}


\begin{flushleft}
del valore TRUE o il suo complementare 1 $-$ FX (q) (cio\`{e} P(X $>$ q), la coda superiore), in corrispondenza del valore FALSE.
\end{flushleft}


\begin{flushleft}
Per calcolare la funzione di ripartizione F X (12.5) di una variabile aleatoria X $\sim$ bin(23, 0.5) in
\end{flushleft}


\begin{flushleft}
R useremo quindi il comando pbinom(q = 12.5, size = 23, prob = 0.5). Non
\end{flushleft}


\begin{flushleft}
abbiamo bisogno di specificare il valore lower.tail = TRUE, perch\'{e} stiamo prendendo
\end{flushleft}


\begin{flushleft}
il valore di default. Se invece fossimo interessati alla probabilit\`{a} P(X $>$ 10), potremmo scrivere
\end{flushleft}


\begin{flushleft}
pbinom(10, 23, 0.5, lower.tail = FALSE).
\end{flushleft}


\begin{flushleft}
Altre funzioni Ci sono altre due funzioni nella famiglia binomiale di R: rbinom e qbinom. La
\end{flushleft}


\begin{flushleft}
prima \`{e} un generatore casuale di risultati distribuiti come una binomiale dei parametri assegnati.
\end{flushleft}


\begin{flushleft}
In sostanza ci genera dei valori X(𝜔) $\in$ ℝ, con X $\sim$ bin(n, p). La sintassi di questa funzione \`{e} la
\end{flushleft}


\begin{flushleft}
seguente: rbinom(n, size, prob), in cui size e prob sono gli stessi parametri gi\`{a}
\end{flushleft}


\begin{flushleft}
incontrati sopra, mentre n indica il numero di realizzazioni da generare.
\end{flushleft}


\begin{flushleft}
Se vogliamo un campione di 100 realizzazioni di una binomiale di parametri
\end{flushleft}


\begin{flushleft}
n = 1 e p = 0.5 (cio\`{e} 100 lanci di una moneta bilanciata), possiamo scrivere
\end{flushleft}


\begin{flushleft}
rbinom(n=100,size=1,prob=0.5).
\end{flushleft}


\begin{flushleft}
La funzione qbinom \`{e} la funzione quantile, che incontreremo più avanti.
\end{flushleft}


\begin{flushleft}
Esempio 8.8. Avremmo potuto rispondere alle domande nell'Esempio 8.7 con il seguente codice:
\end{flushleft}





\begin{flushleft}
p $<$- pbinom(q = 1, size = 15, prob = 0.02, lower.tail = FALSE)
\end{flushleft}


\begin{flushleft}
p \#per visualizzare la prima probabilit\`{a}
\end{flushleft}


\begin{flushleft}
dbinom(x = 1, size = 4, prob = p)
\end{flushleft}


\begin{flushleft}
Lezione 13
\end{flushleft}





\begin{flushleft}
8.3. LO SCHEMA DI BERNOULLI
\end{flushleft}


\begin{flushleft}
Nella sezione precedente abbiamo introdotto le binomiali come somma finita di variabili aleatorie
\end{flushleft}


\begin{flushleft}
Bernoulliane. Possiamo vedere l'esperimento sottostante come una ripetizione finita di esperimenti Bernoulliani. Il passo successivo, per\`{o}, \`{e} considerare una ripetizione infinita, almeno in
\end{flushleft}


\begin{flushleft}
potenza (nel senso che ci aspettiamo che a un certo punto finisca, ma non sappiamo dare a priori
\end{flushleft}


\begin{flushleft}
un limite superiore al numero di ripetizioni).
\end{flushleft}


\begin{flushleft}
8.2. La lettera q viene dal termine quantile che essa rappresenta, che definiremo in seguito.
\end{flushleft}





\begin{flushleft}
\newpage
8.4 GEOMETRICHE
\end{flushleft}





107





\begin{flushleft}
Se ci pensiamo bene, abbiamo gi\`{a} visto un esperimento di questo tipo nell'Esempio 5.15. Possiamo generalizzarlo, considerando una successione infinita di prove, tra loro indipendenti, che
\end{flushleft}


\begin{flushleft}
abbiano successo con probabilit\`{a} comune p (e insuccesso con probabilit\`{a} 1 $-$ p). Avendo introdotto le variabili aleatorie di Bernoulli, possiamo dire che si tratta di una successione infinita di
\end{flushleft}


\begin{flushleft}
variabili aleatorie Bernoulliane indipendenti e identicamente distribuite, di parametro p. L'intera
\end{flushleft}


\begin{flushleft}
successione di prove prende anche il nome di processo di Bernoulli.
\end{flushleft}


\begin{flushleft}
Vogliamo rappresentare il processo di Bernoulli in linguaggio matematico, come spazio di
\end{flushleft}


\begin{flushleft}
probabilit\`{a} ($\Omega$, ℱ, P), come avevamo gi\`{a} accennato nell'Esempio 5.15. Lo spazio degli esiti $\Omega$ \`{e}
\end{flushleft}


\begin{flushleft}
l'insieme delle successioni a valori in \{0, 1\}, quindi $\Omega$ = \{0, 1\}ℕ∖\{0\}.
\end{flushleft}


\begin{flushleft}
Stiamo considerando uno spazio prodotto infinito, quindi vogliamo prendere per ℱ la tribù
\end{flushleft}


\begin{flushleft}
generata dai cilindri, ossia i sottoinsiemi di $\Omega$ ottenuti fissando un numero finito degli indici
\end{flushleft}


\begin{flushleft}
iniziali: un insieme C $\subseteq$ $\Omega$ \`{e} un cilindro se esistono un numero naturale n e un vettore v $\in$ \{0, 1\}n
\end{flushleft}


\begin{flushleft}
tali che le prime n componenti di ogni elemento 𝜔 $\in$ C coincidono col vettore v, ossia
\end{flushleft}


\begin{flushleft}
C = \{𝜔 $\in$ $\Omega$ : 𝜔 i = vi, 1 ⩽ i ⩽ n\}.
\end{flushleft}


\begin{flushleft}
La probabilit\`{a} sullo spazio prodotto \`{e} il prodotto delle probabilit\`{a} sulle varie componenti, uguale
\end{flushleft}


\begin{flushleft}
a p o (1 $-$ p).
\end{flushleft}


\begin{flushleft}
Esempio 8.9. Vediamo alcuni esempi di probabilit\`{a} di eventi (cilindrici) in un processo di Bernoulli di parametro p.
\end{flushleft}


\begin{flushleft}
$-$ La probabilit\`{a} di avere un successo seguito da due insuccessi \`{e} P(100 ∗ ) = p (1 $-$ p)2, in cui
\end{flushleft}


\begin{flushleft}
abbiamo rappresentato con ∗ una qualunque successione di 0 e 1. Possiamo calcolare la probabilit\`{a} di 100 ∗ perch\'{e} \`{e} un cilindro, le cui prime tre componenti sono (1, 0, 0).
\end{flushleft}


\begin{flushleft}
$-$ La probabilit\`{a} che il primo successo sia alla k-sima prova \`{e} P(0. . .01 ∗ ) = (1 $-$ p)k p. In questo
\end{flushleft}


\begin{flushleft}
caso il cilindro \`{e} determinato dal vettore di lunghezza k le cui prime k $-$ 1 componenti sono 0
\end{flushleft}


\begin{flushleft}
e la k-sima \`{e} un 1.
\end{flushleft}


\begin{flushleft}
$-$ La probabilit\`{a} che il terzo lancio sia un successo. L'evento che ci interessa \`{e} \{⋅⋅1 ∗ \}, cio\`{e} due
\end{flushleft}


\begin{flushleft}
componenti qualunque (a scelta tra 0 e 1), seguite da un 1, seguito a sua volta da qualunque
\end{flushleft}


\begin{flushleft}
cosa. Scritto così, \{⋅⋅1 ∗ \} non \`{e} un cilindro, ma possiamo generarlo con cilindri, ossia scriverlo
\end{flushleft}


\begin{flushleft}
come unione numerabile di cilindri e loro complementari:
\end{flushleft}


\{⋅⋅1 ∗ \} = \{001 ∗ \} $\cup$ \{011 ∗ \} $\cup$ \{101 ∗ \} $\cup$ \{111 ∗ \}.


\begin{flushleft}
Questa unione \`{e} disgiunta, quindi possiamo calcolare la probabilit\`{a} cercata sommando le probabilit\`{a} dei quattro cilindri:
\end{flushleft}


\begin{flushleft}
P(⋅⋅1 ∗ ) =
\end{flushleft}


=


=


=





\begin{flushleft}
P(001 ∗ ) + P(011 ∗ ) + P(101 ∗ ) + P(111 ∗ )
\end{flushleft}


\begin{flushleft}
(1 $-$ p)2 p + (1 $-$ p) p 2 + p (1 $-$ p) p + p 3
\end{flushleft}


\begin{flushleft}
p((1 $-$ p)2 + 2 p (1 $-$ p) + p 2)
\end{flushleft}


\begin{flushleft}
p (p + (1 $-$ p))2 = p.
\end{flushleft}





\begin{flushleft}
$-$ La probabilit\`{a} che il primo successo sia in un lancio dispari.
\end{flushleft}





\begin{flushleft}
8.4. GEOMETRICHE
\end{flushleft}


\begin{flushleft}
Consideriamo uno schema di Bernoulli di parametro p: siamo interessati al numero di insuccessi
\end{flushleft}


\begin{flushleft}
prima di ottenere un successo. Chiamiamo T1 l'istante di primo successo in uno schema di Bernoulli. Gli esiti sono della forma 𝜔 = (𝜔1, 𝜔2, . . . ), quindi possiamo scrivere
\end{flushleft}


\begin{flushleft}
T1 = inf \{i ⩾ 1 : 𝜔 i = 1\}.
\end{flushleft}





\newpage
108





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
Allora T1 \`{e} una variabile aleatoria8.3: \`{e} in particolare la variabile aleatoria indicatrice del primo
\end{flushleft}


\begin{flushleft}
successo. Tuttavia non descrive proprio quello che cercavamo: noi siamo interessati agli insuccessi che precedono il primo successo, ossia T1 $-$ 1. Qual \`{e} la loro distribuzione?
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 8.10. Diciamo che una variabile aleatoria X \`{e} geometrica di parametro p se \`{e} l'istante
\end{flushleft}


\begin{flushleft}
precedente al primo successo di uno schema di Bernoulli di parametro p. In questo caso scriviamo X $\sim$
\end{flushleft}


\begin{flushleft}
geom(p).
\end{flushleft}


\begin{flushleft}
Dalla definizione possiamo ricavare immediatamente la densit\`{a} discreta di X $\sim$ geom(p):
\end{flushleft}


\begin{flushleft}
𝜑X (k) = (1 $-$ p)k p
\end{flushleft}


\begin{flushleft}
per k $\in$ ℕ (e 0 altrimenti). Infatti, dire che X = k significa che i primi k tentativi sono insuccessi e
\end{flushleft}


\begin{flushleft}
il (k + 1)-simo \`{e} un successo, da cui, rispettivamente, i due fattori (1 $-$ p)k e p.
\end{flushleft}


\begin{flushleft}
Osservazione 8.11. Nella densit\`{a} discreta non compare un coefficiente binomiale perch\'{e} non
\end{flushleft}


\begin{flushleft}
stiamo chiedendo {``}un successo nei primi k + 1 lanci'', ma stiamo imponendo un ordine: i primi
\end{flushleft}


\begin{flushleft}
k sono insuccessi, il (k + 1)-simo \`{e} un successo.
\end{flushleft}


\begin{flushleft}
Dobbiamo verificare che la definizione data di densit\`{a} discreta sia ben posta, in particolare che
\end{flushleft}


\begin{flushleft}
la somma su tutti i possibili valori sia uguale a 1. Se p = 1, allora X $\equiv$ 0, quindi 𝜑X (k) = 1\{k =0\}. Se
\end{flushleft}


\begin{flushleft}
p $<$ 1, allora
\end{flushleft}


+$\infty$





+$\infty$





\begin{flushleft}
𝜑 X (k) =
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
(1 $-$ p)k p = p
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}





+$\infty$





\begin{flushleft}
(1 $-$ p)k = p ⋅
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
in cui abbiamo usato il fatto che la serie
\end{flushleft}


\begin{flushleft}
0 e 1.
\end{flushleft}





+$\infty$


\begin{flushleft}
∑ k =0 (1 $-$ p)k
\end{flushleft}





1


= 1,


\begin{flushleft}
1 $-$ (1 $-$ p)
\end{flushleft}





\begin{flushleft}
\`{e} geometrica8.4 di ragione 1 $-$ p compresa tra
\end{flushleft}





\begin{flushleft}
Osservazione 8.12. La definizione di variabile geometrica non \`{e} unica: molti definiscono come
\end{flushleft}


\begin{flushleft}
variabile aleatoria geometrica il primo istante di successo (quella che abbiamo chiamato T1). In
\end{flushleft}


\begin{flushleft}
questo caso la densit\`{a} discreta \`{e} leggermente diversa:
\end{flushleft}


\begin{flushleft}
𝜑 T1(k) = (1 $-$ p)k $-$1 p
\end{flushleft}


\begin{flushleft}
per k $\in$ ℕ ∖\{0\}. La sostanza non cambia molto, ma i numeri sì, quindi \`{e} opportuno prestare attenzione. Di solito si distingue tra le due specificando il dominio: nella Definizione 8.10 il dominio
\end{flushleft}


\begin{flushleft}
era ℕ, per il primo successo il dominio \`{e} ℕ ∖ \{0\}.
\end{flushleft}


\begin{flushleft}
Scegliere l'una o l'altra dipende dal gusto estetico o dalla comodit\`{a}. Nel caso di questo corso
\end{flushleft}


\begin{flushleft}
ci siamo allineati, per semplicit\`{a}, alla scelta fatta in R.
\end{flushleft}


\begin{flushleft}
Abbiamo ricavato la densit\`{a} discreta, adesso vediamo com'\`{e} fatta la funzione di ripartizione
\end{flushleft}


\begin{flushleft}
di una variabile aleatoria X geometrica di parametro p:
\end{flushleft}


\begin{flushleft}
FX (x) =
\end{flushleft}





\{\{\{ 0∑





\begin{flushleft}
x$<$0
\end{flushleft}


\begin{flushleft}
⌊x⌋
\end{flushleft}


\begin{flushleft}
⌊x⌋
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
⌊x⌋+1
\end{flushleft}


\begin{flushleft}
k =0 𝜑 X (k) = p ∑ k =0 (1 $-$ p) = 1 $-$ (1 $-$ p)
\end{flushleft}





\begin{flushleft}
x ⩾ 0.
\end{flushleft}





\begin{flushleft}
Osserviamo anche che possiamo ottenere lo stesso risultato in maniera più diretta passando dal
\end{flushleft}


\begin{flushleft}
complementare: se n $\in$ ℕ, P(X $>$ n) = 1 $-$ FX (n) \`{e} la probabilit\`{a} che nei primi n + 1 lanci abbiamo
\end{flushleft}


\begin{flushleft}
avuto solamente insuccessi, quindi
\end{flushleft}


\begin{flushleft}
P(X $>$ n) = 1 $-$ FX (n) = (1 $-$ p)n+1.
\end{flushleft}





(8.1)





\begin{flushleft}
8.3. Appartiene a una famiglia di variabili aleatorie i cui elementi sono detti tempi aleatori o tempi casuali e, in particolare, si tratta di un tempo d'arresto, ossia il primo istante in cui una condizione viene soddisfatta.
\end{flushleft}


\begin{flushleft}
8.4. Qualche informazione in più sulla serie geometrica \`{e} disponibile in Appendice A.2
\end{flushleft}





\begin{flushleft}
\newpage
8.4 GEOMETRICHE
\end{flushleft}





109





\begin{flushleft}
PROPOSIZIONE 8.13. Una variabile aleatoria geometrica X gode della propriet\`{a} di assenza di memoria, cio\`{e}
\end{flushleft}


\begin{flushleft}
per ogni n, k $\in$ ℕ
\end{flushleft}


(8.2)





\begin{flushleft}
P(X ⩾ n + k ∣ X ⩾ n) = P(X ⩾ k).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Partiamo dalla definizione di probabilit\`{a} condizionata,
\end{flushleft}


\begin{flushleft}
P((X ⩾ n + k) $\cap$ (X ⩾ n))
\end{flushleft}


\begin{flushleft}
P(X ⩾ n)
\end{flushleft}


\begin{flushleft}
P(X ⩾ n + k)
\end{flushleft}


=


\begin{flushleft}
P(X $>$ n $-$ 1)
\end{flushleft}


\begin{flushleft}
(1 $-$ p)n+k
\end{flushleft}


=


\begin{flushleft}
(1 $-$ p)n
\end{flushleft}





\begin{flushleft}
P(X ⩾ n + k ∣ X ⩾ n) =
\end{flushleft}





\begin{flushleft}
= (1 $-$ p)k
\end{flushleft}


\begin{flushleft}
= P(X ⩾ k),
\end{flushleft}


\begin{flushleft}
in cui abbiamo usato ripetutamente la (8.1).
\end{flushleft}





□





\begin{flushleft}
Osservazione 8.14. Da dove viene il nome assenza di memoria di questa propriet\`{a}? Possiamo leggere la (8.2) in questo modo: se dopo n lanci non abbiamo ancora visto un successo (X ⩾ n), la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} di avere ancora almeno k insuccessi (X ⩾ n + k) \`{e} uguale alla probabilit\`{a} che, iniziando
\end{flushleft}


\begin{flushleft}
ora uno schema di Bernoulli di uguale parametro, avremo almeno k insuccessi prima del primo
\end{flushleft}


\begin{flushleft}
successo (X ⩾ k). In altre parole, il processo non ha memoria di quanti insuccessi ha gi\`{a} avuto:
\end{flushleft}


\begin{flushleft}
sapere che ci sono stati un certo numero di insuccessi non ci d\`{a} alcuna informazione aggiuntiva
\end{flushleft}


\begin{flushleft}
sull'istante di primo successo (e quindi sull'ultimo istante prima del primo successo).
\end{flushleft}


\begin{flushleft}
Esempio 8.15. Se nel Superenalotto il 55 non esce da 60 estrazioni8.5, quanto \`{e} probabile che esca
\end{flushleft}


\begin{flushleft}
alla prossima estrazione? E che esca per la prima volta tra almeno altre 30?
\end{flushleft}


\begin{flushleft}
A ogni estrazione vengono scelti 6 numeri tra 90, la probabilit\`{a} che esca un particolare numero
\end{flushleft}


\begin{flushleft}
(ad esempio il 55) \`{e}
\end{flushleft}


1$-$





89


6


90


6





=





89


5


90


6





=





89! 84! 6! 6


1


⋅


= = $\approx$ 6.6\%.


84! 5! 90!


90 15





\begin{flushleft}
A ogni estrazione la variabile aleatoria indicatrice dell'evento {``}esce il 55 al Superenalotto'' \`{e} una
\end{flushleft}


1


\begin{flushleft}
Bernoulliana di parametro 15 . Consideriamo lo schema di Bernoulli corrispondente e, in particolare, la probabilit\`{a} che 55 esca alla prossima estrazione sapendo che non \`{e} uscito nelle prime 60.
\end{flushleft}


\begin{flushleft}
Chiamiamo X la variabile aleatoria che descrive l'ultima estrazione in cui non esce 55: la nostra
\end{flushleft}


\begin{flushleft}
richiesta \`{e} allora
\end{flushleft}


1 $-$ 15


\begin{flushleft}
P(X = 60)
\end{flushleft}


=


1


\begin{flushleft}
P(X $>$ 59)
\end{flushleft}


1 $-$ 15


1





\begin{flushleft}
P(X = 60 ∣ X ⩾ 60) =
\end{flushleft}





60 1


15


59+1





=





1


,


15





\begin{flushleft}
cio\`{e} \`{e} identica alla probabilit\`{a} che 55 esca al primo tentativo.
\end{flushleft}


\begin{flushleft}
Analogamente, la probabilit\`{a} che esca per la prima volta tra almeno altre 30 estrazioni \`{e}
\end{flushleft}


\begin{flushleft}
P(X ⩾ 60 + 30 ∣ X ⩾ 60) = P(X ⩾ 30) = 1 $-$
\end{flushleft}





1


15





30





$\approx$ 12.6\%.





\begin{flushleft}
La morale di questo esempio \`{e} che in termini di probabilit\`{a} \`{e} assolutamente irrilevante che il
\end{flushleft}


\begin{flushleft}
55 sia {``}in ritardo'' da 60 estrazioni: la probabilit\`{a} che esca alla prossima estrazione \`{e} esattamente
\end{flushleft}


\begin{flushleft}
la stessa che esca alla prima estrazione. Non solo, la probabilit\`{a} che si debba attendere un po' \`{e}
\end{flushleft}


\begin{flushleft}
spesso sottostimata: la probabilit\`{a} che un numero esca alla prossima estrazione \`{e} approssimativamente uguale alla probabilit\`{a} che non esca prima di 38 estrazioni (6.67\% contro 6.78\%).
\end{flushleft}


\begin{flushleft}
8.5. Dati al 13 aprile 2021, non che sia rilevante, come vedremo.
\end{flushleft}





\newpage
110





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
8.4.1. Geometriche in R
\end{flushleft}


\begin{flushleft}
Come abbiamo detto, la scelta della definizione di variabile aleatoria con distribuzione geometrica fatta \`{e} stata dettata dalla scelta degli sviluppatori di R (e prima di S).
\end{flushleft}


\begin{flushleft}
Le funzioni per una variabile aleatoria geometrica sono dgeom(x, prob) per la densit\`{a}
\end{flushleft}


\begin{flushleft}
discreta, dove x \`{e} il punto in cui vogliamo calcolare la densit\`{a} 𝜑 e prob \`{e} la probabilit\`{a} di successo di ogni tentativo (che abbiamo indicato con p).
\end{flushleft}


\begin{flushleft}
La funzione di ripartizione per una geometrica \`{e} la funzione pgeom(q, prob, lower.tail = TRUE), il cui il parametro prob \`{e} esattamente come sopra, mentre q e lower.tail
\end{flushleft}


\begin{flushleft}
sono come nelle corrispondenti funzioni della binomiale: il primo \`{e} il punto in cui calcoliamo la
\end{flushleft}


\begin{flushleft}
funzione di ripartizione F, mentre il secondo \`{e} un parametro logico che determina se calcoliamo
\end{flushleft}


\begin{flushleft}
F X (q) (il default) o il suo complementare 1 $-$ FX (q).
\end{flushleft}


\begin{flushleft}
In modo del tutto analogo alla binomiale abbiamo anche per la geometrica altre due funzioni
\end{flushleft}


\begin{flushleft}
in R: rgeom e qgeom, rispettivamente la generatrice di valori casuali distribuiti come una geometrica di parametri assegnati e la funzione quantile.
\end{flushleft}


\begin{flushleft}
Esempio 8.16. Avremmo potuto rispondere alle domande nell'Esempio 8.15 con il seguente codice:
\end{flushleft}





\begin{flushleft}
dgeom(x = 60, prob = 1/15)/pgeom(q = 59, prob = 1/15, lower.tail
\end{flushleft}


\begin{flushleft}
= FALSE)
\end{flushleft}


\begin{flushleft}
pgeom(89, 1/15, FALSE)/pgeom(59,1/15,FALSE)
\end{flushleft}





\begin{flushleft}
8.5. BINOMIALI NEGATIVE
\end{flushleft}


\begin{flushleft}
Se per le variabili aleatorie geometriche siamo partiti dall'istante di primo successo di uno schema
\end{flushleft}


\begin{flushleft}
di Bernoulli, ora proviamo a generalizzare, considerando i tempi d'attesa del n-simo successo in
\end{flushleft}


\begin{flushleft}
uno schema di Bernoulli: per n $\in$ ℕ ∖ \{0\}
\end{flushleft}


\begin{flushleft}
T = inf \{
\end{flushleft}


\begin{flushleft}
\{\{i ⩾ 1 :
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\}\}


\}





\begin{flushleft}
𝜔k = n ,
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
k=1
\end{flushleft}





\begin{flushleft}
variabili aleatorie che possiamo anche definire ricorsivamente,
\end{flushleft}


\begin{flushleft}
\{i ⩾ 1 : 𝜔 = 1\}
\end{flushleft}


\begin{flushleft}
\{\{ TT = inf
\end{flushleft}


\begin{flushleft}
= inf \{i $>$ T : 𝜔 = 1\} n ⩾ 1.
\end{flushleft}


\begin{flushleft}
i
\end{flushleft}





1





\begin{flushleft}
n+1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
Se per\`{o} con le variabili aleatorie geometriche eravamo interessati al numero di insuccessi prima
\end{flushleft}


\begin{flushleft}
del primo successo, ora considereremo il numero di insuccessi prima dell'n-simo successo (ossia
\end{flushleft}


\begin{flushleft}
la variabile aleatoria Tn $-$ n. Qual \`{e} la sua distribuzione?
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 8.17. Diciamo che una variabile aleatoria X \`{e} binomiale negativa (o di Pascal) di parametri n e p se \`{e} il numero di insuccessi precedenti all'n-simo successo di uno schema di Bernoulli di
\end{flushleft}


\begin{flushleft}
parametro p. In questo caso scriviamo X $\sim$ NB(n, p).
\end{flushleft}


\begin{flushleft}
Anche in questo caso iniziamo a ricavare, dalla definizione, la funzione di densit\`{a} discreta di
\end{flushleft}


\begin{flushleft}
X $\sim$ NB(n, p), per k ⩾ 0
\end{flushleft}


\begin{flushleft}
𝜑X (k) = P(X = k) = P(Tn = k + n)
\end{flushleft}


\begin{flushleft}
= P(
\end{flushleft}


\begin{flushleft}
((𝜔
\end{flushleft}





\begin{flushleft}
k +n$-$1
\end{flushleft}





\begin{flushleft}
𝜔i = n $-$ 1
\end{flushleft}





\begin{flushleft}
k +n = 1,
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
k + n $-$ 1 n$-$1
\end{flushleft}


\begin{flushleft}
= p
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)k
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
k +n$-$1 n
\end{flushleft}


=


\begin{flushleft}
p (1 $-$ p)k
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}





))


)





\begin{flushleft}
\newpage
8.5 BINOMIALI NEGATIVE
\end{flushleft}





111





\begin{flushleft}
in cui abbiamo iniziato osservando che se abbiamo k insuccessi prima di avere l'n-simo successo,
\end{flushleft}


\begin{flushleft}
questo sar\`{a} al tentativo k + n, allora nei precedenti k + n $-$ 1 tentativi ci sono n $-$ 1 successi e, nella
\end{flushleft}


\begin{flushleft}
penultima riga, abbiamo resa esplicita l'associazione con le binomiali, visto che \`{e} il prodotto della
\end{flushleft}


\begin{flushleft}
probabilit\`{a} di successo alla (k + n)-sima prova (la densit\`{a} discreta di una Bernoulliana di parametro p calcolata in 1) e della probabilit\`{a} di avere n $-$ 1 successi nelle k + n $-$ 1 prove precedenti (la
\end{flushleft}


\begin{flushleft}
densit\`{a} discreta di una binomiale di parametri k + n $-$ 1 e p calcolata in n $-$ 1).
\end{flushleft}


\begin{flushleft}
Osservazione 8.18. Anche per le binomiali negative vale la pena dare una parola di avvertimento.
\end{flushleft}


\begin{flushleft}
Come per le geometriche, anche qui alcuni scelgono di definire le binomiali negative come i tempi
\end{flushleft}


\begin{flushleft}
d'attesa, ossia il numero di tentativi totali prima del successo n-simo. C'\`{e} per\`{o} anche un'ulteriore
\end{flushleft}


\begin{flushleft}
difficolt\`{a}, perch\'{e} \`{e} possibile estendere la definizione al caso in cui n $\in$ ℝ+, perdendo per\`{o} l'interpretazione come istante (precedente) al tempo d'arresto. Se n $\in$ ℝ+ ∖ ℕ la binomiale negativa
\end{flushleft}


\begin{flushleft}
prende anche il nome di distribuzione di P\'{o}lya.
\end{flushleft}


\begin{flushleft}
Esempio 8.19. In un gioco, un personaggio \`{e} rimasto intrappolato sul fondo di una buca profonda. Per uscire ha bisogno di ottenere 3 risultati maggiori di 15 lanciando un dado a 20 facce.
\end{flushleft}


\begin{flushleft}
Ogni lancio di dado corrisponde a 5 minuti di tentativi, nel gioco: con che probabilit\`{a} il personaggio impiegher\`{a} al più mezz'ora per uscire dalla buca?
\end{flushleft}


\begin{flushleft}
I lanci ripetuti del dado nascondono uno schema di Bernoulli, in cui la probabilit\`{a} di successo
\end{flushleft}


5


1


\begin{flushleft}
\`{e} p = 20 = 4 . Per rispondere alla domanda, osserviamo come prima cosa che il tempo necessario
\end{flushleft}


\begin{flushleft}
\`{e} 5 T3, perch\'{e} chiediamo che ci siano almeno tre tentativi con successo e ciascun tentativo (di
\end{flushleft}


\begin{flushleft}
successo o meno) richiede 5 minuti. Chiedere che il personaggio impieghi al più mezz'ora per
\end{flushleft}


\begin{flushleft}
uscire dalla buca equivale allora a chiedere che faccia al più 6 tentativi totali per di ottenere 3
\end{flushleft}


\begin{flushleft}
successi ossia che abbia al più 3 insuccessi. Avendo riformulato il problema in questo modo,
\end{flushleft}


1


\begin{flushleft}
possiamo descriverlo usando una binomiale negativa X, di parametri n = 3 e p = 4 . La probabilit\`{a}
\end{flushleft}


\begin{flushleft}
cercata \`{e} allora
\end{flushleft}


3





3





\begin{flushleft}
𝜑 X (k) =
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
k+2
\end{flushleft}


2





1


4





3





3


4





\begin{flushleft}
k
\end{flushleft}





$\approx$ 17\%.





\begin{flushleft}
8.5.1. Binomiali negative in R
\end{flushleft}


\begin{flushleft}
Le funzioni per una variabile aleatoria binomiale negativa sono dnbinom(x, size, prob)
\end{flushleft}


\begin{flushleft}
per la densit\`{a} discreta, dove x \`{e} il punto in cui vogliamo calcolare la densit\`{a} 𝜑, size \`{e} il numero
\end{flushleft}


\begin{flushleft}
di successi da raggiungere (quello che abbiamo chiamato n) e prob \`{e} la probabilit\`{a} di successo
\end{flushleft}


\begin{flushleft}
di ogni tentativo (che abbiamo indicato con p).
\end{flushleft}


\begin{flushleft}
La funzione di ripartizione per una binomiale negativa \`{e} la funzione pnbinom(q, size,
\end{flushleft}


\begin{flushleft}
prob, lower.tail = TRUE), il cui i parametri size e prob sono esattamente come
\end{flushleft}


\begin{flushleft}
sopra, mentre q e lower.tail sono come nelle corrispondenti funzioni della geometrica e
\end{flushleft}


\begin{flushleft}
della binomiale: il primo \`{e} il punto in cui calcoliamo la funzione di ripartizione F, mentre il
\end{flushleft}


\begin{flushleft}
secondo \`{e} un parametro logico che determina se calcoliamo FX (q) (il default) o il suo complementare 1 $-$ FX (q). Attenzione che in realt\`{a} pnbinom (così come le altre funzioni della famiglia
\end{flushleft}


\begin{flushleft}
binomiale negativa) ha un ulteriore parametro mu, che a noi non interessa, ma che rende necessario esplicitare sempre il nome del parametro lower.tail: dobbiamo scrivere pnbinom(2,
\end{flushleft}


\begin{flushleft}
4, 0.01, lower.tail = TRUE), perch\'{e} pnbinom(2, 4, 0.01, TRUE) d\`{a}
\end{flushleft}


\begin{flushleft}
errore (il valore TRUE \`{e} dove la funzione si aspetta il valore per mu).
\end{flushleft}


\begin{flushleft}
In modo del tutto analogo alle altre distribuzioni viste finora, abbiamo altre due funzioni in
\end{flushleft}


\begin{flushleft}
R: rnbinom e qnbinom, rispettivamente la generatrice di valori casuali distribuiti come una
\end{flushleft}


\begin{flushleft}
binomiale negativa di parametri assegnati e la funzione quantile.
\end{flushleft}


\begin{flushleft}
Avremmo potuto rispondere alla domanda nell'Esempio 8.19 usando il seguente codice R:
\end{flushleft}


\begin{flushleft}
pnbinom(q = 3, size = 3, prob = 0.25, lower.tail = TRUE).
\end{flushleft}





\newpage
112





\begin{flushleft}
Lezione 14
\end{flushleft}





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
8.5.2. Riproducibilit\`{a}
\end{flushleft}


\begin{flushleft}
Le distribuzioni che abbiamo incontrato finora sono tutte parametrizzate, ossia dipendono da
\end{flushleft}


\begin{flushleft}
almeno un parametro. Potremmo allora più correttamente parlare di famiglie di distribuzioni o
\end{flushleft}


\begin{flushleft}
di leggi di probabilit\`{a}. Perch\'{e} farlo?
\end{flushleft}


\begin{flushleft}
Abbiamo visto come trattare la somma di variabili aleatorie, come determinare la legge della
\end{flushleft}


\begin{flushleft}
variabile aleatoria risultante. Possiamo chiederci se, prese due variabili aleatorie (indipendenti)
\end{flushleft}


\begin{flushleft}
di uguale distribuzione la loro somma sia a sua volta una variabile aleatoria con medesima legge.
\end{flushleft}


\begin{flushleft}
Pensandoci un attimo, questo \`{e} probabilmente chiedere troppo. Ma forse, lasciando un po' di
\end{flushleft}


\begin{flushleft}
margine di manovra come ad esempio i parametri di una famiglia, ci possiamo riuscire: sommando due variabili aleatorie della stessa famiglia possiamo ottenere una variabile aleatoria della
\end{flushleft}


\begin{flushleft}
stessa famiglia, magari con parametri diversi.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 8.20. Diciamo che una famiglia di leggi di probabilit\`{a} \`{e} riproducibile se sommando due
\end{flushleft}


\begin{flushleft}
variabili aleatorie indipendenti con leggi di quella famiglia, se ne ottiene un'altra della stessa famiglia.
\end{flushleft}


\begin{flushleft}
Andiamo allora a vedere se le distribuzioni discrete che abbiamo incontrato finora sono riproducibili o no.
\end{flushleft}


\begin{flushleft}
Esempio 8.21. Siano X e Y due variabili aleatorie indipendenti e identicamente distribuite, di
\end{flushleft}


\begin{flushleft}
legge geometrica di parametro p. Cosa possiamo dire della loro somma S?
\end{flushleft}


\begin{flushleft}
Da quanto visto nella Proposizione 7.16, abbiamo
\end{flushleft}


\begin{flushleft}
𝜑 X (j) 𝜑 Y(k $-$ j)
\end{flushleft}





\begin{flushleft}
𝜑S(k) =
\end{flushleft}


\begin{flushleft}
j$\in$ℛ X
\end{flushleft}


+$\infty$





\begin{flushleft}
(1 $-$ p) j p 1\{k $-$ j⩾0\} (1 $-$ p)k $-$ j p
\end{flushleft}





=


\begin{flushleft}
j=0
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





=





\begin{flushleft}
p 2 (1 $-$ p)k
\end{flushleft}





\begin{flushleft}
j=0
\end{flushleft}





\begin{flushleft}
= (k + 1) p 2 (1 $-$ p)k .
\end{flushleft}


\begin{flushleft}
Questa non \`{e} la densit\`{a} discreta di una geometrica, ma ci dovrebbe ricordare qualcosa di altro:
\end{flushleft}


\begin{flushleft}
una binomiale negativa. In effetti possiamo osservare che NB(2, p) ha densit\`{a} discreta
\end{flushleft}


\begin{flushleft}
n+k $-$1 n
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)k = (k + 1) p 2 (1 $-$ p)k ,
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
ossia la somma di due variabili aleatorie indipendenti geometriche di parametro p \`{e} una binomiale negativa di parametri 2 e p.
\end{flushleft}


\begin{flushleft}
Le geometriche non sono quindi riproducibili, ma se osserviamo che una geometrica di parametro p \`{e} una binomiale negativa di parametri 1 e p, abbiamo un suggerimento su quale possa
\end{flushleft}


\begin{flushleft}
essere una famiglia di distribuzioni riproducibili.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 8.22. La famiglia delle distribuzioni binomiali negative a parametro p fissato \`{e} riproducibile. In particolare la somma di una binomiale negativa di parametri n e p e di una (indipendente dalla
\end{flushleft}


\begin{flushleft}
prima) di parametri m e p \`{e} distribuita come una binomiale negativa di parametri n + m e p.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Si pu\`{o} fare come conto, oppure usando il fatto che una binomiale negativa \`{e}
\end{flushleft}


\begin{flushleft}
somma di geometriche. [TBA]
\end{flushleft}


□


\begin{flushleft}
Osservazione 8.23. Il significato di questo risultato non \`{e} molto sorprendente, se lo scriviamo
\end{flushleft}


\begin{flushleft}
esplicitamente: date X $\sim$NB(n, p) e Y $\sim$NB(m, p) indipendenti, allora X+ Y $\sim$ NB(m+ n,p). Se pensiamo all'interpretazione di X e Y, stiamo dicendo che la il numero di insuccessi prima di ottenere
\end{flushleft}


\begin{flushleft}
n successi più il numero di insuccessi prima di ottenere m successi ha la stessa distribuzione del
\end{flushleft}


\begin{flushleft}
numero di insuccessi prima di avere n+m successi. In altre parole, stiamo {``}resettando'' dopo aver
\end{flushleft}


\begin{flushleft}
raggiunto i primi n successi.
\end{flushleft}





\begin{flushleft}
\newpage
8.5 BINOMIALI NEGATIVE
\end{flushleft}





113





\begin{flushleft}
La propriet\`{a} che c'\`{e} sotto \`{e} l'assenza di memoria delle geometriche, perch\'{e} alla fine possiamo
\end{flushleft}


\begin{flushleft}
scrivere ogni binomiale negativa come somma di geometriche.
\end{flushleft}


\begin{flushleft}
Quanto abbiamo visto con le binomiali negative dovrebbe suggerirci qualcos'altro: se abbiamo
\end{flushleft}


\begin{flushleft}
definito le binomiali come somme di Bernoulliane, \`{e} lecito chiedersi se anche le binomiali siano
\end{flushleft}


\begin{flushleft}
riproducibili.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 8.24. La famiglia delle distribuzioni binomiali a parametro p fissato \`{e} riproducibile. In particolare la somma di una binomiale di parametri n e p e di un'altra (indipendente dalla prima) di parametri
\end{flushleft}


\begin{flushleft}
m e p \`{e} distribuita come una binomiale di parametri n + m e p.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Consideriamo X $\sim$ bin(n, p) e Y $\sim$ bin(m, p), tra loro indipendenti. Dalla Proposizione 7.16 abbiamo
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜑X (k) 𝜑Y(l $-$ k).
\end{flushleft}





\begin{flushleft}
𝜑X+Y(l) =
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
Ora possiamo osservare che gli addendi non si annullano solo se 0 ⩽ l $-$ k ⩽ m, cio\`{e} per l $-$ m ⩽ k ⩽ l,
\end{flushleft}


\begin{flushleft}
con la condizione che l $-$ k non vada oltre a m. Continueremo a scrivere le somme per intero,
\end{flushleft}


\begin{flushleft}
con i corrispondenti coefficienti binomiali e potenze, da ignorare nel caso abbiano argomenti o
\end{flushleft}


\begin{flushleft}
esponenti negativi.
\end{flushleft}


\begin{flushleft}
Abbiamo quindi
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)n$-$k 10⩽l$-$k ⩽m
\end{flushleft}


\begin{flushleft}
p l$-$k (1 $-$ p)m$-$(l$-$k)
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
l$-$k
\end{flushleft}





\begin{flushleft}
𝜑X+Y(l) =
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





=





\begin{flushleft}
p l (1 $-$ p)n+m$-$l 10⩽l$-$k ⩽m
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}


\begin{flushleft}
l
\end{flushleft}





\begin{flushleft}
n+m$-$l
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
= p (1 $-$ p)
\end{flushleft}





\begin{flushleft}
10⩽l$-$k ⩽m
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
l$-$k
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
l$-$k
\end{flushleft}





\begin{flushleft}
e per concludere ci basta mostrare che
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
10⩽l$-$k⩽m
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
n+m
\end{flushleft}


=


.


\begin{flushleft}
l$-$k
\end{flushleft}


\begin{flushleft}
l
\end{flushleft}





\begin{flushleft}
Lo facciamo per induzione su n. Lasciamo cadere la funzione indicatrice e osserviamo che combinatoricamente possiamo mettere a 0 i coefficienti binomiali con la {``}parte sotto'' fuori dai limiti.
\end{flushleft}


\begin{flushleft}
Per n = 0,
\end{flushleft}


\begin{flushleft}
0 m
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
0+m
\end{flushleft}


=


=


.


0


\begin{flushleft}
l
\end{flushleft}


\begin{flushleft}
l
\end{flushleft}


\begin{flushleft}
l
\end{flushleft}


\begin{flushleft}
Supponiamo ora che la propriet\`{a} valga per n e mostriamo che vale per n + 1:
\end{flushleft}


\begin{flushleft}
n+1
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
n+1
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
l$-$k
\end{flushleft}





\begin{flushleft}
n+1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


+


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k$-$1
\end{flushleft}





=


\begin{flushleft}
k =0
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





=


\begin{flushleft}
k =0
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





=


\begin{flushleft}
k =0
\end{flushleft}





=


=





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


+


\begin{flushleft}
l$-$k
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


+


\begin{flushleft}
l$-$k
\end{flushleft}





\begin{flushleft}
n+1
\end{flushleft}


\begin{flushleft}
k =1
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
h=0
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
l$-$k
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k $-$1
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
h
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
l$-$k
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
l$-$h$-$1
\end{flushleft}





\begin{flushleft}
n+m
\end{flushleft}


\begin{flushleft}
n+m
\end{flushleft}


+


\begin{flushleft}
l
\end{flushleft}


\begin{flushleft}
l$-$1
\end{flushleft}


\begin{flushleft}
n+m+1
\end{flushleft}


\begin{flushleft}
l
\end{flushleft}





\begin{flushleft}
in cui abbiamo usato due volte l'identit\`{a} 4. della Proposizione 1.26.
\end{flushleft}





□





\newpage
114





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
8.6. IPERGEOMETRICHE
\end{flushleft}


\begin{flushleft}
Un altro esperimento descritto da una variabile aleatoria Bernoulliana \`{e} l'estrazione di una biglia
\end{flushleft}


\begin{flushleft}
da un'urna di composizione nota. In un'urna ci sono m palline bianche e n palline nere, cio\`{e} la
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
proporzione di biglie bianche sul totale \`{e} p = m + n , la variabile aleatoria {``}estrazione di una biglia
\end{flushleft}


\begin{flushleft}
bianca'' ha legge Bernoulliana bin(1, p). Possiamo allora vedere la variabile aleatoria che conta le
\end{flushleft}


\begin{flushleft}
biglie bianche tra k estratte con reimmissione dall'urna come una binomiale bin(k, p).
\end{flushleft}


\begin{flushleft}
Se siamo invece interessati alla variabile aleatoria che conta il numero di biglie bianche tra k
\end{flushleft}


\begin{flushleft}
estratte senza reimmissione, abbiamo bisogno di introdurre una nuova distribuzione.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 8.25. Data un'urna contenente m biglie bianche e n biglie nere, chiamiamo ipergeometrica
\end{flushleft}


\begin{flushleft}
di parametri k, n e m la variabile aleatoria X che conta il numero di palline bianche tra k estratte dall'urna
\end{flushleft}


\begin{flushleft}
senza reimmissione. Scriviamo in questo caso X $\sim$ hyp(k, m, n).
\end{flushleft}


\begin{flushleft}
Ricaviamo la densit\`{a} discreta di una variabile aleatoria ipergeometrica di parametri k, m e n.
\end{flushleft}


\begin{flushleft}
Innanzitutto abbiamo dei vincoli su k, 0 ⩽ k ⩽ m + n, perch\'{e} non possiamo estrarre più biglie di
\end{flushleft}


\begin{flushleft}
quelle presenti nell'urna. In tutto abbiamo n +k m modi di estrarre k biglie tra m + n. Vogliamo
\end{flushleft}


\begin{flushleft}
contare il numero b di biglie bianche estratte, in altre parole b delle k estratte saranno bianche
\end{flushleft}


\begin{flushleft}
e le rimanenti k $-$ b saranno nere. Anche questo impone dei vincoli su b: da un lato 0 ⩽ b ⩽ m,
\end{flushleft}


\begin{flushleft}
perch\'{e} non possiamo pescare più biglie bianche di quelle che ci sono, dall'altro 0 ⩽ k $-$ b ⩽ n (ossia
\end{flushleft}


\begin{flushleft}
k $-$ n ⩽ b ⩽ k) perch\'{e} non possiamo pescare più biglie nere di quelle che ci sono. Possiamo ora
\end{flushleft}


\begin{flushleft}
contare quanti sono le possibili estrazioni a noi favorevoli: dobbiamo scegliere b biglie bianche tra
\end{flushleft}


\begin{flushleft}
le m disponibili e k $-$ b biglie nere tra le n disponibili e lo possiamo fare in mb k n$-$ b modi. Allora
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\{


\begin{flushleft}
𝜑 (b) = \{
\end{flushleft}


\{\{


0


\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k $-$b
\end{flushleft}


\begin{flushleft}
n+m
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
max \{0, k $-$ n\} ⩽ b ⩽ min \{k, m\}
\end{flushleft}


\begin{flushleft}
altrimenti.
\end{flushleft}





\begin{flushleft}
Osservazione 8.26. Grazie a quanto visto nella dimostrazione della Proposizione 8.24, abbiamo
\end{flushleft}


\begin{flushleft}
immediatamente che
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
𝜑 X (b) =
\end{flushleft}


\begin{flushleft}
b=0
\end{flushleft}





\begin{flushleft}
min\{k,m\}
\end{flushleft}





\begin{flushleft}
min\{k,m\}
\end{flushleft}





\begin{flushleft}
𝜑X (b) =
\end{flushleft}


\begin{flushleft}
b=max\{0,k $-$n\}
\end{flushleft}





\begin{flushleft}
∑b=max\{0,k $-$n\}
\end{flushleft}


\begin{flushleft}
n+m
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k $-$b
\end{flushleft}





= 1.





\begin{flushleft}
Esempio 8.27. Un'azienda produce 400 tastiere al giorno e di queste 10 sono difettose. Se ogni
\end{flushleft}


\begin{flushleft}
giorno l'azienda controlla 5 tastiere tra quelle prodotte, come sar\`{a} distribuito il numero di quelle
\end{flushleft}


\begin{flushleft}
difettose tra le tastiere testate?
\end{flushleft}


\begin{flushleft}
Chiamiamo D la variabile aleatoria che conta il numero di tastiere difettose tra quelle testate
\end{flushleft}


\begin{flushleft}
in un dato giorno. Possiamo vedere la situazione in termini di un'urna contenente 400 palline (le
\end{flushleft}


\begin{flushleft}
tastiere prodotte), di cui 10 bianche (le tastiere difettose): estraiamo senza reimmissione 5 biglie
\end{flushleft}


\begin{flushleft}
(le tastiere da controllare) e ci chiediamo quante di queste siano bianche. Allora D $\sim$ hyp(5, 10,
\end{flushleft}


400 $-$ 10).





\begin{flushleft}
Massima verosimiglianza (divagazione) Nella realt\`{a}, per\`{o}, in una situazione come quella
\end{flushleft}


\begin{flushleft}
dell'Esempio 8.27 l'azienda non sa quante siano le tastiere difettose, ma sa quante sono quelle
\end{flushleft}


\begin{flushleft}
difettose tra quelle testate. L'uso della probabilit\`{a} per l'azienda sta nello stimare il valore più
\end{flushleft}


\begin{flushleft}
plausibile del numero di tastiere difettose prodotte, sapendo quante ne ha viste di difettose tra
\end{flushleft}


\begin{flushleft}
le testate. Cerchiamo di riscrivere in modo più esplicito questo problema. Cominciamo con gli
\end{flushleft}


\begin{flushleft}
ingredienti:
\end{flushleft}


\begin{flushleft}
$-$ M \`{e} il numero di tastiere difettose prodotte al giorno; \`{e} la quantit\`{a} (incognita) che vogliamo
\end{flushleft}


\begin{flushleft}
stimare.
\end{flushleft}


\begin{flushleft}
$-$ t \`{e} il numero di tastiere prodotte al giorno; \`{e} noto.
\end{flushleft}


\begin{flushleft}
$-$ N \`{e} il numero di tastiere non difettose prodotte al giorno; non \`{e} noto, ma sappiamo che N =
\end{flushleft}


\begin{flushleft}
t $-$ M.
\end{flushleft}


\begin{flushleft}
$-$ k \`{e} il numero (noto) di tastiere controllate ogni giorno.
\end{flushleft}





\begin{flushleft}
\newpage
8.6 IPERGEOMETRICHE
\end{flushleft}





115





\begin{flushleft}
$-$ b \`{e} il numero osservato di tastiere controllate e difettose.
\end{flushleft}


\begin{flushleft}
Inoltre, siccome sappiamo che il numero di tastiere difettose tra quelle testate (visto come variabile aleatoria, prima di osservare b) ha una distribuzione D $\sim$ hyp(k, M, t $-$ M), possiamo scrivere
\end{flushleft}


\begin{flushleft}
che
\end{flushleft}


\begin{flushleft}
P(D = b) =
\end{flushleft}





\begin{flushleft}
t$-$M
\end{flushleft}


\begin{flushleft}
k $-$b
\end{flushleft}


\begin{flushleft}
t
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
M
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





,





\begin{flushleft}
cio\`{e} dati i valori noti t e k, se sapessimo M avremmo la probabilit\`{a} di osservare proprio b tastiere
\end{flushleft}


\begin{flushleft}
difettose tra quelle controllate. Ma cambiamo il punto di vista: sapendo che abbiamo visto D = b,
\end{flushleft}


\begin{flushleft}
qual \`{e} il valore di M per cui era massima la probabilit\`{a} di vedere proprio b? Qual \`{e} a posteriori il
\end{flushleft}


\begin{flushleft}
valore più verosimile per M?
\end{flushleft}


\begin{flushleft}
Infatti, a ogni possibile valore m di M corrisponde una certa probabilit\`{a} di avere D = b, come
\end{flushleft}


\begin{flushleft}
abbiamo visto nella prima parte dell'esempio, cosa che possiamo scrivere in forma di probabilit\`{a}
\end{flushleft}


\begin{flushleft}
condizionata come
\end{flushleft}


\begin{flushleft}
P(D = b ∣ M = m) =
\end{flushleft}


\begin{flushleft}
ma grazie al teorema di Bayes
\end{flushleft}


\begin{flushleft}
P(M = m ∣ D = b) =
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
t$-$m
\end{flushleft}


\begin{flushleft}
k $-$b
\end{flushleft}


\begin{flushleft}
t
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





,





\begin{flushleft}
P(D = b ∣ M = m) P(M = m)
\end{flushleft}


,


\begin{flushleft}
P(D = b)
\end{flushleft}





(8.3)





\begin{flushleft}
che \`{e} la probabilit\`{a} che vogliamo massimizzare, variando m, per trovare il valore m più verosimile, più compatibile con l'osservazione fatta che D = b.
\end{flushleft}


\begin{flushleft}
Per massimizzare la (8.3) iniziamo con l'osservare che P(D = b) \`{e} costante al variare di m (\`{e}
\end{flushleft}


\begin{flushleft}
uguale per tutti i valori m di M), quindi non gioca alcun ruolo nella massimizzazione, ce ne possiamo dimenticare. Passiamo allora al termine P(M = m) che compare al numeratore. Questo
\end{flushleft}


\begin{flushleft}
contiene la nostra valutazione a priori della plausibilit\`{a} dei valori di M. In assenza di altre informazioni (per esempio il primo giorno in cui vengono fatti i test) possiamo ipotizzare che M sia
\end{flushleft}


\begin{flushleft}
equidistribuita tra i valori possibili, cio\`{e} l'insieme \{0, 1, . . . , t\}, ossia che per ogni m $\in$ \{0, 1, . . . , t\},
\end{flushleft}


1


\begin{flushleft}
P(M = m) = t + 1 .
\end{flushleft}


\begin{flushleft}
Il problema di massimizzare la (8.3) \`{e} diventato allora trovare il valore m $\in$ \{0, 1, . . . , t\} che
\end{flushleft}


\begin{flushleft}
massimizza l'ipergeometrica:
\end{flushleft}


\begin{flushleft}
m = argmax m$\in$\{0,1, . . . ,t\}
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
t$-$m
\end{flushleft}


\begin{flushleft}
k $-$b
\end{flushleft}


\begin{flushleft}
t
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
= argmax m
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
t$-$m
\end{flushleft}


.


\begin{flushleft}
k $-$b
\end{flushleft}





\begin{flushleft}
In questo modo otteniamo il candidato più verosimile come numero di tastiere difettose, avendone testate k, di cui b erano guaste.
\end{flushleft}


\begin{flushleft}
Proviamo con qualche numero: t = 400, k = 5, b = 2, ossia delle 5 testate, 2 sono difettose.
\end{flushleft}





\begin{flushleft}
m $<$- 0:400
\end{flushleft}


\begin{flushleft}
a $<$- choose(m,2)*choose(400-m,3)
\end{flushleft}


\begin{flushleft}
m[which.max(a)]
\end{flushleft}





\begin{flushleft}
8.6.1. Ipergeometriche in R
\end{flushleft}


\begin{flushleft}
Le funzioni per una variabile aleatoria ipergeometrica sono dhyper(x, m, n, k) per la
\end{flushleft}


\begin{flushleft}
densit\`{a} discreta, dove x \`{e} il punto in cui vogliamo calcolare la densit\`{a} 𝜑, m \`{e} il numero di biglie
\end{flushleft}


\begin{flushleft}
bianche nell'urna, n il numero di biglie nere nell'urna e k il numero di biglie estratte dall'urna (i
\end{flushleft}


\begin{flushleft}
nomi dei parametri coincidono con quelli dati sopra nella Definizione 8.25).
\end{flushleft}


\begin{flushleft}
La funzione di ripartizione per un'ipergeometrica \`{e} la funzione phyper(q, m, n, k,
\end{flushleft}


\begin{flushleft}
lower.tail = TRUE), il cui i parametri m, n e k sono esattamente come sopra, mentre q e
\end{flushleft}


\begin{flushleft}
lower.tail sono come nelle corrispondenti funzioni gi\`{a} viste per le altre variabili aleatorie: il
\end{flushleft}


\begin{flushleft}
primo \`{e} il punto in cui calcoliamo la funzione di ripartizione F, mentre il secondo \`{e} un parametro
\end{flushleft}


\begin{flushleft}
logico che determina se calcoliamo F X (q) (il default) o il suo complementare 1 $-$ FX (q).
\end{flushleft}





\newpage
116





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
In modo del tutto analogo alle altre distribuzioni viste finora, abbiamo altre due funzioni in
\end{flushleft}


\begin{flushleft}
R: rhyper e qhyper, rispettivamente la generatrice di valori casuali distribuiti come una binomiale negativa di parametri assegnati e la funzione quantile. Per rhyper dobbiamo solamente
\end{flushleft}


\begin{flushleft}
fare attenzione al fatto che il numero di realizzazioni (che per le altre variabili era n) \`{e} in questo
\end{flushleft}


\begin{flushleft}
caso nn: rhyper(nn, m, n, k).
\end{flushleft}


\begin{flushleft}
Esempio 8.28. Il Blackjack (o 21) \`{e} un gioco d'azzardo, molto diffuso negli Stati Uniti e reso
\end{flushleft}


\begin{flushleft}
famoso da un film (21, appunto). Nella sua versione base8.6a un solo giocatore contro il banco,
\end{flushleft}


\begin{flushleft}
si gioca con un normale mazzo da 52 carte, di cui 2 vengono date al giocatore. Le figure hanno
\end{flushleft}


\begin{flushleft}
un valore pari a 10, gli assi hanno un valore uguale a 1 o 11 e le altre carte hanno il loro valore
\end{flushleft}


\begin{flushleft}
nominale (un 7 vale 7). Il giocatore fa blackjack se le sue due carte sono una carta di valore uguale
\end{flushleft}


\begin{flushleft}
a 10 e un asso (per un totale di 21 punti). Qual \`{e} la probabilit\`{a} di fare blackjack?
\end{flushleft}


\begin{flushleft}
Cominciamo con il calcolare la probabilit\`{a} che le due carte del giocatore siano entrambe o assi
\end{flushleft}


\begin{flushleft}
o carte di valore 10. Usiamo una distribuzione ipergeometrica di parametri k = 2 (le carte date al
\end{flushleft}


\begin{flushleft}
giocatore), m = 20 (3 figure, un asso e un 10 per ciascuno dei quattro semi) e n = 32 (52 carte totali
\end{flushleft}


\begin{flushleft}
meno le 16 {``}buone''). Vogliamo 𝜑(2) $\approx$ 14\% (possiamo calcolarla come dhyper(x = 2, m =
\end{flushleft}


\begin{flushleft}
20, n = 32, k = 2) in R).
\end{flushleft}


\begin{flushleft}
Ora calcoliamo la probabilit\`{a} che entrambe le carte siano assi, usando un'ipergeometrica di
\end{flushleft}


\begin{flushleft}
parametri k =2, m =4, n= 48: 𝜑(2)$\approx$0.5\% (in R dhyper(x = 2, m = 4, n = 48, k = 2)).
\end{flushleft}


\begin{flushleft}
Ancora, calcoliamo la probabilit\`{a} che entrambe le carte abbiano valore 10, questa volta con
\end{flushleft}


\begin{flushleft}
un'ipergeometrica di parametri k = 2, m = 12, n = 40: 𝜑(2) $\approx$ 9\% (in R dhyper(x = 2, m =
\end{flushleft}


\begin{flushleft}
16, n = 36, k = 2)).
\end{flushleft}


\begin{flushleft}
A questo punto possiamo ricavare la probabilit\`{a} di fare blackjack sottraendo le ultime due
\end{flushleft}


\begin{flushleft}
probabilit\`{a} dalla prima: otteniamo all'incirca il 4.8\%.
\end{flushleft}


\begin{flushleft}
Esempio 8.29. Nella versione del poker nota come Texas hold'em, ogni giocatore ha una mano
\end{flushleft}


\begin{flushleft}
di 2 carte personali, da combinare con le carte comuni (fino a 5). Il mazzo \`{e} un normale mazzo
\end{flushleft}


\begin{flushleft}
a 52 carte, con 13 carte per ognuno dei 4 semi. Un giocatore ha in mano un 3 di cuori e un 7 di
\end{flushleft}


\begin{flushleft}
picche. Le prime due carte che escono sul tavolo sono il 3 di picche e la donna di picche. Con che
\end{flushleft}


\begin{flushleft}
probabilit\`{a} le prossime tre carte gli faranno avere colore o un poker?
\end{flushleft}


\begin{flushleft}
Cominciamo con il colore (ossia avere 5 carte dello stesso seme, non necessariamente ordinate,
\end{flushleft}


\begin{flushleft}
nel qual caso sarebbe scala colore). La probabilit\`{a} che lo ottenga \`{e} pari alla probabilit\`{a} che due
\end{flushleft}


\begin{flushleft}
delle prossime tre carte estratte dal mazzo siano di picche, di cui nel mazzo ne restano 13 $-$ 3 = 10:
\end{flushleft}


\begin{flushleft}
abbiamo quindi un'ipergeometrica di parametri k = 3, m = 10 e n = 38 (perch\'{e} nel mazzo restano
\end{flushleft}


\begin{flushleft}
48 carte e di queste 10 sono quelle che vanno bene), di cui vogliamo calcolare la densit\`{a} discreta
\end{flushleft}


\begin{flushleft}
in b = 2 e b = 3. Aiutandoci con R (phyper(q = 1, m = 10, n = 38, k = 3,
\end{flushleft}


\begin{flushleft}
lower.tail = FALSE)) otteniamo 10.6\%. A questa dobbiamo per\`{o} sottrarre la probabilit\`{a}
\end{flushleft}


\begin{flushleft}
di ottenere una scala colore, che possiamo avere con le carte di picche da 3 a 7 (ossia estraendo 4,
\end{flushleft}


\begin{flushleft}
5 e 6 di picche). Questa probabilit\`{a} \`{e} minore di 10$-$4 (dhyper(x = 3, m = 3, n = 45,
\end{flushleft}


\begin{flushleft}
k = 3)) e la differenza \`{e} allora circa 10.6\%.
\end{flushleft}


\begin{flushleft}
Passiamo ora al poker: l'unica coppia che ha gi\`{a} in mano \`{e} quella di 3, per completarla dovrebbero uscire i due 3 rimanenti. Di nuovo abbiamo un'ipergeometrica di parametri k = 3, m = 2 e
\end{flushleft}


\begin{flushleft}
n = 46, di cui calcoliamo la densit\`{a} discreta in b = 2. La probabilit\`{a} \`{e} 0.27\%. In alternativa, pu\`{o}
\end{flushleft}


\begin{flushleft}
ottenere un poker anche pescando le 3 carte rimanenti di un segno tra 7 e donna. Per ciascuno
\end{flushleft}


\begin{flushleft}
di questi casi abbiamo una ipergeometrica di parametri k = 3, m = 3 e n = 45, di cui calcoliamo la
\end{flushleft}


\begin{flushleft}
densit\`{a} discreta in b = 3, ottenendo complessivamente (cio\`{e} sommando le due probabilit\`{a}) 0.01\%.
\end{flushleft}


\begin{flushleft}
Non \`{e} possibile che abbiamo contemporaneamente due poker o un poker e colore, quindi
\end{flushleft}


\begin{flushleft}
possiamo sommare le probabilit\`{a} dei vari eventi, mutualmente esclusivi. Complessivamente,
\end{flushleft}


\begin{flushleft}
dunque, la probabilit\`{a} cercata \`{e} 10.9\%.
\end{flushleft}


\begin{flushleft}
8.6. Quella giocata nei casin\`{o} \`{e} leggermente diversa, con le modifiche che la rendono interessante per la storia (basata
\end{flushleft}


\begin{flushleft}
su fatti realmente accaduti) narrata nel film.
\end{flushleft}





\begin{flushleft}
\newpage
8.6 IPERGEOMETRICHE
\end{flushleft}





117





\begin{flushleft}
Osservazione 8.30. Avendo parlato di riproducibilit\`{a} per altre famiglie di variabili aleatorie, \`{e}
\end{flushleft}


\begin{flushleft}
abbastanza naturale chiedersi se anche la famiglia delle ipergeometriche sia riproducibile. Un
\end{flushleft}


\begin{flushleft}
dubbio sulla possibilit\`{a} che questo sia vero pu\`{o} venirci dal fatto che, a differenza dei due casi di
\end{flushleft}


\begin{flushleft}
variabili riproducibili visti finora, qui non abbiamo un parametro da tenere fisso. In realt\`{a} questa
\end{flushleft}


\begin{flushleft}
non \`{e} in s\'{e} una condizione necessaria, come vedremo.
\end{flushleft}


\begin{flushleft}
Pensiamo a uno dei casi più semplici di variabile aleatoria ipergeometrica, X $\sim$ hyp(1, m, n),
\end{flushleft}


\begin{flushleft}
ossia estraiamo, da un'urna con m biglie bianche e n biglie nere una sola biglia. Prendiamo ora Y $\sim$
\end{flushleft}


\begin{flushleft}
X, ma indipendente e consideriamo la somma X + Y. Se estraiamo una sola biglia, la differenza
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
tra estrazione con e senza reimmissione si perde, e come abbiamo gi\`{a} osservato X $\sim$ bin 1, m + n .
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
Allora dalla riproducibilit\`{a} delle binomiali, sappiamo che X + Y $\sim$ bin 2, m + n , che per\`{o} non \`{e}
\end{flushleft}


\begin{flushleft}
un'ipergeometrica. Infatti, nel momento in cui andiamo a estrarre due biglie, la differenza tra
\end{flushleft}


\begin{flushleft}
estrazione con o senza reimmissione diventa significativa: nel primo caso le estrazioni sono tra
\end{flushleft}


\begin{flushleft}
loro indipendenti (e abbiamo la binomiale), nel secondo non lo sono, hanno influenza le une
\end{flushleft}


\begin{flushleft}
sulle altre (e abbiamo l'ipergeometrica). In particolare la famiglia di variabili aleatorie ipergeometriche non \`{e} riproducibile. Un altro modo di convincersene \`{e} provare a semplificare i coefficienti
\end{flushleft}


\begin{flushleft}
binomiali che si ottengono scrivendo la densit\`{a} discreta della somma di due ipergeometriche
\end{flushleft}


\begin{flushleft}
indipendenti.
\end{flushleft}


\begin{flushleft}
Lezione 15
\end{flushleft}





\begin{flushleft}
Vediamo ora un legame tra le variabili aleatorie con distribuzione ipergeometrica e quelle con
\end{flushleft}


\begin{flushleft}
distribuzione binomiale.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 8.31. Siano \{a i\}i e \{b i\}i due successioni di numeri interi non negativi che tendono monotoai
\end{flushleft}


\begin{flushleft}
namente a +$\infty$ e tali che lim i$\rightarrow$+$\infty$ a + b = 𝛼, per qualche 𝛼 $\in$ [0, 1]. Allora
\end{flushleft}


\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
ai
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
bi
\end{flushleft}


\begin{flushleft}
n$-$k
\end{flushleft}


\begin{flushleft}
ai + bi
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
i$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
𝛼 (1 $-$ 𝛼)n$-$k .
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
Dimostrazione. Procediamo per passi.
\end{flushleft}


\begin{flushleft}
i. Osserviamo che
\end{flushleft}





\begin{flushleft}
bi
\end{flushleft}


\begin{flushleft}
ai + bi
\end{flushleft}





\begin{flushleft}
ii. Per ogni c, d costanti,
\end{flushleft}





\begin{flushleft}
ai
\end{flushleft}





\begin{flushleft}
= 1 $-$ a +b $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ 1 $-$ 𝛼.
\end{flushleft}


\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
ai $-$ c
\end{flushleft}


\begin{flushleft}
ai + bi $-$ d
\end{flushleft}





\begin{flushleft}
i$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
c
\end{flushleft}





\begin{flushleft}
ai
\end{flushleft}





\begin{flushleft}
= a +b ⋅
\end{flushleft}


\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
1$-$ a
\end{flushleft}


1$-$





\begin{flushleft}
i
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
a i + bi
\end{flushleft}





$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ 𝛼.
\end{flushleft}


\begin{flushleft}
i$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
iii. Combinando i primi due punti, per ogni c, d costanti,
\end{flushleft}


\begin{flushleft}
iv. A questo punto abbiamo tutto quello che ci occorre:
\end{flushleft}


\begin{flushleft}
ai
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
bi
\end{flushleft}


\begin{flushleft}
n$-$k
\end{flushleft}


\begin{flushleft}
a i + bi
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





=


=


=


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
i$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
bi $-$ c
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ 1 $-$ 𝛼.
\end{flushleft}


\begin{flushleft}
a i + b i $-$ d i$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
(ai)! (bi)! (ai + bi $-$ n)! n!
\end{flushleft}


\begin{flushleft}
k! (ai $-$ k)! (n $-$ k)! (b i $-$ n + k)! (a i + bi)
\end{flushleft}


\begin{flushleft}
(ai)!
\end{flushleft}


\begin{flushleft}
(b i)!
\end{flushleft}


\begin{flushleft}
(a i + bi $-$ n)!
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k (ai $-$ k)! (b i $-$ n + k)! (a i + bi)!
\end{flushleft}


\begin{flushleft}
a i (ai $-$ 1) ⋅ ⋅ ⋅ (a i $-$ (k $-$ 1))
\end{flushleft}


\begin{flushleft}
b i ⋅ ⋅ ⋅ (bi $-$ (n $-$ k $-$ 1))
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k (ai + b i) (a i + bi $-$ 1) ⋅ ⋅ ⋅ (ai + b i $-$ k + 1) (ai + b i $-$ k) ⋅ ⋅ ⋅ (ai + b i $-$ n + 1)
\end{flushleft}


\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
𝛼 (1 $-$ 𝛼)n$-$k
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
perch\'{e} nella penultima riga abbiamo k termini della forma
\end{flushleft}


\begin{flushleft}
bi $-$ c
\end{flushleft}


.


\begin{flushleft}
a +b $-$d
\end{flushleft}


\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
ai $-$ c
\end{flushleft}


\begin{flushleft}
ai + bi $-$ d
\end{flushleft}





\begin{flushleft}
ed n $-$ k termini della forma
\end{flushleft}


□





\begin{flushleft}
Osservazione 8.32. In termini di variabili aleatorie stiamo dicendo che se una popolazione a i + b i
\end{flushleft}


\begin{flushleft}
cresce all'infinito, convergendo per\`{o} a una proporzione determinata di {``}a'' e {``}b'' (rispettivamente
\end{flushleft}


\begin{flushleft}
𝛼 e 1 $-$ 𝛼), allora se abbiamo una successioni di variabili aleatorie ipergeometriche
\end{flushleft}


\begin{flushleft}
X i $\sim$ hyp(n, a i, b i)
\end{flushleft}





\newpage
118





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
e una variabile aleatoria X $\sim$ bin(n, 𝛼), allora la successione delle densit\`{a} discrete 𝜑Xi converge
\end{flushleft}


\begin{flushleft}
alla densit\`{a} discreta 𝜑X , ossia in un qualche senso8.7 le variabili ipergeometriche tendono a una
\end{flushleft}


\begin{flushleft}
binomiale o, meglio, le leggi delle ipergeometriche tendono alla legge binomiale.
\end{flushleft}





\begin{flushleft}
8.7. POISSON
\end{flushleft}


\begin{flushleft}
Abbiamo rotto il ghiaccio con le sequenze di variabili aleatorie. Vediamone ora altre che entrano
\end{flushleft}


\begin{flushleft}
in gioco nel seguente problema.
\end{flushleft}


\begin{flushleft}
Esempio 8.33. In una partita di Premier League vengono segnati in media8.8 2.5 gol a partita8.9.
\end{flushleft}


\begin{flushleft}
Vorremmo sapere quale pu\`{o} essere una distribuzione di probabilit\`{a} del numero di gol in una
\end{flushleft}


\begin{flushleft}
partita.
\end{flushleft}


\begin{flushleft}
Possiamo pensare, in prima approssimazione, di descrivere questo fenomeno nel modo
\end{flushleft}


\begin{flushleft}
seguente: dividiamo la partita (da 90') in 5 periodi da 18', in ciascuno dei quali abbiamo una
\end{flushleft}


1


\begin{flushleft}
probabilit\`{a} 2 di vedere un gol. Volendo una variabile aleatoria che conta i gol, ci riconduciamo
\end{flushleft}


\begin{flushleft}
a un modello che gi\`{a} conosciamo: il segnare un gol \`{e} per ogni periodo da 18' una Bernoulliana
\end{flushleft}


1


\begin{flushleft}
di parametro 2 e il numero di gol in una partita \`{e} quindi una binomiale di parametri n = 5 e
\end{flushleft}


1


1


\begin{flushleft}
p = 2 . Chiamiamo allora questa variabile aleatoria che conta i gol X1 $\sim$ bin 5, 2 . Osserviamo
\end{flushleft}


\begin{flushleft}
che, anche se non abbiamo ancora definito cosa sia la media di una Bernoulliana o di una bino1
\end{flushleft}


\begin{flushleft}
miale, da un punto di vista intuitivo, ogni 18' ci aspettiamo di vedere 2 gol, per un totale di 2.5
\end{flushleft}


\begin{flushleft}
gol in una partita.
\end{flushleft}


\begin{flushleft}
Questa descrizione del fenomeno, per\`{o}, non ci piace troppo: dalle propriet\`{a} delle binomiali,
\end{flushleft}


\begin{flushleft}
sappiamo che il supporto di X 1 \`{e} l'insieme \{0,..., 5\}, cio\`{e} non \`{e} possibile che ci siano più di 5 gol a
\end{flushleft}


\begin{flushleft}
partita, cosa che non accade troppo spesso, ma che non possiamo escludere del tutto. Più grave,
\end{flushleft}


\begin{flushleft}
da un punto di vista modellistico, \`{e} che non \`{e} possibile avere più di un gol in ogni periodo da 18'.
\end{flushleft}


\begin{flushleft}
Possiamo allora pensare di passare ad una griglia più fine: 10 periodi da 9' ciascuno, in cui
\end{flushleft}


1


1


\begin{flushleft}
per\`{o} la probabilit\`{a} di vedere un gol si \`{e} anch'essa dimezzata, passando da 2 a 4 . Abbiamo quindi
\end{flushleft}


1


\begin{flushleft}
una seconda variabile aleatoria candidata a contare il numero di gol: X 2 $\sim$bin 10, 4 . \`{E} un miglioramento rispetto a prima, ora possiamo vedere fino a 10 gol in una partita e fino a 1 gol in ogni
\end{flushleft}


\begin{flushleft}
periodo da 9', ma possiamo continuare a raffinare la nostra griglia:
\end{flushleft}


1


8


1


\begin{flushleft}
X4 $\sim$ bin 40,
\end{flushleft}


16


\begin{flushleft}
X3 $\sim$ bin 20,
\end{flushleft}





\begin{flushleft}
E in realt\`{a} nessuno ci obbliga a dimezzare la durata degli intervallini ogni volta, quello che
\end{flushleft}


\begin{flushleft}
importa \`{e} mantenere costante il prodotto n ⋅ p = 2.5 (come vedremo, n ⋅ p \`{e} proprio la media o
\end{flushleft}


\begin{flushleft}
valore atteso di una variabile aleatoria binomiale di parametri n e p). Quindi continuiamo con
\end{flushleft}


\begin{flushleft}
X 5 $\sim$ bin 45,
\end{flushleft}





1


,


18





\begin{flushleft}
in cui abbiamo 45 Bernoulliane che descrivono periodi di gioco da 2 minuti ciascuna, e ancora
\end{flushleft}


1


36


1


\begin{flushleft}
X7 $\sim$ bin 180,
\end{flushleft}


72


\begin{flushleft}
X6 $\sim$ bin 90,
\end{flushleft}





\begin{flushleft}
in cui stiamo considerando finestre da 1 minuto o da 30'' ciascuna.
\end{flushleft}


\begin{flushleft}
8.7. Vedremo meglio più avanti i concetti di convergenza per variabili aleatorie.
\end{flushleft}


\begin{flushleft}
8.8. Non abbiamo ancora definito il concetto di media per una variabile aleatoria, anche se non manca molto, lo
\end{flushleft}


\begin{flushleft}
incontreremo nel Capitolo 9. Tuttavia in questo caso stiamo parlando della media empirica, ossia il numero totale di gol
\end{flushleft}


\begin{flushleft}
segnati in Premier League diviso per il numero delle partite.
\end{flushleft}


\begin{flushleft}
8.9. Dati del 14.04.2021.
\end{flushleft}





\begin{flushleft}
\newpage
8.7 POISSON
\end{flushleft}





119





\begin{flushleft}
Cosa succede se continuiamo a sviluppare una successione di questo tipo? Converge a qualcosa? E se sì, a cosa converge?
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 8.34. Diciamo che una variabile aleatoria discreta X \`{e} di Poisson8.10 (o Poissoniana) di
\end{flushleft}


\begin{flushleft}
parametro 𝜆, con 𝜆 numero reale positivo, se ha densit\`{a} discreta
\end{flushleft}


\begin{flushleft}
𝜑 X (k) =
\end{flushleft}





\begin{flushleft}
\{\{ e
\end{flushleft}


\{0


\begin{flushleft}
𝜆k
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





\begin{flushleft}
$-$𝜆
\end{flushleft}





\begin{flushleft}
k$\in$ℕ
\end{flushleft}


\begin{flushleft}
altrimenti.
\end{flushleft}





(8.4)





\begin{flushleft}
In questo caso scriviamo X $\sim$ Pois(𝜆).
\end{flushleft}


\begin{flushleft}
Osservazione 8.35. La funzione 𝜑 X definita in (8.4) soddisfa le propriet\`{a} di una densit\`{a} discreta
\end{flushleft}


\begin{flushleft}
di probabilit\`{a}, in particolare \`{e} non negativa e ha somma uguale a 1 sul proprio supporto. Per
\end{flushleft}


\begin{flushleft}
convincerci di questa seconda propriet\`{a}, osserviamo che
\end{flushleft}


\begin{flushleft}
x2 x3
\end{flushleft}


\begin{flushleft}
e =1+x+ + + ⋅⋅⋅ =
\end{flushleft}


2 3!


\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
quindi abbiamo
\end{flushleft}





\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
𝜑X (k) =
\end{flushleft}


\begin{flushleft}
k $\in$ℕ
\end{flushleft}





\begin{flushleft}
k $\in$ℛ X
\end{flushleft}





\begin{flushleft}
(( 𝜆k! e )) = e
\end{flushleft}


\begin{flushleft}
$-$𝜆
\end{flushleft}





\begin{flushleft}
$-$𝜆
\end{flushleft}





+$\infty$


\begin{flushleft}
k =0
\end{flushleft}





+$\infty$


\begin{flushleft}
k=0
\end{flushleft}





\begin{flushleft}
xk
\end{flushleft}


,


\begin{flushleft}
k!
\end{flushleft}





\begin{flushleft}
𝜆k
\end{flushleft}


\begin{flushleft}
= e $-$𝜆 e 𝜆 = 1.
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





\begin{flushleft}
Osservazione 8.36. Come abbiamo gi\`{a} visto, una variabile aleatoria binomiale conta il numero
\end{flushleft}


\begin{flushleft}
di successi in n prove indipendenti, tutte con uguale probabilit\`{a} p di successo. Tuttavia n o p
\end{flushleft}


\begin{flushleft}
possono non essere noti con precisione, oppure possono essere, rispettivamente, molto grande e
\end{flushleft}


\begin{flushleft}
molto piccolo. In questa situazione pu\`{o} venirci in aiuto la variabile aleatoria di Poisson, per cui
\end{flushleft}


\begin{flushleft}
abbiamo solamente bisogno di conoscere un parametro 𝜆 che gioca il ruolo di n⋅ p (e che intuitivamente \`{e} il numero di successi che ci aspettiamo in media, come poi confermeremo rigorosamente
\end{flushleft}


\begin{flushleft}
più avanti, nel Capitolo 9).
\end{flushleft}


\begin{flushleft}
Alcuni esempi tipici in cui possiamo usare una variabile aleatoria di Poisson per descrivere (o
\end{flushleft}


\begin{flushleft}
modellizzare) il fenomeno sono:
\end{flushleft}


\begin{flushleft}
$-$ il numero di email ricevute da un utente nel corso di una giornata (a priori non possiamo dare
\end{flushleft}


\begin{flushleft}
un limite superiore al numero di email che potrebbe ricevere);
\end{flushleft}


\begin{flushleft}
$-$ il numero di morti sul lavoro in Italia in un dato giorno (abbiamo molta incertezza sul numero
\end{flushleft}


\begin{flushleft}
n dei lavoratori attivi quel giorno, pur avendo un'idea del suo ordine di grandezza, così come
\end{flushleft}


\begin{flushleft}
sul valore più plausibile di p, ma abbiamo delle statistiche storiche che ci dicono che il numero
\end{flushleft}


\begin{flushleft}
medio di morti sul lavoro al giorno \`{e} stato 3.5 nel 20208.11);
\end{flushleft}


\begin{flushleft}
$-$ il numero di domande di iscrizione a Informatica a Trento, anno dopo anno (in media non
\end{flushleft}


\begin{flushleft}
cambieranno troppo, ma non sappiamo quantificare con certezza il numero n di coloro che
\end{flushleft}


\begin{flushleft}
considerano Informatica come indirizzo di studi e, per ciascuno di essi, quale sia la probabilit\`{a}
\end{flushleft}


\begin{flushleft}
p che alla fine si iscrivano).
\end{flushleft}


\begin{flushleft}
Possiamo ora riprendere l'Esempio 8.33 e rendere matematicamente solido quanto detto prima
\end{flushleft}


\begin{flushleft}
sul comportamento limite della successione di binomiali.
\end{flushleft}





\begin{flushleft}
PROPOSIZIONE 8.37. Sia \{pn\}n una successione di numeri in [0, 1] tali che lim n$\rightarrow$+$\infty$ pn ⋅ n = 𝜆, per qualche
\end{flushleft}


\begin{flushleft}
numero reale positivo 𝜆. Allora, per ogni k naturale
\end{flushleft}


\begin{flushleft}
lim
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
𝜆k
\end{flushleft}


\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
pn (1 $-$ pn)n$-$k = e $-$𝜆.
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





\begin{flushleft}
8.10. Sim\'{e}on Denis Poisson (1781 -- 1840).
\end{flushleft}


\begin{flushleft}
8.11. Dati INAIL sul numero di denunce di infortuni con esito mortale. Non \`{e} detto che diano una rappresentazione
\end{flushleft}


\begin{flushleft}
completa del fenomeno, a causa degli infortuni (anche mortali) non denunciati.
\end{flushleft}





\newpage
120





\begin{flushleft}
MODELLI DI VARIABILI ALEATORIE DISCRETE
\end{flushleft}





\begin{flushleft}
Dimostrazione. Cominciamo con lo scrivere esplicitamente il primo membro:
\end{flushleft}


\begin{flushleft}
n (n $-$ 1) ⋅ ⋅ ⋅ (n $-$ k + 1) k k
\end{flushleft}


\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
pn (1 $-$ p n)n$-$k = lim
\end{flushleft}


\begin{flushleft}
n pn (1 $-$ pn)n$-$k
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
k! n k
\end{flushleft}


1


\begin{flushleft}
n n$-$1
\end{flushleft}


\begin{flushleft}
n$-$k +1
\end{flushleft}


\begin{flushleft}
n ⋅ p n n$-$k
\end{flushleft}


=


\begin{flushleft}
lim
\end{flushleft}


⋅


⋅⋅⋅


\begin{flushleft}
(n ⋅ pn)k 1 $-$
\end{flushleft}


\begin{flushleft}
k! n$\rightarrow$+$\infty$ n n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
1 k
\end{flushleft}


\begin{flushleft}
𝜆 n$-$k
\end{flushleft}


=


\begin{flushleft}
𝜆 lim 1 $-$
\end{flushleft}


\begin{flushleft}
k! n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
𝜆k $-$𝜆
\end{flushleft}


\begin{flushleft}
𝜆 $-$k
\end{flushleft}


=


\begin{flushleft}
e lim 1 $-$
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
𝜆 $-$𝜆
\end{flushleft}


=


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}


\begin{flushleft}
in cui nella prima riga abbiamo moltiplicato e diviso per n k , nella seconda riga, i termini in arancione convergono a 1 al limite e i termini in verde convergono a 𝜆 e nel passare dalla terza alla
\end{flushleft}


\begin{flushleft}
quarta riga abbiamo usato una caratterizzazione della funzione esponenziale.
\end{flushleft}


□


\begin{flushleft}
lim
\end{flushleft}





[[





]]





\begin{flushleft}
Osservazione 8.38. In termini di variabili aleatorie stiamo dicendo che se abbiamo una successione di variabili aleatorie binomiali
\end{flushleft}


\begin{flushleft}
X n $\sim$ bin(n, p n)
\end{flushleft}


\begin{flushleft}
e una variabile aleatoria X $\sim$ Pois(𝜆), con 𝜆 = lim n$\rightarrow$+$\infty$ n ⋅ pn, allora la successione delle densit\`{a}
\end{flushleft}


\begin{flushleft}
discrete 𝜑 Xn converge alla densit\`{a} discreta 𝜑X , ossia la variabile aleatoria di Poisson \`{e} il {``}limite''
\end{flushleft}


\begin{flushleft}
delle variabili aleatorie binomiali.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 8.39. Le variabili aleatorie Poissoniane sono riproducibili.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Vogliamo mostrare che, date due variabili aleatorie indipendenti X1 $\sim$ Pois(𝜆 1) e
\end{flushleft}


\begin{flushleft}
X 2 $\sim$ Pois(𝜆2), anche la loro somma ha legge Poissoniana. Consideriamone la densit\`{a} discreta:
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜑 X1+X2(n) =
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





=


\begin{flushleft}
k =0
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





=





[[[





\begin{flushleft}
𝜑X1(k) 𝜑X2(n $-$ k)
\end{flushleft}


\begin{flushleft}
n! 𝜆k1 $-$𝜆1 𝜆n$-$k
\end{flushleft}


2


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e $-$𝜆2
\end{flushleft}


\begin{flushleft}
n! k!
\end{flushleft}


\begin{flushleft}
(n $-$ k)!
\end{flushleft}





\begin{flushleft}
k=0
\end{flushleft}





\begin{flushleft}
n k n$-$k e $-$(𝜆1+𝜆2)
\end{flushleft}


\begin{flushleft}
𝜆 𝜆
\end{flushleft}


\begin{flushleft}
k 1 2
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}





]]]





\begin{flushleft}
(𝜆 1 + 𝜆2)n $-$(𝜆1+𝜆2)
\end{flushleft}


=


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}


\begin{flushleft}
in cui abbiamo messo in evidenza il binomio di Newton nel passare dalla penultima all'ultima
\end{flushleft}


\begin{flushleft}
riga. Osserviamo che in questo modo abbiamo mostrato che X1 + X 2 $\sim$ Pois(𝜆1 + 𝜆 2).
\end{flushleft}


□


\begin{flushleft}
Esempio 8.40. Siano X 1 $\sim$ Pois(𝜆1) e X 2 $\sim$ Pois(𝜆 2) due variabili aleatorie indipendenti e sia S la
\end{flushleft}


\begin{flushleft}
loro somma. Vogliamo determinare la legge di X1 condizionata a S.
\end{flushleft}


\begin{flushleft}
Partiamo dalla definizione di densit\`{a} discreta condizionata:
\end{flushleft}


\begin{flushleft}
𝜑X1∣S(k ∣ n) = P(X1 = k ∣ S = n)
\end{flushleft}


\begin{flushleft}
P(X 1 = k, S = n)
\end{flushleft}


=


\begin{flushleft}
P(S = n)
\end{flushleft}


\begin{flushleft}
P(X 1 = k, X 2 = n $-$ k)
\end{flushleft}


=


\begin{flushleft}
P(S = n)
\end{flushleft}


\begin{flushleft}
P(X 1 = k) P(X 2 = n $-$ k)
\end{flushleft}


=


\begin{flushleft}
P(S = n)
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
𝜆 1 $-$𝜆1 𝜆n$-$k
\end{flushleft}


\begin{flushleft}
n!
\end{flushleft}


2


=


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e $-$𝜆2
\end{flushleft}


\begin{flushleft}
e 𝜆1+𝜆2
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}


\begin{flushleft}
(n $-$ k)!
\end{flushleft}


\begin{flushleft}
(𝜆1 + 𝜆 2)n
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
n$-$k
\end{flushleft}


\begin{flushleft}
𝜆1
\end{flushleft}


\begin{flushleft}
𝜆2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


=


.


\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
𝜆 1 + 𝜆2
\end{flushleft}


\begin{flushleft}
𝜆 1 + 𝜆2
\end{flushleft}





(





)(





)





\begin{flushleft}
\newpage
8.7 POISSON
\end{flushleft}





\begin{flushleft}
Quindi 𝜑 X1∣S(⋅ ∣ n) $\sim$ bin n, 𝜆
\end{flushleft}





121





\begin{flushleft}
𝜆1
\end{flushleft}


\begin{flushleft}
1 + 𝜆2
\end{flushleft}





.





\begin{flushleft}
8.7.1. Poissoniane in R
\end{flushleft}


\begin{flushleft}
Per una variabile aleatoria di Poisson, le funzioni in R sono:
\end{flushleft}


\begin{flushleft}
$-$ la densit\`{a} discreta dpois(x, lambda), con x il punto in cui vogliamo calcolare la densit\`{a}
\end{flushleft}


\begin{flushleft}
discreta 𝜑 e lambda il parametro della Poisson;
\end{flushleft}


\begin{flushleft}
$-$ la funzione di ripartizione ppois(q, lambda, lower.tail = TRUE), in cui lambda \`{e} lo stesso della funzione di densit\`{a} discreta, mentre q e lower.tail sono come nelle
\end{flushleft}


\begin{flushleft}
corrispondenti funzioni gi\`{a} viste per le altre variabili aleatorie;
\end{flushleft}


\begin{flushleft}
$-$ il generatore casuale a distribuzione Poissoniana \`{e} rpois(n, lambda), con n il numero
\end{flushleft}


\begin{flushleft}
di realizzazioni da generare;
\end{flushleft}


\begin{flushleft}
$-$ la funzione quantile \`{e} qpois(p, lambda, lower.tail = TRUE), ma la vedremo
\end{flushleft}


\begin{flushleft}
meglio più avanti.
\end{flushleft}


\begin{flushleft}
Se torniamo all'Esempio 8.33, possiamo generare il numero di gol nelle 10 partite di una giornata
\end{flushleft}


\begin{flushleft}
con il comando rpois(n = 10, lambda = 2.5), ottenendo (ad esempio) la seguente
\end{flushleft}


\begin{flushleft}
realizzazione 3 2 3 3 2 2 5 2 3 4, oppure 4 3 4 2 1 1 1 1 2 1.
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
CAPITOLO 9
\end{flushleft}


\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}


\begin{flushleft}
Spesso la legge di una variabile aleatoria X non \`{e} nota. Un modo di avere qualche informazione
\end{flushleft}


\begin{flushleft}
su X \`{e} considerarne alcuni indicatori, quantit\`{a} deterministiche che riassumono alcune delle caratteristiche della distribuzione di una variabile aleatoria. Il primo indicatore che consideriamo \`{e} la
\end{flushleft}


\begin{flushleft}
media, ossia un valore deterministico (cio\`{e} un numero) che ci d\`{a} in un certo senso9.1 il centro della
\end{flushleft}


\begin{flushleft}
distribuzione. Conoscere la media \`{e} per\`{o} avere molta meno informazione rispetto al conoscere la
\end{flushleft}


\begin{flushleft}
legge: quest'ultima \`{e} una funzione, mentre la media \`{e} un numero.
\end{flushleft}





\begin{flushleft}
9.1. VARIABILI ALEATORIE DISCRETE
\end{flushleft}


\begin{flushleft}
Cominciamo col vedere la definizione di valore atteso per le variabili aleatorie discrete.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.1. Chiamiamo valore atteso, speranza matematica o media di una variabile discreta X
\end{flushleft}


\begin{flushleft}
il baricentro della sua distribuzione, ossia
\end{flushleft}


\begin{flushleft}
𝔼[X] = E[X] =
\end{flushleft}





\begin{flushleft}
k 𝜑 X (k).
\end{flushleft}


\begin{flushleft}
k $\in$ℛ X
\end{flushleft}





\begin{flushleft}
Possiamo notare che la speranza \`{e} una media pesata dei possibili valori k assunti da X, i cui
\end{flushleft}


\begin{flushleft}
pesi sono le corrispondenti probabilit\`{a} 𝜑 X (k) = P(X = k).
\end{flushleft}


\begin{flushleft}
Osservazione 9.2. Non \`{e} detto che la speranza di una variabile aleatoria sia finita (Esempio 9.3),
\end{flushleft}


\begin{flushleft}
che sia positiva o che sia definita (la serie che la definisce potrebbe non convergere9.2). In generale,
\end{flushleft}


\begin{flushleft}
nel seguito, considereremo solamente variabili aleatorie X la cui speranza \`{e} definita e finita, salvo
\end{flushleft}


\begin{flushleft}
diversamente specificato.
\end{flushleft}


\begin{flushleft}
Esempio 9.3. (Paradosso di San Pietroburgo) A Nicholas viene proposto il seguente gioco: lancia
\end{flushleft}


\begin{flushleft}
una moneta equilibrata e, se la prima Testa esce al lancio n, vince 2n monete. Quante monete
\end{flushleft}


\begin{flushleft}
vincer\`{a} in media?
\end{flushleft}


\begin{flushleft}
Usiamo la definizione appena data, chiamando X la variabile aleatoria che rappresenta la vincita. Ci occorre solamente 𝜑X (2 n) = P(T1 = n), dove T1 \`{e} l'istante di prima uscita di una testa nel
\end{flushleft}


\begin{flushleft}
corrispondente schema di Bernoulli. Dobbiamo allora ricordare quale sia la probabilit\`{a} che la
\end{flushleft}


1


1


1


\begin{flushleft}
prima testa esca al lancio n-simo, cio\`{e} 2 n$-$1 2 = 2 n . Allora
\end{flushleft}


\begin{flushleft}
E[X] =
\end{flushleft}





\begin{flushleft}
2n ⋅
\end{flushleft}





\begin{flushleft}
x 𝜑X (x) =
\end{flushleft}


\begin{flushleft}
n$\in$ℕ∖\{0\}
\end{flushleft}





\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





1


=


\begin{flushleft}
2n
\end{flushleft}





1 = +$\infty$.


\begin{flushleft}
n$\in$ℕ∖\{0\}
\end{flushleft}





\begin{flushleft}
Vale la pena notare che pur avendo speranza infinita, X \`{e} una variabile aleatoria finita con probabilit\`{a} 1, infatti
\end{flushleft}


\begin{flushleft}
P(X = +$\infty$) = lim 2 $-$n = 0,
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
perch\'{e} chiedere che sia infinita significa che tutti i lanci devono essere Croce.
\end{flushleft}


\begin{flushleft}
9.1. Vedremo più avanti che non \`{e} il solo.
\end{flushleft}


\begin{flushleft}
9.2. Consideriamo separatamente i casi in cui la serie diverge a $\pm$$\infty$ rispetto a quelli in cui non c'\`{e} proprio convergenza, ossia non esiste limite, n\'{e} finito n\'{e} infinito.
\end{flushleft}





123





\newpage
124





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
La Definizione 9.1 richiede di pesare ogni possibile risultato con la sua probabilit\`{a}. Un'immediata generalizzazione, allora, \`{e} quella in cui consideriamo la probabilit\`{a} condizionata a un
\end{flushleft}


\begin{flushleft}
evento H,
\end{flushleft}


\begin{flushleft}
E[X ∣ H] =
\end{flushleft}





\begin{flushleft}
x ⋅ P(X = x ∣ H)
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
detta speranza di X condizionata ad H, ma anche a eventi speciali, quale ad esempio il valore assunto
\end{flushleft}


\begin{flushleft}
da un'altra variabile aleatoria,
\end{flushleft}


\begin{flushleft}
E[X ∣ Y = y] =
\end{flushleft}





\begin{flushleft}
x ⋅ P(X = x ∣ Y = y) =
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
x ⋅ 𝜑 X∣Y(x ∣ y),
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
la speranza di X condizionata al fatto che Y assuma il valore y. Si pu\`{o} andare ancora oltre e considerare
\end{flushleft}


\begin{flushleft}
la speranza di una variabile aleatoria condizionata a un'altra variabile aleatoria (e non al suo
\end{flushleft}


\begin{flushleft}
valore) o a una tribù. Si parla in questo caso di speranza condizionata, ma non la tratteremo in
\end{flushleft}


\begin{flushleft}
questo corso.
\end{flushleft}


\begin{flushleft}
Esempio 9.4. Sia X $\sim$ bin(1, p), calcoliamone la speranza. Dalla definizione abbiamo
\end{flushleft}


1





\begin{flushleft}
k ⋅ 𝜑X (k) = 0 ⋅ (1 $-$ p) + 1 ⋅ p = p.
\end{flushleft}





\begin{flushleft}
E[X] =
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
Avendo la definizione, possiamo usarla per calcolare la media di altre distribuzioni note e,
\end{flushleft}


\begin{flushleft}
in generale, di una qualunque variabile aleatoria discreta. Tuttavia per farlo abbiamo bisogno di
\end{flushleft}


\begin{flushleft}
conoscere la densit\`{a} discreta della variabile aleatoria. I prossimi risultati ci danno delle scorciatoie.
\end{flushleft}


\begin{flushleft}
TEOREMA 9.5. Siano X una variabile aleatoria di densit\`{a} discreta 𝜑X e Y = g(X). Allora
\end{flushleft}


\begin{flushleft}
E[Y] =
\end{flushleft}





\begin{flushleft}
g(k) 𝜑 X (k).
\end{flushleft}


\begin{flushleft}
k $\in$ℛ X
\end{flushleft}





\begin{flushleft}
Dimostrazione. Partiamo dalla definizione di speranza e sfruttiamo un risultato sulle trasformazioni di variabili aleatorie discrete visto nel Capitolo 6,
\end{flushleft}


\begin{flushleft}
E[Y] =
\end{flushleft}





\begin{flushleft}
y ⋅ 𝜑Y(y)
\end{flushleft}


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
y⋅
\end{flushleft}





=


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
𝜑 X (x)
\end{flushleft}


\begin{flushleft}
x$\in$g $-$1(\{y\})
\end{flushleft}





\begin{flushleft}
g(x) ⋅ 𝜑 X (x)
\end{flushleft}





=


\begin{flushleft}
y$\in$ℛ Y x$\in$g $-$1(\{y\})
\end{flushleft}





\begin{flushleft}
g(x) ⋅ 𝜑X (x),
\end{flushleft}





=


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
in cui abbiamo approfittato del fatto che se x $\in$ g $-$1(\{y\}), allora y = g(x) e che ℛ Y = g(ℛ X ).
\end{flushleft}





□





\begin{flushleft}
Notiamo che per calcolare E[Y] mediante il teorema precedente non abbiamo bisogno di calcolare esplicitamente 𝜑 Y.
\end{flushleft}


\begin{flushleft}
TEOREMA 9.6. Siano (X, Y) un vettore aleatorio di variabili aleatorie discrete con densit\`{a} congiunta 𝜑X,Y
\end{flushleft}


\begin{flushleft}
e sia Z = g(X, Y), per qualche funzione g : ℝ2 $\rightarrow$ ℝ. Allora
\end{flushleft}


\begin{flushleft}
E[Z] =
\end{flushleft}





\begin{flushleft}
g(j, k) ⋅ 𝜑 X,Y(j, k).
\end{flushleft}


\begin{flushleft}
j$\in$ℛ X k $\in$ℛ Y
\end{flushleft}





\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





□





\begin{flushleft}
Esempio 9.7. Siano X e Y due d20 indipendenti tra loro. Sia Z = min (X, Y). Qual \`{e} il valore atteso
\end{flushleft}


\begin{flushleft}
della variabile aleatoria Z9.3?
\end{flushleft}


\begin{flushleft}
9.3. Detta anche {``}tiro con svantaggio''.
\end{flushleft}





\begin{flushleft}
\newpage
9.1 VARIABILI ALEATORIE DISCRETE
\end{flushleft}





125





\begin{flushleft}
Siamo nelle ipotesi del Teorema 9.6, quindi
\end{flushleft}


20





20





\begin{flushleft}
E[Z] =
\end{flushleft}





\begin{flushleft}
min (j, k) 𝜑 X,Y(j, k) =
\end{flushleft}


\begin{flushleft}
j=1 k =1
\end{flushleft}





=





=





1


400


1


400





\begin{flushleft}
j
\end{flushleft}





20


\begin{flushleft}
j=1
\end{flushleft}


20





20





20





\begin{flushleft}
min (j, k)
\end{flushleft}


\begin{flushleft}
j=1 k =1
\end{flushleft}





\begin{flushleft}
(( k + j)) = 1 j (j + 1) + (20 $-$ j) j
\end{flushleft}


((


)) 400


2


1


\begin{flushleft}
(($-$ j2 + 412 j)) = 800
\end{flushleft}


\begin{flushleft}
(j (41 $-$ j))
\end{flushleft}


20





\begin{flushleft}
k =1
\end{flushleft}





20





\begin{flushleft}
k= j+1
\end{flushleft}





\begin{flushleft}
j=1
\end{flushleft}





20





2





\begin{flushleft}
j=1
\end{flushleft}





1


400





\begin{flushleft}
j=1
\end{flushleft}





5740 287


=


=


= 7.175,


800


40


\begin{flushleft}
mentre un normale d20 ha media 10.5.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.8. Il valore atteso (per variabili aleatorie discrete) gode delle seguenti propriet\`{a}.
\end{flushleft}


\begin{flushleft}
Linearit\`{a}. Date due variabili aleatorie discrete X e Y e due numeri reali a e b,
\end{flushleft}


\begin{flushleft}
E[a X + Y + b] = a E[X] + E[Y] + b.
\end{flushleft}


\begin{flushleft}
Prodotto di variabili aleatorie indipendenti. Siano X e Y due variabili aleatorie discrete tra loro indipendenti, allora
\end{flushleft}


\begin{flushleft}
E[X ⋅ Y] = E[X] ⋅ E[Y].
\end{flushleft}


\begin{flushleft}
Monotonia. Sia X una variabile aleatoria discreta. Se X ⩾ 0, allora E[X] ⩾ 0. Inoltre l'uguaglianza vale
\end{flushleft}


\begin{flushleft}
solamente se X $\equiv$ 0.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Dimostriamo separatamente le tre propriet\`{a}.
\end{flushleft}


\begin{flushleft}
Linearit\`{a}. Per questa dimostrazione sfruttiamo il Teorema 9.6, con g(x, y) = a x + y + b,
\end{flushleft}


\begin{flushleft}
E[a X + Y + b] = E[g(X, Y)] =
\end{flushleft}





\begin{flushleft}
g(j, k) 𝜑 X,Y(j, k)
\end{flushleft}


\begin{flushleft}
j$\in$ℛ X k$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
(a j + k + b) 𝜑X,Y(j, k)
\end{flushleft}





=


\begin{flushleft}
j$\in$ℛ X k $\in$ℛ Y
\end{flushleft}





\begin{flushleft}
aj
\end{flushleft}





=


\begin{flushleft}
j$\in$ℛ X
\end{flushleft}





\begin{flushleft}
𝜑X,Y(j, k) +
\end{flushleft}


\begin{flushleft}
k $\in$ℛ Y
\end{flushleft}





\begin{flushleft}
a j 𝜑 X (j) +
\end{flushleft}





=


\begin{flushleft}
j$\in$ℛ X
\end{flushleft}





\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
𝜑 X,Y(j, k) + b
\end{flushleft}


\begin{flushleft}
j$\in$ℛ X
\end{flushleft}





\begin{flushleft}
𝜑X,Y(j, k)
\end{flushleft}


\begin{flushleft}
j$\in$ℛ X k $\in$ℛ Y
\end{flushleft}





\begin{flushleft}
k 𝜑Y(k) + b
\end{flushleft}


\begin{flushleft}
k$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
= a E[X] + E[Y] + b,
\end{flushleft}


\begin{flushleft}
in cui, nella penultima uguaglianza, abbiamo marginalizzato la densit\`{a} discreta congiunta.
\end{flushleft}


\begin{flushleft}
Prodotto. Anche in questo caso il nostro riferimento \`{e} il Teorema 9.6, con g(x, y) = x ⋅ y,
\end{flushleft}


\begin{flushleft}
E[X Y] = E[g(X, Y)] =
\end{flushleft}





\begin{flushleft}
g(j, k) 𝜑 X,Y(j, k)
\end{flushleft}


\begin{flushleft}
j$\in$ℛ X k $\in$ℛ Y
\end{flushleft}





\begin{flushleft}
j k 𝜑X (j) 𝜑Y(k)
\end{flushleft}





=


\begin{flushleft}
j$\in$ℛ X k $\in$ℛ Y
\end{flushleft}





\begin{flushleft}
j 𝜑X (j)
\end{flushleft}





=


\begin{flushleft}
j$\in$ℛ X
\end{flushleft}





\begin{flushleft}
k 𝜑Y(k) = E[X] E[Y],
\end{flushleft}


\begin{flushleft}
k $\in$ℛ Y
\end{flushleft}





\begin{flushleft}
in cui vale la pena sottolineare la necessit\`{a} dell'ipotesi di indipendenza, per riscrivere la densit\`{a} discreta congiunta come prodotto delle densit\`{a} discrete marginali.
\end{flushleft}


\begin{flushleft}
Monotonia. In questo caso partiamo dalla definizione,
\end{flushleft}


\begin{flushleft}
E[X] =
\end{flushleft}





\begin{flushleft}
k 𝜑X (k) ⩾ 0
\end{flushleft}


\begin{flushleft}
k$\in$ℛ X
\end{flushleft}





\begin{flushleft}
perch\'{e} 𝜑 X ⩾0 e, per ipotesi, X \`{e} non negativa, ossia ogni elemento nel supporto ℛ X \`{e} maggiore
\end{flushleft}


\begin{flushleft}
o uguale di zero. La somma pu\`{o} essere nulla solamente se tutti gli addendi sono nulli, ossia
\end{flushleft}


\begin{flushleft}
se X assume solamente il valore 0.
\end{flushleft}


□





\begin{flushleft}
Lezione 16
\end{flushleft}





\newpage
126





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
COROLLARIO 9.9. Se X e Y sono due variabili aleatorie discrete tali che P(X ⩾ Y) = 1 (ossia X ⩾ Y quasi
\end{flushleft}


\begin{flushleft}
certamente), allora E[X] ⩾ E[Y]. Inoltre, se vale E[X] = E[Y], allora X = Y.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Definiamo la variabile aleatoria Z=X$-$ Y. Grazie all'ipotesi P(X⩾Y ) =1, abbiamo
\end{flushleft}


\begin{flushleft}
P(Z ⩾ 0) = 1 e, per linearit\`{a} e monotonia della speranza,
\end{flushleft}





\begin{flushleft}
E[X] $-$ E[Y] = E[Z] ⩾ 0,
\end{flushleft}


\begin{flushleft}
da cui E[X] ⩾ E[Y].
\end{flushleft}





□





\begin{flushleft}
Osservazione 9.10. In generale non \`{e} vero che, date due variabili aleatorie discrete X e Y, se i loro
\end{flushleft}


\begin{flushleft}
valori attesi sono uguali, E[X] = E[Y], allora le due variabili sono uguali. \`{E} necessaria l'ipotesi
\end{flushleft}


\begin{flushleft}
P(X ⩾ Y) = 1. Lasciandola cadere possiamo costruire dei controesempi, ad esempio X $\equiv$ 0 e
\end{flushleft}


\begin{flushleft}
Y = $-$1 + 2 ⋅ bin 1,
\end{flushleft}





1


2





\begin{flushleft}
(cio\`{e} una variabile aleatoria che assume i valori $-$1 e 1 ciascuno con probabilit\`{a} 2 ) hanno entrambe
\end{flushleft}


\begin{flushleft}
media 0, ma non sono uguali.
\end{flushleft}


1





\begin{flushleft}
Abbiamo enunciato e dimostrato queste propriet\`{a} solamente per le variabili aleatorie discrete,
\end{flushleft}


\begin{flushleft}
dal momento che, per ora, abbiamo definito il valore atteso solamente per queste variabili aleatorie. Tuttavia, come vedremo nella prossima sezione, queste propriet\`{a} valgono anche per la
\end{flushleft}


\begin{flushleft}
speranza di variabili aleatorie assolutamente continue.
\end{flushleft}





\begin{flushleft}
9.1.1. Valore atteso di alcune variabili aleatorie note
\end{flushleft}


\begin{flushleft}
Calcoliamo ora la speranza dei modelli di variabili aleatorie discrete che abbiamo definito nel
\end{flushleft}


\begin{flushleft}
Capitolo 8.
\end{flushleft}


\begin{flushleft}
Bernoulliane Come abbiamo gi\`{a} visto nell'Esempio 9.4, se X $\sim$ bin(1, p), allora E[X] = p.
\end{flushleft}


\begin{flushleft}
Binomiali Sia X $\sim$ bin(n, p). Per calcolarne la speranza, possiamo usare la definizione di valore
\end{flushleft}


\begin{flushleft}
atteso, oppure la definizione di binomiale e le propriet\`{a} della speranza. Seguiamo questa seconda
\end{flushleft}


\begin{flushleft}
strada. Abbiamo che X = ∑ ni=1 Yi, con le Yi indipendenti e identicamente distribuite, Yi $\sim$ bin(1, p).
\end{flushleft}


\begin{flushleft}
Allora, per linearit\`{a} del valore atteso,
\end{flushleft}


\begin{flushleft}
E[X] = E
\end{flushleft}





[[[





\begin{flushleft}
n
\end{flushleft}





]]]





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Yi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
E[Yi] =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
p = n p.
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Osserviamo che questo giustifica quanto avevamo detto euristicamente nell'Esempio 8.33, introducendo le variabili aleatorie di Poisson come limite di binomiali.
\end{flushleft}


\begin{flushleft}
Poissoniane Consideriamo X $\sim$ Pois(𝜆), allora la sua densit\`{a} discreta \`{e}, come abbiamo visto,
\end{flushleft}


\begin{flushleft}
𝜑X (k) =
\end{flushleft}





\begin{flushleft}
𝜆k $-$𝜆
\end{flushleft}


\begin{flushleft}
e .
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





\begin{flushleft}
Per ricavare la speranza di X, usiamo la definizione di valore atteso,
\end{flushleft}


+$\infty$





\begin{flushleft}
E[X] =
\end{flushleft}





\begin{flushleft}
k ⋅ 𝜑 X (k) =
\end{flushleft}


\begin{flushleft}
k$\in$ℛ X
\end{flushleft}


+$\infty$





=





\begin{flushleft}
𝜆
\end{flushleft}


\begin{flushleft}
k=0
\end{flushleft}





\begin{flushleft}
k=0
\end{flushleft}





\begin{flushleft}
𝜆k
\end{flushleft}


\begin{flushleft}
k e $-$𝜆 =
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





\begin{flushleft}
𝜆k $-$1 $-$𝜆
\end{flushleft}


\begin{flushleft}
e =𝜆
\end{flushleft}


\begin{flushleft}
(k $-$ 1)!
\end{flushleft}





+$\infty$


\begin{flushleft}
h=0
\end{flushleft}





+$\infty$





\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
k =1
\end{flushleft}





\begin{flushleft}
𝜆h $-$𝜆
\end{flushleft}


\begin{flushleft}
e =𝜆
\end{flushleft}


\begin{flushleft}
h!
\end{flushleft}





\begin{flushleft}
𝜆k $-$𝜆
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





+$\infty$





\begin{flushleft}
𝜑X (h) = 𝜆,
\end{flushleft}


\begin{flushleft}
h=0
\end{flushleft}





\begin{flushleft}
in cui abbiamo usato la propriet\`{a} delle densit\`{a} discrete per cui la somma sul supporto \`{e} 1.
\end{flushleft}





\begin{flushleft}
Ipergeometriche Sia X $\sim$ hyp(k, m, n). Ricordiamo cosa rappresenta X: \`{e} il numero di biglie
\end{flushleft}


\begin{flushleft}
bianche tra le k estratte da un'urna che ne contiene m bianche e n nere. La densit\`{a} discreta \`{e}
\end{flushleft}


\begin{flushleft}
𝜑 X (b) =
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
k $-$b
\end{flushleft}


\begin{flushleft}
n+m
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





,





\begin{flushleft}
\newpage
9.1 VARIABILI ALEATORIE DISCRETE
\end{flushleft}





127





\begin{flushleft}
per b $\in$ \{max \{0, k $-$ n\},..., min \{k, m\}\}. Potremmo usare la definizione di valore atteso per calcolare
\end{flushleft}


\begin{flushleft}
la speranza di X, ma proviamo a sfruttare la definizione di X e le propriet\`{a} della speranza.
\end{flushleft}


\begin{flushleft}
Per fare questo, chiamiamo (Yi)ki=1 le variabili indicatrici, per ciascuna estrazione, del fatto che
\end{flushleft}


\begin{flushleft}
la pallina sia bianca oppure no:
\end{flushleft}


\begin{flushleft}
Yi =
\end{flushleft}





\begin{flushleft}
pallina \`{e} bianca
\end{flushleft}


\begin{flushleft}
\{\{ 10 sese lala i-sima
\end{flushleft}


\begin{flushleft}
i-sima pallina \`{e} nera.
\end{flushleft}





\begin{flushleft}
A questo punto possiamo vedere X come la somma di queste indicatrici: X = ∑ki=1 Yi. Le Yi non
\end{flushleft}


\begin{flushleft}
sono tra loro indipendenti, ma questo non ci crea problemi, perch\'{e} puntiamo a usare la propriet\`{a} di linearit\`{a} della speranza, che non richiede indipendenza tra le variabili aleatorie che
\end{flushleft}


\begin{flushleft}
sommiamo. Abbiamo per\`{o} bisogno di sapere la densit\`{a} discreta delle Yi.
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
Per i = 1, abbiamo P(Y1 = 1) = m + n . Per i $\in$ \{2, . . . , k\}, quanto vale P(Yi = 1)? Se sapessimo che
\end{flushleft}


\begin{flushleft}
biglie abbiamo estratto in precedenza, potremmo {``}aggiornare'' la composizione dell'urna, ma
\end{flushleft}


\begin{flushleft}
questa sarebbe la probabilit\`{a} di Yi = 1 condizionata ai valori delle indicatrici Yj con 1 ⩽ j $<$ i. A noi,
\end{flushleft}


\begin{flushleft}
per\`{o} interessa la probabilit\`{a} P(Yi = 1), senza avere altre informazioni: essa \`{e} la stessa per ogni i,
\end{flushleft}


\begin{flushleft}
𝜑Yi
\end{flushleft}





\{


\begin{flushleft}
(x) = \{
\end{flushleft}


\{\{





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
m+n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
m+n
\end{flushleft}





\begin{flushleft}
x=1
\end{flushleft}


\begin{flushleft}
x=0
\end{flushleft}





\begin{flushleft}
e 0 altrimenti. In altre parole le Yi sono identicamente distribuite, sono tutte Bernoulliane di param
\end{flushleft}


\begin{flushleft}
metro m + n .
\end{flushleft}


\begin{flushleft}
A questo punto possiamo usare la linearit\`{a} della speranza:
\end{flushleft}


\begin{flushleft}
E[X] = E
\end{flushleft}





[[[


[





\begin{flushleft}
k
\end{flushleft}





]]]


]





\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
Yi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
E[Yi] =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
km
\end{flushleft}


=


.


\begin{flushleft}
m+n m+n
\end{flushleft}





\begin{flushleft}
Geometriche Consideriamo ora X $\sim$ geom(p). La densit\`{a} discreta \`{e} 𝜑 X (k) = p (1 $-$ p)k , ma non
\end{flushleft}


\begin{flushleft}
avremo bisogno di usarla esplicitamente. Per la speranza abbiamo infatti
\end{flushleft}


+$\infty$





\begin{flushleft}
E[X] =
\end{flushleft}





\begin{flushleft}
k 𝜑 X (k) =
\end{flushleft}





\begin{flushleft}
k P(X = k)
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
k $\in$ℛ X
\end{flushleft}


\begin{flushleft}
+$\infty$ k $-$1
\end{flushleft}





+$\infty$





+$\infty$





\begin{flushleft}
P(X = k) =
\end{flushleft}





=


\begin{flushleft}
k =1 i=0
\end{flushleft}


+$\infty$





+$\infty$





\begin{flushleft}
P(X $>$ i) =
\end{flushleft}





=





\begin{flushleft}
P(X = k)
\end{flushleft}


\begin{flushleft}
i=0 k =i+1
\end{flushleft}





\begin{flushleft}
i=0
\end{flushleft}





\begin{flushleft}
(1 $-$ p)i+1
\end{flushleft}





\begin{flushleft}
i=0
\end{flushleft}





1


\begin{flushleft}
1$-$p
\end{flushleft}


\begin{flushleft}
= (1 $-$ p)
\end{flushleft}


=


,


\begin{flushleft}
1 $-$ (1 $-$ p)
\end{flushleft}


\begin{flushleft}
p
\end{flushleft}


\begin{flushleft}
[Inserire disegno triangolo con dominio di somma] in cui abbiamo usato la (8.1) e la somma di
\end{flushleft}


\begin{flushleft}
una serie geometrica di ragione 1 $-$ p.
\end{flushleft}


\begin{flushleft}
Binomiali negative Per calcolare il valore atteso di una variabile aleatoria binomiale, ne sfruttiamo la caratterizzazione come somma di variabili aleatorie geometriche, quindi se X $\sim$ NB(n, p),
\end{flushleft}


\begin{flushleft}
e Yi $\sim$ geom(p) per i = 1, . . . , n allora la sua speranza \`{e}
\end{flushleft}


\begin{flushleft}
E[X] = E
\end{flushleft}





[[


[





\begin{flushleft}
n
\end{flushleft}





]]


]





\begin{flushleft}
Yi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n (1 $-$ p)
\end{flushleft}


.


\begin{flushleft}
p
\end{flushleft}





\begin{flushleft}
Osservazione 9.11. Attenzione che, a seconda della definizione data di geometrica e binomiale
\end{flushleft}


\begin{flushleft}
negative, cambia il valore del valore atteso. In particolare la binomiale negativa pu\`{o} essere scritta
\end{flushleft}


\begin{flushleft}
anche come numero di successi dato un numero massimo di fallimenti, nel qual caso 1 $-$ p e p si
\end{flushleft}


\begin{flushleft}
np
\end{flushleft}


\begin{flushleft}
scambiano i ruoli, motivo per cui in alcune fonti la media \`{e} 1 $-$ p .
\end{flushleft}





\newpage
128





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
9.2. VARIABILI ALEATORIE ASSOLUTAMENTE CONTINUE
\end{flushleft}


\begin{flushleft}
In analogia a quanto fatto nella sezione precedente per le variabili aleatorie discrete, definiamo
\end{flushleft}


\begin{flushleft}
ora il valore atteso per le variabili aleatorie assolutamente continue. Non possiamo farlo nello
\end{flushleft}


\begin{flushleft}
stesso modo, dal momento che la densit\`{a} discreta (o in generale la probabilit\`{a} di un singolo punto)
\end{flushleft}


\begin{flushleft}
non \`{e} definita. Possiamo per\`{o} ricordare che la probabilit\`{a} che una variabile aleatoria assolutamente continua X abbia valori in un intervallo [a, b] \`{e} uguale all'integrale della densit\`{a}:
\end{flushleft}


\begin{flushleft}
P(X $\in$ [a, b]) =
\end{flushleft}





\begin{flushleft}
b
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
fX (x) dx.
\end{flushleft}





\begin{flushleft}
Questo ci d\`{a} una giustificazione euristica per la prossima definizione.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.12. Chiamiamo valore atteso, speranza matematica o media di una variabile aleatoria
\end{flushleft}


\begin{flushleft}
assolutamente continua X la quantit\`{a}
\end{flushleft}


\begin{flushleft}
E[X] =
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
x f X (x) dx.
\end{flushleft}





\begin{flushleft}
Anche nel caso assolutamente continuo, come gi\`{a} nel caso discreto, la speranza pu\`{o} non essere
\end{flushleft}


\begin{flushleft}
definita (se l'integrale non esiste), oppure valere $\pm$$\infty$.
\end{flushleft}


\begin{flushleft}
Valgono nel caso di variabili aleatorie assolutamente continue, risultati analoghi ai Teoremi 9.5
\end{flushleft}


\begin{flushleft}
e 9.6, che ci permettono di calcolare la speranza della trasformazione di una variabile aleatoria
\end{flushleft}


\begin{flushleft}
o di una funzione di un vettore aleatorio.
\end{flushleft}


\begin{flushleft}
TEOREMA 9.13. Siano X una variabile aleatoria assolutamente continua di densit\`{a} f X e Y = g(X) una sua
\end{flushleft}


\begin{flushleft}
trasformazione. Allora
\end{flushleft}


\begin{flushleft}
E[Y] =
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
g(x) f X (x) dx.
\end{flushleft}





\begin{flushleft}
Dimostrazione. [TBA] Del tutto analoga a quella vista per il caso discreto.
\end{flushleft}





□





\begin{flushleft}
TEOREMA 9.14. Siano (X, Y) un vettore aleatorio assolutamente continuo di legge fX,Y e Z = g(X, Y) per
\end{flushleft}


\begin{flushleft}
qualche funzione g: ℝ2 $\rightarrow$ ℝ. Allora
\end{flushleft}


\begin{flushleft}
E[Z] =
\end{flushleft}





\begin{flushleft}
ℝ2
\end{flushleft}





\begin{flushleft}
g(x, y) fX,Y(x, y) dx dy.
\end{flushleft}





\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





□





\begin{flushleft}
Possiamo estendere i Teoremi 9.6 e 9.14 al caso di vettori aleatori misti, visti nella Sezione 7.3.
\end{flushleft}


\begin{flushleft}
TEOREMA 9.15. Siano X una variabile aleatoria discreta e Y una variabile aleatoria assolutamente continua
\end{flushleft}


\begin{flushleft}
e che il vettore (X, Y) abbia densit\`{a} mista9.4 f X,Y. Sia inoltre Z = g(X, Y), per qualche funzione g: ℝ2 $\rightarrow$ ℝ.
\end{flushleft}


\begin{flushleft}
Allora
\end{flushleft}


\begin{flushleft}
E[Z] =
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
g(x, y) fX,Y(x, y) dy.
\end{flushleft}





\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





□





\begin{flushleft}
Osservazione 9.16. Visto che stiamo parlando di vettori aleatori e di speranza, possiamo chiederci
\end{flushleft}


\begin{flushleft}
cosa sia la speranza di un vettore aleatorio. Chiamiamo V = (X, Y) il vettore aleatorio. Abbiamo
\end{flushleft}


\begin{flushleft}
detto che la speranza \`{e} il baricentro di una distribuzione e V \`{e} un 2-vettore a valori nel piano
\end{flushleft}


\begin{flushleft}
ℝ2. Il suo baricentro sar\`{a} anch'esso un punto del piano e, in particolare, sar\`{a} quindi una coppia
\end{flushleft}


\begin{flushleft}
ordinata di numeri reali. Mostriamo ora che, come ci potevamo aspettare, \`{e} proprio il vettore
\end{flushleft}


\begin{flushleft}
le cui componenti sono le speranze di X e Y rispettivamente.
\end{flushleft}


\begin{flushleft}
9.4. Abbiamo parlato della densit\`{a} congiunta mista nella Sezione 7.3.
\end{flushleft}





\begin{flushleft}
\newpage
9.3 MOMENTI DI UNA VARIABILE ALEATORIA
\end{flushleft}





129





\begin{flushleft}
Per dimostrare quindi che E[V] = (E[X], E[Y]), usiamo (supponendo che sia X sia Y siano
\end{flushleft}


\begin{flushleft}
assolutamente continue) il Teorema 9.14: se per i = 1, 2 chiamiamo gi : ℝ2 $\rightarrow$ ℝ la proiezione sulla
\end{flushleft}


\begin{flushleft}
i-sima componente, allora
\end{flushleft}


\begin{flushleft}
E[g i(V)] =
\end{flushleft}





\begin{flushleft}
ℝ2
\end{flushleft}





\begin{flushleft}
g i(x, y) fX,Y(x, y) dx dy
\end{flushleft}





\begin{flushleft}
e siccome le proiezioni di V sulle due componenti sono proprio X e Y, abbiamo il risultato.
\end{flushleft}


\begin{flushleft}
Il valore atteso per le variabili aleatorie assolutamente continue gode delle stesse propriet\`{a}
\end{flushleft}


\begin{flushleft}
viste nella Proposizione 9.8 per la speranza di variabili aleatorie discrete. Possiamo quindi enunciare il seguente risultato più generale.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.17. Il valore atteso gode delle seguenti propriet\`{a}.
\end{flushleft}


\begin{flushleft}
Linearit\`{a}. Date due variabili aleatorie X e Y e due numeri reali a e b,
\end{flushleft}


\begin{flushleft}
E[a X + Y + b] = a E[X] + E[Y] + b.
\end{flushleft}


\begin{flushleft}
Prodotto di variabili aleatorie indipendenti. Siano X e Y due variabili aleatorie tra loro indipendenti,
\end{flushleft}


\begin{flushleft}
allora
\end{flushleft}


\begin{flushleft}
E[X ⋅ Y] = E[X] ⋅ E[Y].
\end{flushleft}


\begin{flushleft}
Monotonia. Sia X una variabile aleatoria. Se X ⩾ 0, allora E[X] ⩾0. Inoltre l'uguaglianza vale solamente
\end{flushleft}


\begin{flushleft}
se X $\equiv$ 0.
\end{flushleft}


\begin{flushleft}
Dimostrazione. [TBA] Le idee sono le stesse del caso discreto.
\end{flushleft}





□





\begin{flushleft}
Esempio 9.18. Sia X una variabile aleatoria di densit\`{a} f X (x) = e $-$x per x $>$ 0 (e nulla altrimenti).
\end{flushleft}


1


\begin{flushleft}
Quanto vale la speranza di X? E quella di X /2?
\end{flushleft}


\begin{flushleft}
Per quanto riguarda E[X], usiamo la definizione:
\end{flushleft}


\begin{flushleft}
E[X] =
\end{flushleft}





+$\infty$


0





\begin{flushleft}
x e $-$x dx = $-$[x e $-$x]+$\infty$
\end{flushleft}


0 +





+$\infty$


0





\begin{flushleft}
e $-$x dx = [$-$e $-$x]+$\infty$
\end{flushleft}


0 = 1.





\begin{flushleft}
Passiamo ora a E[X /2] e usiamo il Teorema 9.13, con g(t) = t ,
\end{flushleft}


1





\begin{flushleft}
E[X /2] =
\end{flushleft}


1





=


=





+$\infty$


0


+$\infty$





\begin{flushleft}
$\surd$x e $-$x dx
\end{flushleft}





0





\begin{flushleft}
[[[ 𝜉 e
\end{flushleft}


2





\begin{flushleft}
𝜉 $-$𝜉 2/2
\end{flushleft}


1


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
𝜉 d𝜉 =
\end{flushleft}


2


2


$-$





\begin{flushleft}
𝜉2
\end{flushleft}


2





+$\infty$





]]]





+


0





1


2





+$\infty$


0





0





/2





\begin{flushleft}
d𝜉
\end{flushleft}





2





\begin{flushleft}
+$\infty$ $-$ 𝜉
\end{flushleft}


2





\begin{flushleft}
e
\end{flushleft}





\begin{flushleft}
𝜉2
\end{flushleft}





\begin{flushleft}
𝜉 2 e$-$
\end{flushleft}





\begin{flushleft}
d𝜉 = 0 +
\end{flushleft}





\begin{flushleft}
$\surd$𝜋
\end{flushleft}


,


2





2





\begin{flushleft}
in cui abbiamo fatto un cambio di variabili
\end{flushleft}


\begin{flushleft}
nell'integrale, x = 𝜉 /2, da cui dx = 𝜉 d𝜉 e abbiamo
\end{flushleft}


\begin{flushleft}
+$\infty$ $-$x 2/2
\end{flushleft}


\begin{flushleft}
integrato per parti. L'integrale ∫0 e
\end{flushleft}


\begin{flushleft}
dx \`{e} particolarmente importante in probabilit\`{a}, come
\end{flushleft}


\begin{flushleft}
vedremo più avanti. Qualche informazione in più su come calcolarlo \`{e} in Appendice A.3.
\end{flushleft}





\begin{flushleft}
9.3. MOMENTI DI UNA VARIABILE ALEATORIA
\end{flushleft}


\begin{flushleft}
Possiamo considerare altri indicatori di una variabile aleatoria, oltre alla sua media. Una immediata generalizzazione del valore atteso \`{e} data dai momenti. Anche in questo caso, come gi\`{a} per
\end{flushleft}


\begin{flushleft}
il valore atteso, \`{e} possibile che non tutti i momenti siano definiti o che siano finiti.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.19. Per ogni n $\in$ ℕ ∖ \{0\}, chiamiamo momento n-simo di una variabile aleatoria X il
\end{flushleft}


\begin{flushleft}
numero reale E[X n].
\end{flushleft}


\begin{flushleft}
Chiamiamo inoltre momento centrato n-simo di X il numero reale E[(X $-$ E[X])n].
\end{flushleft}


\begin{flushleft}
Osservazione 9.20. Con questa definizione il valore atteso \`{e} il momento primo di una variabile
\end{flushleft}


\begin{flushleft}
aleatoria e inoltre il momento centrato primo \`{e} nullo per ogni variabile aleatoria: per linearit\`{a}
\end{flushleft}


\begin{flushleft}
E[X $-$ E[X]] = E[X] $-$ E[X] = 0.
\end{flushleft}





\newpage
130





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
DEFINIZIONE 9.21. Data una variabile aleatoria X, il suo momento centrato secondo prende anche il nome
\end{flushleft}


\begin{flushleft}
di varianza e viene denotato con
\end{flushleft}


\begin{flushleft}
Var[X] = E[(X $-$ E[X])2].
\end{flushleft}


\begin{flushleft}
Possiamo dare un'interpretazione fisica di media e varianza: la prima rappresenta il baricentro
\end{flushleft}


\begin{flushleft}
di una distribuzione di probabilit\`{a}, mentre la seconda ne \`{e} il momento di inerzia.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.22. Per la varianza vale la seguente uguaglianza: Var[X] = E[X 2] $-$ (E[X])2.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Scriviamo, per comodit\`{a}, E[X] = 𝜇. Allora
\end{flushleft}


\begin{flushleft}
Var[X] = E[(X $-$ E[X])2] = E[X 2 $-$ 2 𝜇 X + 𝜇2]
\end{flushleft}


\begin{flushleft}
= E[X 2] $-$ 2 𝜇 E[X] + 𝜇2 = E[X 2] $-$ 𝜇2 = E[X 2] $-$ E[X]2,
\end{flushleft}


\begin{flushleft}
in cui abbiamo usato la linearit\`{a} della speranza.
\end{flushleft}





□





\begin{flushleft}
Se vogliamo calcolare la varianza di una variabile aleatoria X, grazie alla Proposizione 9.22
\end{flushleft}


\begin{flushleft}
possiamo farlo calcolando la media E[X] di X e il valore atteso della variabile aleatoria X 2, usando
\end{flushleft}


\begin{flushleft}
il Teorema 9.13 (o il Teorema 9.5, se X \`{e} discreta).
\end{flushleft}


\begin{flushleft}
Possiamo ora mostrare alcune propriet\`{a} della varianza.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.23. Siamo X una variabile aleatoria e Var[X] la sua varianza. Allora
\end{flushleft}


\begin{flushleft}
i. Var[X] ⩾ 0 e l'uguaglianza vale solamente se X \`{e} costante;
\end{flushleft}


\begin{flushleft}
ii. siano a, b $\in$ ℝ, Var[a X + b] = a 2 Var[X].
\end{flushleft}


\begin{flushleft}
Dimostrazione. La prima propriet\`{a} \`{e} una conseguenza immediata della monotonia della speranza, infatti (X $-$ E[X])2 ⩾ 0, dunque
\end{flushleft}


\begin{flushleft}
Var[X] = E[(X $-$ E[X])2] ⩾ 0.
\end{flushleft}


\begin{flushleft}
Inoltre, sempre per la monotonia, E[(X $-$ E[X])2] = 0 se e solo se l'argomento della speranza \`{e}
\end{flushleft}


\begin{flushleft}
nullo, ossia se X = E[X], cio\`{e} se la variabile aleatoria X \`{e} costante, visto che E[X] \`{e} un numero.
\end{flushleft}


\begin{flushleft}
Passiamo alla seconda propriet\`{a},
\end{flushleft}


\begin{flushleft}
Var[a X + b] = E[(a X + b $-$ E[a X + b])2]
\end{flushleft}


\begin{flushleft}
= E[(a X + b $-$ a E[X] $-$ b)2]
\end{flushleft}


\begin{flushleft}
= a 2 E[(X $-$ E[X])2] = a 2 Var[X],
\end{flushleft}


\begin{flushleft}
usando la linearit\`{a} della speranza.
\end{flushleft}





□





\begin{flushleft}
Osservazione 9.24. La proposizione precedente ci mostra in particolare che la varianza di una
\end{flushleft}


\begin{flushleft}
variabile aleatoria non \`{e} lineare: nel calcolare Var[a X + b] il termine noto non gioca alcun ruolo,
\end{flushleft}


\begin{flushleft}
mentre il coefficiente a esce dall'operatore Var al quadrato.
\end{flushleft}


\begin{flushleft}
La seconda propriet\`{a} nella Proposizione 9.23 non copre il caso della varianza della combinazione lineare di due variabili aleatorie, a differenza di quanto visto per la speranza. Per poter
\end{flushleft}


\begin{flushleft}
trattare in generale la varianza della somma di due variabili aleatorie dobbiamo aspettare ancora
\end{flushleft}


\begin{flushleft}
un po', fino alla Sezione 9.5. Nel prossimo risultato, per\`{o}, affrontiamo almeno una situazione
\end{flushleft}


\begin{flushleft}
particolare.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.25. Se X e Y sono due variabili aleatorie indipendenti per cui sia definita la varianza,
\end{flushleft}


\begin{flushleft}
allora Var[X + Y] = Var[X] + Var[Y].
\end{flushleft}


\begin{flushleft}
Dimostrazione. Iniziamo sfruttando la Proposizione 9.22,
\end{flushleft}


\begin{flushleft}
Var[X + Y] = E[(X + Y)2] $-$ (E[X + Y])2
\end{flushleft}


\begin{flushleft}
= E[X 2] + 2 E[X Y] + E[Y 2] $-$ E[X]2 $-$ 2 E[X] E[Y] $-$ E[Y]2
\end{flushleft}


\begin{flushleft}
= Var[X] + Var[Y] + 2 (E[X Y] $-$ E[X] E[Y])
\end{flushleft}





\begin{flushleft}
\newpage
9.3 MOMENTI DI UNA VARIABILE ALEATORIA
\end{flushleft}





131





\begin{flushleft}
in cui l'ultimo addendo si annulla perch\'{e} per l'indipendenza di X e Y, E[X Y] = E[X] E[Y].
\end{flushleft}





□





\begin{flushleft}
Avendone viste alcune propriet\`{a}, vogliamo ora provare a dare un'interpretazione intuitiva
\end{flushleft}


\begin{flushleft}
di cosa sia la varianza di una variabile aleatoria. Consideriamo come esempio la variabile alea1
\end{flushleft}


\begin{flushleft}
toria X, Bernoulliana di parametro 2 , ossia il lancio di una moneta bilanciata. Questa variabile
\end{flushleft}


1


\begin{flushleft}
aleatoria ha media 2 , proviamo a calcolarne la varianza:
\end{flushleft}


1


1


1


\begin{flushleft}
Var[X] = E[X 2] $-$ E[X]2 = 12 ⋅ + 02 ⋅ $-$
\end{flushleft}


2


2


2





2





1


= ,


4





\begin{flushleft}
che per\`{o} non sembra comparire in modo evidente nella descrizione della variabile aleatoria. Se
\end{flushleft}


\begin{flushleft}
riguardiamo la definizione di varianza come momento centrato secondo, Var[X]=E[(X$-$ E[X])2],
\end{flushleft}


\begin{flushleft}
vediamo che la varianza \`{e} la media del quadrato della distanza tra la variabile aleatoria e la sua
\end{flushleft}


\begin{flushleft}
media. Possiamo quindi aspettarci che in qualche senso misuri la {``}larghezza'' della variabile
\end{flushleft}


\begin{flushleft}
aleatoria.
\end{flushleft}


\begin{flushleft}
Per valutare meglio questa idea, modifichiamo la variabile X e consideriamone la seguente
\end{flushleft}


\begin{flushleft}
trasformazione: Y = 2 X. Allora la media di Y sar\`{a} E[Y] = 1 e la varianza Var[Y] = 4 Var[X] = 1,
\end{flushleft}


\begin{flushleft}
cio\`{e} al raddoppiare della {``}larghezza'' della variabile aleatoria, la varianza \`{e} quadruplicata.
\end{flushleft}


\begin{flushleft}
Abbiamo quindi una conferma euristica del fatto che la varianza misuri la dispersione di una
\end{flushleft}


\begin{flushleft}
variabile aleatoria, ossia quanto sono distanti {``}in media'' i valori della variabile aleatoria dalla
\end{flushleft}


\begin{flushleft}
media della variabile aleatoria stessa. Allo stesso tempo, questa misura non \`{e} proprio la {``}larghezza'', dal momento che varia quadraticamente.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.26. Chiamiamo deviazione standard di una variabile aleatoria X la radice quadrata della
\end{flushleft}


\begin{flushleft}
sua varianza, 𝜎X = Var[X] . Possiamo quindi indicare Var[X] con 𝜎X2.
\end{flushleft}


\begin{flushleft}
In questo modo abbiamo un indicatore (ossia un numero) che misura proprio la media della
\end{flushleft}


\begin{flushleft}
distanza di una variabile aleatoria X dalla sua media. Essendo la radice quadrata della varianza,
\end{flushleft}


\begin{flushleft}
essa ha la stessa unit\`{a} di misura di X e della sua media E[X]: se Y = a X, allora
\end{flushleft}


\begin{flushleft}
𝜎Y = Var[Y] = a 2 Var[X] = a 𝜎X .
\end{flushleft}


\begin{flushleft}
Esempio 9.27. Consideriamo la variabile aleatoria X uniforme sull'intervallo [0,1]. Essa ha media
\end{flushleft}


\begin{flushleft}
E[X] =
\end{flushleft}


\begin{flushleft}
e varianza
\end{flushleft}





1


0





\begin{flushleft}
x 1 dx =
\end{flushleft}





1


2





\begin{flushleft}
Var[X] = E[X 2] $-$ E[X]2
\end{flushleft}


1


1


=


\begin{flushleft}
x 2 dx $-$
\end{flushleft}


0


4


1 1 1


= $-$ =


3 4 12


\begin{flushleft}
e la sua deviazione standard \`{e} 𝜎X =
\end{flushleft}





1


12





$\approx$ 0.29.





\begin{flushleft}
9.3.1. Varianza di alcune variabili aleatorie note
\end{flushleft}


\begin{flushleft}
Calcoliamo ora la varianza (e quindi la deviazione standard) di alcuni9.5 modelli di variabili aleatorie discrete che abbiamo definito nel Capitolo 8.
\end{flushleft}


\begin{flushleft}
Bernoulliane Sia X $\sim$ bin(1, p). Allora
\end{flushleft}


\begin{flushleft}
Var[X] = E[X 2] $-$ E[X]2
\end{flushleft}


\begin{flushleft}
= p $-$ p 2 = p (1 $-$ p).
\end{flushleft}


\begin{flushleft}
9.5. Non ricaviamo qui la varianza delle ipergeometriche, perch\'{e} per farlo abbiamo bisogno della covarianza, che
\end{flushleft}


\begin{flushleft}
introdurremo solamente nella Sezione 9.5.
\end{flushleft}





\begin{flushleft}
Lezione 17
\end{flushleft}





\newpage
132





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
Binomiali Sia X $\sim$ bin(n, p). La variabile aleatoria X \`{e} la somma di n Bernoulliane indipendenti
\end{flushleft}


\begin{flushleft}
e identicamente distribuite Yi di legge bin(1, p), quindi
\end{flushleft}


\begin{flushleft}
Var[X] = Var
\end{flushleft}





[[[





\begin{flushleft}
n
\end{flushleft}





]]]





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Var[Yi] = n p (1 $-$ p),
\end{flushleft}





\begin{flushleft}
Yi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
in cui abbiamo usato la Proposizione 9.25 e la forma della varianza per le Bernoulliane.
\end{flushleft}





\begin{flushleft}
Geometriche Sia ora X $\sim$ geom(p). Se volessimo ripetere quanto fatto per il valore atteso,
\end{flushleft}


\begin{flushleft}
avremmo una difficolt\`{a}: non possiamo liberarci altrettanto facilmente del termine k 2 in E[X 2]
\end{flushleft}


\begin{flushleft}
attraverso una somma ausiliaria. Vediamo quindi una strategia alternativa, con cui calcoliamo
\end{flushleft}


\begin{flushleft}
sia la media, sia la varianza.
\end{flushleft}


\begin{flushleft}
Per definizione X \`{e} la variabile aleatoria che conta il numero di insuccessi prima del primo
\end{flushleft}


\begin{flushleft}
successo in un processo di Bernoulli. Sia invece Y la variabile aleatoria che conta il numero di
\end{flushleft}


\begin{flushleft}
insuccessi prima del primo successo escludendo il risultato del primo tentativo. In altre parole
\end{flushleft}


\begin{flushleft}
Y = inf \{n ⩾ 2 : 𝜔n = 1\} $-$ 2
\end{flushleft}


\begin{flushleft}
(troviamo l'istante di primo successo successivo a 1 e togliamo 1 per trascurare il primo tentativo
\end{flushleft}


\begin{flushleft}
e 1 perch\'{e} vogliamo contare il numero di insuccessi). Ne andiamo a scrivere la densit\`{a} discreta,
\end{flushleft}


\begin{flushleft}
𝜑Y(k) = P(Y = k) = 1 ⋅ (1 $-$ p)k ⋅ p,
\end{flushleft}


\begin{flushleft}
del momento che trascuriamo il primo lancio, abbiamo k insuccessi e infine un successo. Ma
\end{flushleft}


\begin{flushleft}
questa \`{e} la densit\`{a} discreta di una geometrica di parametro p, Y $\sim$ X $\sim$ geom(p).
\end{flushleft}


\begin{flushleft}
Ora possiamo scrivere la speranza di X come
\end{flushleft}


+$\infty$





\begin{flushleft}
E[X] =
\end{flushleft}





\begin{flushleft}
k P(X = k)
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}


+$\infty$





\begin{flushleft}
(k P(X = k ∣ 𝜔1 = 0) P(𝜔1 = 0) + k P(X = k ∣ 𝜔1 = 1) P(𝜔1 = 1))
\end{flushleft}





=


\begin{flushleft}
k =0
\end{flushleft}


+$\infty$





+$\infty$





\begin{flushleft}
k P(X = k ∣ 𝜔1 = 0) (1 $-$ p) +
\end{flushleft}





=


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
k P(X = k ∣ 𝜔1 = 1) p
\end{flushleft}


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
= E[X ∣ 𝜔 1 = 0] (1 $-$ p) + E[X ∣ 𝜔 1 = 1] p
\end{flushleft}


+$\infty$





\begin{flushleft}
k P(Y + 1 = k ∣ 𝜔1 = 0) (1 $-$ p) + 0 ⋅ P(X = 0 ∣ 𝜔1 = 1) p
\end{flushleft}





=


\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
= E[Y + 1 ∣ 𝜔 1 = 0] (1 $-$ p)
\end{flushleft}


\begin{flushleft}
= E[Y + 1] (1 $-$ p)
\end{flushleft}


\begin{flushleft}
= E[Y] (1 $-$ p) + 1 $-$ p,
\end{flushleft}


\begin{flushleft}
1$-$p
\end{flushleft}





\begin{flushleft}
da cui, siccome E[X] = E[Y], ricaviamo (supponendo che E[X] sia finita) E[X] = p . Nella catena
\end{flushleft}


\begin{flushleft}
di uguaglianze abbiamo usato che P(X = 0 ∣ 𝜔1 = 1) = 1, che se 𝜔 1 = 0 allora X = Y + 1 e che Y \`{e}
\end{flushleft}


\begin{flushleft}
indipendente dall'evento 𝜔 1 = 0.
\end{flushleft}


\begin{flushleft}
Allo stesso modo abbiamo, per E[X 2],
\end{flushleft}


\begin{flushleft}
E[X 2] = E[X 2 ∣ 𝜔1 = 0] (1 $-$ p) + E[X 2 ∣ 𝜔1 = 1] p
\end{flushleft}


\begin{flushleft}
= E[(Y + 1)2 ∣ 𝜔1 = 0] (1 $-$ p) + 0 ⋅ p
\end{flushleft}


\begin{flushleft}
= (E[Y 2] + 2 E[Y] + 1) (1 $-$ p)
\end{flushleft}


\begin{flushleft}
2(1 $-$ p)2
\end{flushleft}


\begin{flushleft}
= E[Y 2] (1 $-$ p) +
\end{flushleft}


\begin{flushleft}
+ (1 $-$ p),
\end{flushleft}


\begin{flushleft}
p
\end{flushleft}


\begin{flushleft}
da cui (assumendo che E[X 2] $<$ +$\infty$), E[X 2] =
\end{flushleft}


\begin{flushleft}
Var[X] = E[X 2] $-$ E[X]2 =
\end{flushleft}





\begin{flushleft}
2 (1 $-$ p)2 + p (1 $-$ p)
\end{flushleft}


.


\begin{flushleft}
p2
\end{flushleft}





\begin{flushleft}
Allora, per la varianza,
\end{flushleft}





\begin{flushleft}
2 (1 $-$ p)2 + p (1 $-$ p) (1 $-$ p)2 1 $-$ p
\end{flushleft}


$-$


= 2 .


\begin{flushleft}
p2
\end{flushleft}


\begin{flushleft}
p2
\end{flushleft}


\begin{flushleft}
p
\end{flushleft}





\begin{flushleft}
\newpage
9.4 DISUGUAGLIANZE
\end{flushleft}





133





\begin{flushleft}
Binomiali negative Una variabile aleatoria X $\sim$ NB(n, p) \`{e} la somma di n variabili aleatorie geometriche indipendenti e identicamente distribuite Yi $\sim$ geom(p). Allora
\end{flushleft}


\begin{flushleft}
Var[X] =
\end{flushleft}





\begin{flushleft}
n (1 $-$ p)
\end{flushleft}


.


\begin{flushleft}
p2
\end{flushleft}





\begin{flushleft}
Poissoniane Sia ora X $\sim$ Pois(𝜆). Sappiamo che E[X] = 𝜆, quindi per ricavare Var[X] ci basta
\end{flushleft}


\begin{flushleft}
calcolare il momento secondo E[X 2]. Possiamo provare a farlo usando il Teorema 9.5, ma
\end{flushleft}


+$\infty$





\begin{flushleft}
E[X 2] =
\end{flushleft}





\begin{flushleft}
k2
\end{flushleft}


\begin{flushleft}
k=0
\end{flushleft}





\begin{flushleft}
𝜆k $-$𝜆
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





\begin{flushleft}
non sembra semplicissima da trattare. Cerchiamo allora di arrivare al risultato usando un trucco:
\end{flushleft}


+$\infty$





\begin{flushleft}
E[X $-$ X] = E[X (X $-$ 1)] =
\end{flushleft}





\begin{flushleft}
k (k $-$ 1)
\end{flushleft}





2





\begin{flushleft}
k =0
\end{flushleft}


+$\infty$





\begin{flushleft}
k (k $-$ 1)
\end{flushleft}





=





\begin{flushleft}
k =2
\end{flushleft}


+$\infty$


2





\begin{flushleft}
= 𝜆
\end{flushleft}





\begin{flushleft}
j=0
\end{flushleft}





\begin{flushleft}
𝜆k $-$𝜆
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
k!
\end{flushleft}





\begin{flushleft}
𝜆2 ⋅ 𝜆k $-$2
\end{flushleft}


\begin{flushleft}
k (k $-$ 1) (k $-$ 2)!
\end{flushleft}





\begin{flushleft}
𝜆j $-$𝜆 2
\end{flushleft}


\begin{flushleft}
e =𝜆
\end{flushleft}


\begin{flushleft}
j!
\end{flushleft}





\begin{flushleft}
dove abbiamo usato il fatto che i primi due addendi nella prima somma sono nulli e abbiamo
\end{flushleft}


\begin{flushleft}
messo in evidenza, con il cambio di variabile j =k $-$ 2, la somma delle densit\`{a} discrete sul supporto
\end{flushleft}


\begin{flushleft}
di una Poissoniana, somma che sappiamo essere uguale a 1. A questo punto, per linearit\`{a},
\end{flushleft}


\begin{flushleft}
E[X 2] = E[X 2 $-$ X] + E[X] = 𝜆2 + 𝜆
\end{flushleft}


\begin{flushleft}
e per la varianza abbiamo
\end{flushleft}


\begin{flushleft}
Var[X] = E[X 2] $-$ E[X]2 = 𝜆2 + 𝜆 $-$ 𝜆2 = 𝜆.
\end{flushleft}





\begin{flushleft}
9.4. DISUGUAGLIANZE
\end{flushleft}


\begin{flushleft}
Nell'introduzione di questo capitolo, abbiamo detto che vogliamo usare gli indicatori per avere
\end{flushleft}


\begin{flushleft}
alcune informazioni su una distribuzione di probabilit\`{a} ignota. Vediamo ora alcuni risultati che
\end{flushleft}


\begin{flushleft}
ci permettono di dire qualcosa su una variabile aleatoria e la sua distribuzione a partire dalla sua
\end{flushleft}


\begin{flushleft}
speranza e dalla sua varianza.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.28. (DISUGUAGLIANZA DI MARKOV9.6) Sia X una variabile aleatoria non negativa di
\end{flushleft}


\begin{flushleft}
media finita. Allora, per ogni a $>$ 0
\end{flushleft}


\begin{flushleft}
E[X]
\end{flushleft}


\begin{flushleft}
P(X ⩾ a) ⩽
\end{flushleft}


.


(9.1)


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Dimostrazione. Se P(X⩾a)=0, la tesi segue dal fatto che E[X]⩾0 e che quindi il secondo membro
\end{flushleft}


\begin{flushleft}
\`{e} sicuramente non negativo. Supponiamo allora che P(X ⩾ a) $>$ 0: abbiamo
\end{flushleft}


\begin{flushleft}
E[X] = E[X ∣ X $<$ a] P(X $<$ a) + E[X ∣ X ⩾ a] P(X ⩾ a)
\end{flushleft}


\begin{flushleft}
⩾ E[X ∣ X ⩾ a] P(X ⩾ a)
\end{flushleft}


\begin{flushleft}
⩾ a P(X ⩾ a)
\end{flushleft}


\begin{flushleft}
dal momento che stiamo facendo la media per valori che sono almeno a.
\end{flushleft}





□





\begin{flushleft}
Osservazione 9.29. \`{E} possibile dare una dimostrazione alternativa più diretta di questo fatto,
\end{flushleft}


\begin{flushleft}
usando la definizione di speranza nei casi discreto e assolutamente continuo, assieme alle propriet\`{a} di somma e integrale. \`{E} per\`{o} un processo più laborioso.
\end{flushleft}


\begin{flushleft}
9.6. Andrej Andreevi\v{c} Markov (1856 -- 1922). In realt\`{a} pare che questo risultato sia dovuto a Pafnutij L'vovi\v{c} \v{C}eby\v{s}\"{e}v
\end{flushleft}


\begin{flushleft}
(1821 -- 1894), spesso traslitterato come Chebychev, di cui Markov fu allievo.
\end{flushleft}





\newpage
134





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
Osservazione 9.30. Esistono altre varianti della disuguaglianza di Markov (9.1), anche più {``}forti'',
\end{flushleft}


\begin{flushleft}
che spesso vengono chiamate con lo stesso nome. Ad esempio possiamo lasciar cadere l'ipotesi che X abbia media finita, nel qual caso la disuguaglianza \`{e} banalmente vera, senza essere
\end{flushleft}


\begin{flushleft}
per\`{o} molto utile.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.31. (DISUGUAGLIANZA DI CHEBYCHEV) Sia X una variabile aleatoria con varianza
\end{flushleft}


\begin{flushleft}
finita. Allora, per ogni a $>$ 0
\end{flushleft}


\begin{flushleft}
Var[X]
\end{flushleft}


\begin{flushleft}
P(|X $-$ E[X]| ⩾ a) ⩽
\end{flushleft}


(9.2)


\begin{flushleft}
a2
\end{flushleft}


\begin{flushleft}
o equivalentemente
\end{flushleft}


1


\begin{flushleft}
P |X $-$ E[X]| ⩾ a ⋅ Var[X] ⩽ 2 .
\end{flushleft}


(9.3)


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Dimostrazione. Osserviamo innanzitutto che sia a sia |X $-$ E[X]| sono non negativi. Allora
\end{flushleft}


\begin{flushleft}
P(|X $-$ E[X]| ⩾ a) = P((X $-$ E[X])2 ⩾ a 2)
\end{flushleft}


\begin{flushleft}
E[(X $-$ E[X])2]
\end{flushleft}


⩽


\begin{flushleft}
a2
\end{flushleft}


\begin{flushleft}
Var[X]
\end{flushleft}


=


,


\begin{flushleft}
a2
\end{flushleft}


\begin{flushleft}
in cui abbiamo usato la disuguaglianza di Markov (9.1), sfruttando il fatto che la variabile aleatoria (X $-$ E[X])2 \`{e} non negativa. La forma equivalente (9.3) segue dalla (9.2) sostituendo ad a il
\end{flushleft}


\begin{flushleft}
numero reale positivo9.7 a Var[X]
\end{flushleft}


□


\begin{flushleft}
Grazie alla disuguaglianza di Chebychev (9.3) possiamo formalizzare quanto detto prima sul
\end{flushleft}


\begin{flushleft}
significato della deviazione standard: Var[X] misura quanto X sia larga o dispersa, infatti possiamo usarla per valutare la probabilit\`{a} che X si allontani dalla propria media.
\end{flushleft}


\begin{flushleft}
Esempio[TBA]
\end{flushleft}





\begin{flushleft}
9.5. COVARIANZA E CORRELAZIONE
\end{flushleft}


\begin{flushleft}
Gli indicatori che abbiamo visto finora riguardano una singola variabile aleatoria. In certe situazioni, tuttavia, ci farebbe comodo avere un indicatore che misuri quanto due variabili aleatorie
\end{flushleft}


\begin{flushleft}
sono legate tra loro. Infatti sappiamo determinare se sono indipendenti o meno, ma non sappiamo modulare questo secondo caso.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.32. Date due variabili aleatorie X e Y, chiamiamo covarianza di X e Y la quantit\`{a}
\end{flushleft}


\begin{flushleft}
Cov[X, Y] = E[(X $-$ E[X]) (Y $-$ E[Y])].
\end{flushleft}





(9.4)





\begin{flushleft}
La covarianza generalizza la varianza: Cov[X, X]=Var[X]. Anche per la covarianza, come gi\`{a}
\end{flushleft}


\begin{flushleft}
visto per la varianza, abbiamo una seconda formulazione equivalente, spesso più pratica da usare
\end{flushleft}


\begin{flushleft}
Cov[X, Y] = E[X Y] $-$ E[X] E[Y].
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.33. Vediamo alcune propriet\`{a} della covarianza.
\end{flushleft}


\begin{flushleft}
i. La covarianza \`{e} simmetrica: per ogni coppia di variabili aleatorie X e Y, Cov[X, Y] = Cov[Y, X].
\end{flushleft}


\begin{flushleft}
ii. Se X e Y sono variabili aleatorie indipendenti, allora Cov[X, Y] = 0.
\end{flushleft}


\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





□





\begin{flushleft}
DEFINIZIONE 9.34. Se due variabili aleatorie X e Y hanno covarianza nulla (cio\`{e} Cov[X, Y] = 0), diciamo
\end{flushleft}


\begin{flushleft}
che sono scorrelate.
\end{flushleft}


\begin{flushleft}
9.7. In realt\`{a} c'\`{e} il caso in cui Var[X] = 0, ma allora X = E[X] e la disuguaglianza non \`{e} molto interessante.
\end{flushleft}





\begin{flushleft}
\newpage
9.5 COVARIANZA E CORRELAZIONE
\end{flushleft}





135





\begin{flushleft}
Osservazione 9.35. \`{E} importante ricordare che non vale il viceversa della seconda propriet\`{a} nella
\end{flushleft}


\begin{flushleft}
Proposizione 9.33: non \`{e} necessariamente vero che due variabili aleatorie scorrelate siano indipendenti, anche se due variabili indipendenti sono anche scorrelate.
\end{flushleft}


\begin{flushleft}
Esempio 9.36. Siano X e Y due variabili aleatorie di legge congiunta
\end{flushleft}





\begin{flushleft}
𝜑 X,Y
\end{flushleft}





\begin{flushleft}
\{\{ (x, y) $\in$ \{($-$1, $-$1), (1, $-$1)\}
\end{flushleft}


\begin{flushleft}
(x, y) = \{ (x, y) = (0, 1)
\end{flushleft}


\{\{


\begin{flushleft}
0 altrimenti.
\end{flushleft}


1


4


1


2





\begin{flushleft}
Possiamo ricavarci le leggi marginali di X e Y:
\end{flushleft}





\begin{flushleft}
\{\{ x $\in$ \{$-$1, 1\}
\end{flushleft}


\begin{flushleft}
𝜑 (x) = \{
\end{flushleft}


\begin{flushleft}
\{\{ x = 0
\end{flushleft}


\begin{flushleft}
\{ 0 altrimenti
\end{flushleft}


1


4


1


2





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
𝜑 Y(y) =
\end{flushleft}





\begin{flushleft}
\{\{\{ y $\in$ \{$-$1, 1\}
\end{flushleft}


\begin{flushleft}
0 altrimenti.
\end{flushleft}


1


2





\begin{flushleft}
A questo punto possiamo facilmente verificare che X e Y non sono indipendenti, infatti
\end{flushleft}





\begin{flushleft}
𝜑 X,Y
\end{flushleft}





\begin{flushleft}
\{\{ (x, y) $\in$ \{($-$1, $-$1), ($-$1, 1), (1, $-$1), (1, 1)\}
\end{flushleft}


\begin{flushleft}
(x, y) $\neq$ 𝜑 (x) ⋅ 𝜑 (y) = \{ (x, y) $\in$ \{(0, $-$1), (0, 1)\}
\end{flushleft}


\begin{flushleft}
\{\{\{ 0 altrimenti.
\end{flushleft}


\begin{flushleft}
X
\end{flushleft}





1


8


1


4





\begin{flushleft}
Y
\end{flushleft}





\begin{flushleft}
Allo stesso tempo, le due variabili aleatorie sono scorrelate, infatti
\end{flushleft}


1


1


1


\begin{flushleft}
Cov[X, Y] = E[X Y] $-$ E[X] E[Y] = 1 ⋅ + 0 ⋅ + ($-$1) ⋅ $-$ 0 = 0.
\end{flushleft}


4


2


4


\begin{flushleft}
Il precedente esempio ci suggerisce un'osservazione più generale sul calcolo della covarianza:
\end{flushleft}


\begin{flushleft}
a partire dalla (9.4), possiamo usare i teoremi noti sulla speranza della funzione di un vettore
\end{flushleft}


\begin{flushleft}
aleatorio, nel caso particolare in cui g(x, y) = x ⋅ y,
\end{flushleft}


\begin{flushleft}
Cov[X, Y] = E[X Y] $-$ E[X] E[Y]
\end{flushleft}


\begin{flushleft}
= E[g(X, Y)] $-$ E[X] E[Y]
\end{flushleft}


=


\begin{flushleft}
x y f X,Y(x, y) dx dy $-$
\end{flushleft}


2


\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
x f X (x) dx
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
y f Y(y) dy
\end{flushleft}





\begin{flushleft}
nel caso X e Y siano assolutamente continue, oppure
\end{flushleft}


\begin{flushleft}
x y 𝜑X,Y(x, y) $-$
\end{flushleft}





\begin{flushleft}
Cov[X, Y] =
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
x 𝜑X (x)
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
y 𝜑Y(y)
\end{flushleft}


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
nel caso siano entrambe discrete o ancora
\end{flushleft}


\begin{flushleft}
Cov[X, Y] =
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
x y fX,Y(x, y) dy $-$
\end{flushleft}





\begin{flushleft}
x 𝜑 X (x)
\end{flushleft}


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
y fY(y) dy
\end{flushleft}





\begin{flushleft}
nel caso X sia discreta e Y sia assolutamente continua.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.37. La covarianza di due variabili aleatorie X e Y soddisfa anche le seguenti propriet\`{a}.
\end{flushleft}


\begin{flushleft}
i. Ci permette di calcolare la varianza della loro somma anche nel caso in cui X e Y non siano indipendenti:
\end{flushleft}


\begin{flushleft}
Var[X + Y] = Var[X] + Var[Y] + 2 Cov[X, Y].
\end{flushleft}


\begin{flushleft}
ii. La covarianza \`{e} lineare separatamente in ciascun argomento:
\end{flushleft}


\begin{flushleft}
Cov[a X + b Y, Z] = a Cov[X, Z] + b Cov[Y, Z].
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


\begin{flushleft}
iii. La covarianza \`{e} bilineare: se (ai)ni=1 e (bj)m
\end{flushleft}


\begin{flushleft}
j=1 sono due vettori di numeri reali e (X i)i=1 e (Yj)j=1 sono due
\end{flushleft}


\begin{flushleft}
vettori aleatori, allora
\end{flushleft}





[[[


[





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}





\begin{flushleft}
ai Xi,
\end{flushleft}





\begin{flushleft}
Cov
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





]]]


]





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
m
\end{flushleft}





\begin{flushleft}
bj Yj =
\end{flushleft}


\begin{flushleft}
j=1
\end{flushleft}





\begin{flushleft}
a i b j Cov[X i, Yj].
\end{flushleft}


\begin{flushleft}
i=1 j=1
\end{flushleft}





\newpage
136





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





□





\begin{flushleft}
Osservazione 9.38. La Proposizione 9.37 generalizza le propriet\`{a} viste per la varianza. Infatti
\end{flushleft}


\begin{flushleft}
da un lato ci permette di calcolare la varianza della somma di due variabili aleatorie qualunque,
\end{flushleft}


\begin{flushleft}
dall'altro possiamo anche passare alla varianza di una qualsiasi combinazione lineare di variabili
\end{flushleft}


\begin{flushleft}
aleatorie: se (a i)ni=1 \`{e} un vettore di numeri reali e (X i)ni=1 \`{e} un vettore aleatorio, allora
\end{flushleft}


\begin{flushleft}
Var
\end{flushleft}





[[[





\begin{flushleft}
n
\end{flushleft}





]]]





[[[





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
ai Xi = Cov
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
ai Xi,
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





]]]





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
ai Xi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
ai aj Cov[Xi, Xj].
\end{flushleft}





(9.5)





\begin{flushleft}
i=1 j=1
\end{flushleft}





\begin{flushleft}
DEFINIZIONE 9.39. Se (Xi)ni=1 \`{e} un vettore aleatorio, chiamiamo matrice di covarianza la matrice n × n
\end{flushleft}


\begin{flushleft}
le cui componenti sono Cov[X i, X j]. Questa matrice \`{e} spesso indicata con $\Sigma$(X, Y) o, in breve, con $\Sigma$.
\end{flushleft}


\begin{flushleft}
Possiamo allora riscrivere la (9.5) in maniera più compatta come
\end{flushleft}


\begin{flushleft}
Var
\end{flushleft}





[[[





\begin{flushleft}
n
\end{flushleft}





]]]





\begin{flushleft}
\~{} ] = Var[/\~{}a, X
\end{flushleft}


\~{} /]


\begin{flushleft}
\~{} ⋅X
\end{flushleft}


\begin{flushleft}
ai Xi = Var[a
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
ai aj Cov[Xi, Xj]
\end{flushleft}





=


\begin{flushleft}
i=1 j=1
\end{flushleft}





\begin{flushleft}
= \~{}a ⋅ $\Sigma$\~{}a =\~{}a t $\Sigma$\~{}a
\end{flushleft}


\begin{flushleft}
mettendo in evidenza che si tratta di prodotti interni di vettori (prodotto scalare o prodotto componente per componente). La notazione vettoriale o matriciale \`{e} particolarmente comoda in R per
\end{flushleft}


\begin{flushleft}
evitare i cicli for tutte le volte che possiamo scrivere il problema in modo equivalente come operazioni su matrici: il costo computazionale si riduce notevolmente e il codice \`{e} molto più leggibile.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.40. Valgono le seguenti disuguaglianze,
\end{flushleft}


\begin{flushleft}
$-$ Var[X] Var[Y] ⩽ Cov[X, Y] ⩽ Var[X] Var[Y] .
\end{flushleft}


\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





(9.6)


□





\begin{flushleft}
Se a valori grandi di X corrispondono in genere valori grandi di Y e a valori piccoli della prima
\end{flushleft}


\begin{flushleft}
corrispondono valori piccoli della seconda, allora Cov[X, Y] $>$ 0 e diciamo che le due variabili
\end{flushleft}


\begin{flushleft}
aleatorie sono positivamente correlate. Se invece a valori grandi di X corrispondono in genere valori
\end{flushleft}


\begin{flushleft}
piccoli di Y e, viceversa, a valori piccoli di X corrispondono valori grandi di Y, Cov[X, Y] $<$ 0 e
\end{flushleft}


\begin{flushleft}
diciamo che le due variabili aleatorie sono negativamente correlate.
\end{flushleft}


\begin{flushleft}
Esempio 9.41. Sono esempi di variabili aleatorie correlate il livello degli studi completati e il
\end{flushleft}


\begin{flushleft}
reddito, mentre il numero di core di un calcolatore e il tempo di calcolo sono variabili aleatorie
\end{flushleft}


\begin{flushleft}
negativamente correlate.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.42. Date due variabili aleatorie X e Y, chiamiamo correlazione o coefficiente di correlazione lineare il numero reale
\end{flushleft}


\begin{flushleft}
𝜌(X, Y) = corr[X, Y] =
\end{flushleft}





\begin{flushleft}
Cov[X, Y]
\end{flushleft}


.


\begin{flushleft}
Var[X] Var[Y]
\end{flushleft}





\begin{flushleft}
La correlazione 𝜌(X, Y) tra due variabili aleatorie \`{e}, per la (9.6), un numero in [$-$1, 1] ed \`{e} una
\end{flushleft}


\begin{flushleft}
versione normalizzata della covarianza. In particolare 𝜌 $\approx$ 1 indica un'alta correlazione positiva
\end{flushleft}


\begin{flushleft}
tra le due variabili, 𝜌 $\approx$ $-$1 indica un'alta correlazione negativa e 𝜌 $\approx$ 0 indica correlazione bassa o
\end{flushleft}


\begin{flushleft}
assente.
\end{flushleft}


\begin{flushleft}
Esempio 9.43. Avendo definito la covarianza, possiamo ora calcolare la varianza delle ipergeometriche. Sia X $\sim$ hyp(k, m, n).
\end{flushleft}





\begin{flushleft}
\newpage
9.6 ALTRI INDICATORI DI UNA DISTRIBUZIONE
\end{flushleft}





137





\begin{flushleft}
Come abbiamo visto nella Sotto-sezione 9.1.1 nel calcolare la speranza di una ipergeometrica,
\end{flushleft}


\begin{flushleft}
possiamo scrivere X = ∑ki=1 Yi, dove ogni Yi \`{e} una variabile aleatoria che indica se la i-sima biglia
\end{flushleft}


\begin{flushleft}
estratta \`{e} bianca oppure no. Le Yi non sono tra loro indipendenti, ma sono identicamente distrim
\end{flushleft}


\begin{flushleft}
buite come Bernoulliane di parametro m + n .
\end{flushleft}


\begin{flushleft}
Partendo dalla (9.5) possiamo scrivere
\end{flushleft}


\begin{flushleft}
Var[X] = Var
\end{flushleft}





[[


[





\begin{flushleft}
k
\end{flushleft}





]]


]





\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
Yi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Cov[Yi, Yj].
\end{flushleft}





\begin{flushleft}
Var[Yi] + 2
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
1⩽i$<$ j⩽k
\end{flushleft}





\begin{flushleft}
nm
\end{flushleft}





\begin{flushleft}
Conosciamo Var[Yi] = (n + m)2 (indipendente da i), quindi dobbiamo calcolare
\end{flushleft}


\begin{flushleft}
Cov[Yi, Yj] = E[Yi Yj] $-$ E[Yi] E[Yj].
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Sappiamo gi\`{a} le medie E[Yi] =E[Yj] = m + n , non ci resta che ricavare E[Yi Yj]. Per farlo, osserviamo
\end{flushleft}


\begin{flushleft}
che Yi Yj assume solamente i valori 0 o 1: sono binomiali di parametro p = P(Yi Yj = 1) (che \`{e} anche
\end{flushleft}


\begin{flushleft}
la media) ed \`{e} quindi l'ultimo ingrediente che ci occorre,
\end{flushleft}


\begin{flushleft}
E[Yi Yj] = P(Yi Yj = 1) = P(Yi = 1, Yj = 1) = P(Yi = 1) P(Yj = 1 ∣ Yi = 1)
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
n2 $-$ n
\end{flushleft}


=


⋅


=


.


\begin{flushleft}
n + m n + m $-$ 1 (n + m) (n + m $-$ 1)
\end{flushleft}


\begin{flushleft}
La covarianza \`{e} quindi
\end{flushleft}


\begin{flushleft}
Cov[Yi, Yj] =
\end{flushleft}





\begin{flushleft}
n2 $-$ n
\end{flushleft}


\begin{flushleft}
n2
\end{flushleft}


\begin{flushleft}
n3 + n2 m $-$ n2 $-$ n m $-$ n3 $-$ n2 m + n2
\end{flushleft}


$-$


=


.


2


\begin{flushleft}
(n + m) (n + m $-$ 1) (n + m)
\end{flushleft}


\begin{flushleft}
(n + m)2 (n + m $-$ 1)
\end{flushleft}





\begin{flushleft}
Ora possiamo mettere assieme il tutto,
\end{flushleft}


\begin{flushleft}
nm
\end{flushleft}


\begin{flushleft}
nm
\end{flushleft}


\begin{flushleft}
Var[X] = k ⋅
\end{flushleft}


\begin{flushleft}
$-$ k (k $-$ 1)
\end{flushleft}


\begin{flushleft}
(n + m)2
\end{flushleft}


\begin{flushleft}
(n + m)2 (n + m $-$ 1)
\end{flushleft}


\begin{flushleft}
knm
\end{flushleft}


\begin{flushleft}
k $-$1
\end{flushleft}


=


1$-$


.


\begin{flushleft}
n+m$-$1
\end{flushleft}


\begin{flushleft}
(n + m)2
\end{flushleft}





((





))





\begin{flushleft}
Un'ultima osservazione: nel caso con reimmissione in un'urna di uguale composizione, la varianza
\end{flushleft}


\begin{flushleft}
knm
\end{flushleft}


\begin{flushleft}
k $-$1
\end{flushleft}


\begin{flushleft}
sarebbe (n + m)2 , quindi la {``}penalit\`{a}'' dovuta alla mancata reimmissione \`{e} un fattore n + m $-$ 1 , che
\end{flushleft}


\begin{flushleft}
per un'urna molto grande (ossia per n + m $\rightarrow$ +$\infty$) diventa trascurabile.
\end{flushleft}





\begin{flushleft}
9.6. ALTRI INDICATORI DI UNA DISTRIBUZIONE
\end{flushleft}





\begin{flushleft}
Lezione 18
\end{flushleft}





\begin{flushleft}
Se torniamo agli indicatori di una sola variabile aleatoria, speranza e varianza non esauriscono le
\end{flushleft}


\begin{flushleft}
opzioni disponibili. Vediamo alcuni indicatori particolarmente importanti.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.44. Chiamiamo mediana di una variabile aleatoria X un numero mX tale che
\end{flushleft}


\begin{flushleft}
P(X ⩽ m X ) = P(X ⩾ mX ).
\end{flushleft}





(9.7)





\begin{flushleft}
Osservazione 9.45. Cerchiamo un valore m X che sia al centro della distribuzione nel senso
\end{flushleft}


\begin{flushleft}
seguente: la probabilit\`{a} che una realizzazione di X sia minore o uguale di m X \`{e} uguale alla pro1
\end{flushleft}


\begin{flushleft}
babilit\`{a} che sia maggiore o uguale di m X , cio\`{e} sono entrambe uguali a 2 . Questo m X \`{e} al centro
\end{flushleft}


\begin{flushleft}
della distribuzione, ma in un senso diverso da quello della media.
\end{flushleft}


\begin{flushleft}
Possiamo riscrivere la caratterizzazione della mediana (9.7) in termini della funzione di ripar1
\end{flushleft}


\begin{flushleft}
tizione di X: m X \`{e} tale che FX (m X ) = 1 $-$ F X (mX ), cio\`{e} F X (mX ) = 2 , quindi ci verrebbe da dire che
\end{flushleft}


1


\begin{flushleft}
m X = F $-$1 2 , ma non sappiamo se F X sia invertibile, quindi possiamo solamente affermare che
\end{flushleft}





\begin{flushleft}
m X $\in$ F $-$1 2 , cio\`{e} appartiene alla preimmagine di 2 . Consideriamo ora separatamente i casi in
\end{flushleft}


\begin{flushleft}
cui X sia discreta o assolutamente continua. Iniziamo da quest'ultimo.
\end{flushleft}


\begin{flushleft}
Se X \`{e} assolutamente continua, FX \`{e} una funzione continua e monotona crescente tra 0 e 1,
\end{flushleft}


1


\begin{flushleft}
quindi l'insieme F $-$1 2 \`{e} non vuoto, ma non \`{e} detto che sia un singoletto e quindi non \`{e} detto
\end{flushleft}


\begin{flushleft}
che esista la mediana. Un controesempio all'unicit\`{a} della mediana \`{e} rappresentato in Figura 9.1.
\end{flushleft}


1





1





\newpage
138





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
FX fX
\end{flushleft}


1





1/2





0





1





1/2





\begin{flushleft}
x
\end{flushleft}





3/2





\begin{flushleft}
Figura 9.1. Esempio di non unicit\`{a} della mediana: tutti i punti dell'intervallo
\end{flushleft}





1


,1


2





\begin{flushleft}
sono mediane.
\end{flushleft}





\begin{flushleft}
Nel caso in cui X sia una variabile aleatoria discreta, le cose possono andare anche peggio: non
\end{flushleft}


\begin{flushleft}
solo la mediana pu\`{o} non essere unica, ma pu\`{o} addirittura non esistere, infatti in questo caso la
\end{flushleft}


1


\begin{flushleft}
funzione di ripartizione F X non \`{e} più continua, quindi FX$-$1 2 pu\`{o} essere vuoto.
\end{flushleft}


\begin{flushleft}
Esempio 9.46. Sia X $\sim$ bin 1, 2 : allora per ogni x $\in$ (0, 1) abbiamo P(X ⩽ x) = P(X = 0) = 2 , ma
\end{flushleft}


1





1





\begin{flushleft}
anche P(X ⩾ x) = P(X = 1) = 2 , quindi ogni x nell'intervallo aperto9.8 (0, 1) \`{e} una mediana di X.
\end{flushleft}


1





\begin{flushleft}
FX ϕX
\end{flushleft}





1





1/2





\begin{flushleft}
x
\end{flushleft}


0





1





\begin{flushleft}
Figura 9.2. Tutti i punti in (0, 1) sono mediane.
\end{flushleft}





\begin{flushleft}
Esempio 9.47. Definiamo ora la variabile aleatoria discreta X nel modo seguente:
\end{flushleft}





\begin{flushleft}
\{\{ 0 con probabilit\`{a}
\end{flushleft}


\begin{flushleft}
X=\{
\end{flushleft}


\begin{flushleft}
\{\{ 1 con probabilit\`{a}
\end{flushleft}


\begin{flushleft}
\{\{ 2 con probabilit\`{a}
\end{flushleft}


\begin{flushleft}
In questo caso, come vediamo nella Figura 9.3 F X$-$1
\end{flushleft}





1


2





1


6


1


2


1


.


3





= $\emptyset$.





\begin{flushleft}
FX ϕX
\end{flushleft}





1


2/3


1/2


1/3


1/6


0





1





2





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 9.3. La variabile aleatoria X non ammette mediana.
\end{flushleft}


\begin{flushleft}
9.8. Gli estremi non sono inclusi, come mai?
\end{flushleft}





\begin{flushleft}
\newpage
9.6 ALTRI INDICATORI DI UNA DISTRIBUZIONE
\end{flushleft}





139





\begin{flushleft}
Per ogni x $\in$ ($-$$\infty$, 1) abbiamo
\end{flushleft}


1


5


\begin{flushleft}
P(X ⩽ x) ⩽ P(X = 0) =
\end{flushleft}


\begin{flushleft}
P(X ⩾ x) ⩾ P((X = 1) $\cup$ (X = 2)) =
\end{flushleft}


6


6


\begin{flushleft}
cio\`{e} tutti questi x sono troppo sbilanciati verso sinistra rispetto a quella che vorremmo come
\end{flushleft}


\begin{flushleft}
mediana9.9. Allo stesso tempo per ogni x $\in$ (1, +$\infty$)
\end{flushleft}


2


1


\begin{flushleft}
P(X ⩽ x) ⩾ P((X = 0) $\cup$ (X = 1)) =
\end{flushleft}


\begin{flushleft}
P(X ⩾ x) ⩽ P(X = 2) =
\end{flushleft}


3


3


\begin{flushleft}
quindi questi valori di x sono {``}troppo a destra'' per essere delle mediane. Non ci resta che sperare
\end{flushleft}


\begin{flushleft}
in x = 1, ma
\end{flushleft}


2 5


\begin{flushleft}
P(X ⩽ 1) = $\neq$ = P(X ⩾ 1).
\end{flushleft}


3 6


\begin{flushleft}
Questa variabile aleatoria, allora, non ammette alcuna mediana secondo la Definizione 9.44.
\end{flushleft}


\begin{flushleft}
Dal momento che pu\`{o} essere utile avere un concetto di mediana definito per ogni variabile
\end{flushleft}


\begin{flushleft}
aleatoria, possiamo darne una definizione indebolita.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.48. Chiamiamo mediana impropria di una variabile aleatoria X un numero reale m̃X tale
\end{flushleft}


1


1


\begin{flushleft}
che P(X ⩽ m̃ X ) ⩾ 2 e P(X ⩾ m̃ X ) ⩾ 2 .
\end{flushleft}


\begin{flushleft}
Osservazione 9.49. Con questa definizione, la mediana impropria \`{e} il valore soglia tra quelli
\end{flushleft}


\begin{flushleft}
{``}troppo a sinistra'' e quelli {``}troppo a destra'', anche se non soddisfa l'uguaglianza (9.7). La variabile aleatoria X nell'Esempio 9.47 ammette come mediana impropria m̃ X = 1.
\end{flushleft}


\begin{flushleft}
Possiamo ora pensare di generalizzare quanto visto per la mediana, cercando i punti in cui
\end{flushleft}


\begin{flushleft}
{``}tagliare'' una distribuzione in modo che una realizzazione della variabile aleatoria corrispondente abbia una probabilit\`{a} predeterminata di essere minore o uguale al taglio. In altre parole,
\end{flushleft}


\begin{flushleft}
fissiamo p $\in$ [0, 1] e cerchiamo i numeri reali x per cui P(X ⩽ x) = FX (x) = p.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.50. Dati una variabile aleatoria X di legge FX e p $\in$ (0, 1), chiamiamo quantile p (o pquantile) il numero reale Q X (p) tale che
\end{flushleft}


\begin{flushleft}
QX (p) = inf \{x $\in$ ℝ : FX (x) ⩾ p\}.
\end{flushleft}





(9.8)





\begin{flushleft}
Osservazione 9.51. Per p = 2 abbiamo qualcosa di molto simile alla mediana, ma in questo caso
\end{flushleft}


\begin{flushleft}
viene sempre scelto un solo valore9.10. Non solo, dal momento che la funzione di ripartizione FX
\end{flushleft}


\begin{flushleft}
\`{e} sempre continua a destra, l'inf nella (9.8) \`{e} in realt\`{a} un minimo.
\end{flushleft}


\begin{flushleft}
Se la funzione di ripartizione F X \`{e} continua e strettamente crescente, allora per ogni p $\in$ (0, 1)
\end{flushleft}


\begin{flushleft}
abbiamo che Q X (p) \`{e} proprio quel valore che soddisfa FX (Q X (p)) = p. Più in generale se F X \`{e}
\end{flushleft}


\begin{flushleft}
invertibile in quel punto, allora Q X (p) = FX$-$1(p).
\end{flushleft}


1





\begin{flushleft}
DEFINIZIONE 9.52. Chiamiamo funzione quantile della variabile aleatoria X la funzione
\end{flushleft}


\begin{flushleft}
Q : p ↦ Q X (p)
\end{flushleft}


\begin{flushleft}
che associa ad ogni p il quantile corrispondente.
\end{flushleft}


\begin{flushleft}
Abbiamo menzionato più volte prima d'ora le funzioni quantile associate alle varie distribuzioni. Possiamo usarle per calcolare quale sia il punto x che si lascia a sinistra al più probabilit\`{a} p.
\end{flushleft}


\begin{flushleft}
Per esempio, se X \`{e} una variabile aleatoria di Poisson di parametro 𝜆 = 2, la funzione qpois(p
\end{flushleft}


\begin{flushleft}
= 1/3, lambda = 2) ci restituisce 1, infatti
\end{flushleft}


\begin{flushleft}
9.9. Cosa intendiamo con {``}troppo a sinistra'' o {``}troppo a destra''? La mediana \`{e} (almeno moralmente) il punto in cui
\end{flushleft}


\begin{flushleft}
la funzione di ripartizione FX e il suo complemento a 1, 1$-$FX si bilanciano. Sappiamo per\`{o} che al crescere di x la funzione
\end{flushleft}


1


\begin{flushleft}
FX (x) \`{e} crescente e, conseguentemente, la funzione 1$-$FX (x) \`{e} decrescente. Quindi se FX (x) $<$ 2 siamo {``}troppo a sinistra'',
\end{flushleft}


1


\begin{flushleft}
mentre se 1 $-$ FX (x) $<$ 2 siamo {``}troppo a destra''.
\end{flushleft}


\begin{flushleft}
9.10. Quale?
\end{flushleft}





\newpage
140





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
F X (1) = P(X ⩽ 1) $\approx$ 40\%
\end{flushleft}


\begin{flushleft}
e, per x $\in$ (0, 1),
\end{flushleft}


\begin{flushleft}
FX (x) = F X (0) = P(X ⩽ 0) $\approx$ 14\%.
\end{flushleft}


\begin{flushleft}
Possiamo anche per la funzione quantile, come per la funzione di ripartizione, specificare la
\end{flushleft}


\begin{flushleft}
{``}coda'' della distribuzione cui siamo interessati: di default \`{e} (come per la funzione di ripartizione) lower.tail = TRUE, ossia guardiamo la coda sinistra. Se invece ci interessa la coda
\end{flushleft}


\begin{flushleft}
destra, possiamo passare il valore lower.tail = FALSE. In questo caso la funzione ci restituir\`{a} il più piccolo valore di x per cui P(X $>$ x) = 1 $-$ F X (x) ⩽ p. In pratica
\end{flushleft}





\begin{flushleft}
qpois(p,lambda,FALSE)=qpois(1-p,lambda,TRUE)
\end{flushleft}


\begin{flushleft}
e questo vale anche per le altre distribuzioni.
\end{flushleft}


\begin{flushleft}
Osservazione 9.53. Per alcune scelte di p i quantili hanno nomi particolari:
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
$-$ per p = 4 , con k $\in$ \{1, 2, 3\} parliamo di quartili (primo, secondo e terzo);
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
$-$ per p = 10 , con k $\in$ \{1, . . . , 9\} parliamo di decili;
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





\begin{flushleft}
$-$ per p = 100 , con k $\in$ \{1, . . . , 99\} parliamo di percentili.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.54. Chiamiamo moda di una variabile aleatoria X un numero x $\in$ ℛ X tale che
\end{flushleft}


\begin{flushleft}
$-$ se X \`{e} discreta, 𝜑 X \`{e} massima in x, cio\`{e} x $\in$ argmax y 𝜑 X (y)
\end{flushleft}


\begin{flushleft}
$-$ se X \`{e} assolutamente continua, f X \`{e} massima in x, cio\`{e} x $\in$ argmax y fX (y).
\end{flushleft}


\begin{flushleft}
Il caso discreto ci suggerisce quale sia il significato intuitivo della moda: \`{e} il valore più probabile (o meglio, uno dei valori più probabili). Questo non \`{e} del tutto corretto nel caso in cui X sia
\end{flushleft}


\begin{flushleft}
assolutamente continua, visto che la probabilit\`{a} nei punti \`{e} sempre nulla.
\end{flushleft}


\begin{flushleft}
Come accennato, non \`{e} detto che la moda di una distribuzione sia unica. Se lo \`{e} diciamo che
\end{flushleft}


\begin{flushleft}
\`{e} una legge unimodale, se ha due mode diciamo che \`{e} bimodale e in generale se non \`{e} unimodale
\end{flushleft}


\begin{flushleft}
allora \`{e} multimodale.
\end{flushleft}


\begin{flushleft}
Esempio 9.55. Vediamo alcuni esempi di variabili aleatorie e delle loro mode.
\end{flushleft}


\begin{flushleft}
ϕX
\end{flushleft}





\begin{flushleft}
ϕX
\end{flushleft}





1/2





\begin{flushleft}
ϕX
\end{flushleft}





1/2


1/3


1/6





1/4


0





1





2





\begin{flushleft}
x
\end{flushleft}





0





1





\begin{flushleft}
x
\end{flushleft}





0





1





2





3





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 9.4. Tre variabili discrete. Nella prima la moda \`{e} 1, nella seconda sia 0 sia 1 sono mode, nella terza sia 0
\end{flushleft}


\begin{flushleft}
sia 2 sono mode.
\end{flushleft}





\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
0 x0
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
x0
\end{flushleft}





\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
x1
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





0





1





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 9.5. Tre variabili assolutamente continue. Nella prima la moda \`{e} x0, nella seconda sono mode x0 e x1, nella
\end{flushleft}


\begin{flushleft}
terza tutti i punti tra 0 e 1 sono mode.
\end{flushleft}





\begin{flushleft}
Osservazione 9.56. Nel caso continuo potrebbe venirci la tentazione di prendere la derivata della
\end{flushleft}


\begin{flushleft}
funzione densit\`{a} e cercare i punti in cui si annulla. Purtroppo non sempre funziona, come possiamo vedere dagli esempi in Figura 9.6.
\end{flushleft}





\begin{flushleft}
\newpage
9.6 ALTRI INDICATORI DI UNA DISTRIBUZIONE
\end{flushleft}





141





\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





0





0





1





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 9.6. Due variabili assolutamente continue. Nella prima la moda \`{e} 0, ma la derivata \`{e} nulla per x $<$ 0 e per
\end{flushleft}


\begin{flushleft}
x $>$ 1. Nella seconda la moda \`{e} in corrispondenza dell'asintoto verticale in 0 (la densit\`{a} in corrispondenza della
\end{flushleft}


\begin{flushleft}
moda \`{e} infinita).
\end{flushleft}





\begin{flushleft}
Osservazione 9.57. Media, mediana e moda sono tre modi diversi per predire il valore di una
\end{flushleft}


\begin{flushleft}
variabile aleatoria, ottimizzando su criteri diversi.
\end{flushleft}


\begin{flushleft}
La media \`{e} il valore che minimizza lo scarto (o errore) quadratico medio: per ogni c $\in$ ℝ
\end{flushleft}


\begin{flushleft}
E[(X $-$ c)2] =
\end{flushleft}


=


=


⩾





\begin{flushleft}
E[(X $-$ E[X] + E[X] $-$ c)2]
\end{flushleft}


\begin{flushleft}
E[(X $-$ E[X])2] + 2 (E[X] $-$ c) E[X $-$ E[X]] + (E[X] $-$ c)2
\end{flushleft}


\begin{flushleft}
E[(X $-$ E[X])2] + (E[X] $-$ c)2
\end{flushleft}


\begin{flushleft}
E[(X $-$ E[X])2]
\end{flushleft}





\begin{flushleft}
dal momento che (E[X] $-$ c)2 ⩾ 0.
\end{flushleft}


\begin{flushleft}
La mediana, invece, minimizza la media dell'errore assoluto: per ogni c $\in$ ℝ
\end{flushleft}


\begin{flushleft}
E[|X $-$ c|] ⩾ E[|X $-$ m X |].
\end{flushleft}


\begin{flushleft}
Vediamolo nel caso in cui X sia assolutamente continua:
\end{flushleft}


\begin{flushleft}
E[|X $-$ c|] =
\end{flushleft}


=





+$\infty$


$-$$\infty$


\begin{flushleft}
c
\end{flushleft}


$-$$\infty$





\begin{flushleft}
|x $-$ c| f X (x) dx
\end{flushleft}





\begin{flushleft}
$-$(x $-$ c) f X (x) dx +
\end{flushleft}





+$\infty$


\begin{flushleft}
c
\end{flushleft}





\begin{flushleft}
(x $-$ c) fX (x) dx.
\end{flushleft}





\begin{flushleft}
Volendo minimizzare questa quantit\`{a} al variare di c ne possiamo prendere la derivata in c e porla
\end{flushleft}


\begin{flushleft}
uguale a 0:
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
d c
\end{flushleft}


\begin{flushleft}
d +$\infty$
\end{flushleft}


\begin{flushleft}
E[|X $-$ c|] = $-$
\end{flushleft}


\begin{flushleft}
(x $-$ c) f X (x) dx +
\end{flushleft}


\begin{flushleft}
(x $-$ c) f X (x) dx
\end{flushleft}


\begin{flushleft}
dc
\end{flushleft}


\begin{flushleft}
dc $-$$\infty$
\end{flushleft}


\begin{flushleft}
dc c
\end{flushleft}


\begin{flushleft}
c
\end{flushleft}


+$\infty$


= $-$


\begin{flushleft}
fX (x) dx +
\end{flushleft}


\begin{flushleft}
fX (x) dx
\end{flushleft}


$-$$\infty$





\begin{flushleft}
c
\end{flushleft}





\begin{flushleft}
da cui segue che il minimo di E[|X $-$ c|] \`{e} in corrispondenza di c̃ tale che
\end{flushleft}


\begin{flushleft}
c̃
\end{flushleft}





\begin{flushleft}
ossia di c̃ per cui
\end{flushleft}





$-$$\infty$





\begin{flushleft}
fX (x) dx =
\end{flushleft}





+$\infty$


\begin{flushleft}
c̃
\end{flushleft}





\begin{flushleft}
fX (x) dx
\end{flushleft}





\begin{flushleft}
FX (c̃) = 1 $-$ F X (c̃),
\end{flushleft}


\begin{flushleft}
ma questa \`{e} proprio la caratterizzazione (9.7) della mediana nel caso X sia assolutamente continua.
\end{flushleft}


\begin{flushleft}
La moda, infine, \`{e} il valore che massimizza la probabilit\`{a}.
\end{flushleft}


\begin{flushleft}
In generale questi tre numeri non coincidono. Quello {``}giusto'' da usare dipende dal contesto.
\end{flushleft}


\begin{flushleft}
Esempio 9.58. Supponiamo di avere un d6 sbilanciato in cui 1 esce con probabilit\`{a} 6 + 5 𝜀 e le altre
\end{flushleft}


1


\begin{flushleft}
facce ciascuna con probabilit\`{a} 6 $-$ 𝜀, per 𝜀 = 10 $-$3. In questo caso la media (o valore atteso) \`{e} 3.485,
\end{flushleft}


\begin{flushleft}
la mediana non \`{e} definita e la mediana impropria \`{e} 3. La moda \`{e} 1.
\end{flushleft}


1





\newpage
142





\begin{flushleft}
SPERANZA, VARIANZA E ALTRI INDICATORI
\end{flushleft}





\begin{flushleft}
Se vogliamo scommettere su un numero ci conviene scegliere la moda, se vogliamo minimizzare l'errore assoluto tra il numero che scegliamo e il numero che esce, scegliamo la mediana
\end{flushleft}


\begin{flushleft}
(impropria) e se vogliamo minimizzare l'errore quadratico medio scegliamo il valore atteso.
\end{flushleft}


\begin{flushleft}
Per finire questa carrellata sugli indicatori, vediamone alcuni associati ai momenti centrati di
\end{flushleft}


\begin{flushleft}
ordine superiore a 2.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 9.59. Chiamiamo skewness di una variabile aleatoria X il suo momento terzo centrato e
\end{flushleft}


\begin{flushleft}
standardizzato, cio\`{e}
\end{flushleft}


\begin{flushleft}
sk[X] = E
\end{flushleft}





\begin{flushleft}
$-$ E[X] ) ] E[(X $-$ E[X]) ]
\end{flushleft}


\begin{flushleft}
[[[((( XVar[X]
\end{flushleft}


\begin{flushleft}
)) ]] = Var[X] .
\end{flushleft}


3





3





3





\begin{flushleft}
La skewness \`{e} un indicatore della simmetria di X: se X \`{e} simmetrica, allora sk[X]= 0 (ma non \`{e}
\end{flushleft}


\begin{flushleft}
necessariamente vero il viceversa), se sk[X] $>$0 la variabile aleatoria X ha una {``}scentratura'' verso
\end{flushleft}


\begin{flushleft}
sinistra rispetto alla media, se sk[X] $<$ 0 ha una {``}scentratura'' verso destra.
\end{flushleft}





\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
0 E[X]
\end{flushleft}





0





\begin{flushleft}
E[X]
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 9.7. Due variabili aleatorie continue. Quella di sinistra ha skewness positiva, quella di destra ha skewness
\end{flushleft}


\begin{flushleft}
negativa.
\end{flushleft}





\begin{flushleft}
DEFINIZIONE 9.60. Chiamiamo curtosi o kurtosis di una variabile aleatoria X il suo momento quarto
\end{flushleft}


\begin{flushleft}
centrato e standardizzato, cio\`{e}
\end{flushleft}


\begin{flushleft}
kr[X] = E
\end{flushleft}





\begin{flushleft}
[[[((( X $-$ E[X] ))) ]]] = E[(X $-$ E[X]) ] .
\end{flushleft}


\begin{flushleft}
(Var[X])
\end{flushleft}


\begin{flushleft}
Var[X]
\end{flushleft}


4





4





2





\begin{flushleft}
La kurtosis misura la concentrazione di una distribuzione e in questo caso il valore soglia \`{e} 3:
\end{flushleft}


\begin{flushleft}
una variabile con kurtosis maggiore di 3 ha un picco molto alto della densit\`{a} attorno alla media e
\end{flushleft}


\begin{flushleft}
delle code pesanti. Viceversa una variabile con kurtosis minore di 3 ha un {``}plateau'' attorno alla
\end{flushleft}


\begin{flushleft}
sua media e code leggere. Il metro di paragone (con kurtosis uguale a 3) \`{e} la variabile normale
\end{flushleft}


\begin{flushleft}
standard.
\end{flushleft}





\begin{flushleft}
9.7. SPERANZA E VARIANZA CONDIZIONATE
\end{flushleft}


\begin{flushleft}
Come abbiamo gi\`{a} accennato nell'introdurre il concetto di speranza, ma anche nel calcolare la
\end{flushleft}


\begin{flushleft}
speranza delle geometriche, ha senso parlare di speranza condizionata e per definirla non dobbiamo fare altro che considerare al posto di P la probabilit\`{a} condizionata a un evento, P(⋅ ∣ E) e
\end{flushleft}


\begin{flushleft}
dunque la densit\`{a} (discreta) della variabile aleatoria di interesse condizionata a tale evento.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.61. Date una partizione (E i)i di $\Omega$ in eventi disgiunti e una variabile aleatoria X vale
\end{flushleft}


\begin{flushleft}
EX [X] =
\end{flushleft}





\begin{flushleft}
E X [X ∣ Ei] P(Ei),
\end{flushleft}


\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
\newpage
9.7 SPERANZA E VARIANZA CONDIZIONATE
\end{flushleft}





143





\begin{flushleft}
identit\`{a} che prende il nome di fattorizzazione della speranza9.11.
\end{flushleft}


\begin{flushleft}
COROLLARIO 9.62. Siano Y una variabile aleatoria discreta e X una variabile aleatoria qualsiasi. Allora
\end{flushleft}


\begin{flushleft}
EX [X] =
\end{flushleft}





\begin{flushleft}
EX [X ∣ Y = y] P(Y = y) = EY[E X [X ∣ Y]].
\end{flushleft}


\begin{flushleft}
y$\in$ℛ X
\end{flushleft}





\begin{flushleft}
Dimostrazione. Supponiamo che anche X sia una variabile aleatoria discreta. Allora
\end{flushleft}


\begin{flushleft}
E Y[EX [X ∣ Y]] =
\end{flushleft}





\begin{flushleft}
EX [X ∣ Y = y] P(Y = y)
\end{flushleft}


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
x⋅
\end{flushleft}





=


\begin{flushleft}
y$\in$ℛ Y x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





=


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
P(X = x, Y = y)
\end{flushleft}


\begin{flushleft}
P(Y = y)
\end{flushleft}


\begin{flushleft}
P(Y = y)
\end{flushleft}





\begin{flushleft}
P(X = x, Y = y)
\end{flushleft}


\begin{flushleft}
y$\in$ℛ Y
\end{flushleft}





\begin{flushleft}
x P(X = x)
\end{flushleft}





=


\begin{flushleft}
x$\in$ℛ X
\end{flushleft}





\begin{flushleft}
= E X [X]
\end{flushleft}


\begin{flushleft}
in cui abbiamo marginalizzato in X la densit\`{a} discreta congiunta.
\end{flushleft}





□





\begin{flushleft}
Osservazione 9.63. Risultati analoghi valgono anche per variabili aleatorie assolutamente continue, con l'accortezza di usare le densit\`{a} al posto delle densit\`{a} discrete.
\end{flushleft}


\begin{flushleft}
Osservazione 9.64. Possiamo notare che E[X ∣Y] \`{e} essa stessa una variabile aleatoria. La sua parte
\end{flushleft}


\begin{flushleft}
{``}casuale'' \`{e} ereditata da Y. Ad esempio, se Y $\sim$ bin(1, p) allora
\end{flushleft}


\begin{flushleft}
E[X ∣ Y] =
\end{flushleft}





\begin{flushleft}
∣ Y = 0] con probabilit\`{a} 1 $-$ p
\end{flushleft}


\begin{flushleft}
\{\{ E[X
\end{flushleft}


\begin{flushleft}
E[X ∣ Y = 1] con probabilit\`{a} p.
\end{flushleft}





\begin{flushleft}
Come abbiamo introdotto la speranza condizionata, possiamo definire anche la varianza condizionata: sia F un evento, allora
\end{flushleft}


\begin{flushleft}
Var[X ∣ F] = E[(X $-$ E[X ∣ F])2 ∣ F] =
\end{flushleft}





\begin{flushleft}
\{\{\{ ∑ (x $-$ E[X ∣ F]) 𝜑 (x ∣ F)
\end{flushleft}


\begin{flushleft}
∫ (x $-$ E[X ∣ F]) f (x ∣ F) dx.
\end{flushleft}


2





\begin{flushleft}
x
\end{flushleft}





2





\begin{flushleft}
X∣F
\end{flushleft}





\begin{flushleft}
X∣F
\end{flushleft}





\begin{flushleft}
Nel caso particolare in cui F \`{e} determinato da una variabile aleatoria Y (che supponiamo discreta)
\end{flushleft}


\begin{flushleft}
Var[X ∣ Y = y] =
\end{flushleft}





\begin{flushleft}
\{\{ ∑ (x $-$ E[X ∣ Y = y]) 𝜑 (x ∣ y)
\end{flushleft}


\begin{flushleft}
\{ ∫(x $-$ E[X ∣ Y = y]) f (x ∣ y) dx,
\end{flushleft}


2





\begin{flushleft}
x
\end{flushleft}





2





\begin{flushleft}
X∣Y
\end{flushleft}





\begin{flushleft}
X∣Y
\end{flushleft}





\begin{flushleft}
in cui l'ultima densit\`{a} congiunta \`{e} mista. Anche Var[X ∣ Y] pu\`{o} essere vista come una variabile
\end{flushleft}


\begin{flushleft}
aleatoria che eredita la casualit\`{a} da Y.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 9.65. Date due variabili aleatorie X e Y vale la seguente identit\`{a}
\end{flushleft}


\begin{flushleft}
VarX [X] = E Y[VarX [X ∣ Y]] + Var Y[EX [X ∣ Y]],
\end{flushleft}


\begin{flushleft}
detta scomposizione (o fattorizzazione) della varianza.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Riscriviamo il secondo membro dell'uguaglianza
\end{flushleft}


\begin{flushleft}
E Y[VarX [X ∣ Y]] + Var Y[EX [X ∣ Y]] = E Y[EX [X 2 ∣Y]$-$ EX [X ∣Y]2] +EY[E X [X∣ Y]2]$-$ (EY[E X [X∣ Y]])2
\end{flushleft}


\begin{flushleft}
= E Y[EX [X 2 ∣ Y]] $-$ E X [X]2
\end{flushleft}


\begin{flushleft}
= E X [X 2] $-$ EX [X]2 = Var X [X]
\end{flushleft}


\begin{flushleft}
in cui abbiamo usato la linearit\`{a} della speranza e, due volte, il Corollario 9.62.
\end{flushleft}





□





\begin{flushleft}
9.11. La notazione E X serve per mettere in evidenza che si tratta della speranza associata alla variabile aleatoria X. In
\end{flushleft}


\begin{flushleft}
realt\`{a} non \`{e} necessario indicarlo e di solito non lo si fa.
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
CAPITOLO 10
\end{flushleft}


\begin{flushleft}
MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}


\begin{flushleft}
In analogia a quanto fatto nel Capitolo 8 per le variabili aleatorie discrete, vediamo ora alcuni
\end{flushleft}


\begin{flushleft}
modelli di variabili aleatorie assolutamente continue.
\end{flushleft}





\begin{flushleft}
10.1. UNIFORMI
\end{flushleft}


\begin{flushleft}
Le abbiamo gi\`{a} incontrate più volte, ma diamone comunque una definizione.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 10.1. Dati due numeri reali a $<$ b, chiamiamo uniforme su [a, b] una variabile aleatoria
\end{flushleft}


\begin{flushleft}
assolutamente continua X la cui densit\`{a} fX \`{e} costante in [a, b] e nulla altrove. Scriviamo in questo caso
\end{flushleft}


\begin{flushleft}
X $\sim$ unif[a, b] o X $\sim$ unif(a, b).
\end{flushleft}


\begin{flushleft}
Come abbiamo gi\`{a} visto, il valore costante non nullo c di f X in [a, b] \`{e} determinato da a e b:
\end{flushleft}


1=


\begin{flushleft}
da cui ricaviamo
\end{flushleft}





\begin{flushleft}
ℝ
\end{flushleft}





\begin{flushleft}
fX (x) dx =
\end{flushleft}





\begin{flushleft}
fX (x) =
\end{flushleft}





\begin{flushleft}
b
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\{\{


\{0





1


\begin{flushleft}
b$-$a
\end{flushleft}





\begin{flushleft}
c dx = c (b $-$ a),
\end{flushleft}





\begin{flushleft}
x $\in$ (a, b)
\end{flushleft}


\begin{flushleft}
x $\in$ [a, b]c.
\end{flushleft}





\begin{flushleft}
Per definizione la funzione di ripartizione \`{e} l'integrale della densit\`{a}, quindi per X $\sim$ unif[a, b],
\end{flushleft}


0


\{


\{


\begin{flushleft}
F (x) = \{
\end{flushleft}


\{\{ 1





\begin{flushleft}
x $-$a
\end{flushleft}


\begin{flushleft}
b$-$a
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
x⩽a
\end{flushleft}


\begin{flushleft}
a⩽x⩽b
\end{flushleft}


\begin{flushleft}
x ⩾ b.
\end{flushleft}





\begin{flushleft}
Esempio 10.2. La variabile aleatoria uniforme su [1, 3] \`{e} rappresentata in Figura 10.1.
\end{flushleft}





\begin{flushleft}
FX fX
\end{flushleft}





0





1





3





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
Figura 10.1. Funzione di ripartizione e di densit\`{a} di X $\sim$ unif(1, 3).
\end{flushleft}





\begin{flushleft}
10.1.1. Uniformi in R
\end{flushleft}


\begin{flushleft}
La funzione densit\`{a} per un'uniforme \`{e} la funzione dunif(x, min = 0, max = 1). Con
\end{flushleft}


\begin{flushleft}
x indichiamo il punto in cui la vogliamo calcolare, mentre min \`{e} il primo estremo dell'intervallo
\end{flushleft}


\begin{flushleft}
(quello che abbiamo indicato con a) e max il secondo estremo (b nella definizione vista prima).
\end{flushleft}


145





\newpage
146





\begin{flushleft}
MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}





\begin{flushleft}
Abbiamo poi la funzione punif(q, min=0, max = 1, lower.tail = TRUE) che
\end{flushleft}


\begin{flushleft}
ci permette di calcolare, in q, la funzione di ripartizione, con il consueto parametro per determinare quale coda ci interessa.
\end{flushleft}


\begin{flushleft}
La funzione quantile \`{e} qunif(p, min = 0, max = 1, lower.tail = TRUE) e
\end{flushleft}


\begin{flushleft}
il generatore casuale \`{e} runif(n, min = 0, max = 1).
\end{flushleft}





\begin{flushleft}
10.1.2. Indicatori per le uniformi
\end{flushleft}


\begin{flushleft}
Possiamo calcolare gli indicatori per X $\sim$ unif[a, b].
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
b2 $-$ a2
\end{flushleft}


\begin{flushleft}
a+b
\end{flushleft}


\begin{flushleft}
= 2 , come
\end{flushleft}


2


\begin{flushleft}
a+b 2
\end{flushleft}


\begin{flushleft}
(b $-$ a)2
\end{flushleft}


= 12 .


2





\begin{flushleft}
$-$ Speranza: E[X] = ∫a x ⋅ b $-$ a dx = b $-$ a ⋅
\end{flushleft}


1





1





\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
$-$ Varianza: Var[X] = ∫a x 2 ⋅ b $-$ a dx $-$
\end{flushleft}


1





\begin{flushleft}
$-$ Mediana: coincide con la media.
\end{flushleft}





\begin{flushleft}
ci saremmo aspettati.
\end{flushleft}





\begin{flushleft}
$-$ Moda: qualunque valore in (a, b).
\end{flushleft}


\begin{flushleft}
$-$ Skewness: sk[X] =
\end{flushleft}


\begin{flushleft}
integrali,
\end{flushleft}





\begin{flushleft}
E[(X $-$ E[X])3]
\end{flushleft}


\begin{flushleft}
Var[X]
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





3/


2





\begin{flushleft}
= 0, per simmetria della distribuzione, oppure calcolando gli
\end{flushleft}





\begin{flushleft}
(x $-$ a +2 b ) dx =
\end{flushleft}





\begin{flushleft}
b$-$a
\end{flushleft}


2





3





\begin{flushleft}
a$-$b
\end{flushleft}


2





\begin{flushleft}
y 3 dy =
\end{flushleft}





2


\begin{flushleft}
b$-$a
\end{flushleft}





+1


$-$1





\begin{flushleft}
a+b
\end{flushleft}





\begin{flushleft}
z 3 dz = 0,
\end{flushleft}





\begin{flushleft}
b$-$a
\end{flushleft}





\begin{flushleft}
in cui abbiamo fatto i due cambi di variabile y = x $-$ 2 e z = 2 y e abbiamo sfruttato il fatto
\end{flushleft}


\begin{flushleft}
che z 3 \`{e} dispari e integrata in un dominio simmetrico rispetto a 0.
\end{flushleft}


\begin{flushleft}
$-$ Kurtosis: kr[X] =
\end{flushleft}





\begin{flushleft}
E[(X $-$ E[X])4]
\end{flushleft}


\begin{flushleft}
Var[X]2
\end{flushleft}





1





⋅





\begin{flushleft}
(b $-$ a)5
\end{flushleft}





\begin{flushleft}
= b $-$ a(b $-$ a)804 = 5 .
\end{flushleft}


9





144





\begin{flushleft}
Esempio 10.3. Siamo in attesa alla fermata dell'autobus, che (in teoria) passa ogni 15'. Possiamo
\end{flushleft}


\begin{flushleft}
rappresentare il tempo che passiamo alla fermata tra il nostro arrivo e la salita sull'autobus come
\end{flushleft}


\begin{flushleft}
una variabile aleatoria uniforme X $\sim$ unif[0, 15].
\end{flushleft}


\begin{flushleft}
Qual \`{e} la probabilit\`{a} di aspettare più di 5'? Qual \`{e} la probabilit\`{a} che, avendo aspettato (senza
\end{flushleft}


\begin{flushleft}
successo) 5', ne dobbiamo aspettare ancora più di 5?
\end{flushleft}


1


\begin{flushleft}
Sappiamo che la funzione densit\`{a} \`{e} f X (x) = 15 1[0,15](x) e dunque che la funzione di ripartizione \`{e}
\end{flushleft}


\begin{flushleft}
0 x$<$0
\end{flushleft}


\begin{flushleft}
x
\end{flushleft}


\begin{flushleft}
FX (x) = 15 0 ⩽ x $<$ 15
\end{flushleft}


\begin{flushleft}
1 x ⩾ 15.
\end{flushleft}





\{\{


\{\{


\{





\begin{flushleft}
La prima domanda ci chiede di calcolare
\end{flushleft}


\begin{flushleft}
P(X $>$ 5) = 1 $-$ FX (5) = 1 $-$
\end{flushleft}


\begin{flushleft}
La seconda, invece, chiede
\end{flushleft}


\begin{flushleft}
P(X $>$ 10 ∣ X $>$ 5) =
\end{flushleft}





5 2


= .


15 3





\begin{flushleft}
P(X $>$ 10, X $>$ 5) 1 $-$ FX (10) 1 3 1
\end{flushleft}


=


= ⋅ = .


\begin{flushleft}
P(X $>$ 5)
\end{flushleft}


\begin{flushleft}
1 $-$ FX (5) 3 2 2
\end{flushleft}





\begin{flushleft}
Osservazione 10.4. Per generare realizzazioni di una variabile aleatoria di distribuzione assegnata F, possiamo generare realizzazioni di una distribuzione uniforme su [0, 1] (che non a caso
\end{flushleft}


\begin{flushleft}
\`{e} quella di default in R) e calcolarne la funzione quantile. Non \`{e} sempre il modo computazionalmente più efficiente.
\end{flushleft}





\begin{flushleft}
10.2. ESPONENZIALI
\end{flushleft}


\begin{flushleft}
Anche se non l'abbiamo ancora definita, \`{e} una variabile aleatoria che abbiamo incontrato spesso
\end{flushleft}


\begin{flushleft}
in esempi ed esercizi.
\end{flushleft}





\begin{flushleft}
\newpage
10.2 ESPONENZIALI
\end{flushleft}





147





\begin{flushleft}
DEFINIZIONE 10.5. Diciamo che una variabile aleatoria X \`{e} esponenziale di parametro 𝜆 $>$ 0 se ha
\end{flushleft}


\begin{flushleft}
densit\`{a}
\end{flushleft}


0


\begin{flushleft}
x$<$0
\end{flushleft}


\begin{flushleft}
f X (x) =
\end{flushleft}


\begin{flushleft}
$-$𝜆x
\end{flushleft}


\begin{flushleft}
c⋅e
\end{flushleft}


\begin{flushleft}
x ⩾ 0.
\end{flushleft}





\{\{\{





\begin{flushleft}
In questo caso scriviamo X $\sim$ exp(𝜆) o X $\sim$ expo(𝜆). Il parametro 𝜆 prende anche il nome di intensit\`{a} o
\end{flushleft}


\begin{flushleft}
rate dell'esponenziale.
\end{flushleft}


\begin{flushleft}
Da quanto visto sulle costanti di rinormalizzazione, ricaviamo che c = 𝜆. La funzione di ripartizione di X $\sim$ exp(𝜆) \`{e}
\end{flushleft}


0


\begin{flushleft}
x$<$0
\end{flushleft}


\begin{flushleft}
F X (x) =
\end{flushleft}


\begin{flushleft}
$-$𝜆x
\end{flushleft}


\begin{flushleft}
1$-$e
\end{flushleft}


\begin{flushleft}
x ⩾ 0.
\end{flushleft}





\{\{\{





\begin{flushleft}
FX fX
\end{flushleft}


1





\begin{flushleft}
x
\end{flushleft}





0


\begin{flushleft}
Figura 10.2. Funzione di ripartizione e di densit\`{a} di X $\sim$ exp(1).
\end{flushleft}





\begin{flushleft}
In Figura 10.2 sono rappresentate le funzioni di ripartizione e di densit\`{a} dell'esponenziale di
\end{flushleft}


\begin{flushleft}
rate 1. Al variare di 𝜆 abbiamo comportamenti leggermente diversi. In particolare: l'intercetta
\end{flushleft}


\begin{flushleft}
sulle ordinate \`{e} 𝜆 e la pendenza delle curve \`{e} maggiore se 𝜆 $>$ 1 e minore se 𝜆 $<$ 1.
\end{flushleft}





\begin{flushleft}
10.2.1. Esponenziali in R
\end{flushleft}


\begin{flushleft}
La famiglia delle funzioni associate all'esponenziale in R prende il nome exp. Abbiamo dunque
\end{flushleft}


\begin{flushleft}
la densit\`{a} dexp(x, rate = 1), la funzione di ripartizione pexp(q, rate = 1, lower.tail = TRUE) e le funzioni quantile qexp(p, rate = 1, lower.tail = TRUE)
\end{flushleft}


\begin{flushleft}
e generatore casuale rexp(n, rate = 1).
\end{flushleft}





\begin{flushleft}
10.2.2. Indicatori per le esponenziali
\end{flushleft}


\begin{flushleft}
Possiamo calcolare gli indicatori per X $\sim$ exp(𝜆).
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
$-$ Speranza: E[X] = ∫a x ⋅ 𝜆 ⋅ e $-$𝜆x dx = 𝜆
\end{flushleft}


\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
$-$ Varianza: Var[X] = ∫a x 2 ⋅ 𝜆 ⋅ e $-$𝜆x dx $-$
\end{flushleft}





+$\infty$


\begin{flushleft}
e $-$𝜆x
\end{flushleft}


1


\begin{flushleft}
(𝜆 x $-$ 1)
\end{flushleft}


\begin{flushleft}
= 𝜆 , ossia il reciproco
\end{flushleft}


\begin{flushleft}
𝜆2
\end{flushleft}


0


1


1


\begin{flushleft}
= 𝜆2 , integrando per parti.
\end{flushleft}


\begin{flushleft}
𝜆2
\end{flushleft}





\begin{flushleft}
del rate.
\end{flushleft}





\begin{flushleft}
$-$ Mediana: dal momento che F X \`{e} monotona strettamente crescente per x $>$ 0, dobbiamo risol1
\end{flushleft}


1


\begin{flushleft}
vere 1 $-$ e $-$𝜆x = 2 , cio\`{e} $-$𝜆 x = log 2 , da cui x = log(2) ⋅ 𝜆$-$1.
\end{flushleft}


\begin{flushleft}
$-$ Moda: \`{e} il punto di massimo di f X , ossia 0.
\end{flushleft}


\begin{flushleft}
$-$ Skewness: sk[X] =
\end{flushleft}


\begin{flushleft}
$-$ Kurtosis: kr[X] =
\end{flushleft}





\begin{flushleft}
E[(X $-$ E[X])3]
\end{flushleft}


\begin{flushleft}
Var[X]
\end{flushleft}





3/


2





\begin{flushleft}
E[(X $-$ E[X])4]
\end{flushleft}


\begin{flushleft}
Var[X]2
\end{flushleft}





= 2.





= 9.





\begin{flushleft}
Esempio 10.6. Siamo sempre alla fermata dell'autobus come nell'Esempio 10.3 e il tempo medio
\end{flushleft}


15


\begin{flushleft}
di attesa \`{e} ancora una volta 2 . Questa volta, per\`{o}, ipotizziamo che il tempo di attesa per l'arrivo
\end{flushleft}


\begin{flushleft}
dell'autobus sia distribuito come un'esponenziale.
\end{flushleft}





\newpage
148





\begin{flushleft}
MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}





\begin{flushleft}
Qual \`{e} la probabilit\`{a} di aspettare più di 5'? Qual \`{e} la probabilit\`{a} che, avendo aspettato (senza
\end{flushleft}


\begin{flushleft}
successo) 5', ne dobbiamo aspettare ancora più di 5?
\end{flushleft}


2


\begin{flushleft}
Sapendo la media, possiamo ricavare immediatamente il rate dell'esponenziale: 𝜆 = 15 . Per
\end{flushleft}


\begin{flushleft}
rispondere alla prima domanda dobbiamo calcolare
\end{flushleft}


\begin{flushleft}
P(X $>$ 5) = 1 $-$ FX (5) = e
\end{flushleft}





2





$-$ 15 ⋅5





$\approx$ 0.51.





\begin{flushleft}
Per la seconda, invece,
\end{flushleft}


\begin{flushleft}
P(X $>$ 10 ∣ X $>$ 5) =
\end{flushleft}





4


2


2


\begin{flushleft}
1 $-$ FX (10)
\end{flushleft}


$-$


$-$


\begin{flushleft}
= e 3 ⋅ e 3 = e 3 = P(X $>$ 5) $\approx$ 0.51.
\end{flushleft}


\begin{flushleft}
1 $-$ FX (5)
\end{flushleft}





\begin{flushleft}
Il fatto di aver aspettato 5' non fa diminuire la probabilit\`{a} che dobbiamo aspettarne altri 5.
\end{flushleft}


\begin{flushleft}
La descrizione \`{e} abbastanza diversa da quella vista nell'Esempio 10.3: qui possiamo anche
\end{flushleft}


\begin{flushleft}
osservare che la probabilit\`{a} di aspettare più di mezz'ora (nulla nel caso della distribuzione uniforme) \`{e} P(X $>$ 30) = 1 $-$ F X (30) = e $-$4 $\approx$ 0.02.
\end{flushleft}


\begin{flushleft}
Lezione 19
\end{flushleft}





\begin{flushleft}
La risposta alla seconda domanda nell'Esempio 10.6 ci suggerisce che anche per le esponenziali, così come per le geometriche, valga la propriet\`{a} di assenza di memoria.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 10.7. Se X \`{e} una variabile aleatoria esponenziale, allora ha assenza di memoria, ossia per s,
\end{flushleft}


\begin{flushleft}
t $>$0
\end{flushleft}


\begin{flushleft}
P(X $>$ s + t ∣ X $>$ s) = P(X $>$ t).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Basta sfruttare la forma della funzione di ripartizione:
\end{flushleft}


\begin{flushleft}
P(X $>$ s + t, X $>$ s)
\end{flushleft}


\begin{flushleft}
P(X $>$ s)
\end{flushleft}


\begin{flushleft}
1 $-$ FX (s + t)
\end{flushleft}


=


\begin{flushleft}
1 $-$ FX (s)
\end{flushleft}


\begin{flushleft}
= e $-$𝜆(s+t) ⋅ e 𝜆s
\end{flushleft}


\begin{flushleft}
= e $-$𝜆t = 1 $-$ FX (t) = P(X $>$ t)
\end{flushleft}





\begin{flushleft}
P(X $>$ s + t ∣ X $>$ s) =
\end{flushleft}





\begin{flushleft}
semplicemente usando le propriet\`{a} dell'esponenziale.
\end{flushleft}





□





\begin{flushleft}
Osservazione 10.8. Le variabili aleatorie esponenziali sono la controparte continua delle geometriche. Possiamo usarle per descrivere i tempi d'attesa di eventi casuali con assenza di memoria,
\end{flushleft}


\begin{flushleft}
ossia che non diventano più probabili solo perch\'{e} sono {``}in ritardo''. \`{E} anche possibile caratterizzare le esponenziali come limite di variabili aleatorie geometriche.
\end{flushleft}


\begin{flushleft}
Esempio 10.9. Se X $\sim$ exp(𝜆) e Y = 𝛼 X, (con 𝛼 $>$ 0) allora Y $\sim$ exp
\end{flushleft}


\begin{flushleft}
posizione 6.3 che
\end{flushleft}


1


\begin{flushleft}
y
\end{flushleft}


\begin{flushleft}
𝜆 $-$𝜆 y
\end{flushleft}


\begin{flushleft}
f Y(y) = f X
\end{flushleft}


\begin{flushleft}
= e 𝛼.
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
𝜆
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
. Infatti sappiamo dalla Pro-
\end{flushleft}





\begin{flushleft}
10.3. GAUSSIANE O NORMALI
\end{flushleft}


\begin{flushleft}
\`{E} la famiglia più nota e diffusa di variabili aleatorie (vedremo nel prossimo capitolo una delle
\end{flushleft}


\begin{flushleft}
ragioni), dalla caratteristica forma {``}a campana'' della funzione di densit\`{a}. Possiamo averla senza
\end{flushleft}


\begin{flushleft}
parametri (normale standard) oppure con parametri espliciti.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 10.10. Diciamo che una variabile aleatoria X \`{e} una normale (o Gaussiana) standard se ha
\end{flushleft}


\begin{flushleft}
densit\`{a}
\end{flushleft}


\begin{flushleft}
x2
\end{flushleft}


1


$-$


\begin{flushleft}
f X (x) =
\end{flushleft}


\begin{flushleft}
e 2.
\end{flushleft}


\begin{flushleft}
2$\pi$
\end{flushleft}


\begin{flushleft}
Scriviamo in questo caso X $\sim$ 𝒩(0, 1).
\end{flushleft}





\begin{flushleft}
\newpage
10.3 GAUSSIANE O NORMALI
\end{flushleft}





149





\begin{flushleft}
Osservazione 10.11. Consideriamo i vari elementi della funzione densit\`{a} e capiamone il ruolo:
\end{flushleft}


\begin{flushleft}
$-$ il termine e $-$x ci d\`{a} la forma a campana
\end{flushleft}


2





\begin{flushleft}
$-$ il coefficiente
\end{flushleft}


\begin{flushleft}
$-$ il coefficiente
\end{flushleft}





\begin{flushleft}
a esponente semplifica la derivazione
\end{flushleft}





1


2





1


\begin{flushleft}
2$\pi$
\end{flushleft}





\begin{flushleft}
\`{e} la costante di rinormalizzazione (vedi anche Appendice A.3).
\end{flushleft}





\begin{flushleft}
Inoltre possiamo osservare alcune propriet\`{a} della densit\`{a} di una Gaussiana standard, rappresentata in Figura 10.3:
\end{flushleft}


\begin{flushleft}
$-$ \`{e} simmetrica rispetto all'asse x = 0, quindi f X ($-$x) = fX (x)
\end{flushleft}


\begin{flushleft}
$-$ ha massimo in x = 0, con valore 1/
\end{flushleft}





\begin{flushleft}
2$\pi$ $\approx$ 0.4
\end{flushleft}





\begin{flushleft}
$-$ ha flessi in x = $\pm$1 e in tali punti ha valore
\end{flushleft}


\begin{flushleft}
$-$ in $\pm$2 ha valore e
\end{flushleft}


\begin{flushleft}
$-$ in $\pm$3 ha valore
\end{flushleft}





2





\begin{flushleft}
2$\pi$
\end{flushleft}





\begin{flushleft}
e9 2 $\pi$
\end{flushleft}





$-$1





\begin{flushleft}
e2$\pi$
\end{flushleft}





$-$1





$\approx$ 0.24





$\approx$ 0.05





$-$1





$\approx$ 0.004.





\begin{flushleft}
fX
\end{flushleft}


$\surd$


\begin{flushleft}
1/ 2$\pi$
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}


-3





-2





-1





0





1





2





3





\begin{flushleft}
Figura 10.3. Densit\`{a} di una normale standard
\end{flushleft}





\begin{flushleft}
La funzione di ripartizione di una variabile aleatoria normale standard X \`{e}
\end{flushleft}


\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
F X (x) =
\end{flushleft}





\begin{flushleft}
x2
\end{flushleft}


1


$-$


\begin{flushleft}
e 2 dx ≔$\Phi$(x).
\end{flushleft}


\begin{flushleft}
2$\pi$
\end{flushleft}





$-$$\infty$





\begin{flushleft}
Non \`{e} un integrale con soluzione algebrica (anche se siamo in grado di calcolarlo in 0 e $\pm$$\infty$). Per
\end{flushleft}


\begin{flushleft}
sapere il valore di $\Phi$ in un certo punto, possiamo usare le tavole (riportate in molti libri e anche
\end{flushleft}


\begin{flushleft}
qui in Appendice B), oppure usare un software (ad esempio R).
\end{flushleft}





\begin{flushleft}
$\Phi$
\end{flushleft}


1





1/2





0.025


\begin{flushleft}
x
\end{flushleft}


-3





-2





-1





0





1





2





3





\begin{flushleft}
Figura 10.4. Funzione di ripartizione di una normale standard
\end{flushleft}





\newpage
150





\begin{flushleft}
MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}





\begin{flushleft}
Osservazione 10.12. Anche $\Phi$, come gi\`{a} la densit\`{a}, ha alcune propriet\`{a} interessanti, che possiamo
\end{flushleft}


\begin{flushleft}
anche vedere nella Figura 10.4
\end{flushleft}


\begin{flushleft}
$-$ \`{e} simmetrica rispetto al punto 0, 2 , quindi $\Phi$($-$x) = 1 $-$ $\Phi$(x)
\end{flushleft}


1





\begin{flushleft}
$-$ in x = 0 vale
\end{flushleft}





1


2





\begin{flushleft}
$-$ in x = $-$2 vale circa 0.0228, in x = 2 vale circa 0.9772
\end{flushleft}


\begin{flushleft}
$-$ in x = $-$3 vale circa 0.0013, in x = 3 vale circa 0.9987.
\end{flushleft}


\begin{flushleft}
In particolare abbiamo che, per X $\sim$ 𝒩(0, 1), P(X $\in$ ($-$3, 3)) $\approx$ 0.997 e P(X $\in$ ($-$2, 2)) $\approx$ 0.95. La funzione di densit\`{a} \`{e} non nulla su tutto ℝ e quindi X pu\`{o} assumere valori su tutto ℝ, ma in realt\`{a}
\end{flushleft}


\begin{flushleft}
le realizzazioni saranno con alta probabilit\`{a} concentrate in un intervallo centrato in 0 e di larghezza 6.
\end{flushleft}


\begin{flushleft}
La funzione quantile di una normale standard \`{e} l'inversa $\Phi$ $-$1 della funzione di ripartizione $\Phi$.
\end{flushleft}


\begin{flushleft}
Abbiamo
\end{flushleft}


\begin{flushleft}
$\Phi$ $-$1(p) = x ⟺ $\Phi$(x) = p ⟺ P(X ⩽ x) = p.
\end{flushleft}


\begin{flushleft}
La funzione quantile (definita sull'intervallo [0, 1]) \`{e} simmetrica rispetto al punto
\end{flushleft}


\begin{flushleft}
$\Phi$ $-$1(p) = $-$$\Phi$ $-$1(1 $-$ p).
\end{flushleft}





1


,0


2





\begin{flushleft}
, quindi
\end{flushleft}





\begin{flushleft}
10.3.1. Indicatori per la normale standard
\end{flushleft}


\begin{flushleft}
Sia X $\sim$ 𝒩(0, 1). Cominciamo col calcolarne la speranza:
\end{flushleft}


\begin{flushleft}
E[X] =
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
x fX (x) dx =
\end{flushleft}





+$\infty$


0





\begin{flushleft}
$-$x f X ($-$x) dx +
\end{flushleft}





+$\infty$


0





\begin{flushleft}
x fX (x) dx =
\end{flushleft}





+$\infty$


0





\begin{flushleft}
0 ⋅ fX (x) dx = 0.
\end{flushleft}





\begin{flushleft}
In altre parole, grazie alla simmetria rispetto a x = 0 abbiamo che E[X] = 0. Osserviamo che anche
\end{flushleft}


\begin{flushleft}
mediana e moda sono in x = 0.
\end{flushleft}


\begin{flushleft}
Passiamo ora alla varianza:
\end{flushleft}


\begin{flushleft}
Var[X] =
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
x2
\end{flushleft}





[[


[





\begin{flushleft}
x2
\end{flushleft}


\begin{flushleft}
x2
\end{flushleft}


1


1


$-$


$-$


\begin{flushleft}
e 2 dx = $-$x
\end{flushleft}


\begin{flushleft}
e 2
\end{flushleft}


\begin{flushleft}
2$\pi$
\end{flushleft}


\begin{flushleft}
2$\pi$
\end{flushleft}





+$\infty$





]]


]





+


$-$$\infty$





+$\infty$


$-$$\infty$





\begin{flushleft}
x2
\end{flushleft}


1


$-$


\begin{flushleft}
e 2 dx = 1,
\end{flushleft}


\begin{flushleft}
2$\pi$
\end{flushleft}





\begin{flushleft}
in cui abbiamo integrato per parti e usato il fatto che f X \`{e} una densit\`{a} di probabilit\`{a}. Possiamo
\end{flushleft}


\begin{flushleft}
anche calcolare skewness e kurtosis: ricaviamo sk[X] = 0 (per simmetria) e kr[X] = 3.
\end{flushleft}


\begin{flushleft}
Possiamo per\`{o} osservare che, pur non avendo dichiarato che la normale standard non ha
\end{flushleft}


\begin{flushleft}
parametri, l'abbiamo definita come 𝒩(0, 1) e, ora, potremmo avere qualche sospetto su cosa siano
\end{flushleft}


\begin{flushleft}
quei due numeri.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 10.13. Sia Z $\sim$ 𝒩(0, 1) una normale standard. Chiamiamo Gaussiana (o normale) di
\end{flushleft}


\begin{flushleft}
parametri 𝜇 $\in$ ℝ e 𝜎 $\in$ ℝ+0 una variabile aleatoria X tale che X = 𝜎 Z + 𝜇. In questo caso scriviamo X $\sim$
\end{flushleft}


\begin{flushleft}
𝒩(𝜇, 𝜎).
\end{flushleft}


\begin{flushleft}
Osservazione 10.14. Possiamo facilmente ricavare densit\`{a} e funzione di ripartizione di una Gaussiana di parametri 𝜇 e 𝜎, infatti \`{e} per definizione una trasformazione (lineare) di una variabile
\end{flushleft}


\begin{flushleft}
X$-$𝜇
\end{flushleft}


\begin{flushleft}
aleatoria di cui conosciamo la legge: X = 𝜎 Z + 𝜇, ossia Z = 𝜎 , cio\`{e} Z \`{e} centrata e standardizzata.
\end{flushleft}


\begin{flushleft}
A partire dalla legge di Z possiamo scrivere la funzione di ripartizione di X
\end{flushleft}


\begin{flushleft}
F X (x) = P(X ⩽ x) = P(𝜎 Z + 𝜇 ⩽ x) = P Z ⩽
\end{flushleft}


\begin{flushleft}
così come la sua densit\`{a}
\end{flushleft}





\begin{flushleft}
x$-$𝜇
\end{flushleft}


\begin{flushleft}
x$-$𝜇
\end{flushleft}


\begin{flushleft}
x$-$𝜇
\end{flushleft}


\begin{flushleft}
= FZ
\end{flushleft}


\begin{flushleft}
=$\Phi$
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
(x$-$𝜇)
\end{flushleft}


\begin{flushleft}
x$-$𝜇
\end{flushleft}


1


1


$-$


\begin{flushleft}
f X (x) = f Z
\end{flushleft}


=


\begin{flushleft}
e 2𝜎 2 .
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
2$\pi$𝜎2
\end{flushleft}


2





(10.1)





\begin{flushleft}
In particolare possiamo calcolare la funzione di ripartizione usando la stessa funzione (o le stesse
\end{flushleft}


\begin{flushleft}
tavole) definite per la funzione di ripartizione $\Phi$ della normale standard.
\end{flushleft}





\begin{flushleft}
\newpage
10.3 GAUSSIANE O NORMALI
\end{flushleft}





151





\begin{flushleft}
10.3.2. Indicatori per una normale
\end{flushleft}


\begin{flushleft}
Se X $\sim$ 𝒩(𝜇, 𝜎), possiamo ricavare facilmente i suoi indicatori usando il fatto che \`{e} una trasformazione lineare di una normale standard:
\end{flushleft}


\begin{flushleft}
E[X] = E[𝜎 Z + 𝜇] = 𝜎 E[Z] + 𝜇 = 𝜇
\end{flushleft}


\begin{flushleft}
per la speranza (ma anche per la mediana e la moda) e
\end{flushleft}


\begin{flushleft}
Var[X] = Var[𝜎 Z + 𝜇] = 𝜎 2 Var[Z] = 𝜎 2
\end{flushleft}


\begin{flushleft}
per la varianza. I due parametri che caratterizzano una distribuzione normale sono la sua media
\end{flushleft}


\begin{flushleft}
e la sua deviazione standard (o equivalentemente la sua varianza 𝜎 2).
\end{flushleft}


\begin{flushleft}
Skewness e kurtosis sono invariate, rispetto a una normale standard: sk[X] = 0, dal momento
\end{flushleft}


\begin{flushleft}
3𝜎4
\end{flushleft}


\begin{flushleft}
che la simmetria rispetto al valore atteso non \`{e} venuta meno, e kr[X] = 𝜎 4 = 3.
\end{flushleft}


\begin{flushleft}
Osservazione 10.15. Si pu\`{o} equivalentemente usare la varianza come secondo parametro di una
\end{flushleft}


\begin{flushleft}
normale. Questo \`{e} comodo perch\'{e} semplifica alcune scritture, in particolare quella per la somma
\end{flushleft}


\begin{flushleft}
di due Gaussiane, come vedremo tra poco, e nel momento in cui passiamo alle Gaussiane multivariate, nelle quali entra in gioco la matrice di covarianza. In queste note abbiamo scelto di usare
\end{flushleft}


\begin{flushleft}
la deviazione standard 𝜎 e non la varianza 𝜎 2 per allinearci alla convenzione usata da R.
\end{flushleft}


\begin{flushleft}
Osservazione 10.16. Siccome abbiamo trasformato linearmente una normale standard, la funzione di densit\`{a} sar\`{a} una traslazione e dilatazione della densit\`{a} di una normale standard, come
\end{flushleft}


\begin{flushleft}
possiamo vedere nella (10.1) o nella Figura 10.5.
\end{flushleft}


\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
$\mu$ $-$ 3$\sigma$
\end{flushleft}





\begin{flushleft}
$\mu$$-$$\sigma$
\end{flushleft}





\begin{flushleft}
$\mu$
\end{flushleft}





\begin{flushleft}
$\mu$ + 3$\sigma$x
\end{flushleft}





\begin{flushleft}
$\mu$+$\sigma$
\end{flushleft}





\begin{flushleft}
Figura 10.5. Densit\`{a} di una normale
\end{flushleft}





\begin{flushleft}
In 𝜇 abbiamo il massimo e in 𝜇 $\pm$ 𝜎 abbiamo i due flessi, e al di fuori dell'intervallo [𝜇 $-$ 3 𝜎,
\end{flushleft}


\begin{flushleft}
𝜇 + 3 𝜎] la densit\`{a} \`{e} molto piccola (pur non essendo nulla). Questo \`{e} importante in fase di modellizzazione: da un lato non \`{e} del tutto corretto usare una Gaussiana per descrivere un fenomeno
\end{flushleft}


\begin{flushleft}
aleatorio in cui sappiamo che i valori sono necessariamente all'interno di un intervallo, ma se
\end{flushleft}


\begin{flushleft}
vogliamo (o dobbiamo) farlo, \`{e} necessario che controlliamo almeno che le realizzazioni della
\end{flushleft}


\begin{flushleft}
variabile aleatoria che scegliamo cadano con altissima probabilit\`{a} all'interno dell'intervallo di
\end{flushleft}


\begin{flushleft}
interesse, cosa che \`{e} codificata nei parametri 𝜇 e 𝜎.
\end{flushleft}


\begin{flushleft}
Naturalmente, al variare di 𝜇 e 𝜎 varieranno il centro della densit\`{a}, l'altezza del massimo e la
\end{flushleft}


\begin{flushleft}
concentrazione della distribuzione, come vediamo ad esempio in Figura 10.6
\end{flushleft}





\begin{flushleft}
fX
\end{flushleft}





\begin{flushleft}
$\mu$ $-$ 3$\sigma$
\end{flushleft}





\begin{flushleft}
$\mu$$-$$\sigma$ $\mu$ $\mu$+$\sigma$
\end{flushleft}





\begin{flushleft}
$\mu$ + 3$\sigma$
\end{flushleft}





\begin{flushleft}
Figura 10.6. Densit\`{a} di un'altra normale
\end{flushleft}





\begin{flushleft}
x
\end{flushleft}





\newpage
152





\begin{flushleft}
MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}





\begin{flushleft}
PROPOSIZIONE 10.17. La famiglia delle distribuzioni Gaussiane \`{e} riproducibile. Date X1 $\sim$ 𝒩(𝜇1, 𝜎1) e
\end{flushleft}


\begin{flushleft}
X 2 $\sim$ 𝒩(𝜇2, 𝜎2) indipendenti,
\end{flushleft}


\begin{flushleft}
X1 + X 2 $\sim$ 𝒩 𝜇1 + 𝜇 2, 𝜎12 + 𝜎22
\end{flushleft}


\begin{flushleft}
ossia la loro somma \`{e} una Gaussiana di media la somma delle medie e di varianza la somma delle varianze.
\end{flushleft}


\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





□





\begin{flushleft}
Osservazione 10.18. Possiamo lasciar cadere l'ipotesi di indipendenza. Prese due qualunque
\end{flushleft}


\begin{flushleft}
Gaussiane X 1 $\sim$ 𝒩(𝜇 1, 𝜎1) e X 2 $\sim$ 𝒩(𝜇2, 𝜎2) aventi correlazione 𝜌 = corr[X 1, X2], la loro somma \`{e}
\end{flushleft}


\begin{flushleft}
una Gaussiana di media 𝜇1 + 𝜇2 e di varianza 𝜎12 + 𝜎22 + 2 𝜎1 𝜎2 𝜌, ossia uguale alla somma delle
\end{flushleft}


\begin{flushleft}
varianze, infatti
\end{flushleft}


\begin{flushleft}
Var[X1 + X 2] = Var[X1] + Var[X 2] + 2 Cov[X 1, X 2]
\end{flushleft}


\begin{flushleft}
= Var[X1] + Var[X 2] + 2 Corr[X 1, X 2] Var[X 1] Var[X 2] .
\end{flushleft}


\begin{flushleft}
Osservazione 10.19. Come abbiamo visto, possiamo calcolare la funzione di ripartizione di una
\end{flushleft}


\begin{flushleft}
Gaussiana appoggiandoci alla funzione di ripartizione $\Phi$ di una Gaussiana standard. Questa
\end{flushleft}


\begin{flushleft}
X$-$𝜇
\end{flushleft}


\begin{flushleft}
trasformazione X $\rightarrow$ 𝜎 prende il nome di standardizzazione ed entra in gioco non solo per la
\end{flushleft}


\begin{flushleft}
funzione di ripartizione, ma anche per la sua inversa, la funzione quantile $\Phi$ $-$1. Se stiamo cercando il p-quantile di X $\sim$ 𝒩(𝜇, 𝜎), il problema che vogliamo risolvere \`{e} trovare x $\in$ ℝ tale che
\end{flushleft}


\begin{flushleft}
P(X ⩽ x) = p. Cominciamo riscrivendo questa identit\`{a} mediante la standardizzazione, come gi\`{a}
\end{flushleft}


\begin{flushleft}
fatto in precedenza:
\end{flushleft}


\begin{flushleft}
x$-$𝜇
\end{flushleft}


\begin{flushleft}
x$-$𝜇
\end{flushleft}


\begin{flushleft}
p = P(X ⩽ x) = P Z ⩽
\end{flushleft}


\begin{flushleft}
=$\Phi$
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
e ora approfittiamo del fatto che la funzione $\Phi$ \`{e} invertibile per avere
\end{flushleft}


\begin{flushleft}
$\Phi$ $-$1(p) = $\Phi$ $-$1 $\Phi$
\end{flushleft}





\begin{flushleft}
x$-$𝜇
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





=





\begin{flushleft}
x$-$𝜇
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
che, scritta esplicitamente in x, ci d\`{a} x = 𝜎 $\Phi$ $-$1(p) + 𝜇.
\end{flushleft}





\begin{flushleft}
10.3.3. Gaussiane in R
\end{flushleft}


\begin{flushleft}
Le variabili aleatorie Gaussiane o normali sono descritte in R nella famiglia norm. In particolare,
\end{flushleft}


\begin{flushleft}
la densit\`{a} di una normale \`{e} dnorm(x, mean = 0, sd = 1), in cui mean \`{e} la media e sd \`{e}
\end{flushleft}


\begin{flushleft}
la deviazione standard. Osserviamo anche che, se non passiamo valori per questi due parametri,
\end{flushleft}


\begin{flushleft}
di default R considerer\`{a} la normale standard.
\end{flushleft}


\begin{flushleft}
La funzione di ripartizione \`{e} pnorm(q, mean=0, sd=1, lower.tail=TRUE),
\end{flushleft}


\begin{flushleft}
mentre la sua inversa (la funzione quantile) \`{e} qnorm(p, mean = 0, sd = 1, lower.tail = TRUE).
\end{flushleft}


\begin{flushleft}
Infine, per generare numeri casuali distribuiti secondo una Gaussiana, possiamo usare la funzione rnorm(n, mean = 0, sd = 1).
\end{flushleft}





\begin{flushleft}
10.3.4. Normali multivariate
\end{flushleft}


\begin{flushleft}
Abbiamo visto che possiamo considerare vettori aleatori invece di variabili aleatorie e che questi
\end{flushleft}


\begin{flushleft}
sono caratterizzati dalla loro densit\`{a} congiunta (nel caso assolutamente continuo). Vediamo ora
\end{flushleft}


\begin{flushleft}
un caso particolare, quello delle normali multivariate.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 10.20. Diciamo che un vettore aleatorio (X 1,..., X n) \`{e} una normale standard multivariata
\end{flushleft}


\begin{flushleft}
o vettore aleatorio normale standard se le sue componenti X i sono indipendenti e identicamente distribuite come normali standard, ossia X i $\sim$ 𝒩(0, 1). In questo caso scriviamo X $\sim$ 𝒩(𝟎, Id), con 𝟎 il vettore ndimensionale di soli 0 e Id la matrice identit\`{a} n × n.
\end{flushleft}


\begin{flushleft}
Osserviamo che in questo caso la densit\`{a} congiunta \`{e}
\end{flushleft}


\begin{flushleft}
fX1, . . . ,Xn(x1, . . . , xn) =
\end{flushleft}





1


1


1


1


1


1


\begin{flushleft}
$-$ 2 ∑ni =1xi2
\end{flushleft}


\begin{flushleft}
$-$ 2 𝒙⋅𝒙
\end{flushleft}


\begin{flushleft}
$-$ 2 𝒙 t𝒙
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


=


\begin{flushleft}
e
\end{flushleft}


=


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
(2 $\pi$)n
\end{flushleft}


\begin{flushleft}
(2 $\pi$)n
\end{flushleft}


\begin{flushleft}
(2 $\pi$)n
\end{flushleft}





\begin{flushleft}
\newpage
10.3 GAUSSIANE O NORMALI
\end{flushleft}





153





\begin{flushleft}
in cui abbiamo usato la notazione 𝒙 = (x 1, . . . , x n) per compattezza.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 10.21. Diciamo che un vettore aleatorio X = (X 1, . . . , X n) \`{e} una normale multivariata o
\end{flushleft}


\begin{flushleft}
vettore aleatorio normale (non degenere) se esistono un n-vettore aleatorio standard Z, un n-vettore
\end{flushleft}


\begin{flushleft}
colonna10.1 𝝁 e una matrice n × n 𝑴 tali che X = 𝑴 Z + 𝝁. In questo caso scriviamo X $\sim$ 𝒩(𝝁, 𝚺), dove
\end{flushleft}


\begin{flushleft}
𝚺 = 𝑴 𝑴 t.
\end{flushleft}


\begin{flushleft}
In questo caso la densit\`{a} congiunta \`{e}
\end{flushleft}


\begin{flushleft}
fX1, . . . ,Xn(x1, . . . , xn) =
\end{flushleft}





1


1


\begin{flushleft}
$-$ (𝒙$-$𝝁)t 𝚺 $-$1 (𝒙$-$𝝁)
\end{flushleft}


\begin{flushleft}
e 2
\end{flushleft}


.


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
|𝚺|(2 $\pi$)
\end{flushleft}





\begin{flushleft}
Il vettore 𝝁 \`{e} il vettore media e la matrice 𝚺 \`{e} la matrice di covarianza, con determinante |𝚺|. Nel
\end{flushleft}


\begin{flushleft}
caso particolare n = 2, 𝝁 = (𝜇 1, 𝜇 2)t e
\end{flushleft}


\begin{flushleft}
𝚺=
\end{flushleft}





\begin{flushleft}
(( 𝜎
\end{flushleft}


\begin{flushleft}
( 𝜌𝜎 𝜎
\end{flushleft}


2


1





1 2





))


)





\begin{flushleft}
𝜌 𝜎1 𝜎2
\end{flushleft}


,


\begin{flushleft}
𝜎22
\end{flushleft}





\begin{flushleft}
dove 𝜎i \`{e} la deviazione standard di Xi (e dunque 𝜎i2 ne \`{e} la varianza), 𝜌 = corr[X1, X 2] e quindi
\end{flushleft}


\begin{flushleft}
𝜌 𝜎1 𝜎2 = Cov[X1, X2]. Allora
\end{flushleft}


\begin{flushleft}
f X1,X2(x1, x2) =
\end{flushleft}





1


\begin{flushleft}
(2 $\pi$)2 𝜎12 𝜎22 (1 $-$ 𝜌 2)
\end{flushleft}





\begin{flushleft}
e
\end{flushleft}





$-$





1


\begin{flushleft}
2 1$-$𝜌 2
\end{flushleft}





\begin{flushleft}
x1$-$𝜇 1 2
\end{flushleft}


\begin{flushleft}
x $-$𝜇 x $-$𝜇
\end{flushleft}


\begin{flushleft}
x $-$𝜇 2
\end{flushleft}


\begin{flushleft}
$-$2𝜌 1𝜎 1 2𝜎 2 + 2𝜎 2
\end{flushleft}


\begin{flushleft}
𝜎1
\end{flushleft}


1


2


2





\begin{flushleft}
fX2 (x2 )
\end{flushleft}





\begin{flushleft}
fX1 ,X2
\end{flushleft}





\begin{flushleft}
fX1 (x1 )
\end{flushleft}


0.4


0.2


0


$-$1





4


0





3





\begin{flushleft}
fX1 ,X2 (x1 , x2 )
\end{flushleft}


0.15





2





1





0.1


\begin{flushleft}
x1
\end{flushleft}





2





1


3





\begin{flushleft}
x2
\end{flushleft}





0


4 $-$1





\begin{flushleft}
Figura 10.7. Una Gaussiana bivariata (𝜇 1 = 1, 𝜎1 = 0.5, 𝜇 2 = 2, 𝜎2 = 1, 𝜌 = 0)
\end{flushleft}


\begin{flushleft}
10.1. Vogliamo un vettore colonna, per moltiplicare meglio. In particolare anche X \`{e} un vettore aleatorio colonna.
\end{flushleft}





5 · 10$-$2


0





\newpage
154





\begin{flushleft}
MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}





\begin{flushleft}
fX2 (x2 )
\end{flushleft}





\begin{flushleft}
fX1 ,X2
\end{flushleft}





\begin{flushleft}
fX1 (x1 )
\end{flushleft}


0.4


0.2


0


$-$1





4


0





3





\begin{flushleft}
fX1 ,X2 (x1 , x2 )
\end{flushleft}


0.3





2





1


\begin{flushleft}
x1
\end{flushleft}





2





1


3





0.2


\begin{flushleft}
x2
\end{flushleft}





0.1





0





0





4 $-$1


\begin{flushleft}
Figura 10.8. Una Gaussiana bivariata (𝜇 1 = 1, 𝜎1 = 0.5, 𝜇 2 = 2, 𝜎2 = 1, 𝜌 = $-$0.75)
\end{flushleft}





\begin{flushleft}
10.4. CHI QUADRO
\end{flushleft}


\begin{flushleft}
Partiamo da una variabile aleatoria normale standard: X $\sim$ 𝒩(0, 1). Qual \`{e} la legge di Y = X 2?
\end{flushleft}


\begin{flushleft}
Abbiamo (per y ⩾ 0)
\end{flushleft}


\begin{flushleft}
FY(y) = P(X 2 ⩽ y) = P $-$ y ⩽ X ⩽ y = P X ⩽ y $-$ P X ⩽ $-$ y = 2 $\Phi$
\end{flushleft}


\begin{flushleft}
usando la propriet\`{a} di $\Phi$ per cui $-$$\Phi$ $-$ y = $-$ 1 $-$ $\Phi$
\end{flushleft}


\begin{flushleft}
f Y(y) =
\end{flushleft}





\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
2$\Phi$
\end{flushleft}


\begin{flushleft}
dy
\end{flushleft}





\begin{flushleft}
y $-$1 =
\end{flushleft}





\begin{flushleft}
y
\end{flushleft}





1


\begin{flushleft}
fX
\end{flushleft}


\begin{flushleft}
y
\end{flushleft}





\begin{flushleft}
y $-$1
\end{flushleft}





\begin{flushleft}
. Per la funzione densit\`{a} (per y $>$ 0),
\end{flushleft}


\begin{flushleft}
y
\end{flushleft}


1


$-$


\begin{flushleft}
e 2.
\end{flushleft}


\begin{flushleft}
2$\pi$y
\end{flushleft}





\begin{flushleft}
y =
\end{flushleft}





\begin{flushleft}
Prendiamo ora due normali standard tra loro indipendenti X 1 e X2 e siano Y1 = X12 e Y2 = X 22 i
\end{flushleft}


\begin{flushleft}
loro quadrati. Qual \`{e} la legge della variabile aleatoria Z = Y1 + Y2?
\end{flushleft}


\begin{flushleft}
Abbiamo
\end{flushleft}


\begin{flushleft}
F Z(z) = P(X12 + X22 ⩽ z) =
\end{flushleft}





\begin{flushleft}
A
\end{flushleft}





\begin{flushleft}
fX1,X2(x1, x2) dx1 dx2 =
\end{flushleft}





\begin{flushleft}
A
\end{flushleft}





\begin{flushleft}
1 $-$ 12 (x12+x22)
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
dx1 dx2
\end{flushleft}


\begin{flushleft}
2$\pi$
\end{flushleft}





\begin{flushleft}
in cui abbiamo usato nell'ultima uguaglianza l'indipendenza tra X 1 e X 2. Qual \`{e} il dominio di
\end{flushleft}


\begin{flushleft}
integrazione A? \`{E} l'insieme dei punti (x1, x 2) del piano ℝ2 tali che x 12 + x22 ⩽ z, ossia (per z ⩾ 0)
\end{flushleft}





\begin{flushleft}
\newpage
10.4 CHI QUADRO
\end{flushleft}





155





\begin{flushleft}
il cerchio centrato in (0, 0) e di raggio $\surd$z . Allora (passando a coordinate polari, ossia raggio e
\end{flushleft}


\begin{flushleft}
angolo)
\end{flushleft}


\begin{flushleft}
F Z(z) =
\end{flushleft}





\begin{flushleft}
A
\end{flushleft}





\begin{flushleft}
1 $-$ 12 r 2
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
r d𝜗 dr =
\end{flushleft}


\begin{flushleft}
2$\pi$
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}





\begin{flushleft}
$\surd$z
\end{flushleft}


0





$-$


\begin{flushleft}
e f Z(z) = FZ′ (z) = 2 e 2 per z ⩾ 0, ossia Z $\sim$ exp
\end{flushleft}


1





1


2





1


1


1


\begin{flushleft}
$-$ r2
\end{flushleft}


\begin{flushleft}
$-$ r2
\end{flushleft}


\begin{flushleft}
r e 2 2 $\pi$ dr = $-$e 2
\end{flushleft}


\begin{flushleft}
2$\pi$
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}


\begin{flushleft}
$\surd$z
\end{flushleft}


$-$2


\begin{flushleft}
0 =1$-$e
\end{flushleft}





.





\begin{flushleft}
DEFINIZIONE 10.22. Se una variabile aleatoria X \`{e} la somma dei quadrati di n variabili aleatorie Gaussiane
\end{flushleft}


\begin{flushleft}
standard indipendenti, la chiamiamo chi quadro con n gradi di libert\`{a} (spesso indicati con df) e la indichiamo con X $\sim$ 𝜒 2(n) o X $\sim$ 𝜒 n2.
\end{flushleft}


\begin{flushleft}
Non \`{e} semplicissimo ricavare la densit\`{a} di una chi quadro con n gradi di libert\`{a}, tuttavia se X$\sim$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜒 n2,
\end{flushleft}





$-$1 $-$





\begin{flushleft}
x
\end{flushleft}





\begin{flushleft}
allora fX (x) = cn x 2 e 2 , dove cn \`{e} un'opportuna costante di rinormalizzazione (che dipende
\end{flushleft}


\begin{flushleft}
da n). In Figura 10.9 possiamo vedere le funzioni densit\`{a} di alcune chi quadro, al variare dei
\end{flushleft}


\begin{flushleft}
gradi di libert\`{a}: il loro comportamento cambia abbastanza e, al crescere di n, assomiglia sempre
\end{flushleft}


\begin{flushleft}
di più a quello di una Gaussiana.
\end{flushleft}





1.25





\begin{flushleft}
Gradi di libert\`{a}
\end{flushleft}


\begin{flushleft}
df=1
\end{flushleft}


\begin{flushleft}
df=2
\end{flushleft}


\begin{flushleft}
df=3
\end{flushleft}


\begin{flushleft}
df=4
\end{flushleft}





1.00





\begin{flushleft}
df=9
\end{flushleft}





\begin{flushleft}
f(x)
\end{flushleft}





0.75





0.50





0.25





0.00


0





5





10





15





\begin{flushleft}
x
\end{flushleft}


\begin{flushleft}
Figura 10.9. Densit\`{a} di alcune chi quadro, al variare dei gradi di libert\`{a}
\end{flushleft}





20





\newpage
156





\begin{flushleft}
MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}





\begin{flushleft}
10.4.1. Chi quadro in R
\end{flushleft}


\begin{flushleft}
Non abbiamo detto esplicitamente chi siano la funzione di ripartizione e la funzione quantile di
\end{flushleft}


\begin{flushleft}
una 𝜒n2, perch\'{e} la loro forma non \`{e} semplice. Come gi\`{a} visto nel caso della normale, ci appoggiamo alle tavole o alle funzioni di R.
\end{flushleft}


\begin{flushleft}
La famiglia delle chi quadro in R \`{e} chisq. La densit\`{a} \`{e} dchisq(x, df), in cui \`{e} necessario
\end{flushleft}


\begin{flushleft}
specificare il numero di gradi di libert\`{a} df. Per la funzione di ripartizione abbiamo pchisq(q,
\end{flushleft}


\begin{flushleft}
df, lower.tail = TRUE) in cui dobbiamo prestare attenzione a passare il parametro
\end{flushleft}


\begin{flushleft}
lower.tail sempre con il nome, dal momento che la funzione prevede un ulteriore parametro
\end{flushleft}


\begin{flushleft}
(ncp = 0, del quale non ci interessiamo) tra df e lower.tail. Per la funzione quantile (che
\end{flushleft}


\begin{flushleft}
ci sar\`{a} molto utile in statistica) abbiamo qchisq(p, df, lower.tail = TRUE), con la
\end{flushleft}


\begin{flushleft}
stessa accortezza vista per pchisq. Il generatore casuale \`{e} rchisq(n, df).
\end{flushleft}





\begin{flushleft}
10.4.2. Indicatori delle chi quadro
\end{flushleft}


2


\begin{flushleft}
Per definizione le chi quadro sono riproducibili: se X $\sim$ 𝜒 n2 e Y $\sim$ 𝜒 m2 , allora X + Y $\sim$ 𝜒n+m
\end{flushleft}


\begin{flushleft}
. Questo
\end{flushleft}


\begin{flushleft}
ci aiuta nel calcolo dei momenti, permettendoci di calcolarli in modo ricorsivo. Cominciamo
\end{flushleft}


\begin{flushleft}
dunque dal caso n = 1. Abbiamo X $\sim$ 𝜒 12, cio\`{e} X = Z 2, con Z $\sim$ 𝒩(0, 1). Allora E[X] = E[Z 2] =
\end{flushleft}


\begin{flushleft}
Var[Z] = 1 e
\end{flushleft}





\begin{flushleft}
Var[X] = E[X 2] $-$ E[X]2 = E[Z 4] $-$ 1 = kr[Z] $-$ 1 = 2.
\end{flushleft}


\begin{flushleft}
Se ora Y $\sim$ 𝜒 n2, allora Y = ∑ni=1 X i con le X i indipendenti e identicamente distribuite Xi $\sim$ 𝜒12. Allora
\end{flushleft}


\begin{flushleft}
E[Y] = E
\end{flushleft}





[[[





\begin{flushleft}
n
\end{flushleft}





]]]





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Xi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
E[Xi] = n
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
e per la varianza, grazie all'indipendenza,
\end{flushleft}


\begin{flushleft}
Var[Y] = Var
\end{flushleft}





[[[





\begin{flushleft}
n
\end{flushleft}





]]]





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Xi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Var[X i] = 2 n.
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
10.5. t DI STUDENT
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 10.23. Diciamo che una variabile aleatoria X \`{e} distribuita come una t di Student con n
\end{flushleft}


\begin{flushleft}
Z
\end{flushleft}


\begin{flushleft}
gradi di libert\`{a} se esistono Z $\sim$ 𝒩(0, 1) e W $\sim$ 𝜒 n2 indipendenti tali che X = W . Scriviamo in questo caso
\end{flushleft}


\begin{flushleft}
/n
\end{flushleft}


\begin{flushleft}
X $\sim$ t(n) o X $\sim$ t n.
\end{flushleft}


\begin{flushleft}
\`{E} una variante della normale standard, ma con le code molto più pesanti (ossia la probabilit\`{a}
\end{flushleft}


\begin{flushleft}
di essere lontani dal centro \`{e} maggiore). Anche in questo caso (come per le normali e per le chi
\end{flushleft}


\begin{flushleft}
quadro) la legge \`{e} abbastanza difficile da scrivere esplicitamente, ma possiamo usare le tavole
\end{flushleft}


\begin{flushleft}
oppure R. Possiamo per\`{o} osservare che le t ereditano la simmetria delle normali standard, quindi
\end{flushleft}


\begin{flushleft}
se X $\sim$ t n, allora fX ($-$x) = f X (x), FX ($-$x) = 1 $-$ FX (x) e, per la funzione quantile, F X$-$1(p) = $-$F X$-$1(1 $-$ p).
\end{flushleft}


\begin{flushleft}
Anche per le t, come per le Gaussiane, nelle tavole sono riportati solo {``}met\`{a}'' dei valori.
\end{flushleft}


\begin{flushleft}
In Figura 10.10 vediamo le densit\`{a} di alcune t di Student al variare del numero di gradi di
\end{flushleft}


\begin{flushleft}
libert\`{a}. Possiamo osservare che al crescere di n il comportamento \`{e} sempre più simile a quello di
\end{flushleft}


\begin{flushleft}
una Gaussiana.
\end{flushleft}





\begin{flushleft}
\newpage
10.5 t DI STUDENT
\end{flushleft}





157





\begin{flushleft}
Gradi di libert\`{a}
\end{flushleft}





0.4





\begin{flushleft}
df=1
\end{flushleft}


\begin{flushleft}
df=10
\end{flushleft}


\begin{flushleft}
df=100
\end{flushleft}





\begin{flushleft}
f(x)
\end{flushleft}





0.3





0.2





0.1





0.0


$-$5





0





5





\begin{flushleft}
x
\end{flushleft}


\begin{flushleft}
Figura 10.10. Densit\`{a} di alcune t di Student, al variare dei gradi di libert\`{a}
\end{flushleft}





\begin{flushleft}
Osserviamo che la speranza di X $\sim$ t n \`{e} E[X] = 0 per simmetria rispetto all'origine. La varianza
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
non \`{e} definita per n = 1, \`{e} infinita per n = 2, mentre per n $>$ 2 \`{e} n $-$ 2 .
\end{flushleft}


\begin{flushleft}
Osservazione 10.24. Dalla definizione se X $\sim$ tn, allora X =
\end{flushleft}





\begin{flushleft}
Z
\end{flushleft}


\begin{flushleft}
W/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
con Z normale standard e W chi
\end{flushleft}





\begin{flushleft}
quadro con n gradi di libert\`{a}. Possiamo allora studiare (anche se per ora solo qualitativamente)
\end{flushleft}


\begin{flushleft}
W
\end{flushleft}


\begin{flushleft}
W
\end{flushleft}


\begin{flushleft}
il comportamento di n al crescere di n: E n = 1, fatto che non ci stupisce, visto che E[W] = n.
\end{flushleft}


\begin{flushleft}
W
\end{flushleft}


\begin{flushleft}
Inoltre Var n $\rightarrow$ 0 al tendere di n a +$\infty$, quindi possiamo dire con più confidenza che al crescere
\end{flushleft}


\begin{flushleft}
del numero n dei gradi di libert\`{a} t n tende in qualche senso a una normale standard.
\end{flushleft}


\begin{flushleft}
Questo entra in gioco nella consultazione delle tavole: la Gaussiana non ha la sua tavola delle
\end{flushleft}


\begin{flushleft}
funzioni quantile, ma compare in quella delle t di Student come caso con infiniti gradi di libert\`{a}.
\end{flushleft}





\begin{flushleft}
10.5.1. t di Student in R
\end{flushleft}


\begin{flushleft}
Come gi\`{a} detto le funzioni in R sono abbastanza cruciali per poter manipolare le t di Student, dal
\end{flushleft}


\begin{flushleft}
momento che non abbiamo una forma esplicita della legge. La famiglia delle t in R \`{e} t. La densit\`{a}
\end{flushleft}


\begin{flushleft}
\`{e} dt(x, df), in cui \`{e} necessario specificare il numero di gradi di libert\`{a} df. Per la funzione di
\end{flushleft}


\begin{flushleft}
ripartizione abbiamo pt(q, df, lower.tail = TRUE) in cui dobbiamo prestare attenzione a passare il parametro lower.tail sempre con il nome, dal momento che la funzione
\end{flushleft}


\begin{flushleft}
prevede un ulteriore parametro (ncp, del quale non ci interessiamo) tra df e lower.tail. Per
\end{flushleft}





\newpage
158





\begin{flushleft}
MODELLI ASSOLUTAMENTE CONTINUI
\end{flushleft}





\begin{flushleft}
la funzione quantile (che ci sar\`{a} molto utile in statistica) abbiamo qt(p, df, lower.tail
\end{flushleft}


\begin{flushleft}
= TRUE), con la stessa accortezza vista per pt. Il generatore casuale \`{e} rt(n, df).
\end{flushleft}





\begin{flushleft}
\newpage
CAPITOLO 11
\end{flushleft}


\begin{flushleft}
TEOREMI LIMITE
\end{flushleft}


\begin{flushleft}
In questo capitolo vogliamo dare un significato rigoroso a un concetto che abbiamo toccato in
\end{flushleft}


\begin{flushleft}
precedenza: data una successione (Xn)n$\in$ℕ di variabili aleatorie su uno spazio di probabilit\`{a} ($\Omega$,
\end{flushleft}


\begin{flushleft}
ℱ, P), cosa significa dire che lim n$\rightarrow$+$\infty$ X n = X, ossia passare al limite? Come vedremo, ci sono
\end{flushleft}


\begin{flushleft}
diverse nozioni di convergenza di variabili aleatorie.
\end{flushleft}


\begin{flushleft}
Una volta viste queste nozioni vedremo alcuni risultati (i teoremi limite) che ci garantiscono
\end{flushleft}


\begin{flushleft}
sotto opportune ipotesi, la convergenza di alcune particolari successioni di variabili aleatorie.
\end{flushleft}





\begin{flushleft}
11.1. CONVERGENZA DI VARIABILI ALEATORIE
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 11.1. Siano ($\Omega$, ℱ, P) uno spazio di probabilit\`{a}, X una variabile aleatoria su tale spazio e
\end{flushleft}


\begin{flushleft}
(X n)n$\in$ℕ una successione di variabili aleatorie sullo stesso spazio. Diciamo che (X n)n converge quasi
\end{flushleft}


\begin{flushleft}
q.c.
\end{flushleft}


\begin{flushleft}
certamente (o puntualmente) a X e scriviamo X n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X se esiste un evento E $\in$ ℱ con P(E) = 1 tale
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
che per ogni esito 𝜔 $\in$ E, lim n$\rightarrow$+$\infty$ Xn(𝜔) = X(𝜔).
\end{flushleft}


\begin{flushleft}
Osserviamo che il limite lim n$\rightarrow$+$\infty$ Xn(𝜔) = X(𝜔) \`{e} il limite di una successione di numeri reali.
\end{flushleft}


\begin{flushleft}
Per indicare la convergenza quasi certa possiamo anche usare la scrittura P(lim n$\rightarrow$+$\infty$ Xn = X) = 1.
\end{flushleft}


\begin{flushleft}
Osservazione 11.2. Il concetto di convergenza quasi certa \`{e} molto forte: stiamo chiedendo che la
\end{flushleft}


\begin{flushleft}
successione di funzioni converga puntualmente per quasi ogni 𝜔 $\in$ $\Omega$. \`{E} un tipo di convergenza
\end{flushleft}


\begin{flushleft}
molto difficile da verificare direttamente.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 11.3. Siano (X n)n$\in$ℕ una successione di variabili aleatorie e X una variabile aleatoria sul
\end{flushleft}


\begin{flushleft}
medesimo spazio di probabilit\`{a} ($\Omega$, ℱ, P). Diciamo che (X n)n converge in probabilit\`{a} a X e scriviamo
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
Xn $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X se, per ogni 𝜀 $>$ 0, lim n$\rightarrow$+$\infty$ P(|Xn $-$ X| $>$ 𝜀) = 0.
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
Anche in questo caso ci siamo ricondotti al limite di una successione di numeri reali, ma in
\end{flushleft}


\begin{flushleft}
modo diverso: ogni |X n $-$ X| \`{e} una variabile aleatoria, di cui chiediamo la probabilit\`{a} di essere
\end{flushleft}


\begin{flushleft}
maggiore di 𝜀, probabilit\`{a} che \`{e} un numero reale (tra 0 e 1).
\end{flushleft}


\begin{flushleft}
Osservazione 11.4. A differenza della convergenza quasi certa, la convergenza in probabilit\`{a}
\end{flushleft}


\begin{flushleft}
guarda il comportamento globale della successione di variabili aleatorie. Dobbiamo infatti controllare che gli esiti 𝜔 $\in$$\Omega$ per cui |Xn(𝜔) $-$ X(𝜔)| $>$𝜀 siano un insieme di probabilit\`{a} che, al tendere
\end{flushleft}


\begin{flushleft}
di n all'infinito, converge a 0.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 11.5. Siano (X n)n$\in$ℕ una successione di variabili aleatorie e X una variabile aleatoria sul
\end{flushleft}


\begin{flushleft}
medesimo spazio di probabilit\`{a} ($\Omega$, ℱ, P). Diciamo che (Xn)n converge in media quadratica (o in L2) a
\end{flushleft}


\begin{flushleft}
L2
\end{flushleft}





\begin{flushleft}
X e scriviamo X n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X se lim n$\rightarrow$+$\infty$ E[|Xn $-$ X|2] = 0.
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
Ancora una volta abbiamo espresso una convergenza di variabili aleatorie (e quindi di funzioni) in termini di una convergenza di numeri reali: ogni |Xn $-$ X| \`{e} una variabile aleatoria, di cui
\end{flushleft}


\begin{flushleft}
chiediamo che convergano i momenti secondi (che sono numeri reali).
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 11.6. La convergenza in media quadratica implica la convergenza in probabilit\`{a}, ossia se
\end{flushleft}


\begin{flushleft}
L2
\end{flushleft}





\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
Xn $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X, allora X n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X.
\end{flushleft}


159





\begin{flushleft}
Lezione 20
\end{flushleft}





\newpage
160





\begin{flushleft}
TEOREMI LIMITE
\end{flushleft}





\begin{flushleft}
Dimostrazione. Prendiamo 𝜀 $>$ 0. Dalla disuguaglianza di Markov (9.1) abbiamo per ogni n
\end{flushleft}


\begin{flushleft}
P(|Xn $-$ X| ⩾ 𝜀) = P(|X n $-$ X|2 ⩾ 𝜀 2)
\end{flushleft}


\begin{flushleft}
E[|Xn $-$ X|2]
\end{flushleft}


⩽


.


\begin{flushleft}
𝜀2
\end{flushleft}


\begin{flushleft}
Ora possiamo prendere il limite per n $\rightarrow$ +$\infty$:
\end{flushleft}


\begin{flushleft}
lim P(|Xn $-$ X| $>$ 𝜀) ⩽
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
lim n$\rightarrow$+$\infty$ E[|X n $-$ X|2]
\end{flushleft}


=0


\begin{flushleft}
𝜀2
\end{flushleft}





\begin{flushleft}
in cui l'ultima uguaglianza \`{e} garantita dalla convergenza in media quadratica.
\end{flushleft}





□


\begin{flushleft}
q.c.
\end{flushleft}





\begin{flushleft}
PROPOSIZIONE 11.7. La convergenza quasi certa implica la convergenza in probabilit\`{a}, ossia se Xn $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X,
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
allora X n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X.
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





□





\begin{flushleft}
Osservazione 11.8. Viene naturale, a questo punto, chiedersi quale sia {``}più forte'' tra le convergenze in L2 e quasi certa, ossia se ce ne sia una delle due che implica l'altra. In realt\`{a} si pu\`{o}
\end{flushleft}


\begin{flushleft}
mostrare che le due convergenze non sono confrontabili: esistono successioni di variabili aleatorie che convergono quasi certamente ma non in L2 e, viceversa, successioni che convergono in
\end{flushleft}


\begin{flushleft}
L2 ma non quasi certamente.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 11.9. Siano (X n)n$\in$ℕ una successione di variabili aleatorie su uno spazio di probabilit\`{a} ($\Omega$,
\end{flushleft}


\begin{flushleft}
ℱ, P) e X una variabile aleatoria sullo spazio di probabilit\`{a} ($\Omega$̃, ℱ̃, P̃). Diciamo che (Xn)n converge in
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}





\begin{flushleft}
ℒ
\end{flushleft}





\begin{flushleft}
legge (o in distribuzione o debolmente) a X e scriviamo X n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X o Xn $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X, se per ogni x $\in$ ℝ
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
lim n$\rightarrow$+$\infty$ P(Xn ⩽ x) = P(X ⩽ x), ossia se lim n$\rightarrow$+$\infty$ FXn(x) = F X (x).
\end{flushleft}


\begin{flushleft}
Osservazione 11.10. Questa nozione \`{e} chiaramente più debole della convergenza in probabilit\`{a}
\end{flushleft}


\begin{flushleft}
(e quindi delle altre due). In particolare non \`{e} necessario che la successione (X n)n e il suo limite X
\end{flushleft}


\begin{flushleft}
siano nello stesso spazio di probabilit\`{a}, come sottolineato nella definizione prendendo ($\Omega$, ℱ, P)
\end{flushleft}


\begin{flushleft}
e ($\Omega$̃, ℱ̃, P̃).
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
PROPOSIZIONE 11.11. La convergenza in probabilit\`{a} implica la convergenza in legge, ossia se X n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X,
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
ℒ
\end{flushleft}


\begin{flushleft}
allora X n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ X.
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





□





\begin{flushleft}
Osservazione 11.12. Possiamo riassumere i legami tra i vari concetti di convergenza di variabili
\end{flushleft}


\begin{flushleft}
aleatorie con lo schema in Figura 11.1. Ci sono casi in cui \`{e} possibile invertire le implicazioni, sotto
\end{flushleft}


\begin{flushleft}
opportune ipotesi, ma vanno oltre i contenuti di questo corso.
\end{flushleft}


\begin{flushleft}
Xn
\end{flushleft}





\begin{flushleft}
q.c.
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}


\begin{flushleft}
Xn
\end{flushleft}





\begin{flushleft}
Xn
\end{flushleft}





\begin{flushleft}
L2
\end{flushleft}





\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
Xn
\end{flushleft}





\begin{flushleft}
L
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
X
\end{flushleft}





\begin{flushleft}
Figura 11.1. Gerarchia delle convergenze di variabili aleatorie
\end{flushleft}





\begin{flushleft}
11.2. TEOREMI LIMITE
\end{flushleft}


\begin{flushleft}
Cominciamo con qualche richiamo di risultati gi\`{a} visti.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 11.13. Siano X 1, . . . , X n variabili aleatorie indipendenti di media comune 𝜇 e di varianza
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
comune 𝜎 2. Sia inoltre Sn la variabile aleatoria somma, S n = ∑i=1 X i. Allora
\end{flushleft}





\begin{flushleft}
\newpage
11.2 TEOREMI LIMITE
\end{flushleft}





161





\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
=𝜇
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
e
\end{flushleft}





\begin{flushleft}
Var
\end{flushleft}





\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}


= .


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Dimostrazione. Sappiamo che la speranza \`{e} lineare, quindi (senza necessit\`{a} dell'ipotesi di indipendenza)
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


1


1


\begin{flushleft}
E
\end{flushleft}


\begin{flushleft}
= E
\end{flushleft}


\begin{flushleft}
Xi =
\end{flushleft}


\begin{flushleft}
E[X i] = 𝜇.
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





[[[





]]]





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Per la varianza abbiamo invece bisogno dell'indipendenza,
\end{flushleft}


\begin{flushleft}
Var
\end{flushleft}





\begin{flushleft}
Sn
\end{flushleft}


1


\begin{flushleft}
= 2 Var
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





[[


[





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





]]


]





\begin{flushleft}
Xi =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





1


\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
Var[X i] = ,
\end{flushleft}


2


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n i=1
\end{flushleft}





\begin{flushleft}
concludendo la dimostrazione.
\end{flushleft}





□





\begin{flushleft}
Osservazione 11.14. \`{E} interessante notare come si comportino i risultati della Proposizione 11.13
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
al crescere di n: la speranza E n converge a 𝜇 per n $\rightarrow$ +$\infty$ (addirittura \`{e} costantemente uguale
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
a 𝜇 per ogni n), mentre la varianza Var n converge a 0 per n $\rightarrow$ +$\infty$. Abbiamo allora per ogni n
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
una variabile aleatoria n che mantiene il suo centro in 𝜇 e che si restringe sempre di più, fino a
\end{flushleft}


\begin{flushleft}
essere costantemente uguale alla sua media al limite.
\end{flushleft}


\begin{flushleft}
\`{E} arrivato il momento di uno dei risultati di probabilit\`{a} più citati (solitamente a sproposito),
\end{flushleft}


\begin{flushleft}
che rende rigoroso (in termini di convergenza di variabili aleatorie) quanto detto nell'Osservazione 11.14.
\end{flushleft}


\begin{flushleft}
TEOREMA 11.15. (LEGGE DEBOLE DEI GRANDI NUMERI) Sia (Xn)n$\in$ℕ una successione di variabili aleatorie indipendenti, ciascuna di media 𝜇 e varianza finita 𝜎 2. Sia inoltre S n = ∑ni=1 Xi la variabile aleatoria
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
somma parziale delle X i. Allora la variabile aleatoria n converge in probabilit\`{a} a 𝜇, ossia per ogni 𝜀 $>$ 0
\end{flushleft}


\begin{flushleft}
lim P
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
$-$ 𝜇 $>$ 𝜀 = 0.
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Dimostrazione. Sfruttiamo la Proposizione 11.13 e la disuguaglianza di Chebychev (9.2): sia
\end{flushleft}


\begin{flushleft}
infatti 𝜀 $>$ 0, allora
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
$-$𝜇 $>$𝜀 = P
\end{flushleft}


\begin{flushleft}
$-$E
\end{flushleft}


\begin{flushleft}
$>$𝜀
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


⩽





\begin{flushleft}
Var
\end{flushleft}





\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜀2
\end{flushleft}


2





\begin{flushleft}
𝜎
\end{flushleft}


.


\begin{flushleft}
n 𝜀2
\end{flushleft}


\begin{flushleft}
Passando al limite per n $\rightarrow$ +$\infty$, l'ultimo termine converge a 0.
\end{flushleft}


=





□





\begin{flushleft}
Osservazione 11.16. Il fatto che il Teorema 11.15 si chiami {``}Legge debole dei grandi numeri''
\end{flushleft}


\begin{flushleft}
suggerisce che ci siano altri enunciati, più forti. Così \`{e}, in effetti: esiste anche la legge forte dei
\end{flushleft}


\begin{flushleft}
grandi numeri che d\`{a} sotto ipotesi meno restrittive un risultato più forte, ossia garantisce la convergenza quasi certa (che, come abbiamo visto nella Proposizione 11.7, implica in particolare la
\end{flushleft}


\begin{flushleft}
convergenza in probabilit\`{a}). In questo corso dovremo per\`{o} accontentarci della legge debole dei
\end{flushleft}


\begin{flushleft}
grandi numeri, senza enunciare (o dimostrare) altre varianti.
\end{flushleft}


\begin{flushleft}
Vediamo ora cosa dice (e cosa non dice) la legge debole dei grandi numeri. Prendiamo, come
\end{flushleft}


1


\begin{flushleft}
esempio guida, un processo di Bernoulli di parametro 2 , ossia infiniti lanci consecutivi di una
\end{flushleft}


1


\begin{flushleft}
moneta bilanciata. Le Xi sono indipendenti e identicamente distribuite, X i $\sim$ bin 1, 2 . Inoltre la
\end{flushleft}


\begin{flushleft}
variabile aleatoria {``}somma parziale'' Sn conta il numero di 1 (ossia di successi) nei primi n lanci,
\end{flushleft}


1


1


\begin{flushleft}
quindi \`{e} una binomiale di parametri n e p = 2 : Sn $\sim$ bin n, 2 . La legge debole dei grandi numeri
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


1


\begin{flushleft}
ci dice che n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ 2 = E[X1].
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\newpage
162





\begin{flushleft}
TEOREMI LIMITE
\end{flushleft}





\begin{flushleft}
Questo risultato viene spesso (erroneamente) letto come
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
Sn $\sim$
\end{flushleft}


\begin{flushleft}
o, peggio,
\end{flushleft}


\begin{flushleft}
Sn ⟶ .
\end{flushleft}


2


2


\begin{flushleft}
Entrambe queste scritture dovrebbero insospettirci in partenza: non sono precise (nel primo caso)
\end{flushleft}


\begin{flushleft}
o non hanno proprio senso (nel secondo caso: se stiamo passando al limite non pu\`{o} esserci un n
\end{flushleft}


\begin{flushleft}
dopo il limite).
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
Cerchiamo di scrivere meglio la prima, S n $\sim$ 2 , in modo che abbia più significato. Abbiamo
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





2


0





\begin{flushleft}
sTrasl
\end{flushleft}





4





6





\begin{flushleft}
Sn $-$ 2
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


1


\begin{flushleft}
Sn 1
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


⟺


$-$ $\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$0


⟺


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$ 0.


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
n n$\rightarrow$+$\infty$ 2
\end{flushleft}


\begin{flushleft}
n 2 n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
Non dobbiamo fraintendere l'ultima leggendola come Sn $-$ 2 $\rightarrow$ 0: questa \`{e} falsa, non in modo grosn
\end{flushleft}


\begin{flushleft}
solano come la Sn ⟶ 2 , ma falsa ugualmente. Infatti quello che noi sappiamo dalla legge debole
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
dei grandi numeri \`{e} che S n $-$ 2 cresce più lentamente di n, non che decresce. Anzi, se facciamo
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
qualche esperimento, possiamo vedere che la quantit\`{a} Sn $-$ 2 cresce al crescere di n (all'incirca
\end{flushleft}


\begin{flushleft}
come $\surd$n , come vedremo tra poco).
\end{flushleft}


\begin{flushleft}
La moneta che stiamo lanciando non ha idea di cosa sia uscito, quindi non cerca di bilanciare il
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
numero di teste e croci (ossia di mandare S n $-$ 2 a 0), ma bilancia la frequenza sul totale: il rapporto
\end{flushleft}


1


\begin{flushleft}
di teste sul totale dei lanci tende a 2 , ma sono possibili sbilanciamenti molto ampi sul numero.
\end{flushleft}


\begin{flushleft}
Vediamo una rappresentazione di questa situazione nella Figura 11.2.
\end{flushleft}





0





50





100





150





200





\begin{flushleft}
1:N
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Figura 11.2. n Una realizzazione di 200 lanci di una moneta. In nero la quantit\`{a} Sn $-$ 2 , che oscilla e non converge,
\end{flushleft}


\begin{flushleft}
Sn $-$
\end{flushleft}


\begin{flushleft}
in rosso n 2 che converge (molto rapidamente) a 0.
\end{flushleft}





\begin{flushleft}
\newpage
11.2 TEOREMI LIMITE
\end{flushleft}





163





\begin{flushleft}
Vediamo anche il codice usato per generare la Figura 11.2:
\end{flushleft}





\begin{flushleft}
N $<$- 200 \# lunghezza dei vettori
\end{flushleft}


\begin{flushleft}
x $<$- rbinom(N, size = 1, prob = 1/2) \# lanci della moneta
\end{flushleft}


\begin{flushleft}
uni $<$- rep(1, N) \# N-vettore di soli 1
\end{flushleft}


\begin{flushleft}
M $<$- matrix(1, nrow = N, ncol = N) \# matrice NxN di soli 1
\end{flushleft}


\begin{flushleft}
M[upper.tri(M)] $<$- 0 \# che trasformiamo in una matrice
\end{flushleft}


\begin{flushleft}
\# triangolare inferiore di soli 1
\end{flushleft}


\begin{flushleft}
\# (diagonale inclusa)
\end{flushleft}


\begin{flushleft}
s $<$- M \%*\% x \# vettore dei valori di Sn, ottenuto mediante
\end{flushleft}


\begin{flushleft}
\# moltiplicazione di matrici (e vettori)
\end{flushleft}


\begin{flushleft}
sTrasl $<$- s - 1/2 * M \%*\% uni \# vettore Sn-n/2, di nuovo via
\end{flushleft}


\begin{flushleft}
\# moltiplicazione di matrici
\end{flushleft}


\begin{flushleft}
\# Senza passare da s avremmo potuto scrivere
\end{flushleft}


\begin{flushleft}
\# sTrasl $<$- M \%*\% (x - 1/2*uni)
\end{flushleft}


\begin{flushleft}
plot(1:N, sTrasl, type = {``}l'')
\end{flushleft}


\begin{flushleft}
lines(1:N,sTrasl/(M\%*\%uni), col = {``}red'')
\end{flushleft}


\begin{flushleft}
in cui abbiamo usato una rappresentazione geometrica (matrici) per evitare cicli for.
\end{flushleft}





\begin{flushleft}
Esempio 11.17. Un numero al Superenalotto in media uscir\`{a} ogni 6 = 15 estrazioni. Infatti
\end{flushleft}


\begin{flushleft}
possiamo vedere la successione di estrazioni come un processo di Bernoulli (come gi\`{a} visto
\end{flushleft}


6


\begin{flushleft}
nell'Esempio 8.15) in cui a ogni estrazione abbiamo probabilit\`{a} 90 di successo (ossia di vedere
\end{flushleft}


\begin{flushleft}
uscire il numero scelto). Sappiamo anche che se prendiamo n estrazioni, ci aspettiamo in media
\end{flushleft}


6


90


\begin{flushleft}
n ⋅ 90 successi. Noi vogliamo trovare n per cui abbiamo in media 1 successo, quindi n = 6 = 15.
\end{flushleft}


90





\begin{flushleft}
Questo per\`{o} non significa che se il nostro numero manca (o {``}ritarda'') da un po' allora \`{e} {``}più
\end{flushleft}


\begin{flushleft}
probabile che esca, per la legge dei grandi numeri''. La probabilit\`{a} non cambia (di nuovo, come
\end{flushleft}


\begin{flushleft}
visto nell'Esempio 8.15), quello che succede per la legge dei grandi numeri \`{e} che la frequenza con
\end{flushleft}


1


\begin{flushleft}
cui il nostro numero esce tender\`{a} a 15 .
\end{flushleft}


\begin{flushleft}
TEOREMA 11.18. (TEOREMA CENTRALE DEL LIMITE) Sia (X n)n$\in$ℕ una successione di variabili aleatorie
\end{flushleft}


\begin{flushleft}
indipendenti, ciascuna di media 𝜇 e varianza finita 𝜎 2. Sia inoltre Sn =∑ni=1 Xi la variabile aleatoria somma
\end{flushleft}


\begin{flushleft}
parziale delle X i. Allora
\end{flushleft}


\begin{flushleft}
ℒ
\end{flushleft}


\begin{flushleft}
Sn $-$ n 𝜇
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ 𝒩(0, 1)
\end{flushleft}


\begin{flushleft}
𝜎 $\surd$n n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
cio\`{e}
\end{flushleft}





\begin{flushleft}
Dimostrazione. [TBA]
\end{flushleft}





\begin{flushleft}
lim P
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
( S𝜎$-$$\surd$nn𝜇 ⩽ x) = $\Phi$(x).
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





□


\begin{flushleft}
Sn $-$ n 𝜇
\end{flushleft}





\begin{flushleft}
Il teorema centrale del limite ci dice che 𝜎 $\surd$n converge in legge (o distribuzione) a una normale
\end{flushleft}


\begin{flushleft}
standard. Qualunque sia la distribuzione originaria di ciascuna delle Xi, giustificando l'importanza della distribuzione normale11.1. Possiamo per\`{o} leggerci qualcosa di più: abbiamo che (la
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
variabile aleatoria) S n $-$ 2 va all'infinito come $\surd$n . Non pu\`{o} andare più rapidamente, altrimenti
\end{flushleft}


\begin{flushleft}
avremmo un'esplosione all'infinito, ossia una distribuzione limite con varianza infinita, ma nemmeno più lentamente, altrimenti la distribuzione limite sarebbe concentrata in 0 con varianza
\end{flushleft}


\begin{flushleft}
nulla.
\end{flushleft}





\begin{flushleft}
Vediamo, nella Tabella 11.1, l'andamento di alcune grandezze al crescere di n, nell'esempio
\end{flushleft}


\begin{flushleft}
guida del processo di Bernoulli con la moneta bilanciata.
\end{flushleft}


\begin{flushleft}
11.1. E il suo nome: si chiama normale perch\'{e} \`{e} la norma.
\end{flushleft}





\newpage
164





\begin{flushleft}
TEOREMI LIMITE
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
$\surd$n
\end{flushleft}





10





3.16...





5





($-$3.16, 3.16)





100





10





50





($-$10, 10)





10 4





100





5000





($-$100, 100)





10 8





104





5 ⋅ 107





($-$10 4, 10 4)





\begin{flushleft}
E[Sn] =
\end{flushleft}





\begin{flushleft}
Sn $-$
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Sn $-$ 2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1 1


$-$ ,


3 3


1 1


$-$ ,


10 10


1


1


$-$


,


100 100


1 1


$-$ 4, 4


10 10


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Tabella 11.1. Confronto tra gli ordini di grandezza degli intervalli in cui assumono valore Sn $-$ 2 e
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
di n, usando il comportamento asintotico di Sn $-$ 2 dell'ordine di $\surd$n .
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Sn $-$ 2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
al crescere
\end{flushleft}





\begin{flushleft}
Osservazione 11.19. Nella pratica non useremo sostanzialmente mai il teorema centrale del limite
\end{flushleft}


\begin{flushleft}
come limite, ossia usando quanto visto nell'enunciato
\end{flushleft}


\begin{flushleft}
lim P
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
(( S𝜎$-$$\surd$nn𝜇 ⩽ x)) = $\Phi$(x).
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Infatti non avremo mai infinite realizzazioni di un esperimento (e quindi infinite variabili aleatorie X i di cui fare la somma).
\end{flushleft}


\begin{flushleft}
Il teorema servir\`{a} invece per avere delle approssimazioni: quando n \`{e} {``}sufficientemente
\end{flushleft}


\begin{flushleft}
grande'' abbiamo
\end{flushleft}


\begin{flushleft}
Sn $-$ n 𝜇
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
⩽ x $\approx$ $\Phi$(x).
\end{flushleft}


\begin{flushleft}
𝜎 $\surd$n
\end{flushleft}


\begin{flushleft}
Scriviamo anche, in questo caso,
\end{flushleft}


\begin{flushleft}
Sn $-$ n 𝜇
\end{flushleft}


$\sim$


\begin{flushleft}
˙ 𝒩(0, 1)
\end{flushleft}


\begin{flushleft}
𝜎 $\surd$n
\end{flushleft}





((





))





\begin{flushleft}
Sn $-$ n 𝜇
\end{flushleft}





\begin{flushleft}
per dire che la distribuzione di 𝜎 $\surd$n \`{e} approssimativamente normale standard. Possiamo riscrivere questa distribuzione approssimata anche come
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


$\sim$


\begin{flushleft}
oppure
\end{flushleft}


\begin{flushleft}
Sn $\sim$
\end{flushleft}


\begin{flushleft}
˙ 𝒩 𝜇,
\end{flushleft}


\begin{flushleft}
˙ 𝒩(n 𝜇, 𝜎 $\surd$n ).
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
$\surd$n
\end{flushleft}


\begin{flushleft}
Resta per\`{o} una domanda: quand'\`{e} che n \`{e} sufficientemente grande? Lasciamola un momento da
\end{flushleft}


\begin{flushleft}
parte e vediamo un esempio di applicazione del teorema centrale del limite.
\end{flushleft}


\begin{flushleft}
Esempio 11.20. (Baldi) Un calcolatore somma 10 6 numeri, con un errore di arrotondamento in
\end{flushleft}


\begin{flushleft}
ciascuna operazione. I singoli errori sono indipendenti e hanno distribuzione uniforme sull'intervallo [$-$0.5 ⋅ 10 $-$10, 0.5 ⋅ 10$-$10]. Qual \`{e} la probabilit\`{a} che l'errore assoluto finale sia minore di 0.5 ⋅
\end{flushleft}


10 $-$7?


\begin{flushleft}
Come prima cosa formuliamo il problema in termini di variabili aleatorie: per i $\in$ \{1, . . . , n\}
\end{flushleft}


\begin{flushleft}
abbiamo Xi $\sim$ unif($-$0.5 ⋅ 10$-$10, 0.5 ⋅ 10$-$10), tutte indipendenti che rappresentano gli errori fatti in
\end{flushleft}


\begin{flushleft}
ciascuna operazione. Abbiamo inoltre Sn = ∑ni=1 Xi che rappresenta l'errore totale e, dai dati del
\end{flushleft}


\begin{flushleft}
problema, sappiamo anche n = 10 6.
\end{flushleft}


\begin{flushleft}
Ora pensiamo un momento a cosa ci interessa: non vogliamo calcolare la legge {``}vera'' di Sn,
\end{flushleft}


\begin{flushleft}
ma vogliamo calcolare
\end{flushleft}


\begin{flushleft}
P(|S n| $<$ 0.5 ⋅ 10$-$7) = P(S n $<$ 0.5 ⋅ 10$-$7) $-$ P(S n $<$ $-$0.5 ⋅ 10$-$7)
\end{flushleft}


\begin{flushleft}
e siamo quindi interessati a (un'approssimazione di) P(S n ⩽ y), per qualche y. Dal teorema centrale del limite (nell'enunciato approssimato) sappiamo che
\end{flushleft}


\begin{flushleft}
S n $-$ n E[X 1]
\end{flushleft}


$\sim$


\begin{flushleft}
˙ 𝒩(0, 1),
\end{flushleft}


\begin{flushleft}
$\surd$n Var[X 1]
\end{flushleft}





\begin{flushleft}
ossia che
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
(( S $-$ n E[X ] ⩽ x)) ≃ $\Phi$(x).
\end{flushleft}


\begin{flushleft}
( $\surd$n Var[X ] )
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





1





1





(11.1)





\begin{flushleft}
\newpage
11.2 TEOREMI LIMITE
\end{flushleft}





165





\begin{flushleft}
Cerchiamo di riscrivere (11.1) in modo da mettere in evidenza Sn e ottenere qualcosa della
\end{flushleft}


\begin{flushleft}
forma P(S n ⩽ y): manipolando il primo membro della (11.1) abbiamo
\end{flushleft}


\begin{flushleft}
P Sn ⩽ x ⋅ $\surd$n Var[X1] + n E[X1] ≃ $\Phi$(x),
\end{flushleft}


\begin{flushleft}
quindi vogliamo determinare x tale che
\end{flushleft}


\begin{flushleft}
x ⋅ $\surd$n Var[X1] + n E[X1] = y,
\end{flushleft}


\begin{flushleft}
cio\`{e}
\end{flushleft}


\begin{flushleft}
x=
\end{flushleft}





\begin{flushleft}
y $-$ n E[X1]
\end{flushleft}


.


\begin{flushleft}
$\surd$n Var[X1]
\end{flushleft}





\begin{flushleft}
Saremmo potuti arrivare allo stesso risultato ricordando che S n $\sim$
\end{flushleft}


\begin{flushleft}
˙ 𝒩 y $-$ n E[X 1], $\surd$n Var[X1] e
\end{flushleft}


\begin{flushleft}
usando le propriet\`{a} di standardizzazione di una Gaussiana, per cui
\end{flushleft}


\begin{flushleft}
P(Sn ⩽ y) = FSn(y) ≃ $\Phi$
\end{flushleft}





\begin{flushleft}
(( y $-$ n E[X ] )).
\end{flushleft}


\begin{flushleft}
( $\surd$n Var[X ] )
\end{flushleft}


1





1





\begin{flushleft}
Quanto fatto finora non usa il contesto specifico del problema che stiamo considerando, ma
\end{flushleft}


\begin{flushleft}
ora andiamo a sostituire i valori specifici:
\end{flushleft}


10 $-$20


\begin{flushleft}
n = 106,
\end{flushleft}


\begin{flushleft}
E[X1] = 0,
\end{flushleft}


\begin{flushleft}
Var[X1] =
\end{flushleft}


,


\begin{flushleft}
y = $\pm$0.5 ⋅ 10$-$7,
\end{flushleft}


12


\begin{flushleft}
quindi
\end{flushleft}


\begin{flushleft}
P(|Sn| $<$ 0.5 ⋅ 10 $-$7) = P(Sn $<$ 0.5 ⋅ 10 $-$7) $-$ P(Sn $<$ $-$0.5 ⋅ 10 $-$7)
\end{flushleft}


\begin{flushleft}
= FSn(0.5 ⋅ 10$-$7) $-$ FSn($-$0.5 ⋅ 10 $-$7)
\end{flushleft}





(( 0.5 ⋅ 10


(( 10 ⋅ ⋅ 10


$-$7





\begin{flushleft}
≃ 2$\Phi$
\end{flushleft}





1





3





$-$10





12





\begin{flushleft}
≃ 2 $\Phi$(1.75) $-$ 1
\end{flushleft}


= 1.9108 $-$ 1





)) $-$ 1


))





\begin{flushleft}
e la probabilit\`{a} cercata \`{e} all'incirca 91\%.
\end{flushleft}


\begin{flushleft}
Osservazione 11.21. Nell'Esempio 11.20 siamo passati da P(S n $<$ y) a P(Sn ⩽ y) senza porci troppi
\end{flushleft}


\begin{flushleft}
problemi, grazie al fatto che le variabili aleatorie coinvolte erano assolutamente continue. Se per\`{o}
\end{flushleft}


\begin{flushleft}
sommiamo variabili aleatorie discrete un singolo punto pu\`{o} avere probabilit\`{a} non nulla, quindi
\end{flushleft}


\begin{flushleft}
possiamo commettere errori (anche significativi) se non prestiamo attenzione nell'uso del teorema centrale del limite per le approssimazioni.
\end{flushleft}


\begin{flushleft}
Per fortuna c'\`{e} un facile accorgimento (che prende il nome di correzione di continuit\`{a}) che ci
\end{flushleft}


\begin{flushleft}
viene in aiuto in questo caso: se S n \`{e} una somma di variabili aleatorie discrete, allora
\end{flushleft}


\begin{flushleft}
F Sn
\end{flushleft}


\begin{flushleft}
in cui quel termine
\end{flushleft}





1


2





\begin{flushleft}
x+
\end{flushleft}


\begin{flushleft}
(x) ≃ $\Phi$(
\end{flushleft}


\begin{flushleft}
(( $\surd$n
\end{flushleft}





1


2





\begin{flushleft}
$-$ n E[X 1]
\end{flushleft}


\begin{flushleft}
Var[X 1]
\end{flushleft}





)),


)





\begin{flushleft}
che compare al numeratore in $\Phi$ \`{e} la correzione di continuit\`{a}.
\end{flushleft}





\begin{flushleft}
Torniamo alla domanda che ci eravamo posti prima: quanto deve essere grande n per avere
\end{flushleft}


\begin{flushleft}
una buona approssimazione? La risposta non \`{e} unica e dipende dalla distribuzione delle X i, in
\end{flushleft}


\begin{flushleft}
particolare dalla loro {``}forma''. Vediamo alcuni casi:
\end{flushleft}


\begin{flushleft}
$-$ X i $\sim$ 𝒩: in questo caso n = 1, grazie alla riproducibilit\`{a}
\end{flushleft}


\begin{flushleft}
$-$ X i $\sim$ unif: in questo caso n ⩾ 5 d\`{a} di solito buoni risultati
\end{flushleft}


\begin{flushleft}
$-$ X i $\sim$ exp o Xi $\sim$ geom: abbiamo bisogno di n ⩾ 15 (sono molto dissimili da delle normali)
\end{flushleft}


\begin{flushleft}
$-$ X i $\sim$ 𝜒 2: possiamo usare la riproducibilit\`{a} 𝜒n2 $\sim$
\end{flushleft}


\begin{flushleft}
˙ 𝒩 n, 2 n e l'approssimazione \`{e} buona per
\end{flushleft}


\begin{flushleft}
n ⩾ 25 quindi se sommiamo 𝜒 2(1) ne occorrono almeno 25, se sommiamo 𝜒 2(9) ne bastano
\end{flushleft}


\begin{flushleft}
circa 3.
\end{flushleft}





\newpage
166





\begin{flushleft}
TEOREMI LIMITE
\end{flushleft}





\begin{flushleft}
Abbiamo lasciato fuori due casi importanti, che meritano di essere considerati a parte: binomiale
\end{flushleft}


\begin{flushleft}
e Poisson.
\end{flushleft}


\begin{flushleft}
Binomiale. \`{E} necessario che la distribuzione non sia troppo sbilanciata, quindi che p sia {``}lontano'' dagli estremi 0 e 1. In tal caso possiamo usare il teorema centrale del limite per avere
\end{flushleft}


\begin{flushleft}
un'approssimazione della distribuzione stessa,
\end{flushleft}


\begin{flushleft}
bin(n, p) $\sim$
\end{flushleft}


\begin{flushleft}
˙ 𝒩 n p, n p (1 $-$ p) .
\end{flushleft}


\begin{flushleft}
La condizione su p (lontano dagli estremi) dipende da n, come regola di massima si chiede che
\end{flushleft}


\begin{flushleft}
n p (1 $-$ p) ≳ 3.
\end{flushleft}


\begin{flushleft}
Poisson. Anche in questo caso abbiamo la riproducibilit\`{a} che ci viene in aiuto,
\end{flushleft}


\begin{flushleft}
Pois(𝜆) $\sim$
\end{flushleft}


\begin{flushleft}
˙ 𝒩 𝜆, 𝜆
\end{flushleft}


\begin{flushleft}
per 𝜆 ≳ 30. Possiamo infatti vedere una Poisson di parametro 𝜆 (ricordiamo che 𝜆 \`{e} sia la
\end{flushleft}


\begin{flushleft}
𝜆
\end{flushleft}


\begin{flushleft}
media sia la varianza, per una Poisson) come la somma di n Poisson di parametro 𝜆˜ = n .
\end{flushleft}





\begin{flushleft}
\newpage
Parte II
\end{flushleft}


\begin{flushleft}
Statistica
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
CAPITOLO 12
\end{flushleft}


\begin{flushleft}
STIME PUNTUALI
\end{flushleft}


\begin{flushleft}
Con questo capitolo iniziamo l'esplorazione della Statistica, costruendo sulle fondamenta di Probabilit\`{a}. Nello studio della Probabilit\`{a} abbiamo usato un livello abbastanza alto di astrazione: le
\end{flushleft}


\begin{flushleft}
ipotesi alla base dei modelli erano {``}assolute'' e alle volte impossibili da verificare in casi applicati.
\end{flushleft}


\begin{flushleft}
Abbiamo visto come calcolare probabilit\`{a} e momenti, che sono tutti valori deterministici e certi.
\end{flushleft}


\begin{flushleft}
In Statistica abbiamo invece dati reali e ipotesi ragionevoli (anche se approssimate, come ad
\end{flushleft}


\begin{flushleft}
esempio X $\sim$
\end{flushleft}


\begin{flushleft}
˙ 𝒩). Calcoliamo stime di parametri (o momenti o altre quantit\`{a}) e facciamo verifiche
\end{flushleft}


\begin{flushleft}
della compatibilit\`{a} delle ipotesi con in dati a nostra disposizione. Ma in questo caso i valori (ad
\end{flushleft}


\begin{flushleft}
esempio dei parametri) hanno margini di incertezza, non sono certi come lo erano in Probabilit\`{a}.
\end{flushleft}





\begin{flushleft}
12.1. INTRODUZIONE ALLA STATISTICA
\end{flushleft}


\begin{flushleft}
Alla base della Probabilit\`{a} avevamo lo spazio degli esiti, in Statistica questo ruolo \`{e} preso dalla
\end{flushleft}


\begin{flushleft}
popolazione.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.1. Chiamiamo popolazione (di riferimento) un insieme costituito da elementi distinti,
\end{flushleft}


\begin{flushleft}
sui quali conduciamo la nostra indagine. Chiamiamo tali elementi esemplari, individui o unit\`{a} statistiche.
\end{flushleft}


\begin{flushleft}
Esempio 12.2. Sono esempi di popolazione di riferimento:
\end{flushleft}


\begin{flushleft}
$-$ la popolazione mondiale,
\end{flushleft}


\begin{flushleft}
$-$ gli animali ospitati in uno zoo,
\end{flushleft}


\begin{flushleft}
$-$ gli studenti che frequentano un corso,
\end{flushleft}


\begin{flushleft}
$-$ le aziende in una determinata provincia,
\end{flushleft}


\begin{flushleft}
$-$ i prodotti di uno stabilimento.
\end{flushleft}


\begin{flushleft}
In Statistica siamo interessati alle misure di (alcune) caratteristiche degli individui, dette dati.
\end{flushleft}


\begin{flushleft}
Vogliamo usare questi dati per avere informazioni riguardo all'intera popolazione. Abbiamo
\end{flushleft}


\begin{flushleft}
per\`{o} davanti a noi una biforcazione nella Statistica, proprio a questo punto: da un lato abbiamo
\end{flushleft}


\begin{flushleft}
la Statistica descrittiva, dall'altro la Statistica inferenziale. Di queste, la prima non chiama in gioco
\end{flushleft}


\begin{flushleft}
la Probabilit\`{a}: abbiamo misure sull'intera popolazione e vogliamo descrivere alcune caratteristiche
\end{flushleft}


\begin{flushleft}
dell'intera popolazione a partire da queste misure, calcolandone opportune funzioni che riassumano tutte le informazioni in una quantit\`{a} ridotta di numeri o indicatori.
\end{flushleft}


\begin{flushleft}
La seconda, invece, entra in campo quando non abbiamo dati sull'intera popolazione, ma
\end{flushleft}


\begin{flushleft}
solamente su un suo sottoinsieme, detto campione. Vogliamo fare affermazioni sull'intera popolazione, ma abbiamo bisogno di ricavarle (o inferirle) dalle informazioni sul campione, usando
\end{flushleft}


\begin{flushleft}
opportuni modelli probabilistici.
\end{flushleft}


\begin{flushleft}
La Statistica descrittiva e quella inferenziale hanno forti legami, ma sono ben distinte. Da un
\end{flushleft}


\begin{flushleft}
lato i metodi e le tecniche che si usano sono molto differenti, dall'altro quando ci restringiamo
\end{flushleft}


\begin{flushleft}
al campione (considerandolo come nuova popolazione) e calcoliamo funzioni delle grandezze
\end{flushleft}


\begin{flushleft}
misurate, stiamo facendo Statistica descrittiva.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.3. Chiamiamo campione un sottoinsieme della popolazione di riferimento.
\end{flushleft}


169





\begin{flushleft}
Lezione 21
\end{flushleft}





\newpage
170





\begin{flushleft}
STIME PUNTUALI
\end{flushleft}





\begin{flushleft}
Il campione \`{e} la controparte statistica degli eventi (che erano opportuni sottoinsiemi dello
\end{flushleft}


\begin{flushleft}
spazio degli esiti). Per gli eventi chiedevamo fossero soddisfatte alcune ipotesi astratte, cio\`{e} che
\end{flushleft}


\begin{flushleft}
la loro famiglia fosse una tribù. Per i campioni abbiamo alcune richieste, che per\`{o} non sono così
\end{flushleft}


\begin{flushleft}
rigidamente definite. Prima di arrivare a queste caratteristiche, per\`{o}, cerchiamo di rispondere a
\end{flushleft}


\begin{flushleft}
una domanda: perch\'{e} concentrarci su un campione? Una prima ragione \`{e} la praticit\`{a}: la popolazione pu\`{o} essere molto grande, oppure le misurazioni che prendiamo richiedono la distruzione
\end{flushleft}


\begin{flushleft}
degli esemplari (pensiamo ad esempio ai crash test degli autoveicoli). Ci sono poi anche ragioni
\end{flushleft}


\begin{flushleft}
di costo e di etica.
\end{flushleft}


\begin{flushleft}
Vorremmo che il campione del quale raccogliamo le misurazioni sia il più possibile rappresentativo della popolazione di riferimento, ma \`{e} difficile dare una definizione assoluta di cosa
\end{flushleft}


\begin{flushleft}
significhi rappresentativo. Ci sono anche modi diversi di scegliere un campione, nella pratica.
\end{flushleft}


\begin{flushleft}
Ciascun modo ha un costo (decrescente nell'elenco qui sotto) e caratteristiche peculiari:
\end{flushleft}


\begin{flushleft}
$-$ campionamento casuale semplice,
\end{flushleft}


\begin{flushleft}
$-$ campionamento casuale stratificato (nel quale vogliamo preservare alcune caratteristiche della
\end{flushleft}


\begin{flushleft}
popolazione),
\end{flushleft}


\begin{flushleft}
$-$ campionamento a grappoli (ad esempio se la popolazione sono gli scolari della Provincia
\end{flushleft}


\begin{flushleft}
Autonoma di Trento, i grappoli potrebbero esse singole classi che scegliamo a caso, ma come
\end{flushleft}


\begin{flushleft}
unit\`{a}); pu\`{o} essere a uno o due stadi, a seconda che all'interno dei grappoli facciamo o meno
\end{flushleft}


\begin{flushleft}
un campionamento,
\end{flushleft}


\begin{flushleft}
$-$ campionamento selettivo,
\end{flushleft}


\begin{flushleft}
$-$ campionamento per convenienza o disponibilit\`{a},
\end{flushleft}


\begin{flushleft}
$-$ campionamento per quote (da non confondere con il campionamento stratificato).
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.4. Le caratteristiche che misuriamo prendono il nome di variabili, i valori che assumono
\end{flushleft}


\begin{flushleft}
si chiamano livelli o modalit\`{a}.
\end{flushleft}


\begin{flushleft}
Le variabili possono essere di tipo
\end{flushleft}


\begin{flushleft}
$-$ qualitativo o categorico, se sono aggettivi o simili, in particolare
\end{flushleft}


\begin{flushleft}
$\bullet$ nominale, se non hanno un ordinamento naturale,
\end{flushleft}


\begin{flushleft}
$\bullet$ ordinale, se hanno un ordinamento naturale;
\end{flushleft}


\begin{flushleft}
$-$ quantitativo o numerico, se sono grandezze descritte da numeri, in particolare
\end{flushleft}


\begin{flushleft}
$\bullet$ discreto, se sono descritte da numeri interi,
\end{flushleft}


\begin{flushleft}
$\bullet$ continuo, se sono descritte da numeri reali.
\end{flushleft}


\begin{flushleft}
Nel caso di variabili numeriche, la scala di misurazione pu\`{o} essere di tipo
\end{flushleft}


\begin{flushleft}
$-$ intervallo, se lo 0 \`{e} fissato in modo arbitrario,
\end{flushleft}


\begin{flushleft}
$-$ rapporto, se lo 0 \`{e} fissato in modo naturale.
\end{flushleft}


\begin{flushleft}
Esempio 12.5. Vediamo alcuni esempi di variabili dei diversi tipi.
\end{flushleft}


\begin{flushleft}
Osservazione 12.6. Nell'ambito della Statistica inferenziale, possiamo identificare un esemplare
\end{flushleft}


\begin{flushleft}
con le misure a esso associate. In questo modo possiamo vedere la popolazione come la distribuzione (non nota) di una variabile aleatoria.
\end{flushleft}


\begin{flushleft}
Esempio 12.7. Una ditta produce bulloni di 7 mm di diametro. Un bullone \`{e} accettabile se il suo
\end{flushleft}


\begin{flushleft}
diametro \`{e} compreso tra 6.5 mm e 7.5 mm.
\end{flushleft}


\begin{flushleft}
Prendiamo un bullone e misuriamo il suo diametro effettivo. Possiamo vedere questo come
\end{flushleft}


\begin{flushleft}
un esperimento aleatorio e possiamo descrivere il diametro come una variabile aleatoria di densit\`{a} f X .
\end{flushleft}





\begin{flushleft}
\newpage
12.2 STIMATORI E STIME
\end{flushleft}





171





\begin{flushleft}
Il problema diventa allora come utilizzare le misurazioni del diametro di alcuni bulloni per
\end{flushleft}


\begin{flushleft}
inferire la distribuzione fX e poter prendere decisioni sull'intera popolazione, come per esempio
\end{flushleft}


\begin{flushleft}
ricalibrare la macchina, qualora il diametro medio fosse troppo piccolo o troppo grande. Procedendo in questo modo stiamo vedendo le misurazioni fatte sul campione come variabili aleatorie
\end{flushleft}


\begin{flushleft}
indipendenti e identicamente distribuite. La distribuzione comune \`{e} la distribuzione (non nota)
\end{flushleft}


\begin{flushleft}
dell'intera popolazione.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.8. Una statistica \`{e} una funzione calcolabile a partire dalla misurazione del campione.
\end{flushleft}


\begin{flushleft}
Esempio 12.9. Sono esempi di statistiche calcolate per un campione (x1, . . . , xn)
\end{flushleft}


\begin{flushleft}
1. la media campionaria x̄: = n ∑ni=1 xi
\end{flushleft}


1





\begin{flushleft}
2. la varianza campionaria a media 𝜇 nota: s ∗2 ≔ n ∑ ni=1 (xi $-$ 𝜇)2
\end{flushleft}


1





\begin{flushleft}
3. la varianza campionaria a media ignota: s 2 ≔ n $-$ 1 ∑ ni=1 (xi $-$ x̄)2
\end{flushleft}


1





\begin{flushleft}
4. il numero di misurazioni eccedenti una certa soglia c: \# i $\in$ \{1, . . . , n\} : xi $>$ c
\end{flushleft}


\begin{flushleft}
5. il primo esemplare del campione per cui la misurazione \`{e} inferiore a una certa soglia c: inf i $\in$
\end{flushleft}


\begin{flushleft}
\{1, . . . , n\} : xi $<$ c .
\end{flushleft}


\begin{flushleft}
Osservazione 12.10. Vale la pena prestare attenzione alla notazione che useremo: se abbiamo delle
\end{flushleft}


\begin{flushleft}
quantit\`{a}, dei numeri, usiamo in genere la lettera minuscola. La lettera maiuscola denota invece
\end{flushleft}


\begin{flushleft}
le variabili aleatorie, ossia funzioni di esemplari (ignoti) del campione. In generale, dunque, s 2
\end{flushleft}


\begin{flushleft}
e S 2 indicheranno cose diverse: la prima sar\`{a} un numero, la seconda una variabile aleatoria, il
\end{flushleft}


\begin{flushleft}
risultato di un esperimento aleatorio.
\end{flushleft}





\begin{flushleft}
Ci sono molti modi in cui la distribuzione fX pu\`{o} essere ignota, ma li possiamo dividere in
\end{flushleft}


\begin{flushleft}
due categorie. Nella prima categoria il modello \`{e} noto a meno di parametri. Ad esempio, sappiamo che X \`{e} una variabile aleatoria di Poisson, ma non ne conosciamo il parametro 𝜆. In questo
\end{flushleft}


\begin{flushleft}
caso il nostro obiettivo \`{e} stimare il parametro (o i parametri) a partire dai dati. Parliamo quindi
\end{flushleft}


\begin{flushleft}
di Statistica parametrica. Nella seconda categoria, invece, il modello \`{e} completamente ignoto: in
\end{flushleft}


\begin{flushleft}
questo caso parliamo di Statistica non parametrica. In questo corso ci occuperemo esclusivamente
\end{flushleft}


\begin{flushleft}
di Statistica parametrica.
\end{flushleft}


\begin{flushleft}
Osservazione 12.11. Parliamo di modelli per la popolazione perch\'{e} non ci aspettiamo di conoscere
\end{flushleft}


\begin{flushleft}
con certezza la realt\`{a}: un modello \`{e} una ragionevole astrazione o approssimazione della verit\`{a}.
\end{flushleft}


\begin{flushleft}
Inoltre sono modelli statistici, ossia modelli di variabili aleatorie (cio\`{e} una distribuzione) che ipotizziamo essere la legge comune all'intera popolazione. Questo modello sar\`{a} parametrico, ossia
\end{flushleft}


\begin{flushleft}
avremo per ipotesi la famiglia di appartenenza e vorremo determinarne i parametri.
\end{flushleft}


\begin{flushleft}
Esempio 12.12. Se ipotizziamo che il passaggio degli autobus della linea 5 a Povo sia distribuito
\end{flushleft}


\begin{flushleft}
secondo una legge esponenziale, dovremo stimarne il parametro 𝜆 o, equivalentemente, il valore
\end{flushleft}


\begin{flushleft}
atteso a partire dalle misurazioni del campione.
\end{flushleft}





\begin{flushleft}
12.2. STIMATORI E STIME
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.13. Chiamiamo stimatore di un parametro una variabile aleatoria che sia una funzione
\end{flushleft}


\begin{flushleft}
del campione (ossia una statistica), il cui valore \`{e} {``}spesso vicino'' al parametro che ci interessa.
\end{flushleft}


\begin{flushleft}
Il valore deterministico assunto dallo stimatore usando i dati osservati prende il nome di stima.
\end{flushleft}


\begin{flushleft}
\`{E} importante sottolineare quanto appena detto nella definizione: lo stimatore \`{e} una funzione, in
\end{flushleft}


\begin{flushleft}
particolare una variabile aleatoria, che ha come argomenti le osservazioni. La stima \`{e} un numero,
\end{flushleft}


\begin{flushleft}
una quantit\`{a} deterministica calcolata a partire dalle effettive misure fatte.
\end{flushleft}





\newpage
172





\begin{flushleft}
STIME PUNTUALI
\end{flushleft}





\begin{flushleft}
Esempio 12.14. Se il nostro campione (da un punto di vista astratto, prima di fare le misurazioni)
\end{flushleft}


\begin{flushleft}
\`{e} un vettore di n variabili aleatorie indipendenti e identicamente distribuite (X1, . . ., Xn), un parametro di interesse \`{e} il valore atteso comune E[Xi] = 𝜇, che supponiamo ignoto. Uno stimatore
\end{flushleft}


1


\begin{flushleft}
della media \`{e} la media campionaria (intesa come funzione) X = n ∑ ni=1 X i. Abbiamo una variabile
\end{flushleft}


\begin{flushleft}
aleatoria X e una quantit\`{a} deterministica 𝜇.
\end{flushleft}


\begin{flushleft}
Il fatto che X sia uno stimatore (cio\`{e} X $\approx$ 𝜇) ci \`{e} suggerito dalla legge dei grandi numeri (Teorema 11.15): sappiamo infatti che
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
∑ i=1 Xi 1
\end{flushleft}


=


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
Xi = (X)n $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ 𝜇.
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
\`{E} legittimo chiedersi come cambi lo stimatore al crescere del numero delle osservazioni nel
\end{flushleft}


\begin{flushleft}
campione. Possiamo sottolineare questo aspetto indicando in modo esplicito la dipendenza da n
\end{flushleft}


\begin{flushleft}
a pedice: $\Theta$n = 𝜗ˆ ((Xi)ni=1).
\end{flushleft}


\begin{flushleft}
In generale, nello stimare una quantit\`{a}, ci aspettiamo di commettere un errore. Questo errore
\end{flushleft}


\begin{flushleft}
prende il nome di errore di stima, che vorremmo quantificare e controllare. Anche questo errore \`{e}
\end{flushleft}


\begin{flushleft}
una variabile aleatoria, quindi siamo interessati, se \`{e} possibile, ad averne la distribuzione.
\end{flushleft}


\begin{flushleft}
Esempio 12.15. Se sapessimo che X 1, . . ., Xn sono variabili aleatorie indipendenti e identicamente
\end{flushleft}


\begin{flushleft}
distribuite con media 𝜇 ignota, ma varianza 𝜎 2 nota (ad esempio per le specifiche tecniche del
\end{flushleft}


\begin{flushleft}
macchinario), allora potremmo avere una distribuzione per l'errore commesso nello stimare 𝜇
\end{flushleft}


\begin{flushleft}
con X: il teorema centrale del limite (Teorema 11.18) ci dice infatti che
\end{flushleft}


\begin{flushleft}
X $-$ 𝜇 $\sim$ 𝒩 0,
\end{flushleft}





\begin{flushleft}
𝜎
\end{flushleft}


.


\begin{flushleft}
$\surd$n
\end{flushleft}





\begin{flushleft}
Osservazione 12.16. Un parametro non ha necessariamente un unico stimatore. In particolare
\end{flushleft}


\begin{flushleft}
possiamo avere più stimatori, ottenuti a partire da statistiche (cio\`{e} da funzioni) diverse. Gli errori
\end{flushleft}


\begin{flushleft}
di stima a essi associati avranno in genere distribuzioni diverse tra loro. Vorremmo quindi individuare caratteristiche degli stimatori che ci permettano di scegliere quelli migliori12.1, tra quelli
\end{flushleft}


\begin{flushleft}
che possiamo calcolare coi dati a nostra disposizione.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.17. Diciamo che uno stimatore $\Theta$ di un parametro 𝜗 \`{e}:
\end{flushleft}


\begin{flushleft}
$-$ corretto o non distorto (unbiased), se E[$\Theta$] = 𝜗
\end{flushleft}


\begin{flushleft}
$-$ distorto (biased), se E[$\Theta$] $\neq$ 𝜗; in questo caso il valore E[$\Theta$] $-$ 𝜗 si dice distorsione o bias.
\end{flushleft}


\begin{flushleft}
Se lim n$\rightarrow$+$\infty$ E[$\Theta$n] = 𝜗 diciamo che $\Theta$ \`{e} asintoticamente non distorto.
\end{flushleft}


\begin{flushleft}
NOTAZIONE 12.18. Spesso invece di $\Theta$ usiamo 𝜗ˆ o 𝜗ˆ (X) per indicare uno stimatore del parametro 𝜗. In
\end{flushleft}


\begin{flushleft}
particolare lo faremo per la media 𝜇, visto che la maiuscola greca sarebbe M.
\end{flushleft}


\begin{flushleft}
Osservazione 12.19. Dire che uno stimatore \`{e} biased significa che abbiamo un errore sistematico
\end{flushleft}


\begin{flushleft}
di sottostima o sovrastima. Questo errore pu\`{o} essere costante o dipendere dal valore del parametro o dalla numerosit\`{a} del campione.
\end{flushleft}


\begin{flushleft}
Il bias misura solamente un aspetto dell'errore. Possiamo considerare altre funzioni di errore,
\end{flushleft}


\begin{flushleft}
che penalizzino un maggiore allontanamento dal valore {``}vero'' del parametro.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.20. Chiamiamo errore quadratico medio (mean square error) di uno stimatore $\Theta$ del
\end{flushleft}


\begin{flushleft}
parametro 𝜗 la quantit\`{a}
\end{flushleft}


\begin{flushleft}
MSE[$\Theta$] = E[($\Theta$ $-$ 𝜗)2].
\end{flushleft}


\begin{flushleft}
12.1. Non abbiamo ancora specificato rispetto a quale metrica intendiamo misurare la bont\`{a} degli stimatori. Ce ne
\end{flushleft}


\begin{flushleft}
sono infatti diverse, come vedremo tra poco.
\end{flushleft}





\begin{flushleft}
\newpage
12.2 STIMATORI E STIME
\end{flushleft}





173





\begin{flushleft}
Osservazione 12.21. Possiamo scrivere l'errore quadratico medio in modo leggermente diverso,
\end{flushleft}


\begin{flushleft}
in analogia a quanto visto per la varianza (anche questo \`{e} un momento secondo):
\end{flushleft}


\begin{flushleft}
MSE[$\Theta$] =
\end{flushleft}


=


=


=





\begin{flushleft}
E[($\Theta$ $-$ 𝜗)2] = E[($\Theta$ $-$ E[$\Theta$] + E[$\Theta$] $-$ 𝜗)2]
\end{flushleft}


\begin{flushleft}
E[($\Theta$ $-$ E[$\Theta$])2] + E[(E[$\Theta$] $-$ 𝜗)2] + 2 E[($\Theta$ $-$ E[$\Theta$]) (E[$\Theta$] $-$ 𝜗)]
\end{flushleft}


\begin{flushleft}
Var[$\Theta$] + (bias)2 + 2 (E[$\Theta$] $-$ E[$\Theta$]) (E[$\Theta$] $-$ 𝜗)
\end{flushleft}


\begin{flushleft}
Var[$\Theta$] + (bias)2.
\end{flushleft}





\begin{flushleft}
In particolare se $\Theta$ \`{e} corretto il bias \`{e} nullo e MSE[$\Theta$] = Var[$\Theta$], ma non \`{e} detto che conosciamo
\end{flushleft}


\begin{flushleft}
la varianza di $\Theta$.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.22. Diciamo che uno stimatore $\Theta$ di un parametro 𝜗 \`{e} consistente se $\Theta$n converge in
\end{flushleft}


\begin{flushleft}
probabilit\`{a} a 𝜗 per n $\rightarrow$ +$\infty$. Se inoltre $\Theta$n converge in media quadratica a 𝜗 per n $\rightarrow$ +$\infty$, diciamo che $\Theta$ \`{e}
\end{flushleft}


\begin{flushleft}
consistente in media quadratica.
\end{flushleft}


\begin{flushleft}
Il prossimo risultato ci d\`{a} una condizione sufficiente per la consistenza di uno stimatore.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE 12.23. Se $\Theta$ \`{e} asintoticamente non distorto e lim n$\rightarrow$+$\infty$ Var[$\Theta$n] = 0, allora $\Theta$ \`{e} uno stimatore consistente in media quadratica (e quindi anche consistente).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Chiedere che $\Theta$ sia consistente in media quadratica significa chiedere che
\end{flushleft}


\begin{flushleft}
lim E[($\Theta$n $-$ 𝜗)2] = 0
\end{flushleft}





\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
ossia che lim n$\rightarrow$+$\infty$ MSE[$\Theta$n] = 0. Ma per quanto visto nell'Osservazione 12.21,
\end{flushleft}


\begin{flushleft}
MSE[$\Theta$n] = Var[$\Theta$n] + (E[$\Theta$n] $-$ 𝜗)2
\end{flushleft}


\begin{flushleft}
e la convergenza a 0 \`{e} assicurata dalle ipotesi, separatamente per i due addendi a secondo membro.
\end{flushleft}


\begin{flushleft}
La consistenza segue dalla consistenza in media quadratica perch\'{e} la convergenza in L2 implica
\end{flushleft}


\begin{flushleft}
la convergenza in probabilit\`{a} (Proposizione 11.6).
\end{flushleft}


□





\begin{flushleft}
Osservazione 12.24. Uno stimatore pu\`{o} essere corretto ma non consistente. Ad esempio se le
\end{flushleft}


\begin{flushleft}
variabili aleatorie (X 1, . . . , X n) sono indipendenti e identicamente distribuite, allora ciascuna X i \`{e}
\end{flushleft}


\begin{flushleft}
uno stimatore non distorto della media 𝜇, poich\'{e} E[X i] = 𝜇 per ogni i $\in$ \{1, . . . , n\}.
\end{flushleft}


\begin{flushleft}
Tuttavia, posta 𝜎 2 = Var[X i] $\neq$ 0 (comune a tutte le Xi), non possiamo avere convergenza in
\end{flushleft}


\begin{flushleft}
probabilit\`{a} di alcuno di questi stimatori a 𝜇, poich\'{e}, per qualche 𝜀 $>$ 0
\end{flushleft}


\begin{flushleft}
P(|X i $-$ 𝜇| $>$ 𝜀) $\neq$ 0
\end{flushleft}


\begin{flushleft}
e, per ogni n, lo stimatore (X i) \`{e} una variabile aleatoria di media 𝜇 e di varianza costante 𝜎 2 $\neq$ 0.
\end{flushleft}


\begin{flushleft}
Non possiamo dunque avere convergenza in legge ad una costante 𝜇 e, a maggior ragione, non
\end{flushleft}


\begin{flushleft}
possiamo avere convergenza in probabilit\`{a}.
\end{flushleft}





\begin{flushleft}
12.2.1. Alcuni stimatori
\end{flushleft}





\begin{flushleft}
Lezione 22
\end{flushleft}





\begin{flushleft}
Assumiamo, per questa sottosezione, che le variabili aleatorie X 1, . . . , X n che costituiscono il
\end{flushleft}


\begin{flushleft}
campione siano indipendenti e identicamente distribuite di valore atteso comune E[Xi] = 𝜇 e di
\end{flushleft}


\begin{flushleft}
varianza comune Var[X i] = 𝜎 2.
\end{flushleft}


1


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
La media campionaria 𝜇ˆ = 𝜇ˆ n = n ∑ i=1 Xi (alle volte indicata anche come X) \`{e} uno stimatore
\end{flushleft}


\begin{flushleft}
corretto e consistente del valore atteso E[X 1] = 𝜇: questo segue dal teorema centrale del limite
\end{flushleft}


\begin{flushleft}
(Teorema 11.18) o dalle propriet\`{a} del valore atteso e della varianza:
\end{flushleft}


\begin{flushleft}
E[𝜇ˆ ] = E
\end{flushleft}





\begin{flushleft}
[[ n1
\end{flushleft}


[





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





1


\begin{flushleft}
X ]] =
\end{flushleft}


\begin{flushleft}
] n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
E[X i] =
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





1


\begin{flushleft}
⋅n⋅𝜇=𝜇
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





1


\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
Var[𝜇ˆ ] = 2
\end{flushleft}


\begin{flushleft}
Var[Xi] =
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$ 0.


\begin{flushleft}
n n$\rightarrow$+$\infty$
\end{flushleft}


\begin{flushleft}
n i=1
\end{flushleft}





\newpage
174





\begin{flushleft}
STIME PUNTUALI
\end{flushleft}





2


\begin{flushleft}
Per la varianza 𝜎 2 possiamo usare lo stimatore S∗2 = S ∗n
\end{flushleft}


\begin{flushleft}
= n ∑ni=1 (Xi $-$ 𝜇)2, ma dobbiamo conoscere la speranza 𝜇. Questo stimatore \`{e} corretto
\end{flushleft}


1





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
E[S ∗2] =
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
E[(Xi $-$ 𝜇)2] =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Var[X i] = Var[Xi]
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
ed \`{e} anche consistente, poich\'{e} per la legge dei grandi numeri (Teorema 11.15)
\end{flushleft}


2


\begin{flushleft}
S∗n
\end{flushleft}


=





\begin{flushleft}
n
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
(Xi $-$ 𝜇)2 $\rightarrow$
\end{flushleft}


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


$\rightarrow$


\begin{flushleft}
$\rightarrow$ E[(Xi $-$ 𝜇)2] = Var[X i].
\end{flushleft}


\begin{flushleft}
n$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Se non conosciamo la speranza 𝜇, la prima idea \`{e} di sostituire a 𝜇 lo stimatore 𝜇ˆ . Tuttavia
\end{flushleft}


1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





1


\begin{flushleft}
(Xi $-$ 𝜇ˆ ) =
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
i=1
\end{flushleft}





((


(





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
X 𝜇ˆ + n 𝜇 )
\end{flushleft}


\begin{flushleft}
)) = n1 (((
\end{flushleft}





\begin{flushleft}
X i2 $-$ 2
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
i
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





ˆ2





\begin{flushleft}
n
\end{flushleft}





))


)





\begin{flushleft}
Xi2 $-$ n 𝜇ˆ 2
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
e, se ne prendiamo il valore atteso,
\end{flushleft}


\begin{flushleft}
E
\end{flushleft}





\begin{flushleft}
[[[ n1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





]]]





\begin{flushleft}
X i2 $-$ 𝜇ˆ 2 = E
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
[[[ n1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





]]]





\begin{flushleft}
(Xi2 $-$ 𝜇2) $-$ (𝜇ˆ 2 $-$ 𝜇2)
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





1


\begin{flushleft}
= n 𝜎 2 $-$ Var[𝜇ˆ ]
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
= 𝜎2⋅
\end{flushleft}


,


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
ossia abbiamo uno stimatore distorto, dal momento che
\end{flushleft}


1


\begin{flushleft}
E[[
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


[





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





(12.1)





]]


]





1


\begin{flushleft}
(X i $-$ 𝜇ˆ )2 $-$ 𝜎 2 = $-$ ⋅ 𝜎 2 $\neq$ 0.
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Vale la pena notare, prima di proseguire, che questo stimatore, pur distorto, \`{e} consistente, ancora
\end{flushleft}


\begin{flushleft}
una volta per la legge dei grandi numeri.
\end{flushleft}


\begin{flushleft}
La (12.1) ci suggerisce per\`{o} la correzione da fare allo stimatore per renderlo non distorto:
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
possiamo moltiplicarlo per n $-$ 1 . Quindi uno stimatore per la varianza, se non conosciamo la spe1
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
ranza 𝜇, \`{e} S 2 = S n2 = n $-$ 1 ∑ i=1 (X i $-$ 𝜇ˆ )2. Questo \`{e} uno stimatore corretto, come possiamo facilmente
\end{flushleft}


\begin{flushleft}
verificare ripercorrendo quanto appena visto, e anche consistente, sempre per la legge dei grandi
\end{flushleft}


\begin{flushleft}
numeri.
\end{flushleft}


\begin{flushleft}
Osservazione 12.25. Lo stimatore S 2 pu\`{o} essere scritto in forma matematicamente equivalente
\end{flushleft}


\begin{flushleft}
come
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1


\begin{flushleft}
S 2 = S n2 =
\end{flushleft}


\begin{flushleft}
X i2 $-$ n 𝜇ˆ 2 ,
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}





((


(





\begin{flushleft}
i=1
\end{flushleft}





))


)





\begin{flushleft}
ma da un punto di vista numerico o computazionale, questa forma \`{e} molto più instabile.
\end{flushleft}


\begin{flushleft}
Osservazione 12.26. Possiamo prendere, come stimatori della deviazione standard, S= S 2 oppure
\end{flushleft}


\begin{flushleft}
S ∗ = S ∗2 . \`{E} possibile per\`{o} mostrare che entrambi questi stimatori sono consistenti ma distorti.
\end{flushleft}


\begin{flushleft}
In generale non esiste uno stimatore non distorto della deviazione standard valido indipendentemente dalla particolare distribuzione della popolazione (e quindi del campione).
\end{flushleft}





\begin{flushleft}
12.2.2. Distribuzione degli stimatori
\end{flushleft}


\begin{flushleft}
Vorremmo ora sfruttare meglio il fatto che gli stimatori siano variabili aleatorie e cercare di usare
\end{flushleft}


\begin{flushleft}
le loro propriet\`{a} per ottenere una valutazione degli errori di stima. Per farlo abbiamo per\`{o} bisogno
\end{flushleft}


\begin{flushleft}
di conoscere la distribuzione di probabilit\`{a} dello stimatore.
\end{flushleft}


\begin{flushleft}
Consideriamo la seguente situazione: supponiamo che la popolazione abbia una distribuzione
\end{flushleft}


\begin{flushleft}
Gaussiana di parametri (ignoti) 𝜇 e 𝜎. Stiamo quindi affermando che ogni Xi nel campione ha
\end{flushleft}


\begin{flushleft}
legge 𝒩(𝜇, 𝜎).
\end{flushleft}





\begin{flushleft}
\newpage
12.2 STIMATORI E STIME
\end{flushleft}





175





\begin{flushleft}
Abbiamo gi\`{a} visto, nella Sotto-sezione 12.2.1 uno stimatore per la media e uno per la
\end{flushleft}


\begin{flushleft}
varianza12.2 adatti a questo caso: la media campionaria 𝜇ˆ (o X) e la varianza campionaria (a media
\end{flushleft}


\begin{flushleft}
ignota) S 2. Ora siamo interessati a determinarne le distribuzioni. Per farlo, iniziamo sfruttando
\end{flushleft}


1


\begin{flushleft}
la riproducibilit\`{a} delle Gaussiane: se tutte le X i sono Gaussiane, anche 𝜇ˆ n = Xn = n ∑ X i \`{e} Gaus2
\end{flushleft}


\begin{flushleft}
siana e, in particolare ha valore atteso 𝜇 e varianza 𝜎 /n:
\end{flushleft}


\begin{flushleft}
𝜇ˆ n $-$ 𝜇 Xn $-$ 𝜇
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜇ˆ n = X n $\sim$ 𝒩 𝜇,
\end{flushleft}


\begin{flushleft}
ossia
\end{flushleft}


\begin{flushleft}
= 𝜎
\end{flushleft}


\begin{flushleft}
$\sim$ 𝒩(0, 1).
\end{flushleft}


\begin{flushleft}
𝜎/
\end{flushleft}


\begin{flushleft}
/$\surd$n
\end{flushleft}


\begin{flushleft}
$\surd$n
\end{flushleft}


\begin{flushleft}
$\surd$n
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
Sapevamo gi\`{a}, qualunque fosse la distribuzione della popolazione, che E[𝜇ˆ n] = 𝜇 e Var[𝜇ˆ n] = n ,
\end{flushleft}


\begin{flushleft}
ma ora abbiamo l'informazione aggiuntiva che 𝜇ˆ ha distribuzione normale e quindi, sapendone
\end{flushleft}


\begin{flushleft}
anche i parametri, ne conosciamo completamente la legge.
\end{flushleft}


\begin{flushleft}
Vogliamo fare lo stesso per lo stimatore S 2: determinarne la distribuzione nel caso di una
\end{flushleft}


\begin{flushleft}
popolazione Gaussiana. Iniziamo dalla definizione di S 2 e manipoliamola un po':
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(X i $-$ 𝜇ˆ )2 =
\end{flushleft}





\begin{flushleft}
(n $-$ 1) Sn2 =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Xi2 $-$ n 𝜇ˆ 2.
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
La scrittura a ultimo membro mette in evidenza che (modulo i coefficienti), S 2 \`{e} la somma di
\end{flushleft}


\begin{flushleft}
quadrati di Gaussiane indipendenti e identicamente distribuite più un'ulteriore Gaussiana al quadrato. Questo ci suggerisce un possibile legame con una variabile aleatoria chi quadro.
\end{flushleft}


\begin{flushleft}
Per approfondire questo legame, andiamo a riscrivere S 2 in termini di normali standard:
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(n $-$ 1) S n2
\end{flushleft}





=





\begin{flushleft}
Xi2 $-$ n 𝜇ˆ 2n =
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(Xi2 + 𝜇2) $-$ n (𝜇ˆ 2n + 𝜇2)
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(𝜇ˆ 2n $-$ 2 Xi 𝜇 + 𝜇2)
\end{flushleft}





\begin{flushleft}
(Xi2 $-$ 2 X i 𝜇 + 𝜇2) $-$
\end{flushleft}





=


\begin{flushleft}
i=1
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





=





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
(Xi $-$ 𝜇)2 $-$ n (𝜇ˆ n $-$ 𝜇)2.
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Ora dividiamo primo e ultimo membro per 𝜎 2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(n $-$ 1) Sn2
\end{flushleft}


=


\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}


\begin{flushleft}
e, osservando che ogni
\end{flushleft}


\begin{flushleft}
come
\end{flushleft}





\begin{flushleft}
Xi $-$ 𝜇
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
Xi $-$ 𝜇
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





2





$-$





\begin{flushleft}
(( 𝜇ˆ /$-$ 𝜇 ))
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
$\surd$n
\end{flushleft}





\begin{flushleft}
\`{e} una normale standard, così come
\end{flushleft}


\begin{flushleft}
𝜇ˆ n $-$ 𝜇
\end{flushleft}


\begin{flushleft}
(n $-$ 1) Sn2
\end{flushleft}


\begin{flushleft}
+ 𝜎
\end{flushleft}


\begin{flushleft}
/$\surd$n
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





((





)) =


2





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





2





\begin{flushleft}
Xi $-$ 𝜇
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
𝜇ˆ n $-$ 𝜇
\end{flushleft}


,


\begin{flushleft}
𝜎/
\end{flushleft}


\begin{flushleft}
$\surd$n
\end{flushleft}





\begin{flushleft}
riscriviamo questa identit\`{a}
\end{flushleft}





2





,





\begin{flushleft}
in cui a secondo membro abbiamo la somma di n Gaussiane
\end{flushleft}


\begin{flushleft}
standard indipendenti (ossia una 𝜒 2
\end{flushleft}


\begin{flushleft}
(n $-$ 1) Sn2
\end{flushleft}


\begin{flushleft}
a n gradi di libert\`{a}) e a primo membro abbiamo 𝜎 2 più il quadrato di una normale standard
\end{flushleft}


\begin{flushleft}
(ossia una 𝜒 2 a un grado di libert\`{a}). Allora, per la propriet\`{a} di riproducibilit\`{a} delle chi quadro,
\end{flushleft}


\begin{flushleft}
deve essere12.3
\end{flushleft}


\begin{flushleft}
(n $-$ 1) Sn2
\end{flushleft}


\begin{flushleft}
𝜎2 2
\end{flushleft}


\begin{flushleft}
$\sim$ 𝜒 2(n $-$ 1)
\end{flushleft}


\begin{flushleft}
cio\`{e}
\end{flushleft}


\begin{flushleft}
S n2 $\sim$
\end{flushleft}


\begin{flushleft}
𝜒 (n $-$ 1).
\end{flushleft}


2


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
Riassumendo, abbiamo ottenuto che per una popolazione Gaussiana di speranza 𝜇 e varianza 𝜎 2,
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
lo stimatore media campionaria ha distribuzione Gaussiana 𝜇ˆ $\sim$ 𝒩 𝜇, $\surd$n e lo stimatore varianza
\end{flushleft}


2


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
campionaria a media ignota ha distribuzione S n2 $\sim$ n $-$ 1 𝜒 2(n $-$ 1) e che queste variabili aleatorie
\end{flushleft}


\begin{flushleft}
sono tra loro indipendenti. Ne segue un importante risultato.
\end{flushleft}


\begin{flushleft}
12.2. Ci concentriamo sulla varianza e non sulla deviazione standard perch\'{e} la prima ha uno stimatore corretto e
\end{flushleft}


\begin{flushleft}
consistente.
\end{flushleft}


\begin{flushleft}
12.3. Il risultato \`{e} vero, ma stiamo imbrogliando un po' nella giustificazione, infatti dovremmo mostrare che i termini
\end{flushleft}


\begin{flushleft}
a primo membro sono tra loro indipendenti, cosa che non facciamo in queste note.
\end{flushleft}





\newpage
176





\begin{flushleft}
STIME PUNTUALI
\end{flushleft}





\begin{flushleft}
COROLLARIO 12.27. Sia (X1, . . . , Xn) un campione n- dimensionale estratto da una popolazione a distribuzione Gaussiana di speranza 𝜇 e varianza 𝜎 2. Allora
\end{flushleft}


\begin{flushleft}
𝜇ˆ n $-$ 𝜇
\end{flushleft}


\begin{flushleft}
Sn2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
$\sim$ t(n $-$ 1).
\end{flushleft}





\begin{flushleft}
Dimostrazione. \`{E} sufficiente manipolare la variabile aleatoria che stiamo considerando e usare
\end{flushleft}


\begin{flushleft}
quanto appena mostrato:
\end{flushleft}


\begin{flushleft}
𝜇ˆ n $-$ 𝜇
\end{flushleft}


\begin{flushleft}
Sn2
\end{flushleft}





\begin{flushleft}
/n
\end{flushleft}





=





\begin{flushleft}
𝜇ˆ n $-$ 𝜇
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





2





\begin{flushleft}
/n
\end{flushleft}





⋅





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
=Z⋅
\end{flushleft}


\begin{flushleft}
S n2
\end{flushleft}





1


\begin{flushleft}
Sn2
\end{flushleft}





\begin{flushleft}
/𝜎 2
\end{flushleft}





=





\begin{flushleft}
Z
\end{flushleft}


\begin{flushleft}
Sn2
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
(n $-$ 1) ⋅ n $-$ 1
\end{flushleft}


1





=





\begin{flushleft}
Z
\end{flushleft}


\begin{flushleft}
W
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}





,





\begin{flushleft}
con Z $\sim$𝒩(0,1) e W $\sim$𝜒 2(n $-$ 1). Ora possiamo concludere osservando che quella a ultimo membro
\end{flushleft}


\begin{flushleft}
\`{e} precisamente la definizione di una t di Student a n $-$ 1 gradi di libert\`{a}.
\end{flushleft}


□


\begin{flushleft}
DEFINIZIONE 12.28. Chiamiamo funzione ancillare per un parametro 𝜗 una variabile aleatoria la cui
\end{flushleft}


\begin{flushleft}
legge sia nota a priori12.4 e che dipenda dai dati, da parametri noti e da 𝜗, unico parametro non noto.
\end{flushleft}


\begin{flushleft}
Parliamo anche di quantit\`{a} pivot, se lasciamo cadere la richiesta di dipendenza da un solo parametro
\end{flushleft}


\begin{flushleft}
incognito.
\end{flushleft}


\begin{flushleft}
Esempio 12.29. Vediamo alcuni esempi di funzione ancillare (per una popolazione Gaussiana):
\end{flushleft}


$-$





\begin{flushleft}
𝜇ˆ n $-$ 𝜇
\end{flushleft}


\begin{flushleft}
𝜎/
\end{flushleft}


\begin{flushleft}
$\surd$n
\end{flushleft}





\begin{flushleft}
$\sim$ 𝒩(0, 1) \`{e} una funzione ancillare per il parametro 𝜇 se la deviazione standard 𝜎 \`{e} nota,
\end{flushleft}





\begin{flushleft}
𝜇ˆ n $-$ 𝜇
\end{flushleft}





\begin{flushleft}
$\sim$ t(n $-$ 1) \`{e} una funzione ancillare per il parametro 𝜇 se la deviazione standard 𝜎 non \`{e}
\end{flushleft}





\begin{flushleft}
infatti la legge 𝒩 (0, 1) non dipende dai parametri e la variabile aleatoria \`{e} funzione di 𝜇
\end{flushleft}


\begin{flushleft}
(ignoto), di 𝜎 (nota) e della dimensione n del campione, oltre che dai dati;
\end{flushleft}


$-$





\begin{flushleft}
S 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
nota;
\end{flushleft}


$-$





\begin{flushleft}
Sn2
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





$-$





2


\begin{flushleft}
S∗n
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
(n $-$ 1) $\sim$ 𝜒 2(n $-$ 1) \`{e} una funzione ancillare per la varianza 𝜎 2;
\end{flushleft}


\begin{flushleft}
n = ∑ni=1
\end{flushleft}





\begin{flushleft}
Xi $-$ 𝜇 2
\end{flushleft}


\begin{flushleft}
$\sim$ 𝜒 2(n)
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
\`{e} una funzione ancillare per la varianza 𝜎 2 se la speranza 𝜇 \`{e} nota.
\end{flushleft}





\begin{flushleft}
12.3. COSTRUIRE STIMATORI
\end{flushleft}


\begin{flushleft}
Un problema interessante \`{e} quello di costruire stimatori per i parametri di nostro interesse in
\end{flushleft}


\begin{flushleft}
una popolazione. Abbiamo costruito alcuni stimatori nella sezione precedente, ma ora vogliamo
\end{flushleft}


\begin{flushleft}
studiare metodi più generali.
\end{flushleft}


\begin{flushleft}
Come prima cosa pensiamo alla notazione. Dal momento che, come detto, ci occupiamo di
\end{flushleft}


\begin{flushleft}
problemi di statistica parametrica, vuol dire che, a meno dei parametri, conosciamo la forma
\end{flushleft}


\begin{flushleft}
della funzione di densit\`{a} (o di densit\`{a} discreta, se il modello \`{e} discreto). Se abbiamo un solo parametro 𝜗 da stimare, possiamo rendere esplicita la dipendenza della funzione densit\`{a} da questo
\end{flushleft}


\begin{flushleft}
parametro usando la notazione f X (x ∣ 𝜗). Se abbiamo più di un parametro (ad esempio per una
\end{flushleft}


\begin{flushleft}
distribuzione normale, che dipende dalla speranza 𝜇 e dalla varianza 𝜎 2), possiamo prendere
\end{flushleft}


\begin{flushleft}
come 𝜗 il vettore di tutti i parametri (nell'esempio della normale 𝜗 = (𝜇, 𝜎 2)).
\end{flushleft}


\begin{flushleft}
Siccome per definizione il campione \`{e} un vettore di variabili aleatorie indipendenti e identicamente distribuite, esso avr\`{a} densit\`{a} (eventualmente discreta) congiunta
\end{flushleft}


\begin{flushleft}
f X1, . . . ,Xn(x 1, . . . , x n ∣ 𝜗) = fX (x 1 ∣ 𝜗) ⋅ ⋅ ⋅ f X (xn ∣ 𝜗).
\end{flushleft}


\begin{flushleft}
Vogliamo sfruttare questo fatto per costruire degli stimatori per 𝜗.
\end{flushleft}


\begin{flushleft}
12.4. Dire che la legge \`{e} nota a priori significa che la distribuzione della variabile aleatoria non dipende dai parametri.
\end{flushleft}





\begin{flushleft}
\newpage
12.3 COSTRUIRE STIMATORI
\end{flushleft}





177





\begin{flushleft}
12.3.1. Metodo dei momenti
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.30. Chiamiamo k-simo momento campionario la variabile aleatoria
\end{flushleft}


\begin{flushleft}
𝜇ˆ k = 𝜇ˆ kn =
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
X ik .
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Chiamiamo k-simo momento della popolazione il numero 𝜇k = E[X ik ].
\end{flushleft}


\begin{flushleft}
Osservazione 12.31. La statistica 𝜇ˆ k \`{e} uno stimatore corretto di 𝜇k . Infatti
\end{flushleft}


\begin{flushleft}
E[𝜇ˆ kn] = E
\end{flushleft}





\begin{flushleft}
[[ n1
\end{flushleft}


[





\begin{flushleft}
n
\end{flushleft}





]]


]





\begin{flushleft}
Xik =
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
E[X ik ] =
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜇k = 𝜇k .
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
In generale il momento k-simo di una popolazione che dipende da un parametro 𝜗 sar\`{a} una
\end{flushleft}


\begin{flushleft}
funzione deterministica di 𝜗. Abbiamo infatti
\end{flushleft}


\begin{flushleft}
𝜇k = 𝜇k (𝜗) = E[X1k ] =
\end{flushleft}





+$\infty$


$-$$\infty$





\begin{flushleft}
x k ⋅ fX (x ∣ 𝜗) ⋅ dx.
\end{flushleft}





\begin{flushleft}
DEFINIZIONE 12.32. Chiamiamo stimatore col metodo dei momenti del parametro scalare 𝜗 la soluzione (se esiste) 𝜗ˆmom dell'equazione
\end{flushleft}


\begin{flushleft}
𝜇1(𝜗ˆmom) = 𝜇ˆ 1.
\end{flushleft}


\begin{flushleft}
Se 𝜗 \`{e} un vettore di lunghezza h di parametri, chiamiamo stimatore col metodo dei momenti del parametro vettoriale 𝜗 la soluzione (se esiste) 𝜗ˆmom del sistema h-dimensionale di equazioni
\end{flushleft}





\begin{flushleft}
\{\{ 𝜇⋅ ⋅ ⋅(𝜗ˆ
\end{flushleft}


\{\{ ˆ


\begin{flushleft}
\{ 𝜇 (𝜗
\end{flushleft}


1





ˆ1


\begin{flushleft}
mom) = 𝜇
\end{flushleft}





\begin{flushleft}
h
\end{flushleft}





\begin{flushleft}
ˆ h.
\end{flushleft}


\begin{flushleft}
mom) = 𝜇
\end{flushleft}





\begin{flushleft}
Esempio 12.33. Consideriamo una popolazione Gaussiana e un campione (X1, . . . , X n) di dimensione n, con Xi $\sim$ 𝒩(𝜇, 𝜎), di varianza 𝜎 2 nota. Vogliamo stimare il parametro 𝜗 = 𝜇 con il metodo
\end{flushleft}


\begin{flushleft}
dei momenti.
\end{flushleft}


\begin{flushleft}
In questo caso abbiamo
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1


\begin{flushleft}
𝜇1(𝜗) = 𝜇1(𝜇) = E[X 1] = 𝜇
\end{flushleft}


\begin{flushleft}
e, allo stesso tempo,
\end{flushleft}


\begin{flushleft}
𝜇ˆ 1 =
\end{flushleft}


\begin{flushleft}
Xi = X = 𝜇ˆ .
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}


\begin{flushleft}
Lo stimatore dei momenti di 𝜇 \`{e} 𝜇ˆ mom tale che
\end{flushleft}


\begin{flushleft}
𝜇1(𝜇ˆ mom) = 𝜇ˆ ,
\end{flushleft}


\begin{flushleft}
ossia, siccome in questo caso la funzione 𝜇1 \`{e} l'identit\`{a}, 𝜇ˆ mom = 𝜇ˆ , cio\`{e} lo stimatore di 𝜇 con il
\end{flushleft}


\begin{flushleft}
metodo dei momenti \`{e} la media campionaria.
\end{flushleft}


\begin{flushleft}
Esempio 12.34. Consideriamo una popolazione Gaussiana e un campione (X1, . . . , X n) di dimensione n, con X i $\sim$ 𝒩(𝜇, 𝜎), di varianza 𝜎 2 ignota. Vogliamo stimare con il metodo dei momenti i
\end{flushleft}


2


\begin{flushleft}
parametri 𝜇 e 𝜎 2, quindi cerchiamo 𝜗ˆmom = (𝜇ˆ mom, 𝜎ˆmom
\end{flushleft}


).


\begin{flushleft}
Abbiamo
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1


1


\begin{flushleft}
𝜇ˆ =
\end{flushleft}


\begin{flushleft}
X i = X = 𝜇ˆ
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
𝜇1(𝜗) = E[X 1] = 𝜇 = 𝜗1
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}


\begin{flushleft}
e anche
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
𝜇2(𝜗) = E[X12] = 𝜇2 + 𝜎 2 = 𝜗 12 + 𝜗 22
\end{flushleft}


1


\begin{flushleft}
𝜇ˆ 2 =
\end{flushleft}


\begin{flushleft}
X i2.
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Vogliamo risolvere il sistema
\end{flushleft}





\begin{flushleft}
\{\{ 𝜇 (𝜗ˆ
\end{flushleft}


\begin{flushleft}
\{ 𝜇 (𝜗ˆ
\end{flushleft}


1


2





ˆ1


\begin{flushleft}
mom) = 𝜇
\end{flushleft}


ˆ2


\begin{flushleft}
mom) = 𝜇
\end{flushleft}





⟺





\begin{flushleft}
\{\{ 𝜇ˆ
\end{flushleft}


\begin{flushleft}
\{ 𝜇ˆ
\end{flushleft}





ˆ





ˆ


\begin{flushleft}
mom = 𝜗 mom,1 = 𝜇
\end{flushleft}





1


2


2


2


2


\begin{flushleft}
ˆmom
\end{flushleft}


\begin{flushleft}
= 𝜗ˆmom,1
\end{flushleft}


\begin{flushleft}
+ 𝜗ˆmom,2
\end{flushleft}


\begin{flushleft}
=n
\end{flushleft}


\begin{flushleft}
mom + 𝜎
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
∑ i=1 Xi2,
\end{flushleft}





\newpage
178





\begin{flushleft}
STIME PUNTUALI
\end{flushleft}





\begin{flushleft}
quindi abbiamo
\end{flushleft}


\begin{flushleft}
𝜇ˆ mom = 𝜇ˆ = X
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1


1


2


ˆ


\begin{flushleft}
𝜎mom =
\end{flushleft}


\begin{flushleft}
X i2 $-$ 𝜇ˆ 2mom =
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1


=


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
X i2 $-$ X 2 =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





((


(





\begin{flushleft}
n
\end{flushleft}





))


)





\begin{flushleft}
Xi2 $-$ n X 2
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n$-$1 2
\end{flushleft}


\begin{flushleft}
(X i $-$ X)2 =
\end{flushleft}


\begin{flushleft}
S .
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Allora lo stimatore dei momenti della speranza \`{e} anche in questo caso la media campionaria,
\end{flushleft}


\begin{flushleft}
mentre lo stimatore della varianza ottenuto col metodo dei momenti \`{e} lo stimatore distorto della
\end{flushleft}


\begin{flushleft}
varianza che avevamo gi\`{a} incontrato in precedenza.
\end{flushleft}


\begin{flushleft}
Esempio 12.35. Consideriamo una popolazione uniforme sull'intervallo [$-$a, a] e un campione
\end{flushleft}


\begin{flushleft}
(X 1, . . . , Xn) di dimensione n, con Xi $\sim$ unif($-$a, a). Vogliamo stimare il parametro 𝜗 = a usando il
\end{flushleft}


\begin{flushleft}
metodo dei momenti.
\end{flushleft}


1


\begin{flushleft}
In questo caso la densit\`{a} \`{e} fX (x ∣𝜗) = fX (x ∣a)= 2 a per ogni x $\in$[$-$a,a] (e nulla altrimenti). Quindi
\end{flushleft}


1


1


\begin{flushleft}
se andiamo a scrivere 𝜇 e 𝜇ˆ abbiamo
\end{flushleft}


\begin{flushleft}
𝜇ˆ 1 =
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Xi = 𝜇ˆ = X,
\end{flushleft}





\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
come gi\`{a} negli esempi precedenti, ma
\end{flushleft}


\begin{flushleft}
𝜇1(𝜗) = 𝜇1(a) = E[X1] =
\end{flushleft}





\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$-$a
\end{flushleft}





1


\begin{flushleft}
⋅ x dx = 0.
\end{flushleft}


\begin{flushleft}
2a
\end{flushleft}





\begin{flushleft}
Non possiamo allora avere soluzioni (in a) per l'equazione X = 0, dunque (in questo caso) non
\end{flushleft}


\begin{flushleft}
esiste lo stimatore dei momenti per 𝜗 = a.
\end{flushleft}


\begin{flushleft}
Lezione 23
\end{flushleft}





\begin{flushleft}
12.3.2. Metodo di massima verosimiglianza
\end{flushleft}


\begin{flushleft}
Partiamo sempre dalla funzione di densit\`{a} congiunta f X (x1,..., xn ∣ 𝜗), ma la leggiamo in un modo
\end{flushleft}


\begin{flushleft}
diverso: come verosimiglianza della n-upla di valori (x 1, . . . , xn) dato il parametro 𝜗, cio\`{e} quanto \`{e}
\end{flushleft}


\begin{flushleft}
verosimile vedere proprio i valori (x1,..., x n) se il parametro assume il valore 𝜗. Possiamo pensare
\end{flushleft}


\begin{flushleft}
al problema in questo modo: vogliamo scegliere un valore per 𝜗, quindi ha senso prendere quello
\end{flushleft}


\begin{flushleft}
che massimizza la verosimiglianza che (x 1, . . . , x n), i valori che osserviamo nel campione alla sua
\end{flushleft}


\begin{flushleft}
realizzazione, siano quelli assunti dalla variabile aleatoria di cui 𝜗 \`{e} parametro.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 12.36. Chiamiamo stimatore di massima verosimiglianza12.5 del parametro 𝜗 la quantit\`{a}
\end{flushleft}


\begin{flushleft}
𝜗ˆMLE che soddisfa
\end{flushleft}


\begin{flushleft}
𝜗ˆMLE = argmax 𝜃 f (x1, . . . , xn ∣ 𝜃) = argmax 𝜃 log( f (x 1, . . . , x n ∣ 𝜃)).
\end{flushleft}


\begin{flushleft}
Osserviamo che massimizzare la verosimiglianza (likelihood, in inglese) o massimizzarne il
\end{flushleft}


\begin{flushleft}
logaritmo \`{e} indifferente, per quanto riguarda il punto in cui il massimo \`{e} ottenuto (anche se
\end{flushleft}


\begin{flushleft}
cambia il valore), grazie al fatto che il logaritmo \`{e} una funzione monotona crescente.
\end{flushleft}


\begin{flushleft}
Esempio 12.37. Consideriamo una popolazione Gaussiana e un campione (X1, . . . , X n) di dimensione n, con Xi $\sim$ 𝒩(𝜇, 𝜎), di varianza 𝜎 2 ignota. Vogliamo stimare con il metodo di massima
\end{flushleft}


2


\begin{flushleft}
verosimiglianza i parametri 𝜇 e 𝜎 2, quindi cerchiamo 𝜗ˆMLE = (𝜇ˆ MLE, 𝜎ˆMLE
\end{flushleft}


\begin{flushleft}
). In particolare il parametro da stimare \`{e} vettoriale.
\end{flushleft}


\begin{flushleft}
Come prima cosa scriviamo esplicitamente la densita congiunta
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
f (x 1, . . . , x n ∣ 𝜗) = f (x1, . . . , xn ∣ 𝜇, 𝜎 2) =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





1


\begin{flushleft}
2$\pi$𝜎2
\end{flushleft}





\begin{flushleft}
e
\end{flushleft}





$-$





\begin{flushleft}
(xi $-$𝜇)2
\end{flushleft}


\begin{flushleft}
2𝜎 2
\end{flushleft}





=





\begin{flushleft}
12.5. In inglese si chiama maximum likelihood estimator, da cui la sigla MLE.
\end{flushleft}





1


\begin{flushleft}
2$\pi$
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
1 $-$ 2𝜎1 2 ∑ni =1(xi $-$𝜇)2
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


.


\begin{flushleft}
𝜎n
\end{flushleft}





\begin{flushleft}
\newpage
12.3 COSTRUIRE STIMATORI
\end{flushleft}





179





\begin{flushleft}
Vogliamo trovare 𝜗 = (𝜇, 𝜎 2) che massimizza questa quantit\`{a}. Data la forma esponenziale della
\end{flushleft}


\begin{flushleft}
funzione, prendiamone il logaritmo, che poi andremo a massimizzare
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1


\begin{flushleft}
log f (x1, . . . , xn ∣ 𝜇, 𝜎 2) = $-$ log(2 $\pi$) $-$ log(𝜎 2) $-$
\end{flushleft}


2


2


\begin{flushleft}
2𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(x i $-$ 𝜇)2.
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Per trovare il massimo di questa funzione al variare di 𝜇 e 𝜎 , possiamo calcolarne le derivate
\end{flushleft}


\begin{flushleft}
(parziali)
\end{flushleft}


2





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





$\partial$


1


1


\begin{flushleft}
log f (x1, . . . , xn ∣ 𝜇, 𝜎 2) = $-$ 2
\end{flushleft}


\begin{flushleft}
($-$2) (xi $-$ 𝜇) =
\end{flushleft}


\begin{flushleft}
(xi $-$ 𝜇)
\end{flushleft}


\begin{flushleft}
$\partial$𝜇
\end{flushleft}


\begin{flushleft}
2 𝜎 i=1
\end{flushleft}


\begin{flushleft}
2 𝜎 2 i=1
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





$\partial$


\begin{flushleft}
n
\end{flushleft}


1


\begin{flushleft}
log f (x1, . . . , xn ∣ 𝜇, 𝜎 2) = $-$ 2 +
\end{flushleft}


\begin{flushleft}
(x i $-$ 𝜇)2
\end{flushleft}


\begin{flushleft}
$\partial$𝜎 2
\end{flushleft}


\begin{flushleft}
2𝜎
\end{flushleft}


\begin{flushleft}
2 (𝜎 2)2 i=1
\end{flushleft}


\begin{flushleft}
e azzerarle12.6
\end{flushleft}





1


\begin{flushleft}
∑ni=1 (xi $-$ 𝜇) = 0
\end{flushleft}


\begin{flushleft}
2𝜎2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


1


\begin{flushleft}
+ (𝜎 2)2 ∑ni=1 (x i $-$ 𝜇)2 = 0
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





\{\{\{


\{$-$





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
i=1 x i
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2


\begin{flushleft}
i=1 (x i $-$ 𝜇) .
\end{flushleft}





\begin{flushleft}
\{\{ 𝜇 = ∑
\end{flushleft}


\begin{flushleft}
\{𝜎 = ∑
\end{flushleft}


1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
da cui
\end{flushleft}





2





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n$-$1
\end{flushleft}


2


\begin{flushleft}
Gli stimatori di massima verosimiglianza sono dunque 𝜇ˆ MLE = X e 𝜎ˆMLE
\end{flushleft}


\begin{flushleft}
= n S 2, ossia gli stessi
\end{flushleft}


\begin{flushleft}
stimatori ottenuti con il metodo dei momenti.
\end{flushleft}





\begin{flushleft}
Esempio 12.38. Consideriamo una popolazione Bernoulliana e un campione (X1,...,Xn) di dimensione n, con X i $\sim$ bin(1, p). Vogliamo stimare p usando il metodo di massima verosimiglianza.
\end{flushleft}


\begin{flushleft}
Iniziamo scrivendo la funzione di verosimiglianza, che in questo caso \`{e} la funzione di densit\`{a}
\end{flushleft}


\begin{flushleft}
discreta dato p, cio\`{e}
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
f (x1, . . . , xn ∣ p) = 𝜑 X (x1, . . . , xn ∣ p) = p ∑i =1xi (1 $-$ p)n$-$∑i =1xi .
\end{flushleft}


\begin{flushleft}
Anche in questo caso ci conviene prenderne il logaritmo
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





((


(





\begin{flushleft}
x i ⋅ log(p) + n $-$
\end{flushleft}





\begin{flushleft}
log f (x1, . . . , xn ∣ p) =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





))


)





\begin{flushleft}
x i log(1 $-$ p)
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
che poi deriviamo in p, ponendo la derivata uguale a 0
\end{flushleft}





\begin{flushleft}
da cui
\end{flushleft}





\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
log f (x1, . . . , xn ∣ p) =
\end{flushleft}


\begin{flushleft}
dp
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(1 $-$ p)
\end{flushleft}





((


(





1


\begin{flushleft}
xi ⋅ $-$ n $-$
\end{flushleft}


\begin{flushleft}
p
\end{flushleft}





(((





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
xi = p n $-$
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
)) 1 $-$1 p = 0
\end{flushleft}


)





\begin{flushleft}
xi
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





)))





\begin{flushleft}
xi .
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Lo stimatore di massima verosimiglianza per p \`{e} allora
\end{flushleft}


\begin{flushleft}
p̂MLE =
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
X i = X.
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Esempio 12.39. Consideriamo ora una popolazione esponenziale di parametro ignoto 𝜆, da cui
\end{flushleft}


\begin{flushleft}
estraiamo un campione (X 1, . . . , Xn) di variabili indipendenti. Vogliamo calcolare lo stimatore di
\end{flushleft}


\begin{flushleft}
massima verosimiglianza 𝜆ˆ MLE per il parametro 𝜆.
\end{flushleft}


\begin{flushleft}
La densit\`{a} congiunta dato 𝜆, che vediamo come funzione di verosimiglianza, \`{e}
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
f X (x1, . . . , xn ∣ 𝜆) = 𝜆n e $-$𝜆∑i =1xi .
\end{flushleft}


\begin{flushleft}
12.6. Dovremmo controllare che i punti così ottenuti siano di massimo globale e non siano punti di minimo, di sella
\end{flushleft}


\begin{flushleft}
o di massimo locale.
\end{flushleft}





\newpage
180





\begin{flushleft}
STIME PUNTUALI
\end{flushleft}





\begin{flushleft}
Ne prendiamo il logaritmo, lo deriviamo in 𝜆 e poniamo la derivata uguale a 0
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


1


\begin{flushleft}
log f (x1, . . . , xn ∣ 𝜆) = n $-$
\end{flushleft}


\begin{flushleft}
d𝜆
\end{flushleft}


\begin{flushleft}
𝜆
\end{flushleft}


\begin{flushleft}
da cui otteniamo 𝜆ˆ MLE = X $-$1.
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
xi = 0
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Esempio 12.40. Per lo stimatore di massima verosimiglianza del parametro di una popolazione
\end{flushleft}


\begin{flushleft}
di Poisson, prendiamo la densit\`{a} discreta congiunta dato 𝜆,
\end{flushleft}


\begin{flushleft}
f X (x1, . . . , xn ∣ 𝜆) =
\end{flushleft}





\begin{flushleft}
𝜆∑ixi
\end{flushleft}


\begin{flushleft}
⋅ e $-$n𝜆
\end{flushleft}


\begin{flushleft}
∏ i x i!
\end{flushleft}





\begin{flushleft}
ne prendiamo il logaritmo, ne facciamo la derivata rispetto a 𝜆 e la poniamo uguale a 0
\end{flushleft}





\begin{flushleft}
cio\`{e} 𝜆ˆ MLE = X.
\end{flushleft}





\begin{flushleft}
d
\end{flushleft}


1


\begin{flushleft}
log f X (x1, . . . , xn ∣ 𝜆) =
\end{flushleft}


\begin{flushleft}
d𝜆
\end{flushleft}


\begin{flushleft}
𝜆
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
xi $-$ n = 0
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
Esempio 12.41. Lo stimatore di massima verosimiglianza per il parametro a di una popolazione
\end{flushleft}


\begin{flushleft}
uniforme su [$-$a, a] \`{e} âMLE = max (|min i (x i)|, |max i (xi)|). Infatti
\end{flushleft}


1


\begin{flushleft}
f X (x1, . . . , xn ∣ a) =
\end{flushleft}


\begin{flushleft}
(2 a)n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
1[$-$a,a](x i) =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





1


1


.


\begin{flushleft}
(2 a)n \{$-$a⩽min i (xi )⩽max i (xi )⩽a\}
\end{flushleft}





\begin{flushleft}
Osserviamo per\`{o} che in questo caso derivare non ci \`{e} di grande aiuto. Tuttavia il fattore (2 a)$-$n \`{e}
\end{flushleft}


\begin{flushleft}
decrescente in a, ma il fattore 1\{a⩾max(|min i (xi )|,|max i (xi )|)\} \`{e} nullo per a $<$ max (|min i (xi)|, |max i (xi)|),
\end{flushleft}


\begin{flushleft}
quindi il massimo \`{e} in âMLE = max (|min i (xi)|, |max i (x i)|).
\end{flushleft}


\begin{flushleft}
Esempio 12.42. Lo stimatore di massima verosimiglianza per i parametri a e b di una popolazione
\end{flushleft}


\begin{flushleft}
uniforme su [a, b] \`{e} il vettore (âMLE, b̂MLE) = (min i (xi), max i (xi)). Anche in questo caso partiamo
\end{flushleft}


\begin{flushleft}
dalla densit\`{a} congiunta
\end{flushleft}


\begin{flushleft}
fX (x 1, . . . , x n ∣ a, b) =
\end{flushleft}





1


\begin{flushleft}
(b $-$ a)n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
1[a,b](xi) =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





1


1


\begin{flushleft}
(b $-$ a)n \{a⩽min i (xi )⩽max i (xi )⩽b\}
\end{flushleft}





\begin{flushleft}
e osserviamo che \`{e} una funzione decrescente in b, purch\'{e} b ⩾max i (xi) ed \`{e} una funzione crescente
\end{flushleft}


\begin{flushleft}
in a, purch\'{e} a ⩽ min i (xi).
\end{flushleft}





\begin{flushleft}
\newpage
CAPITOLO 13
\end{flushleft}


\begin{flushleft}
INTERVALLI DI CONFIDENZA
\end{flushleft}


\begin{flushleft}
Rimaniamo nel contesto della stima di parametri, ma vogliamo ora concentrarci su un particolare
\end{flushleft}


\begin{flushleft}
aspetto: l'errore di stima. Anche quando abbiamo uno stimatore corretto, nel momento in cui
\end{flushleft}


\begin{flushleft}
passiamo dallo stimatore alla stima, ossia nel momento in cui calcoliamo la statistica in funzione
\end{flushleft}


\begin{flushleft}
dei valori osservati, cio\`{e} della realizzazione del campione, commettiamo un errore e la stima, per
\end{flushleft}


\begin{flushleft}
quanto prossima, sar\`{a} diversa dal valore {``}teorico13.1'' del parametro per la popolazione considerata.
\end{flushleft}


\begin{flushleft}
Se conosciamo la distribuzione dell'errore di stima, ossia se abbiamo delle opportune funzioni
\end{flushleft}


\begin{flushleft}
ancillari, possiamo per\`{o} calcolare non solo un valore numerico per la stima, cio\`{e} quella stima puntuale su cui ci siamo concentrati nel capitolo precedente, ma anche un margine d'errore. L'idea \`{e}
\end{flushleft}


\begin{flushleft}
quella di individuare un range di valori possibili per il parametro che stiamo stimando, all'interno
\end{flushleft}


\begin{flushleft}
del quale abbiamo un certo livello di sicurezza (confidenza, come vedremo tra qualche pagina) che
\end{flushleft}


\begin{flushleft}
si trovi il valore {``}teorico'' del parametro.
\end{flushleft}


\begin{flushleft}
Per semplicit\`{a} studieremo gli intervalli di confidenza guidandoci con alcuni esempi specifici.
\end{flushleft}





\begin{flushleft}
13.1. MEDIA DI UNA NORMALE DI VARIANZA NOTA
\end{flushleft}


\begin{flushleft}
Abbiamo un campione (X1,...,Xn) estratto da una popolazione Gaussiana di media 𝜇 (che vogliamo
\end{flushleft}


\begin{flushleft}
stimare) e varianza 𝜎 2 che assumiamo nota. Abbiamo gi\`{a} osservato nel Capitolo 12 che la media
\end{flushleft}


\begin{flushleft}
campionaria X n \`{e} uno stimatore per la media 𝜇, ma anche che
\end{flushleft}





\begin{flushleft}
Xn $-$ 𝜇
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
$\sim$ 𝒩(0, 1).
\end{flushleft}





\begin{flushleft}
Sapendo la distribuzione della variabile aleatoria
\end{flushleft}





\begin{flushleft}
Xn $-$ 𝜇
\end{flushleft}





\begin{flushleft}
, possiamo calcolare la probabilit\`{a} che sia
\end{flushleft}





\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
maggiore o minore di un qualche valore: per a e b in ℝ
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
(( X $-$ 𝜇 ⩽ b)) = $\Phi$(b),
\end{flushleft}


(( / ))


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎
\end{flushleft}





2





\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(( X $-$ 𝜇 ⩾ a)) = 1 $-$ $\Phi$(a).
\end{flushleft}


(( / ))


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Specularmente, possiamo anche fissare una probabilit\`{a} 𝛽 $\in$ (0, 1) e chiederci quali siano i
\end{flushleft}


\begin{flushleft}
numeri reali x e y per cui la variabile aleatoria sia minore o uguale di x con probabilit\`{a} 𝛽 o maggiore o uguale di y con probabilit\`{a} 𝛽 (ossia i quantili 𝛽 e 1 $-$ 𝛽, rispettivamente),
\end{flushleft}





\begin{flushleft}
((( X $-$ 𝜇 ⩽ x))) = 𝛽 ⟺ x = $\Phi$
\end{flushleft}


(( / ))


\begin{flushleft}
( X $-$ 𝜇 ⩾ y)) = 𝛽 ⟺ y = $\Phi$
\end{flushleft}


\begin{flushleft}
P(
\end{flushleft}


(( / ))


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
(𝛽)
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





$-$1





$-$1





\begin{flushleft}
(1 $-$ 𝛽) = $-$$\Phi$ $-$1(𝛽).
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
13.1. \`{E} preferibile usare l'attributo teorico a vero, perch\'{e} in un certo senso il parametro della distribuzione non \`{e} vero
\end{flushleft}


\begin{flushleft}
nella realt\`{a} (che misuriamo), ma solamente nel modello, teorico appunto.
\end{flushleft}





181





\newpage
182





\begin{flushleft}
INTERVALLI DI CONFIDENZA
\end{flushleft}





\begin{flushleft}
Rimettiamo a fuoco il problema che vogliamo risolvere: vogliamo determinare un range di
\end{flushleft}


\begin{flushleft}
valori in cui abbiamo un certo livello di fiducia o confidenza che giaccia il valore teorico del parametro 𝜇. Chiamiamo 1 $-$ 𝛼 questo livello di confidenza13.2, per 𝛼 $\in$ (0, 1).
\end{flushleft}





\begin{flushleft}
13.1.1. Intervalli bilaterali di confidenza
\end{flushleft}


\begin{flushleft}
Supponiamo inoltre di non voler sbagliare troppo n\'{e} in eccesso, n\'{e} in difetto. In altre parole
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
vogliamo che il range sia un intervallo [A, B] e che la probabilit\`{a} che 𝜇 sia minore di A sia 2 , così
\end{flushleft}


\begin{flushleft}
come la probabilit\`{a} che 𝜇 sia maggiore di B:
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
P(𝜇 $<$ A) =
\end{flushleft}


\begin{flushleft}
P(𝜇 $>$ B) = .
\end{flushleft}


2


2


\begin{flushleft}
In questo modo P(A ⩽ 𝜇 ⩽ B) = 1 $-$ 𝛼.
\end{flushleft}


\begin{flushleft}
Come mai parliamo di probabilit\`{a}? Il parametro 𝜇, per quanto ignoto, non \`{e} una variabile
\end{flushleft}


\begin{flushleft}
aleatoria, quindi saranno variabili aleatorie gli estremi A e B, come suggerito dalla scrittura maiuscola, anzi saranno statistiche, ossia variabili aleatorie dipendenti dal campione e da parametri
\end{flushleft}


\begin{flushleft}
fissati (ad esempio 𝛼). Andiamo infatti a riscrivere il tutto in modo da mettere in evidenza lo
\end{flushleft}


\begin{flushleft}
stimatore puntuale X n della media 𝜇,
\end{flushleft}





(((


(





\begin{flushleft}
X n $-$ 𝜇 Xn $-$ A
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
= P(𝜇 $<$ A) = P
\end{flushleft}


$>$


2


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
))) ⟺ X $-$ A = $-$$\Phi$
\end{flushleft}


/


)


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





$-$1





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
da cui, risolvendo in A,
\end{flushleft}


\begin{flushleft}
A = X n + $\Phi$ $-$1
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
= Xn $-$ $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
e, in maniera del tutto analoga,
\end{flushleft}





((


((





\begin{flushleft}
X n $-$ 𝜇 Xn $-$ B
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
= P(𝜇 $>$ B) = P
\end{flushleft}


$<$


2


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
)) ⟺ X $-$ B = $\Phi$
\end{flushleft}


))


/


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





$-$1





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
da cui, risolvendo in B,
\end{flushleft}


\begin{flushleft}
B = X n $-$ $\Phi$ $-$1
\end{flushleft}


\begin{flushleft}
Allora abbiamo
\end{flushleft}





((


(





\begin{flushleft}
P Xn $-$ $\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
= Xn + $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
⩽ 𝜇 ⩽ X n + $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


.


\begin{flushleft}
n
\end{flushleft}





))


)





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
= 1 $-$ 𝛼.
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Gli estremi dell'intervallo, come accennato in precedenza, sono statistiche: dipendono dal
\end{flushleft}


\begin{flushleft}
campione e da parametri prefissati (in questo caso 𝛼). Quindi, avendo realizzato il campione,
\end{flushleft}


\begin{flushleft}
gli estremi saranno dei numeri.
\end{flushleft}


\begin{flushleft}
DEFINIZIONE 13.1. Dato un campione (X1,..., X n) estratto da una famiglia Gaussiana di media 𝜇 ignota e
\end{flushleft}


\begin{flushleft}
varianza 𝜎 2 nota e fissato un numero 𝛼 $\in$ (0, 1), chiamiamo intervallo di confidenza bilaterale a livello
\end{flushleft}


\begin{flushleft}
1 $-$ 𝛼 per la media 𝜇 l'intervallo
\end{flushleft}





\begin{flushleft}
((X $-$ $\Phi$
\end{flushleft}


(


\begin{flushleft}
n
\end{flushleft}





$-$1





1$-$





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
, X n + $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





))


)





\begin{flushleft}
𝜎2
\end{flushleft}


.


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Valori tipici per 1 $-$ 𝛼 sono 90\%, 95\% e 99\%. In questi casi abbiamo
\end{flushleft}


\begin{flushleft}
lit\`{a}.
\end{flushleft}





\begin{flushleft}
13.2. La nostra fiducia o confidenza \`{e} un numero reale in (0, 1), ma come osserveremo più avanti non \`{e} una probabi-
\end{flushleft}





\begin{flushleft}
\newpage
13.1 MEDIA DI UNA NORMALE DI VARIANZA NOTA
\end{flushleft}





\begin{flushleft}
1$-$𝛼
\end{flushleft}


0.9


0.95


0.99





1$-$ 2


0.95


0.975


0.995





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝛼
\end{flushleft}


0.1


0.05


0.01





\begin{flushleft}
𝛼
\end{flushleft}





0.05


0.025


0.005





183





\begin{flushleft}
$\Phi$ $-$1 1 $-$ 2
\end{flushleft}


1.645


1.96


2.576





\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
1$-$𝛼
\end{flushleft}





\begin{flushleft}
$\Phi$ $-$1
\end{flushleft}





\begin{flushleft}
$\Phi$ $-$1 1 $-$ 2
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
Osservazione 13.2. Come mai parliamo di confidenza e non di probabilit\`{a} per questi intervalli? Il
\end{flushleft}


\begin{flushleft}
motivo \`{e} legato alla differenza tra stimatore e stima: il primo \`{e} una variabile aleatoria, la seconda
\end{flushleft}


\begin{flushleft}
\`{e} un numero. Per gli intervalli, finch\'{e} sono scritti in termini degli stimatori possiamo parlare di
\end{flushleft}


\begin{flushleft}
probabilit\`{a}, ma quando andiamo a sostituire le stime, ossia i valori calcolati a partire dalla realizzazione del campione, tutto \`{e} deterministico: non ha senso parlare di probabilit\`{a}. In particolare,
\end{flushleft}


\begin{flushleft}
mentre possiamo dire che il parametro 𝜗 sta nell'intervallo aleatorio con probabilit\`{a} 1 $-$ 𝛼, nel
\end{flushleft}


\begin{flushleft}
momento in cui gli estremi sono calcolati a partire dai dati o il parametro 𝜗 sta lì dentro, oppure
\end{flushleft}


\begin{flushleft}
non ci sta, non ci sono probabilit\`{a}. Per questo motivo parliamo di confidenza.
\end{flushleft}


\begin{flushleft}
Esempio 13.3. Supponiamo di avere un campione di taglia 16 estratto da una popolazione Gaussiana di media 𝜇 e varianza 𝜎 2 =9. Il valore della media campionaria calcolata su questo campione
\end{flushleft}


\begin{flushleft}
\`{e} x = 104.7.
\end{flushleft}


\begin{flushleft}
Allora l'intervallo di confidenza a livello 95\% per 𝜇 \`{e}
\end{flushleft}





\begin{flushleft}
((x $-$ $\Phi$
\end{flushleft}


(





$-$1





(0.025) ⋅





\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
, x + $\Phi$ $-$1(0.025) ⋅
\end{flushleft}


16


16





)) =


)





3


3


104.7 $-$ 1.96 ⋅ , 104.7 + 1.96 ⋅


4


4





= (103.23, 106.17).


\begin{flushleft}
Per curiosit\`{a}, la popolazione da cui \`{e} stato estratto il campione aveva media 𝜇 = 105.
\end{flushleft}


\begin{flushleft}
Supponiamo ora di voler risolvere un problema leggermente diverso, sempre con una popolazione Gaussiana di media 𝜇 da stimare e varianza 𝜎 2nota. Vogliamo sapere (prima di raccogliere
\end{flushleft}


\begin{flushleft}
le osservazioni) quale deve essere la numerosit\`{a} n del campione per garantire che l'intervallo
\end{flushleft}


\begin{flushleft}
di confidenza bilaterale per la media 𝜇 a livello 1 $-$ 𝛼 non sia più ampio di una certa lunghezza
\end{flushleft}


\begin{flushleft}
prefissata l.
\end{flushleft}


\begin{flushleft}
Come prima cosa, osserviamo che, per quanto scritto sopra, la larghezza dell'intervallo di
\end{flushleft}


\begin{flushleft}
confidenza a livello 1 $-$ 𝛼 \`{e}
\end{flushleft}


\begin{flushleft}
Xn + $\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
$-$ X n + $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
= 2 $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
e dipende da 𝛼, da 𝜎 2 e da n, ma non da X n. Non solo, dei tre parametri che determinano la larghezza, solo n \`{e} variabile, perch\'{e} la varianza e il livello di confidenza sono assegnati. Osserviamo
\end{flushleft}


\begin{flushleft}
che la larghezza dell'intervallo diminuisce al crescere di n.
\end{flushleft}


\begin{flushleft}
Il problema che vogliamo risolvere \`{e} determinare n tale che
\end{flushleft}


\begin{flushleft}
l = 2 $\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\newpage
184





\begin{flushleft}
INTERVALLI DI CONFIDENZA
\end{flushleft}





\begin{flushleft}
cio\`{e}, con qualche manipolazione algebrica,
\end{flushleft}


\begin{flushleft}
4 ⋅ $\Phi$ $-$1 1 $-$ 2
\end{flushleft}


\begin{flushleft}
l2
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
n=
\end{flushleft}





2





\begin{flushleft}
⋅𝜎2
\end{flushleft}





.





\begin{flushleft}
Dobbiamo per\`{o} prestare attenzione al fatto che n $\in$ ℕ, quindi in generale dovremo approssimare
\end{flushleft}


\begin{flushleft}
questa soluzione e, per garantire che l'intervallo sia sufficientemente ampio, dovremo farlo per
\end{flushleft}


\begin{flushleft}
eccesso,
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
4 ⋅ $\Phi$ $-$1 1 $-$ 2 2 ⋅ 𝜎 2
\end{flushleft}


\begin{flushleft}
n=
\end{flushleft}


.


(13.1)


\begin{flushleft}
l2
\end{flushleft}





⌈⌈⌈





⌉⌉⌉





\begin{flushleft}
Esempio 13.4. Supponiamo di avere una popolazione Gaussiana di varianza 𝜎 2 =4 di cui vogliamo
\end{flushleft}


\begin{flushleft}
stimare la media 𝜇. Vogliamo un intervallo di confidenza al 99\% si ampiezza inferiore a 2 e
\end{flushleft}


\begin{flushleft}
vogliamo determinare la numerosit\`{a} del campione che ci occorre.
\end{flushleft}


\begin{flushleft}
Dalla (13.1) otteniamo
\end{flushleft}


\begin{flushleft}
4 ⋅ ($\Phi$ $-$1(0.995))2 ⋅ 4
\end{flushleft}


\begin{flushleft}
n=
\end{flushleft}


= ⌈26.54⌉ = 27.


22





⌈⌈





⌉⌉





\begin{flushleft}
Se avessimo voluto un intervallo di larghezza massima 1, allora
\end{flushleft}


\begin{flushleft}
n=
\end{flushleft}





⋅4


⌈⌈ 4 ⋅ (2.576)


⌉⌉ = ⌈106.158⌉ = 107,


1


2





2





\begin{flushleft}
per uno di ampiezza massima 0.5,
\end{flushleft}


\begin{flushleft}
n=
\end{flushleft}





⋅4


⌈⌈ 4 ⋅ (2.576)


⌉⌉ = ⌈424.633⌉ = 425.


0.5


2





2





\begin{flushleft}
Al dimezzarsi della larghezza massima dell'intervallo, il numero di osservazioni necessarie quadruplica. E questo non ci dovrebbe stupire.
\end{flushleft}


\begin{flushleft}
Lezione 24
\end{flushleft}





\begin{flushleft}
13.1.2. Intervalli unilaterali di confidenza
\end{flushleft}


\begin{flushleft}
Facciamo un passo indietro: a volte potremmo essere interessati ad avere un range diverso rispetto
\end{flushleft}


\begin{flushleft}
a un intervallo, ad esempio potremmo voler avere una soglia sola, essere confidenti che la media
\end{flushleft}


\begin{flushleft}
sia al di sopra (o al di sotto) di un certo numero. In sostanza stiamo cercando A (una variabile aleatoria) tale che P(𝜇 $<$ A) = 𝛼, cio\`{e} tale che P(𝜇 ⩾ A) = 1 $-$ 𝛼 (o analogamente una variabile
\end{flushleft}


\begin{flushleft}
aleatoria B tale che P(𝜇 $>$ B) = 𝛼, cio\`{e} P(𝜇 ⩽ B) = 1 $-$ 𝛼).
\end{flushleft}


\begin{flushleft}
L'impostazione per\`{o} non cambia molto, rispetto a prima: abbiamo
\end{flushleft}





\begin{flushleft}
A = Xn $-$ $\Phi$ $-$1(1 $-$ 𝛼)
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
B = Xn + $\Phi$ $-$1(1 $-$ 𝛼)
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}


.


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
DEFINIZIONE 13.5. Dato un campione (X1,..., X n) estratto da una famiglia Gaussiana di media 𝜇 ignota e
\end{flushleft}


\begin{flushleft}
varianza 𝜎 2 nota e fissato un numero 𝛼 $\in$ (0, 1), chiamiamo intervallo di confidenza unilaterale destro
\end{flushleft}


\begin{flushleft}
(rispettivamente sinistro) a livello 1 $-$ 𝛼 per la media 𝜇 la semiretta
\end{flushleft}





\begin{flushleft}
((X $-$ $\Phi$
\end{flushleft}


(


\begin{flushleft}
n
\end{flushleft}





$-$1





\begin{flushleft}
(1 $-$ 𝛼)
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}


, +$\infty$


\begin{flushleft}
n
\end{flushleft}





))


)





\begin{flushleft}
(rispettivamente
\end{flushleft}





\begin{flushleft}
(($-$$\infty$, X + $\Phi$
\end{flushleft}


(


\begin{flushleft}
n
\end{flushleft}





$-$1





\begin{flushleft}
(1 $-$ 𝛼)
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





))


)





).





\begin{flushleft}
Esempio 13.6. Abbiamo le seguenti osservazioni, estratte da una popolazione Gaussiana di media
\end{flushleft}


\begin{flushleft}
𝜇 ignota e varianza 𝜎 2 = 1:
\end{flushleft}


3.35 3.73 3.14 4.37 4.28 2.91 2.96 1.94 2.29


\begin{flushleft}
Vogliamo calcolare per la media l'intervallo di confidenza destro al 90\% e l'intervallo di confidenza sinistro al 99\%.
\end{flushleft}


\begin{flushleft}
Possiamo calcolare la media campionaria, ad esempio usando il comando R mean:
\end{flushleft}





\begin{flushleft}
\newpage
13.2 COSTRUIRE INTERVALLI DI CONFIDENZA
\end{flushleft}





185





\begin{flushleft}
mean(c(3.35,3.73,3.14,4.37,4.28,2.91,2.96,1.94,2.29))
\end{flushleft}


[1] 3.218889


\begin{flushleft}
Allora l'intervallo di confidenza destro al 90\% ha come estremo sinistro
\end{flushleft}


\begin{flushleft}
x $-$ $\Phi$ $-$1(0.9) ⋅
\end{flushleft}





1


1


= 3.22 $-$ 1.282 ⋅ = 2.793


9


3





\begin{flushleft}
(e come estremo destro +$\infty$).
\end{flushleft}


\begin{flushleft}
L'intervallo di confidenza sinistro al 99\% ha come estremo destro
\end{flushleft}


\begin{flushleft}
x + $\Phi$ $-$1(0.99) ⋅
\end{flushleft}





1


1


= 3.22 + 2.326 ⋅ = 3.995.


9


3





\begin{flushleft}
13.2. COSTRUIRE INTERVALLI DI CONFIDENZA
\end{flushleft}


\begin{flushleft}
Vediamo ora un algoritmo per costruire intervalli di confidenza bilaterali per un parametro 𝜗 a
\end{flushleft}


\begin{flushleft}
livello di confidenza 1 $-$ 𝛼.
\end{flushleft}


\begin{flushleft}
Algoritmo per intervalli di confidenza bilaterali
\end{flushleft}


\begin{flushleft}
1. Determinare la migliore funzione ancillare f (X) per il caso in considerazione.
\end{flushleft}


\begin{flushleft}
2. Trovare i quantili della legge associata ai livelli di confidenza richiesti, ossia
\end{flushleft}


\begin{flushleft}
3. Ricavare dall'identit\`{a} P(a ⩽ f (X) ⩽ b) = 1 $-$ 𝛼 gli estremi a e b.
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
e 1$-$ 2.
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
4. Scrivere l'intervallo (aleatorio) rispetto a 𝜗, i cui estremi A e B saranno statistiche.
\end{flushleft}


\begin{flushleft}
Esempio 13.7. Mettiamo in pratica l'algoritmo in un caso concreto: vogliamo stimare la media 𝜇
\end{flushleft}


\begin{flushleft}
di una popolazione Gaussiana di varianza 𝜎 2 ignota.
\end{flushleft}


\begin{flushleft}
1. Il nostro parametro 𝜗 \`{e} la media 𝜇. Siamo nel caso in cui la varianza \`{e} ignota, quindi
\end{flushleft}


\begin{flushleft}
Xn $-$ 𝜇
\end{flushleft}


\begin{flushleft}
$\sim$ t(n $-$ 1)
\end{flushleft}


\begin{flushleft}
Sn/
\end{flushleft}


\begin{flushleft}
$\surd$n
\end{flushleft}


\begin{flushleft}
\`{e} la migliore candidata come funzione ancillare.
\end{flushleft}


\begin{flushleft}
2. La legge associata \`{e} una t di Student a n $-$ 1 gradi di libert\`{a}, quindi i quantili che ci interessano
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
sono F t$-$1
\end{flushleft}


\begin{flushleft}
e Ft$-$1
\end{flushleft}


\begin{flushleft}
1 $-$ 2 . Possiamo calcolarli, ad 𝛼 fissato, con R o con le tavole.
\end{flushleft}


\begin{flushleft}
n$-$1 2
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
3. Abbiamo
\end{flushleft}





\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
da cui
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
a = F t$-$1
\end{flushleft}


\begin{flushleft}
n$-$1 2
\end{flushleft}





\begin{flushleft}
(( X /$-$ 𝜇 ⩾ a)) = 1 $-$ 𝛼2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}





\begin{flushleft}
$\surd$n
\end{flushleft}





\begin{flushleft}
⟺ P
\end{flushleft}





\begin{flushleft}
(( X /$-$ 𝜇 ⩽ a)) = 𝛼2 ,
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}





\begin{flushleft}
$\surd$n
\end{flushleft}





\begin{flushleft}
. Similmente,
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
((( X /$-$ 𝜇 ⩽ b))) = 1 $-$ 𝛼2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
Sn
\end{flushleft}





\begin{flushleft}
$\surd$n
\end{flushleft}





\begin{flushleft}
⟺ b = F t$-$1
\end{flushleft}


1$-$


\begin{flushleft}
n$-$1
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


.


2





\begin{flushleft}
4. Dal punto precedente abbiamo
\end{flushleft}


\begin{flushleft}
F t$-$1
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}





\begin{flushleft}
Xn $-$ 𝜇
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
⩽ Sn
\end{flushleft}


\begin{flushleft}
⩽ Ft$-$1
\end{flushleft}


1$-$


\begin{flushleft}
n$-$1
\end{flushleft}


2


2


\begin{flushleft}
/$\surd$n
\end{flushleft}





\begin{flushleft}
che possiamo scrivere esplicitamente, per 𝜇,
\end{flushleft}


\begin{flushleft}
Xn $-$ F t$-$1
\end{flushleft}


1$-$


\begin{flushleft}
n$-$1
\end{flushleft}





\begin{flushleft}
𝛼 Sn
\end{flushleft}


\begin{flushleft}
𝛼 Sn
\end{flushleft}


\begin{flushleft}
𝛼 Sn
\end{flushleft}


⋅


\begin{flushleft}
⩽ 𝜇 ⩽ Xn $-$ F t$-$1
\end{flushleft}


⋅


\begin{flushleft}
= X n + Ft$-$1
\end{flushleft}


1$-$


⋅


,


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
2 $\surd$n
\end{flushleft}


\begin{flushleft}
2 $\surd$n
\end{flushleft}


\begin{flushleft}
2 $\surd$n
\end{flushleft}





\begin{flushleft}
in cui abbiamo sfruttato le propriet\`{a} di simmetria di Ft$-$1
\end{flushleft}


\begin{flushleft}
(attenzione che non tutte le statistiche
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
ancillari hanno leggi simmetriche).
\end{flushleft}





\newpage
186





\begin{flushleft}
INTERVALLI DI CONFIDENZA
\end{flushleft}





\begin{flushleft}
Esempio 13.8. Sempre usando l'algoritmo visto sopra, determiniamo l'intervallo di confidenza
\end{flushleft}


\begin{flushleft}
bilaterale per la varianza di una popolazione Gaussiana a media ignota.
\end{flushleft}


\begin{flushleft}
1. La funzione ancillare in questo caso \`{e}
\end{flushleft}


\begin{flushleft}
2. I quantili (non simmetrici!) sono F𝜒$-$1n$-$1
\end{flushleft}


2


\begin{flushleft}
3. Per gli estremi abbiamo
\end{flushleft}





\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
(( 𝜎S
\end{flushleft}





\begin{flushleft}
(( 𝜎S
\end{flushleft}





2


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
Sn2
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
(n $-$ 1) $\sim$ 𝜒 2(n $-$ 1).
\end{flushleft}


\begin{flushleft}
e F𝜒$-$1n$-$1
\end{flushleft}


2


\begin{flushleft}
1 $-$ 2 , da calcolare con R o con le tavole.
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}





))





2


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
(n $-$ 1) ⩽ a =
\end{flushleft}





))





\begin{flushleft}
(n $-$ 1) ⩽ b = 1 $-$
\end{flushleft}





\begin{flushleft}
4. Infine,
\end{flushleft}





((





\begin{flushleft}
P F𝜒$-$1n$-$1
\end{flushleft}


2





\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
⟹ a = F𝜒$-$1n$-$1
\end{flushleft}


2


2


2


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
⟹ b = F𝜒$-$1n$-$1
\end{flushleft}


2


1$-$ .


2


2





\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
Sn2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
⩽ 2 (n $-$ 1) ⩽ F𝜒$-$1n$-$1
\end{flushleft}


2


1$-$


2


2


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
)) = 1 $-$ 𝛼
\end{flushleft}





\begin{flushleft}
che d\`{a}, esplicitato in 𝜎 2,
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
((( S (n $-$ 1)
\end{flushleft}


\begin{flushleft}
(F 1 $-$
\end{flushleft}


2


\begin{flushleft}
n
\end{flushleft}


$-$1


2


\begin{flushleft}
𝜒n$-$1
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
⩽𝜎2⩽
\end{flushleft}





)))


)





\begin{flushleft}
Sn2 (n $-$ 1)
\end{flushleft}


\begin{flushleft}
=1$-$𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
F𝜒$-$1n$-$1
\end{flushleft}


2


2





\begin{flushleft}
in cui vale la pena notare che, siccome 𝜎 2 era al denominatore, F𝜒$-$1n$-$1
\end{flushleft}


2


\begin{flushleft}
1 $-$ 2 \`{e} passato all'estremo
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
sinistro e F𝜒$-$1n$-$1
\end{flushleft}


2


\begin{flushleft}
all'estremo
\end{flushleft}


\begin{flushleft}
destro.
\end{flushleft}


2


\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
Osservazione 13.9. Possiamo con qualche accortezza usare il medesimo algoritmo per trovare
\end{flushleft}


\begin{flushleft}
anche gli intervalli unilaterali destri o sinistri. Quello che cambia \`{e} la necessit\`{a} di trovare solamente un quantile (e non due): dobbiamo per\`{o} prestare attenzione a prendere quello giusto e
\end{flushleft}


\begin{flushleft}
calcolato al livello giusto.
\end{flushleft}


\begin{flushleft}
Nel caso di una popolazione Gaussiana 𝒩(𝜇, 𝜎) abbiamo i seguenti intervalli di confidenza:
\end{flushleft}


\begin{flushleft}
𝜗
\end{flushleft}


\begin{flushleft}
𝜇
\end{flushleft}





\begin{flushleft}
note
\end{flushleft}





\begin{flushleft}
Int. bilaterale
\end{flushleft}





\begin{flushleft}
𝜎 2 nota
\end{flushleft}





\begin{flushleft}
𝜇 𝜎 2 ignota
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
𝜇 nota
\end{flushleft}





\begin{flushleft}
𝜎 2 𝜇 ignota
\end{flushleft}





(((


(





\begin{flushleft}
Int. sinistro
\end{flushleft}


2





\begin{flushleft}
Xn $\pm$ $\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Xn $\pm$ F t$-$1
\end{flushleft}


1$-$


\begin{flushleft}
n$-$1
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
S2
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
(( S n
\end{flushleft}


\begin{flushleft}
(F 1$-$
\end{flushleft}





2


\begin{flushleft}
∗n
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


$-$1


\begin{flushleft}
𝜒n2
\end{flushleft}


2


2


\begin{flushleft}
S n (n $-$ 1)
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
F𝜒$-$1n$-$1
\end{flushleft}


1$-$ 2


2





,


,





2


\begin{flushleft}
S ∗n
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
$-$1 𝛼
\end{flushleft}


\begin{flushleft}
F𝜒n2 2
\end{flushleft}





))


)





\begin{flushleft}
S n2 (n $-$ 1)
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
F𝜒$-$1n$-$1
\end{flushleft}


2


2





\begin{flushleft}
(($-$$\infty$, X + $\Phi$ (1 $-$ 𝛼)
\end{flushleft}


(


\begin{flushleft}
(($-$$\infty$, X + F (1 $-$ 𝛼)
\end{flushleft}


(


\begin{flushleft}
((0, S n ))
\end{flushleft}


\begin{flushleft}
( F (𝛼) )
\end{flushleft}


\begin{flushleft}
((0, S (n $-$ 1) ))
\end{flushleft}


\begin{flushleft}
( F (𝛼) )
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





)))


)





$-$1





$-$1


\begin{flushleft}
tn$-$1
\end{flushleft}





2


\begin{flushleft}
∗n
\end{flushleft}


$-$1


\begin{flushleft}
𝜒n2
\end{flushleft}





2


\begin{flushleft}
n
\end{flushleft}


$-$1


2


\begin{flushleft}
𝜒n$-$1
\end{flushleft}





\begin{flushleft}
Int. destro
\end{flushleft}





\begin{flushleft}
)) ((X $-$ $\Phi$ (1 $-$ 𝛼) 𝜎n , +$\infty$))
\end{flushleft}


)(


)


\begin{flushleft}
S )(
\end{flushleft}


\begin{flushleft}
S
\end{flushleft}


)


\begin{flushleft}
n)
\end{flushleft}


\begin{flushleft}
) ((X $-$ F (1 $-$ 𝛼) n , +$\infty$))
\end{flushleft}


\begin{flushleft}
(( S n , +$\infty$))
\end{flushleft}


\begin{flushleft}
( F (1 $-$ 𝛼) )
\end{flushleft}


\begin{flushleft}
(( S (n $-$ 1) , +$\infty$))
\end{flushleft}


\begin{flushleft}
( F (1 $-$ 𝛼) )
\end{flushleft}


2





\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





2





\begin{flushleft}
n
\end{flushleft}





2





$-$1





2





$-$1


\begin{flushleft}
tn$-$1
\end{flushleft}





$-$1


\begin{flushleft}
𝜒n2
\end{flushleft}


2


\begin{flushleft}
n
\end{flushleft}


$-$1


2


\begin{flushleft}
𝜒n$-$1
\end{flushleft}





2


\begin{flushleft}
∗n
\end{flushleft}





\begin{flushleft}
Tabella 13.1. Intervalli di confidenza per una popolazione Gaussiana a livello 1 $-$ 𝛼.
\end{flushleft}


2


\begin{flushleft}
in cui X n = n ∑ni=1 Xi, S ∗n
\end{flushleft}


\begin{flushleft}
= n ∑ni=1 (X i $-$ 𝜇)2 e Sn2 = n $-$ 1 ∑ni=1 (X i $-$ Xn)2.
\end{flushleft}


1





1





1





\begin{flushleft}
13.3. INTERVALLI DI CONFIDENZA PER LA DIFFERENZA DI MEDIE
\end{flushleft}


\begin{flushleft}
Consideriamo ora una situazione un po' diversa. Abbiamo due popolazioni, entrambe Gaussiane. Ci chiediamo quanto grande sia la differenza tra le loro medie.
\end{flushleft}


\begin{flushleft}
Come prima cosa osserviamo che, avendo due popolazioni, avremo anche due campioni:
\end{flushleft}


\begin{flushleft}
(X i)ni=1 e (Yj)m
\end{flushleft}


\begin{flushleft}
j=1, con ciascuna X i $\sim$ 𝒩(𝜇 X , 𝜎X ) e ciascuna Yj $\sim$ 𝒩(𝜇 Y, 𝜎Y). Osserviamo che, come
\end{flushleft}


\begin{flushleft}
sottolineato dalla notazione che abbiamo usato, i due campioni non sono necessariamente della
\end{flushleft}


\begin{flushleft}
stessa taglia.
\end{flushleft}





\begin{flushleft}
\newpage
13.3 INTERVALLI DI CONFIDENZA PER LA DIFFERENZA DI MEDIE
\end{flushleft}





187





\begin{flushleft}
Il nostro obiettivo \`{e} stimare la differenza tra la media della prima popolazione e quella della
\end{flushleft}


\begin{flushleft}
seconda, ossia 𝜇X $-$ 𝜇Y. Uno stimatore di questa quantit\`{a} (che in particolare \`{e} lo stimatore di massima verosimiglianza) \`{e} X n $-$ Ym, quindi abbiamo una stima puntuale.
\end{flushleft}


\begin{flushleft}
Se siamo per\`{o} interessati a una stima intervallare, abbiamo bisogno di indagare più a fondo
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜎Y
\end{flushleft}


\begin{flushleft}
sulla distribuzione di Xn $-$ Ym. Come prima cosa osserviamo che Xn $\sim$𝒩 𝜇X , $\surd$Xn e Ym $\sim$𝒩 𝜇 Y, $\surd$m .
\end{flushleft}


\begin{flushleft}
I due campioni sono estratti da popolazioni diverse, quindi li possiamo considerare indipendenti.
\end{flushleft}


\begin{flushleft}
Sapendo che combinazioni lineari di Gaussiane indipendenti sono a loro volta Gaussiane,
\end{flushleft}





(((


(





\begin{flushleft}
𝜎X2 𝜎Y2
\end{flushleft}


+


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}





\begin{flushleft}
Xn $-$ Ym $\sim$ 𝒩 𝜇X $-$ 𝜇 Y,
\end{flushleft}





)))


)





\begin{flushleft}
in cui vale la pena osservare che, anche se delle medie abbiamo la differenza, delle varianze
\end{flushleft}


\begin{flushleft}
abbiamo la somma, infatti
\end{flushleft}


\begin{flushleft}
E[Xn $-$ Ym] = E[X n] $-$ E[Ym] = 𝜇X $-$ 𝜇 Y
\end{flushleft}


\begin{flushleft}
Var[Xn $-$ Ym] = Var[X n] + ($-$1)2 Var[Ym] =
\end{flushleft}


\begin{flushleft}
Con le (ormai consuete) manipolazioni, abbiamo
\end{flushleft}


\begin{flushleft}
(Xn $-$ Ym) $-$ (𝜇 X $-$ 𝜇Y)
\end{flushleft}


\begin{flushleft}
𝜎X2
\end{flushleft}





2





\begin{flushleft}
/n + 𝜎Y/m
\end{flushleft}





\begin{flushleft}
𝜎X2 𝜎Y2
\end{flushleft}


+ .


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}





\begin{flushleft}
$\sim$ 𝒩(0, 1).
\end{flushleft}





\begin{flushleft}
A questo punto, se sappiamo 𝜎X e 𝜎Y, possiamo ricavare l'intervallo di confidenza: stiamo rifacendo quanto visto per la media di una Gaussiana a varianza nota. Avremo dunque che
\end{flushleft}





((


(





\begin{flushleft}
(𝜇X $-$ 𝜇 Y) $\in$ (x $-$ y) $-$ $\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝜎X2 𝜎Y2
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
+ , (x $-$ y) + $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}


2





\begin{flushleft}
𝜎X2 𝜎Y2
\end{flushleft}


+


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
m
\end{flushleft}





))


)





\begin{flushleft}
\`{e} un intervallo di confidenza bilaterale a livello 1 $-$ 𝛼 (in cui abbiamo messo in evidenza le stime
\end{flushleft}


\begin{flushleft}
x e y, ossia gli stimatori calcolati nei campioni realizzati. In modo analogo possiamo ricavare gli
\end{flushleft}


\begin{flushleft}
intervalli unilaterali.
\end{flushleft}


\begin{flushleft}
Tuttavia non sempre sappiamo le varianze delle due popolazioni, siamo in grado di dire qualcosa nel caso in cui esse siano ignote? Nel caso di una singola Gaussiana abbiamo usato
\end{flushleft}


\begin{flushleft}
Xn $-$ 𝜇
\end{flushleft}


\begin{flushleft}
$\sim$ t(n $-$ 1),
\end{flushleft}


\begin{flushleft}
Sn/
\end{flushleft}


\begin{flushleft}
$\surd$n
\end{flushleft}


\begin{flushleft}
per ottenere la quale abbiamo sfruttato la distribuzione 𝜒 2 di Sn2. Se proviamo a replicare questa
\end{flushleft}


\begin{flushleft}
strategia nel caso della differenza abbiamo
\end{flushleft}


\begin{flushleft}
(Xn $-$ Ym) $-$ (𝜇 X $-$ 𝜇Y)
\end{flushleft}


2


\begin{flushleft}
SX,n
\end{flushleft}





\begin{flushleft}
/n + SY,m/m
\end{flushleft}


2





,





\begin{flushleft}
S
\end{flushleft}


\begin{flushleft}
per cui in generale abbiamo una distribuzione di X,n/n + SY,m/m che non \`{e} semplice da ricavare e che
\end{flushleft}


\begin{flushleft}
dipende dalle due varianze, rendendoci quindi impossibile l'uso come funzione ancillare 13.3.
\end{flushleft}


\begin{flushleft}
C'\`{e} per\`{o} un caso speciale: il caso omoschedastico, cio\`{e} in cui le varianze delle due popolazioni,
\end{flushleft}


\begin{flushleft}
pur ignote, coincidono, 𝜎X2 = 𝜎Y2 = 𝜎 2. In questa situazione
\end{flushleft}


2


2


2


2


\begin{flushleft}
S X,n
\end{flushleft}


\begin{flushleft}
SX,n
\end{flushleft}


\begin{flushleft}
SY,m
\end{flushleft}


\begin{flushleft}
SY,m
\end{flushleft}


2


\begin{flushleft}
(n
\end{flushleft}


$-$


1)


=


\begin{flushleft}
(n $-$ 1) $\sim$ 𝜒 2(n $-$ 1),
\end{flushleft}


\begin{flushleft}
2 (m $-$ 1) = 𝜎 2 (m $-$ 1) $\sim$ 𝜒 (m $-$ 1)
\end{flushleft}


2


2


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
Y
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜎X
\end{flushleft}


\begin{flushleft}
e sommandole, grazie all'indipendenza dei due campioni e alla riproducibilit\`{a} delle 𝜒 2,
\end{flushleft}


2





2





2


2


\begin{flushleft}
SX,n
\end{flushleft}


\begin{flushleft}
S Y,m
\end{flushleft}


\begin{flushleft}
(n $-$ 1) + 2 (m $-$ 1) $\sim$ 𝜒 2(n $-$ 1) + 𝜒 2(m $-$ 1) $\sim$ 𝜒 2(n + m $-$ 2).
\end{flushleft}


2


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
13.3. Ricordiamo che una funzione ancillare pu\`{o} avere al più un parametro ignoto, in questo caso ne avremmo due.
\end{flushleft}





\newpage
188





\begin{flushleft}
INTERVALLI DI CONFIDENZA
\end{flushleft}





\begin{flushleft}
Possiamo allora scrivere
\end{flushleft}


2


2


2


2


\begin{flushleft}
S X,n
\end{flushleft}


\begin{flushleft}
SY,m
\end{flushleft}


\begin{flushleft}
S X,n
\end{flushleft}


\begin{flushleft}
(n $-$ 1) + S Y,m
\end{flushleft}


\begin{flushleft}
(m $-$ 1) n + m $-$ 2
\end{flushleft}


\begin{flushleft}
(n
\end{flushleft}


$-$


1)


+


\begin{flushleft}
(m
\end{flushleft}


$-$


1)


=


⋅


\begin{flushleft}
n+m$-$2
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}


2


\begin{flushleft}
SP
\end{flushleft}


\begin{flushleft}
≔ 2 (n + m $-$ 2) $\sim$ 𝜒 2(n + m $-$ 2),
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
in analogia con quanto visto per una singola popolazione Gaussiana di varianza ignota. Abbiamo
\end{flushleft}


\begin{flushleft}
così introdotto lo stimatore SP2 , detto stimatore pooled della varianza, che \`{e} una media pesata di S X2 e
\end{flushleft}


\begin{flushleft}
n$-$1
\end{flushleft}


\begin{flushleft}
m$-$1
\end{flushleft}


\begin{flushleft}
S Y2 di pesi dati dai gradi di libert\`{a} delle loro distribuzioni (ossia n + m $-$ 2 e n + m $-$ 2 ).
\end{flushleft}


\begin{flushleft}
A questo punto possiamo ancora una volta continuare come nel caso della singola popolazione Gaussiana di varianza ignota e otteniamo
\end{flushleft}


\begin{flushleft}
(X n $-$ Ym) $-$ (𝜇X $-$ 𝜇 Y)
\end{flushleft}


\begin{flushleft}
SP2
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





+





1


\begin{flushleft}
m
\end{flushleft}





=





\begin{flushleft}
(Xn $-$ Ym) $-$ (𝜇 X $-$ 𝜇Y)
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
$\sim$ 𝒩(0, 1) ⋅
\end{flushleft}





1


\begin{flushleft}
n
\end{flushleft}





+





1


\begin{flushleft}
m
\end{flushleft}





⋅





1


\begin{flushleft}
SP2
\end{flushleft}


\begin{flushleft}
𝜎2
\end{flushleft}





1


\begin{flushleft}
𝜒 2(n+m$-$2)
\end{flushleft}





\begin{flushleft}
(n + m $-$ 2) ⋅ n + m $-$ 2
\end{flushleft}


1





\begin{flushleft}
$\sim$ t(n + m $-$ 2).
\end{flushleft}





\begin{flushleft}
/n+m$-$2
\end{flushleft}





\begin{flushleft}
A questo punto individuare gli intervalli di confidenza \`{e} analogo a quanto visto nel caso di una
\end{flushleft}


\begin{flushleft}
Gaussiana con varianza ignota. In particolare, nel caso bilaterale abbiamo
\end{flushleft}





(((





$-$1


\begin{flushleft}
(𝜇X $-$ 𝜇 Y) $\in$ (x $-$ y) $-$ F t(n+m$-$2)
\end{flushleft}


1$-$





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
SP2
\end{flushleft}





1 1


\begin{flushleft}
𝛼
\end{flushleft}


$-$1


+


\begin{flushleft}
, (x $-$ y) + F t(n+m$-$2)
\end{flushleft}


1$-$


\begin{flushleft}
n m
\end{flushleft}


2





\begin{flushleft}
SP2
\end{flushleft}





1 1


+


\begin{flushleft}
n m
\end{flushleft}





))).





\begin{flushleft}
13.4. INTERVALLI DI CONFIDENZA APPROSSIMATI
\end{flushleft}


\begin{flushleft}
Oltre alle funzioni ancillari esatte, grazie al teorema centrale del limite abbiamo anche delle funzioni ancillari approssimate. Queste alle volte ci vengono in aiuto quando le funzioni ancillari
\end{flushleft}


\begin{flushleft}
esatte sono difficili o impossibili da usare. Dobbiamo per\`{o} essere consapevoli che gli intervalli
\end{flushleft}


\begin{flushleft}
così ottenuti non saranno altrettanto precisi di quelli ottenuti con funzioni ancillari non approssimate.
\end{flushleft}





\begin{flushleft}
13.4.1. Popolazione Bernoulliana
\end{flushleft}


\begin{flushleft}
Consideriamo il caso di una popolazione Bernoulliana di parametro p. In altre parole stiamo
\end{flushleft}


\begin{flushleft}
dicendo che ogni individuo nella popolazione ha una determinata caratteristica con probabilit\`{a} p.
\end{flushleft}


\begin{flushleft}
Alcuni esempi di caratteristiche di questo tipo possono essere {``}possedere un'automobile'', {``}avere
\end{flushleft}


\begin{flushleft}
un certa caratteristica genetica uniformemente diffusa nella popolazione''.
\end{flushleft}


\begin{flushleft}
Vogliamo stimare il parametro p. Iniziamo osservando che ogni elemento del campione \`{e}
\end{flushleft}


\begin{flushleft}
una variabile aleatoria Bernoulliana, ossia assume il valore 1 con probabilit\`{a} p e 0 con probabilit\`{a}
\end{flushleft}


\begin{flushleft}
1 $-$ p. Abbiamo allora la variabile aleatoria Yn = ∑ ni=1 X i che conta il numero di successi (e ha
\end{flushleft}


\begin{flushleft}
distribuzione binomiale).
\end{flushleft}


\begin{flushleft}
Dal teorema centrale del limite (Teorema 11.18) sappiamo che per n sufficientemente grande
\end{flushleft}


\begin{flushleft}
Yn $-$ n p
\end{flushleft}


$\sim$


\begin{flushleft}
˙ 𝒩(0, 1),
\end{flushleft}


\begin{flushleft}
n p (1 $-$ p)
\end{flushleft}


\begin{flushleft}
ossia abbiamo una funzione ancillare approssimata per il parametro p. Tuttavia non siamo in
\end{flushleft}


\begin{flushleft}
grado di usarla direttamente: sappiamo che
\end{flushleft}





((


(





\begin{flushleft}
P $-$$\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
Yn $-$ n p
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


⩽


\begin{flushleft}
⩽ $\Phi$ $-$1 1 $-$
\end{flushleft}


2


2


\begin{flushleft}
n p (1 $-$ p)
\end{flushleft}





\begin{flushleft}
)) = 1 $-$ 𝛼,
\end{flushleft}


)





\begin{flushleft}
\newpage
13.4 INTERVALLI DI CONFIDENZA APPROSSIMATI
\end{flushleft}





189





\begin{flushleft}
ma se proviamo a scriverlo esplicitamente in termini di p ci blocchiamo, perch\'{e} p compare anche
\end{flushleft}


\begin{flushleft}
a denominatore e per giunta sotto una radice quadrata.
\end{flushleft}


\begin{flushleft}
Abbiamo bisogno di una seconda approssimazione: sappiamo che p \`{e} la media di ciascuna
\end{flushleft}


\begin{flushleft}
variabile aleatoria estratta dalla popolazione (gli individui sono tutti Bernoulliani di parametro p)
\end{flushleft}


\begin{flushleft}
Yn
\end{flushleft}


\begin{flushleft}
Yn
\end{flushleft}


\begin{flushleft}
e sappiamo anche che Xn = n \`{e} uno stimatore della media. Poniamo quindi p̂ = n = Xn. \`{E} una statistica calcolabile del campione e n p (1 $-$ p) $\approx$ n p̂ (1 $-$ p̂) e dunque abbiamo una nuova funzione
\end{flushleft}


\begin{flushleft}
ancillare (ulteriormente) approssimata
\end{flushleft}


\begin{flushleft}
n p̂ $-$ n p
\end{flushleft}


\begin{flushleft}
n p̂ (1 $-$ p̂)
\end{flushleft}





$\sim$


\begin{flushleft}
˙ 𝒩(0, 1).
\end{flushleft}





\begin{flushleft}
A questo punto possiamo riprendere la strada iniziata prima:
\end{flushleft}





(((


(





\begin{flushleft}
P $-$$\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
n p̂ $-$ n p
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


⩽


\begin{flushleft}
⩽ $\Phi$ $-$1 1 $-$
\end{flushleft}


2


2


\begin{flushleft}
n p̂ (1 $-$ p̂)
\end{flushleft}





\begin{flushleft}
))) $\approx$ 1 $-$ 𝛼
\end{flushleft}


)





\begin{flushleft}
che ora possiamo riscrivere in modo da avere un intervallo esplicito per p:
\end{flushleft}





((





\begin{flushleft}
P p̂ $-$ $\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
p̂ (1 $-$ p̂)
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
⩽ p ⩽ p̂ + $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
p̂ (1 $-$ p̂)
\end{flushleft}


\begin{flushleft}
$\approx$1$-$𝛼
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





))





\begin{flushleft}
e analogamente per gli intervalli unilaterali.
\end{flushleft}


\begin{flushleft}
Osservazione 13.10. Anche per le Bernoulliane ha senso chiedersi quanto grande debba essere
\end{flushleft}


\begin{flushleft}
la numerosit\`{a} n del campione per garantire che l'ampiezza dell'intervallo (bilaterale) sia al di
\end{flushleft}


\begin{flushleft}
sotto di una certa soglia l. L'ampiezza \`{e} 2 $\Phi$ $-$1 1 $-$ 2
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
osservazioni del campione, così come il corrispondente
\end{flushleft}


\begin{flushleft}
4 $\Phi$
\end{flushleft}


\begin{flushleft}
n = ⌈⌈
\end{flushleft}





$-$1





1$-$ 2





\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
l2
\end{flushleft}





2





\begin{flushleft}
p̂ (1 $-$ p̂)
\end{flushleft}


,


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
ma dipende da p̂ e quindi dalle
\end{flushleft}





⌉⌉





\begin{flushleft}
p̂ (1 $-$ p̂) .
\end{flushleft}





\begin{flushleft}
Qual \`{e} il problema? Che non sappiamo quanto vale p̂ prima di iniziare a raccogliere i nostri dati.
\end{flushleft}


\begin{flushleft}
In questo caso una soluzione pratica \`{e} iniziare a raccogliere i dati e, dalle prime m misurazioni,
\end{flushleft}


\begin{flushleft}
stimare rozzamente p (e quindi anche p̂) con X m usando questo valore per stimare la numerosit\`{a}
\end{flushleft}


\begin{flushleft}
necessaria del campione. A questo punto \`{e} possibile continuare a raccogliere gli ulteriori dati.
\end{flushleft}


\begin{flushleft}
Esempio 13.11. Vogliamo stimare la proporzione di studenti che consulta libri in biblioteca e vorremmo avere un margine di incertezza (ossia met\`{a} dell'ampiezza dell'intervallo di confidenza)
\end{flushleft}


\begin{flushleft}
del 2.5\% per un intervallo al 95\%.
\end{flushleft}


\begin{flushleft}
Iniziamo intervistando i primi 25 studenti, di cui 9 consultano libri in biblioteca. La nostra
\end{flushleft}


9


\begin{flushleft}
stima grossolana di p \`{e} p ∗ = 25 = 0.36. Questo ci suggerisce di intervistare in tutto
\end{flushleft}


\begin{flushleft}
n=
\end{flushleft}





⌈⌈⌈ 4





\begin{flushleft}
$\Phi$ $-$1 1 $-$ 2
\end{flushleft}


\begin{flushleft}
l2
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





2





⋅ 1.96


⌉⌉⌉ ⌈⌈ 40.05





\begin{flushleft}
p ∗ (1 $-$ p ∗) =
\end{flushleft}





2





2





⌉⌉





⋅ 0.36 ⋅ 0.64 = 1417,





\begin{flushleft}
cio\`{e} altri 1392. Di questi 535 rispondono positivamente, per una stima puntuale di p uguale a
\end{flushleft}


535 + 9


\begin{flushleft}
p̂ = 1392 + 25 ≃ 0.384.
\end{flushleft}


\begin{flushleft}
Il nostro intervallo di confidenza (approssimato) \`{e} quindi
\end{flushleft}


\begin{flushleft}
p̂ $\pm$ $\Phi$ $-$1 1 $-$
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
p̂ (1 $-$ p̂)
\end{flushleft}


0.384 ⋅ 0.616


= 0.384 $\pm$ 1.96 ⋅


,


\begin{flushleft}
n
\end{flushleft}


1417





\begin{flushleft}
cio\`{e} (0.359, 0.409), che ha ampiezza 0.05 e margine d'errore 0.025.
\end{flushleft}





\newpage
190





\begin{flushleft}
INTERVALLI DI CONFIDENZA
\end{flushleft}





\begin{flushleft}
Osservazione 13.12. Stiamo approssimando a più livelli, quindi ci aspettiamo un po' di errore
\end{flushleft}


\begin{flushleft}
aggiuntivo. Tuttavia possiamo, come esercizio, chiederci cosa succeda se invece di p ∗ o p̂ usassimo il vero valore di p nel determinare la numerosit\`{a} del campione. In questo caso
\end{flushleft}


4


\begin{flushleft}
n = ⌈⌈
\end{flushleft}


⌈





\begin{flushleft}
$\Phi$ $-$1 1 $-$ 2
\end{flushleft}


\begin{flushleft}
l2
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





2





\begin{flushleft}
$\Phi$
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)⌉⌉ ⩽ ⌈⌈
\end{flushleft}


⌉ ⌈





$-$1





1$-$ 2


\begin{flushleft}
l2
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





2





⌉⌉⌉,





\begin{flushleft}
poich\'{e} p (1 $-$ p) ⩽ 1/4. Questa approssimazione (che non dipende da p) \`{e} per\`{o} sempre meno precisa
\end{flushleft}


\begin{flushleft}
quanto più p \`{e} vicino agli estremi 0 o 1.
\end{flushleft}





\begin{flushleft}
13.4.2. Popolazione Poissoniana
\end{flushleft}


\begin{flushleft}
Se abbiamo una popolazione Poissoniana di parametro 𝜆 che vogliamo stimare (ossia 𝜗 = 𝜆),
\end{flushleft}


\begin{flushleft}
abbiamo immediatamente uno stimatore per 𝜆, che \`{e} la media della distribuzione, ossia la media
\end{flushleft}


\begin{flushleft}
campionaria X n. Inoltre, poich\'{e} la distribuzione Poissoniana \`{e} riproducibile, ne conosciamo anche
\end{flushleft}


\begin{flushleft}
la distribuzione: n ⋅ X n $\sim$ Pois(n 𝜆), quindi
\end{flushleft}


\begin{flushleft}
P(X n = k) = P
\end{flushleft}





(((





\begin{flushleft}
n
\end{flushleft}





)))





\begin{flushleft}
Xi = n k =
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
(n 𝜆)nk $-$n𝜆
\end{flushleft}


\begin{flushleft}
e .
\end{flushleft}


\begin{flushleft}
(n k)!
\end{flushleft}





\begin{flushleft}
Grazie a questa informazione, possiamo costruire degli intervalli di confidenza per 𝜆, ma con un
\end{flushleft}


\begin{flushleft}
po' di difficolt\`{a}. Sappiamo che i tempi d'attesa tra due eventi Poissoniani di media 𝜆 sono distribuiti secondo una legge esponenziale di intensit\`{a} 𝜆, che le variabili aleatorie esponenziali sono
\end{flushleft}


\begin{flushleft}
𝜆
\end{flushleft}


1


\begin{flushleft}
scalabili, cio\`{e} che 𝛼 ⋅ exp(𝜆) $\sim$ exp 𝛼 , che exp 2 $\sim$ 𝜒 2(2) e che la distribuzione 𝜒 2 \`{e} riproducibile.
\end{flushleft}


\begin{flushleft}
Mettendo assieme queste informazioni abbiamo che
\end{flushleft}


\begin{flushleft}
FPois(𝜆)(k) = 1 $-$ F𝜒 2(2(k +1))(2 𝜆)
\end{flushleft}


\begin{flushleft}
da cui possiamo ricavare13.4 che un intervallo bilaterale di confidenza a livello 1 $-$ 𝛼 per 𝜆 \`{e}
\end{flushleft}


1 $-$1


\begin{flushleft}
𝛼 1 $-$1
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
F𝜒 2(2nXn)
\end{flushleft}


,


\begin{flushleft}
F𝜒 2(2nXn +2) 1 $-$
\end{flushleft}


\begin{flushleft}
2n
\end{flushleft}


\begin{flushleft}
2 2n
\end{flushleft}


2





.





\begin{flushleft}
Data la forma non semplicissima, possiamo in alternativa accontentarci di un intervallo di
\end{flushleft}


\begin{flushleft}
confidenza approssimato, sfruttando il teorema centrale del limite, in questo caso
\end{flushleft}


\begin{flushleft}
Xn $-$ 𝜆
\end{flushleft}


\begin{flushleft}
𝜆/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





$\sim$


\begin{flushleft}
˙ 𝒩(0, 1).
\end{flushleft}





\begin{flushleft}
Come nel caso della binomiale, tuttavia, abbiamo un fattore 𝜆 a denominatore che ci causa
\end{flushleft}


\begin{flushleft}
problemi, ma possiamo approssimarlo anche in questo caso con X n. A questo punto l'intervallo
\end{flushleft}


\begin{flushleft}
bilaterale di confidenza approssimato a livello 1 $-$ 𝛼 che otteniamo \`{e}
\end{flushleft}





\begin{flushleft}
((X $-$ $\Phi$
\end{flushleft}


(


\begin{flushleft}
n
\end{flushleft}





$-$1





1$-$





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
Xn
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
, X n + $\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


2





))


)





\begin{flushleft}
Xn
\end{flushleft}


.


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Esempio 13.13. Il numero di email di studenti ricevute da un docente nel corso di una giornata
\end{flushleft}


\begin{flushleft}
\`{e} ipotizzato essere distribuito come una Poisson di media 𝜆 ignota. Vengono contate le email
\end{flushleft}


\begin{flushleft}
ricevute giorno per giorno per 100 giorni. La media campionaria misurata \`{e} x = 5.04. Qual \`{e} un
\end{flushleft}


\begin{flushleft}
intervallo di confidenza bilaterale al 95\% per 𝜆?
\end{flushleft}


\begin{flushleft}
Calcoliamo come prima cosa l'intervallo di confidenza esatto: esso \`{e}
\end{flushleft}


1


1


\begin{flushleft}
⋅ F𝜒$-$12(2⋅100⋅5.04)(0.025),
\end{flushleft}


\begin{flushleft}
⋅ F $-$12
\end{flushleft}


(0.975)


2 ⋅ 100


\begin{flushleft}
200 𝜒 (2⋅100⋅5.04+2)
\end{flushleft}


\begin{flushleft}
che ha centro 5.054688 $\neq$ x e ampiezza 0.8903049.
\end{flushleft}


\begin{flushleft}
13.4. Non vediamo i dettagli, che non sono banali.
\end{flushleft}





= (4.609536, 5.499841),





\begin{flushleft}
\newpage
13.4 INTERVALLI DI CONFIDENZA APPROSSIMATI
\end{flushleft}





191





\begin{flushleft}
Passiamo invece all'intervallo approssimato: esso \`{e}
\end{flushleft}





\begin{flushleft}
((5.04 $-$ $\Phi$
\end{flushleft}


(





$-$1





(0.975)





))


)





5.04


5.04


\begin{flushleft}
, 5.04 $-$ $\Phi$ $-$1(0.975)
\end{flushleft}


= (4.599989, 5.480011),


100


100





\begin{flushleft}
che ha centro 5.04 = x e ampiezza 0.8800216.
\end{flushleft}


\begin{flushleft}
Osserviamo in particolare che il primo, a differenza del secondo, non \`{e} simmetrico rispetto
\end{flushleft}


\begin{flushleft}
alla media campionaria x = 5.04.
\end{flushleft}


\begin{flushleft}
Possiamo fare questi conti in R, usando il seguente codice13.5
\end{flushleft}





\begin{flushleft}
n\_days $<$- 100
\end{flushleft}


\begin{flushleft}
lambda $<$- 5
\end{flushleft}


\begin{flushleft}
alpha $<$- 0.05
\end{flushleft}


\begin{flushleft}
x $<$- rpois(n\_days, lambda)
\end{flushleft}


\begin{flushleft}
x\_bar $<$- mean(x)
\end{flushleft}


\begin{flushleft}
\# Intervallo corretto
\end{flushleft}


\begin{flushleft}
ci\_chi $<$- c(1/(2*n\_days)*qchisq(alpha/2, df = 2*n\_days*x\_bar),
\end{flushleft}


\begin{flushleft}
1/(2*n\_days)*qchisq(1-alpha/2, df = 2*n\_days*x\_bar+2))
\end{flushleft}


\begin{flushleft}
\# Intervallo approssimato
\end{flushleft}


\begin{flushleft}
ci\_approx $<$- sapply(c(alpha/2, 1-alpha/2),function(x)\{x\_bar +
\end{flushleft}


\begin{flushleft}
qnorm(x)*sqrt(x\_bar/n\_days)\})
\end{flushleft}


\begin{flushleft}
\# centri dei due intervalli
\end{flushleft}


\begin{flushleft}
mean(ci\_chi)
\end{flushleft}


\begin{flushleft}
mean(ci\_approx)
\end{flushleft}


\begin{flushleft}
\# ampiezza dei due intervalli (\%*\% \`{e} il prodotto matriciale)
\end{flushleft}


\begin{flushleft}
ci\_chi \%*\% c(-1,1)
\end{flushleft}


\begin{flushleft}
ci\_approx \%*\% c(-1,1)
\end{flushleft}


\begin{flushleft}
Osservazione 13.14. Per campioni di numerosit\`{a} elevata la differenza tra gli intervalli ottenuti nei
\end{flushleft}


\begin{flushleft}
due modi \`{e} trascurabile. Nel caso di campioni di numerosit\`{a} ridotta la differenza \`{e} più significativa, come si pu\`{o} verificare adattando il codice appena visto.
\end{flushleft}


\begin{flushleft}
Osservazione 13.15. In generale, non solo per le distribuzioni di Poisson, ci possono essere più
\end{flushleft}


\begin{flushleft}
scelte possibili di intervalli di confidenza, sia esatti, sia approssimati: questo succede se si parte
\end{flushleft}


\begin{flushleft}
da quantit\`{a} pivot (o statistiche ancillari) diverse, se si usano approssimazioni diverse e così via.
\end{flushleft}


\begin{flushleft}
13.5. Siccome generiamo il campione in modo aleatorio, gli estremi dell'intervallo saranno diversi in iterazioni diverse.
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
CAPITOLO 14
\end{flushleft}


\begin{flushleft}
TEST STATISTICI
\end{flushleft}


\begin{flushleft}
L'idea che sta alla base dei test statistici \`{e} la seguente: abbiamo un'ipotesi (ad esempio {``}in media
\end{flushleft}


\begin{flushleft}
una confezione contiene 1 kg di pomodori'') e vogliamo vedere se le osservazioni a nostra disposizione (i dati) supportano (cio\`{e} non contraddicono) questa ipotesi o se la contraddicono. Possiamo
\end{flushleft}


\begin{flushleft}
mostrare graficamente l'idea:
\end{flushleft}


1.1


\begin{flushleft}
1kg
\end{flushleft}


0.9





\begin{flushleft}
contrapposto a
\end{flushleft}





1.1


\begin{flushleft}
1kg
\end{flushleft}


0.9





\begin{flushleft}
osservazioni
\end{flushleft}





\begin{flushleft}
osservazioni
\end{flushleft}





\begin{flushleft}
Nell'immagine a sinistra non possiamo escludere che il valore corrispondente alla retta orizzontale sia la media della popolazione da cui abbiamo estratto il campione, mentre nell'immagine
\end{flushleft}


\begin{flushleft}
a destra sembra poco plausibile che quel valore sia la media.
\end{flushleft}


\begin{flushleft}
Come si lega questo con quanto abbiamo visto finora in Statistica? Abbiamo una popolazione
\end{flushleft}


\begin{flushleft}
sottostante che supponiamo avere una distribuzione comune, dipendente da un parametro (ad
\end{flushleft}


\begin{flushleft}
esempio la media). Pensiamo che la media della popolazione sia un certo valore 𝜇0 e vogliamo
\end{flushleft}


\begin{flushleft}
mettere alla prova questa ipotesi, usando i dati, ossia il campione estratto dalla popolazione.
\end{flushleft}


\begin{flushleft}
Nel Capitolo 12 abbiamo visto che, a partire dal campione, possiamo stimare la media con
\end{flushleft}


\begin{flushleft}
la media campionaria X, quindi una possibilit\`{a} per testare la nostra ipotesi potrebbe essere la
\end{flushleft}


\begin{flushleft}
seguente: se il valore stimato X coincide con la nostra ipotesi 𝜇 0, allora \`{e} vero che la popolazione
\end{flushleft}


\begin{flushleft}
ha proprio quella media, altrimenti no. Abbiamo per\`{o} visto che la stima puntuale \`{e} troppo imprecisa per poter fare un ragionamento del genere.
\end{flushleft}


\begin{flushleft}
Nel Capitolo 13 abbiamo per\`{o} introdotto la stima intervallare: potremmo pensare di adattare
\end{flushleft}


\begin{flushleft}
quella. Se 𝜇0 \`{e} nell'intervallo di confidenza a un certo livello attorno a X, allora non escludiamo
\end{flushleft}


\begin{flushleft}
che 𝜇0 possa davvero essere il valore della media, mentre se 𝜇0 giace al di fuori dell'intervallo di
\end{flushleft}


\begin{flushleft}
confidenza, escludiamo che sia il valore della media della popolazione.
\end{flushleft}


\begin{flushleft}
Questo per\`{o} \`{e} ancora molto impreciso, anche se ci d\`{a} un'idea di quello che vogliamo fare. Per
\end{flushleft}


\begin{flushleft}
rendere il ragionamento più rigoroso, iniziamo introducendo una terminologia più precisa.
\end{flushleft}


\begin{flushleft}
Chiamiamo ipotesi statistica da verificare su una popolazione (o distribuzione) un'affermazione
\end{flushleft}


\begin{flushleft}
relativa a uno (o più) dei suoi parametri. Usando il termine ipotesi vogliamo sottolineare che
\end{flushleft}


\begin{flushleft}
a priori non sappiamo se questa affermazione sia vera oppure no. La forma che prende un'ipotesi statistica pu\`{o} variare: se il parametro di interesse \`{e} 𝜗 e 𝜗 0 \`{e} un valore soglia (o target) fissato,
\end{flushleft}


\begin{flushleft}
sono esempi di ipotesi statistiche 𝜗 = 𝜗 0, 𝜗 ⩾ 𝜗0 e così via.
\end{flushleft}





\begin{flushleft}
Per fare un test statistico, come prima cosa stabiliamo due ipotesi: un'ipotesi nulla, denotata
\end{flushleft}


\begin{flushleft}
con H0, che rappresenta il caso di default (ad esempio H0: 𝜗 = 𝜗 0) e un'ipotesi alternativa, denotata
\end{flushleft}


\begin{flushleft}
con H 1 o Ha, a essa complementare (nel nostro esempio H 1: 𝜗 $\neq$ 𝜗0). L'ipotesi nulla \`{e} la risposta
\end{flushleft}


\begin{flushleft}
che diamo in caso di test negativo: accettiamo quella come risposta di default se non abbiamo
\end{flushleft}


\begin{flushleft}
evidenza (statistica) del contrario nei dati, se non possiamo escludere che l'ipotesi nulla sia vera.
\end{flushleft}


\begin{flushleft}
L'ipotesi alternativa \`{e} la risposta in caso di test positivo, ossia se abbiamo evidenza (statistica) che
\end{flushleft}


\begin{flushleft}
l'ipotesi nulla sia falsa. Torneremo su questo aspetto più avanti.
\end{flushleft}


193





\begin{flushleft}
Lezione 25
\end{flushleft}





\newpage
194





\begin{flushleft}
TEST STATISTICI
\end{flushleft}





\begin{flushleft}
Il secondo passo in un test statistico \`{e} il seguente: mettiamo alla prova la nostra ipotesi (nulla)
\end{flushleft}


\begin{flushleft}
usando un campione estratto dalla popolazione. Per fare questo, determiniamo una regione di
\end{flushleft}


\begin{flushleft}
accettazione dello spazio n-dimensionale: se il campione (un vettore n-dimensionale, ossia un
\end{flushleft}


\begin{flushleft}
punto nello spazio n-dimensionale) cade all'interno della regione, allora accettiamo l'ipotesi nulla,
\end{flushleft}


\begin{flushleft}
altrimenti la rifiutiamo, scegliendo l'ipotesi alternativa14.1. Il complementare della regione di accettazione, ossia la porzione dello spazio n-dimensionale in cui rifiutiamo l'ipotesi nulla prende il
\end{flushleft}


\begin{flushleft}
nome di regione critica. Vedremo a breve come determinare queste regioni dello spazio (e da cosa
\end{flushleft}


\begin{flushleft}
dipendono), ma nel frattempo osserviamo il contatto con gli intervalli di confidenza suggerito
\end{flushleft}


\begin{flushleft}
poco sopra: una possibilit\`{a} potrebbe essere quella di calcolarci un'opportuna statistica a partire
\end{flushleft}


\begin{flushleft}
dal campione e prendere come regione di accettazione un'intervallo, magari di confidenza. Dobbiamo per\`{o} far entrare in gioco anche il nostro valore target.
\end{flushleft}


\begin{flushleft}
Prima di continuare in concreto, per\`{o}, abbiamo bisogno di altre considerazioni astratte. In
\end{flushleft}


\begin{flushleft}
particolare vogliamo pensare agli errori che possiamo commettere in un test statistico: possiamo
\end{flushleft}


\begin{flushleft}
infatti sbagliare in due modi: rifiutare l'ipotesi nulla H0 quando questa \`{e} vera (errore di prima
\end{flushleft}


\begin{flushleft}
specie) oppure accettare l'ipotesi nulla quando questa \`{e} falsa (errore di seconda specie). Le quattro
\end{flushleft}


\begin{flushleft}
possibili situazioni sono rappresentate nella Tabella 14.1.
\end{flushleft}


\begin{flushleft}
𝑯0
\end{flushleft}


\begin{flushleft}
𝑯1
\end{flushleft}


\begin{flushleft}
H0
\end{flushleft}


\begin{flushleft}
ok
\end{flushleft}


\begin{flushleft}
Errore di seconda specie
\end{flushleft}


\begin{flushleft}
H1 Errore di prima specie
\end{flushleft}


\begin{flushleft}
ok
\end{flushleft}


\begin{flushleft}
Tabella 14.1. Nella colonna abbiamo la risposta del test, nella riga (in grassetto) la realt\`{a}.
\end{flushleft}





\begin{flushleft}
Come abbiamo accennato prima, l'ipotesi nulla \`{e} anche detta test negativo e l'ipotesi alternativa
\end{flushleft}


\begin{flushleft}
test positivo, terminologia ereditata dai test clinici. Possiamo allora dare nomi diversi alle quattro
\end{flushleft}


\begin{flushleft}
possibili situazioni, riportati in Tabella 14.2.
\end{flushleft}


\begin{flushleft}
𝑯0
\end{flushleft}


\begin{flushleft}
𝑯1
\end{flushleft}


\begin{flushleft}
H0 Vero negativo (TN) Falso negativo (FN)
\end{flushleft}


\begin{flushleft}
H1 Falso positivo (FP) Vero positivo (TP)
\end{flushleft}


\begin{flushleft}
Tabella 14.2. Nella colonna abbiamo la risposta del test, nella riga (in grassetto) la realt\`{a}.
\end{flushleft}





\begin{flushleft}
Indichiamo con 𝛼 la probabilit\`{a} di commettere un errore di prima specie. Solitamente vorremo che 𝛼 sia al di sotto di una certa soglia 𝛼 detta livello di significativit\`{a}. Indichiamo invece con
\end{flushleft}


\begin{flushleft}
𝛽 la probabilit\`{a} di commettere un errore di seconda specie. In un certo senso14.2, le due quantit\`{a}
\end{flushleft}


\begin{flushleft}
𝛼 e 𝛽 misurano la {``}qualit\`{a}'' di un test: un test molto buono avr\`{a} sia 𝛼 sia 𝛽 molto piccoli, un test
\end{flushleft}


\begin{flushleft}
perfetto (che non esiste!) li avr\`{a} entrambi nulli.
\end{flushleft}


\begin{flushleft}
Per tornare alla regione di accettazione, quello che vorremmo fare \`{e} fissare una soglia massima
\end{flushleft}


\begin{flushleft}
𝛼 per la probabilit\`{a} 𝛼 di errori di prima specie (ed eventualmente assegnare qualche condizione
\end{flushleft}


\begin{flushleft}
su 𝛽) e a partire da ci\`{o} determinare la regione di accettazione e la regione critica. Inoltre, siccome
\end{flushleft}


\begin{flushleft}
quello che abbiamo a disposizione \`{e} un campione estratto dalla popolazione, ne calcoleremo una
\end{flushleft}


\begin{flushleft}
funzione (cio\`{e} una statistica) che useremo per il nostro test.
\end{flushleft}


\begin{flushleft}
Ci sono diversi modi per procedere, che si differenziano tra loro per il bilanciamento della
\end{flushleft}


\begin{flushleft}
complessit\`{a} tra la statistica da calcolare e quella della regione di accettazione.
\end{flushleft}





\begin{flushleft}
14.1. IMPOSTARE TEST STATISTICI
\end{flushleft}


\begin{flushleft}
Algoritmo per un test bilaterale
\end{flushleft}


\begin{flushleft}
1. Stabilire le ipotesi da testare. Nel caso bilaterale saranno della forma H0: 𝜗 = 𝜗 0 e H 1: 𝜗 $\neq$ 𝜗 0.
\end{flushleft}


\begin{flushleft}
14.1. Sarebbe meglio indicare le due alternative come non rifiuto dell'ipotesi nulla e rifiuto dell'ipotesi nulla. Come
\end{flushleft}


\begin{flushleft}
vedremo, accettare l'ipotesi nulla \`{e} un po' fuorviante come terminologia.
\end{flushleft}


\begin{flushleft}
14.2. Vedremo alcuni dettagli in più tra qualche pagina.
\end{flushleft}





\begin{flushleft}
\newpage
14.1 IMPOSTARE TEST STATISTICI
\end{flushleft}





195





\begin{flushleft}
2. Fissare il livello di significativit\`{a} 𝛼 (piccolo).
\end{flushleft}


\begin{flushleft}
3. Determinare la funzione ancillare più adatta per il caso in considerazione.
\end{flushleft}


\begin{flushleft}
4. Calcolare a partire dal campione la statistica standard del test, ossia la funzione ancillare per
\end{flushleft}


\begin{flushleft}
il valore soglia 𝜗 = 𝜗 0.
\end{flushleft}


\begin{flushleft}
5. Individuare i quantili a e b per per la statistica, come per un intervallo di confidenza a
\end{flushleft}


\begin{flushleft}
livello 1 $-$ 𝛼. Questo determina la regione di accettazione RA = [a, b].
\end{flushleft}


\begin{flushleft}
6. Accettare H0 se la statistica standard \`{e} nella regione di accettazione, altrimenti rifiutare H0
\end{flushleft}


\begin{flushleft}
e accettare H 1.
\end{flushleft}


\begin{flushleft}
Esempio 14.1. Mettiamo in pratica l'algoritmo in un caso concreto: un test sulla media 𝜇 di una
\end{flushleft}


\begin{flushleft}
popolazione Gaussiana di varianza nota 𝜎 2 = 1. Il nostro campione ha taglia 81 e media campionaria x = 5.96. Vogliamo sapere se queste osservazioni sono compatibili con una media teorica
\end{flushleft}


\begin{flushleft}
uguale a 5.38, a un livello di significativit\`{a} pari al 5\%.
\end{flushleft}


\begin{flushleft}
1. Il nostro parametro incognito 𝜗 \`{e} la media 𝜇. Fissato il valore soglia 𝜗 0 = 𝜇0, in questo esempio
\end{flushleft}


\begin{flushleft}
𝜇 0 = 5.38, le ipotesi sono H0: 𝜇 = 𝜇0 = 5.38 e H 1: 𝜇 $\neq$ 𝜇 0 = 5.38.
\end{flushleft}


\begin{flushleft}
2. Fissiamo il livello 𝛼 = 5\% = 0.05.
\end{flushleft}


\begin{flushleft}
3. La popolazione \`{e} Gaussiana e la varianza \`{e} nota. La funzione ancillare più adatta per 𝜇 \`{e} allora
\end{flushleft}


\begin{flushleft}
X$-$𝜇
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
4. La statistica standard \`{e}
\end{flushleft}


\begin{flushleft}
Z0 =
\end{flushleft}





\begin{flushleft}
X $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





=





\begin{flushleft}
$\sim$ 𝒩(0, 1).
\end{flushleft}


5.96 $-$ 5.38


= 5.22.


1/


81





\begin{flushleft}
Osserviamo che nel momento in cui abbiamo le osservazioni del campione (anzi, in realt\`{a} ci
\end{flushleft}


\begin{flushleft}
basta solamente il valore della media campionaria) questo \`{e} un numero, z 0.
\end{flushleft}


\begin{flushleft}
5. Avendo fissato il livello di significativit\`{a} 𝛼 = 0.05, 1 $-$ 𝛼 = 0.95 e i quantili che ci interessano
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
sono a = $\Phi$ $-$1 2 = $-$$\Phi$ $-$1 1 $-$ 2 = $-$$\Phi$ $-$1(0.975) = $-$1.96 e b = $\Phi$ $-$1 1 $-$ 2 = $\Phi$ $-$1(0.975) = 1.96. La
\end{flushleft}


\begin{flushleft}
regione di accettazione \`{e} quindi RA Z = [$-$1.96, 1.96].
\end{flushleft}


\begin{flushleft}
6. Siccome Z0 $\notin$ RA Z (infatti 5.22 $\notin$ [$-$1.96, 1.96]) rifiutiamo l'ipotesi nulla e accettiamo l'ipotesi
\end{flushleft}


\begin{flushleft}
alternativa: abbiamo evidenza statistica che la media della popolazione da cui abbiamo estratto
\end{flushleft}


\begin{flushleft}
il campione non sia 5.38. Non possiamo escluderlo con certezza, ma \`{e} improbabile, in particolare c'\`{e} al più il 5\% di probabilit\`{a} che la media teorica sia 5.38.
\end{flushleft}


\begin{flushleft}
A questo punto sorge spontaneo chiedersi perch\'{e} quanto abbiamo visto funzioni. Vediamolo
\end{flushleft}


\begin{flushleft}
con qualche dettaglio: sia 𝛼 la probabilit\`{a} di un errore di prima specie, allora
\end{flushleft}





\begin{flushleft}
𝛼 = P(dire H 1 ∣ \`{e} vera H0)
\end{flushleft}


\begin{flushleft}
= P(Z 0 $\notin$ RA Z ∣ \`{e} vera H0)
\end{flushleft}


\begin{flushleft}
= P(Z 0 $\notin$ [a, b] ∣ Z 0 $\sim$ 𝒩(0, 1))
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
= P Z 0 $\notin$ $\Phi$ $-$1
\end{flushleft}


\begin{flushleft}
, $\Phi$ $-$1 1 $-$
\end{flushleft}


2


2


\begin{flushleft}
= 𝛼
\end{flushleft}





\begin{flushleft}
∣ Z 0 $\sim$ 𝒩(0, 1)
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
a = $\Phi$ $-$1
\end{flushleft}





\begin{flushleft}
1$-$𝛼
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
b = $\Phi$ $-$1 1 $-$ 2
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





\newpage
196





\begin{flushleft}
TEST STATISTICI
\end{flushleft}





\begin{flushleft}
in cui abbiamo usato che se \`{e} vera H 0, allora 𝜇0 = 𝜇 e quindi
\end{flushleft}


\begin{flushleft}
Z0 =
\end{flushleft}





\begin{flushleft}
X $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
H0
\end{flushleft}





$\Leftarrow$


$\Rightarrow$


$\Leftarrow$


$\Rightarrow$


$\Leftarrow$


$\Rightarrow$


$\Leftarrow$


$\Rightarrow$


$\Leftarrow$


$\Rightarrow$


$\Leftarrow$


$\Rightarrow$


$\Leftarrow$


$\Rightarrow$





\begin{flushleft}
X$-$𝜇
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
$\sim$ 𝒩(0, 1)
\end{flushleft}





\begin{flushleft}
e che a e b sono proprio i quantili 2 e 1 $-$ 2 di una normale standard. Quindi, se H 0 \`{e} vera, la
\end{flushleft}


\begin{flushleft}
risposta del test \`{e} H 1 con probabilit\`{a} minore o uguale al livello di significativit\`{a} 𝛼 (mell'esempio
\end{flushleft}


\begin{flushleft}
appena fatto 𝛼 = 𝛼, ma in generale sar\`{a} a ⩽ 𝛼). Come nel caso degli intervalli di confidenza bilaterali, stiamo suddividendo la probabilit\`{a} di errore tra lo sbagliare per eccesso e lo sbagliare per
\end{flushleft}


\begin{flushleft}
difetto.
\end{flushleft}


\begin{flushleft}
Se invece \`{e} vera H 1, quale sar\`{a} la risposta del test? Se \`{e} vera H 1, allora 𝜇0 $\neq$ 𝜇, quindi
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
Z0 =
\end{flushleft}





\begin{flushleft}
X $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
X$-$𝜇
\end{flushleft}





=





\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜇 $-$ 𝜇0
\end{flushleft}





+





\begin{flushleft}
$\sim$ 𝒩(0, 1) + $\Delta$ $\sim$ 𝒩($\Delta$, 1)
\end{flushleft}





\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
con $\Delta$ $\neq$ 0, cio\`{e} la probabilit\`{a} che la risposta del test sia H 1 \`{e} l'area tratteggiata in arancione nella
\end{flushleft}


\begin{flushleft}
Figura 14.1, la probabilit\`{a} che Z 0 cada al di fuori dell'intervallo [a, b]. Ricordando la definizione
\end{flushleft}


\begin{flushleft}
di 𝛽 come probabilit\`{a} che il test risponda H0 se \`{e} vera H1, 𝛽 \`{e} l'area non tratteggiata in arancione
\end{flushleft}


\begin{flushleft}
sotto la curva arancione.
\end{flushleft}





\begin{flushleft}
𝒩(0, 1)
\end{flushleft}





\begin{flushleft}
Z0 $\sim$ 𝒩($\Delta$, 1)
\end{flushleft}





\begin{flushleft}
$\Delta$
\end{flushleft}





\begin{flushleft}
𝛽
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
b
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}


2





\begin{flushleft}
P(Z0 $\notin$ [a, b])
\end{flushleft}





$-$


\begin{flushleft}
Figura 14.1. Probabilit\`{a} che il test risponda H 1 se \`{e} vera H 1.
\end{flushleft}





\begin{flushleft}
Per analizzarla meglio si pu\`{o} introdurre la curva operativa caratteristica (OCC) 𝛽(𝜇), come segue:
\end{flushleft}





\begin{flushleft}
𝛽(𝜇) = P(dire H0 ∣ la media \`{e} 𝜇) = P(Z 0 $\in$ RA Z ∣ la media \`{e} 𝜇)
\end{flushleft}





\begin{flushleft}
(( X $-$ 𝜇 ⩽ b||la media \`{e} 𝜇))
\end{flushleft}


((


))


|


/


\begin{flushleft}
( 𝜇 $-$ 𝜇 ⩽ X $-$ 𝜇 + 𝜇 $-$ 𝜇 ⩽ b + 𝜇 $-$ 𝜇 |||la media \`{e} 𝜇))
\end{flushleft}


\begin{flushleft}
= P(a +
\end{flushleft}


((


))


/


/


/


/ |


\begin{flushleft}
((a + 𝜇 $-$ 𝜇 ⩽ X $-$ 𝜇 ⩽ b + 𝜇 $-$ 𝜇 ||la media \`{e} 𝜇)))
\end{flushleft}


\begin{flushleft}
= P(
\end{flushleft}


((


))


/


/


/ ||


\begin{flushleft}
𝜇 $-$𝜇
\end{flushleft}


\begin{flushleft}
𝜇 $-$𝜇
\end{flushleft}


\begin{flushleft}
= $\Phi$(
\end{flushleft}


\begin{flushleft}
((b + / ))) $-$ $\Phi$(((a + / ))).
\end{flushleft}


\begin{flushleft}
= P a⩽
\end{flushleft}





0





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





0





0





\begin{flushleft}
𝜎
\end{flushleft}





2





2





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





0





\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





0





2





0





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





0





\begin{flushleft}
𝜎2
\end{flushleft}


0





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





0





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Chiamiamo il suo complemento a 1, ossia 1 $-$ 𝛽(𝜇), funzione di potenza del test. Per 𝜇 fissato, la
\end{flushleft}


\begin{flushleft}
potenza del test misura la probabilit\`{a} di rifiutare H0 (ossia rifiutare che la media sia 𝜇 0) quando
\end{flushleft}


\begin{flushleft}
la media \`{e} 𝜇.
\end{flushleft}





\begin{flushleft}
\newpage
14.2 IL p-DEI-DATI
\end{flushleft}





197





\begin{flushleft}
Questo ci permette di fare alcune considerazioni. La funzione 𝛽(𝜇) dipende anche dalla numerosit\`{a} del campione e, con gli altri parametri fissati, \`{e} decrescente in n. Allora, se vogliamo che
\end{flushleft}


\begin{flushleft}
il nostro test abbia significativit\`{a} 𝛼 e che sia sufficientemente potente da commettere errori di
\end{flushleft}


\begin{flushleft}
seconda specie con probabilit\`{a} al più 𝛽 se il valore vero della media \`{e} 𝜇 T $\neq$ 𝜇0 (cio\`{e} 𝛽(𝜇 T ) ⩽ 𝛽),
\end{flushleft}


\begin{flushleft}
ci basta scegliere n sufficientemente grande affinch\'{e} 𝛽(𝜇 T ) $\approx$ 𝛽. Inoltre, se non guardiamo 𝛽, ma
\end{flushleft}


\begin{flushleft}
solamente 𝛼, come accade effettivamente il caso nell'algoritmo visto prima, accettare H 0 non significa che questa sia vera con alta probabilit\`{a}, ma solamente che non abbiamo abbastanza evidenza
\end{flushleft}


\begin{flushleft}
per escluderla, cosa che \`{e} ben diversa da dire che i dati sostengono l'ipotesi nulla.
\end{flushleft}


\begin{flushleft}
Osservazione 14.2. Una volta che abbiamo capito come funzionano le cose nel caso del test bilaterale per la media di una Gaussiana, possiamo facilmente passare a test bilaterali per altri parametri
\end{flushleft}


\begin{flushleft}
di altre popolazioni di cui conosciamo funzioni ancillari, eventualmente approssimate. Possiamo
\end{flushleft}


\begin{flushleft}
anche considerare test unilaterali, in cui l'ipotesi nulla \`{e} della forma H0: 𝜗 ⩾ 𝜗 0 e l'ipotesi alternativa \`{e} H1: 𝜗 $<$ 𝜗0 (o viceversa, H0: 𝜗 ⩽ 𝜗 0 e H 1: 𝜗 $>$ 𝜗 0): in questo caso la regione di accettazione
\end{flushleft}


\begin{flushleft}
sar\`{a} non più un intervallo, ma (in genere) una semiretta.
\end{flushleft}





\begin{flushleft}
14.2. IL p-DEI-DATI
\end{flushleft}


\begin{flushleft}
Un'altra possibile via per il test delle ipotesi \`{e} la seguente: calcoliamo una statistica, detta p-dei-dati
\end{flushleft}


\begin{flushleft}
o p-value, un po' più complicata rispetto alla statistica standard vista prima ma per cui la regione
\end{flushleft}


\begin{flushleft}
di accettazione \`{e} della forma [𝛼, 1]. In altre parole, se il p-value \`{e} compreso tra 𝛼 e 1 accettiamo
\end{flushleft}


\begin{flushleft}
l'ipotesi nulla H 0, mentre se \`{e} tra 0 e 𝛼, rifiutiamo H0 e accettiamo l'ipotesi alternativa H 1.
\end{flushleft}


\begin{flushleft}
Osservazione 14.3. In questo caso, se il p-value \`{e} molto piccolo (ad esempio 10$-$4), allora sceglieremo sempre H1, mentre se \`{e} molto grande (ad esempio 0.3) accetteremo sempre H0. Inoltre, a
\end{flushleft}


\begin{flushleft}
differenza delle regioni di accettazione ricavate prima, possiamo cambiare la soglia 𝛼 senza fare
\end{flushleft}


\begin{flushleft}
troppi conti: in questo caso infatti la dipendenza da 𝛼 \`{e} molto semplice, a differenza di quanto
\end{flushleft}


\begin{flushleft}
visto nel caso precedente. Possiamo quindi trattare meglio i casi limite o valutare al volo, senza
\end{flushleft}


\begin{flushleft}
bisogno di ricalcolare, se un'ipotesi \`{e} accettabile al 5\% ma non all'1\%.
\end{flushleft}


\begin{flushleft}
L'idea alla base di questa costruzione \`{e} molto semplice: vogliamo sfruttare il fatto che le funzioni di ripartizione sono crescenti. Con il test precedente avevamo una regione di accettazione
\end{flushleft}


\begin{flushleft}
della forma a ⩽ $\Theta$0 ⩽ b per qualche statistica $\Theta$ calcolata in 𝜗 = 𝜗 0 ($\Theta$0 \`{e} la statistica standard del
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
test, nella nomenclatura usata prima), in cui a = Fℒ$-$1 2 e b = F ℒ$-$1 1 $-$ 2 , in cui ℒ \`{e} la legge della
\end{flushleft}


\begin{flushleft}
funzione ancillare associata alla statistica $\Theta$. Dunque il test risponde con H 0 se e solo se a⩽$\Theta$0 ⩽ b,
\end{flushleft}


\begin{flushleft}
ma qui entra in gioco l'idea, perch\'{e} questa condizione \`{e} equivalente a F ℒ (a) ⩽ F ℒ ($\Theta$0) ⩽ Fℒ (b),
\end{flushleft}


\begin{flushleft}
grazie alla monotonia crescente della funzione di ripartizione Fℒ . Possiamo riscrivere la stessa
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
condizione esplicitando la forma di a e b: 2 ⩽ Fℒ ($\Theta$0) ⩽ 1 $-$ 2 , ossia
\end{flushleft}


)


\begin{flushleft}
\{\{ 𝛼2 $-$⩽𝛼2⩾F 2($\Theta$
\end{flushleft}


\begin{flushleft}
F ($\Theta$ )
\end{flushleft}


\begin{flushleft}
ℒ
\end{flushleft}





0





\begin{flushleft}
ℒ
\end{flushleft}





0





\begin{flushleft}
da cui ricaviamo che accettiamo H0 se e solo se 𝛼 ⩽ 2 min Fℒ ($\Theta$0), 1 $-$ Fℒ ($\Theta$0) . Il p-dei-dati \`{e}
\end{flushleft}


\begin{flushleft}
quindi 2 min Fℒ ($\Theta$0), 1 $-$ F ℒ ($\Theta$0) , una quantit\`{a} numerica che possiamo ricavare dalla legge ℒ
\end{flushleft}


\begin{flushleft}
della funzione ancillare associata alla statistica, dal valore target 𝜗 0 del parametro 𝜗 che stiamo
\end{flushleft}


\begin{flushleft}
testando e dalla realizzazione del campione.
\end{flushleft}


\begin{flushleft}
Esempio 14.4. Supponiamo di avere una popolazione Gaussiana di media 𝜇 che vogliamo testare
\end{flushleft}


\begin{flushleft}
contro un valore target 𝜇 0 e di varianza ignota. In questo caso H 0: 𝜇 = 𝜇 0 e H1: 𝜇 $\neq$ 𝜇0.
\end{flushleft}


\begin{flushleft}
La statistica di riferimento in questo caso \`{e} quella per la media di una Gaussiana a 𝜎 ignota,
\end{flushleft}


\begin{flushleft}
T=
\end{flushleft}





\begin{flushleft}
Xn $-$ 𝜇
\end{flushleft}


\begin{flushleft}
S 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
$\sim$ t(n $-$ 1).
\end{flushleft}





\newpage
198





\begin{flushleft}
TEST STATISTICI
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
La statistica test (che ricordiamo essere un numero) \`{e} T0 = (Xn $-$ 𝜇 0) S 2 .
\end{flushleft}


\begin{flushleft}
Per definizione il p-dei-dati \`{e} 2 min F t(n$-$1)(T0), 1 $-$ Ft(n$-$1)(T0) , ma in questo caso possiamo
\end{flushleft}


\begin{flushleft}
sfruttare il fatto che t(n $-$ 1) abbia delle propriet\`{a} di simmetria:
\end{flushleft}


\begin{flushleft}
$-$ se T0 $<$ 0, il minimo \`{e} Ft(n$-$1)(T0) = 1 $-$ F t(n$-$1)($-$T0),
\end{flushleft}


\begin{flushleft}
$-$ se T0 $>$ 0, il minimo \`{e} 1 $-$ Ft(n$-$1)(T0),
\end{flushleft}


\begin{flushleft}
quindi possiamo semplificare il p-dei-dati: 2 $-$ 2 Ft(n$-$1)(|T0|).
\end{flushleft}


\begin{flushleft}
Ora non ci resta che calcolare questo numero in funzione dei parametri noti e della realizzazione del campione e confrontarlo con il livello di significativit\`{a} fissato 𝛼: se il p-dei-dati \`{e}
\end{flushleft}


\begin{flushleft}
maggiore o uguale di 𝛼 accettiamo H 0, se \`{e} minore scegliamo H1.
\end{flushleft}


\begin{flushleft}
Abbiamo un campione di taglia 64 e vogliamo testare l'ipotesi che 𝜇 = 5.5. La media campionaria \`{e} x = 5.213 e la varianza campionaria \`{e} s 2 = 3.684. La statistica test \`{e} quindi T0 = $-$1.196 e il
\end{flushleft}


\begin{flushleft}
p-dei-dati \`{e} 0.236, non possiamo quindi scartare l'ipotesi nulla che la media sia veramente 5.5, se
\end{flushleft}


\begin{flushleft}
non a un livello superiore al 23.6\% (che sarebbe molto alto). La popolazione da cui \`{e} stato estratto
\end{flushleft}


\begin{flushleft}
il campione aveva media 5 e deviazione standard 2.
\end{flushleft}


\begin{flushleft}
Se vogliamo usare R in un caso simile, supponiamo di avere il campione salvato nel vettore
\end{flushleft}


\begin{flushleft}
x. Allora la media campionaria \`{e} mean(x), la varianza campionaria \`{e} var(x) e la statistica standard T0 \`{e}, per 𝜇0 =5.5, (mean(x)-5.5)/(sqrt(var(x)/length(x))). Supponendo di
\end{flushleft}


\begin{flushleft}
aver assegnato questo valore alla variabile T\_0, possiamo calcolare il p-value usando la funzione
\end{flushleft}


\begin{flushleft}
pt (dal momento che la funzione ancillare \`{e} una t): 2-2*pt(abs(T\_0),length(x)-1).
\end{flushleft}


\begin{flushleft}
Osservazione 14.5. Possiamo vedere il p-dei-dati come la soglia critica della significativit\`{a}: per
\end{flushleft}


\begin{flushleft}
tutti gli 𝛼 $>$ p-dei-dati rifiutiamo H 0, per tutti gli 𝛼 ⩽ p-dei-dati accettiamo H0. Da un altro punto
\end{flushleft}


\begin{flushleft}
di vista, il p-dei-dati \`{e} la probabilit\`{a} di vedere un evento {``}altrettanto o più estremo'' di quello
\end{flushleft}


\begin{flushleft}
osservato nel campione se \`{e} vera l'ipotesi nulla.
\end{flushleft}


\begin{flushleft}
Lezione 26
\end{flushleft}





\begin{flushleft}
Esempio 14.6. Consideriamo ora una popolazione Gaussiana di media e varianza ignote. Vogliamo
\end{flushleft}


\begin{flushleft}
un test statistico sul valore della varianza, H 0: 𝜎 2 = 𝜎02 e H 1: 𝜎 2 $\neq$ 𝜎02.
\end{flushleft}


\begin{flushleft}
Come prima cosa individuiamo la statistica di riferimento W e la statistica test W0:
\end{flushleft}





\begin{flushleft}
S2
\end{flushleft}


\begin{flushleft}
S2
\end{flushleft}


2


\begin{flushleft}
(n
\end{flushleft}


$-$


1)


$\sim$


\begin{flushleft}
𝜒
\end{flushleft}


\begin{flushleft}
(n
\end{flushleft}


$-$


1)


\begin{flushleft}
W
\end{flushleft}


=


\begin{flushleft}
(n $-$ 1).
\end{flushleft}


0


\begin{flushleft}
𝜎2
\end{flushleft}


\begin{flushleft}
𝜎02
\end{flushleft}


\begin{flushleft}
Il p-dei-dati \`{e}, dalla definizione, 2 min F𝜒 2(n$-$1)(W0), 1 $-$ F𝜒 2(n$-$1)(W0) . In questo caso non abbiamo
\end{flushleft}


\begin{flushleft}
propriet\`{a} di simmetria che possiamo usare per semplificare la formulazione, ma siamo comunque
\end{flushleft}


\begin{flushleft}
in grado di calcolare questo valore a partire dai dati.
\end{flushleft}


\begin{flushleft}
Supponiamo di avere un campione di taglia 49 per cui s 2 = 3.744. Se 𝜎02 = 4, allora la statistica
\end{flushleft}


\begin{flushleft}
test \`{e} W0 = 44.928 e il p-dei-dati \`{e} 0.801. Non possiamo escludere che la varianza vera sia 4 (come
\end{flushleft}


\begin{flushleft}
effettivamente \`{e} nel campione da cui sono estratti i dati). Avessimo voluto testare l'ipotesi che la
\end{flushleft}


\begin{flushleft}
varianza fosse 2.5 avremmo avuto W0 = 71.885 e un p-dei-dati corrispondente di 0.029. In questo
\end{flushleft}


\begin{flushleft}
caso a un livello di significativit\`{a} del 5\% rifiutiamo l'ipotesi nulla, ma a un livello di significativit\`{a}
\end{flushleft}


\begin{flushleft}
dell'1\% la accettiamo: non abbiamo in quest'ultimo caso abbastanza evidenza statistica per escludere che sia vera l'ipotesi nulla, che ricordiamo \`{e} la risposta {``}di default''.
\end{flushleft}


\begin{flushleft}
Anche in questo caso possiamo aiutarci con R per i calcoli. Se salviamo in W0 la statistica test
\end{flushleft}


\begin{flushleft}
var(x)*(length(x)-1)/4 (nel caso in cui 𝜎02 = 4), il calcolo del p-dei-dati si appoggia sulla
\end{flushleft}


\begin{flushleft}
funzione pchisq,
\end{flushleft}


\begin{flushleft}
W=
\end{flushleft}





\begin{flushleft}
2*min(pchisq(W0,df=length(x)-1),1-pchisq(W0,df =length(x)-1))
\end{flushleft}


\begin{flushleft}
Osservazione 14.7. Anche con il p-dei-dati \`{e} possibile impostare test statistici unilaterali, in cui
\end{flushleft}


\begin{flushleft}
l'ipotesi nulla \`{e} della forma H0: 𝜗 ⩽ 𝜗0 (rispettivamente H 0: 𝜗 ⩾ 𝜗 0) e l'ipotesi alternativa \`{e} della
\end{flushleft}


\begin{flushleft}
forma H1: 𝜗 $>$ 𝜗 0 (rispettivamente H 1: 𝜗 $<$ 𝜗 0). Le idee sono sostanzialmente le stesse, ma come gi\`{a}
\end{flushleft}


\begin{flushleft}
nel caso degli intervalli di confidenza, dobbiamo stare attenti ai valori da considerare.
\end{flushleft}





\begin{flushleft}
\newpage
14.3 TEST STATISTICI UNILATERALI
\end{flushleft}





199





\begin{flushleft}
14.3. TEST STATISTICI UNILATERALI
\end{flushleft}


\begin{flushleft}
Abbiamo visto, nel caso dei test bilaterali, che accettiamo l'ipotesi nulla 𝜗 = 𝜗0 se lo stimatore $\Theta$
\end{flushleft}


\begin{flushleft}
non \`{e} troppo lontano da 𝜗0, n\'{e} troppo più grande, n\'{e} troppo più piccolo. Quanto sia {``}troppo'' lo
\end{flushleft}


\begin{flushleft}
abbiamo quantificato in funzione della taglia del campione, del livello di significativit\`{a} e di altri
\end{flushleft}


\begin{flushleft}
parametri, determinando così una regione di accettazione. Nel caso dei test unilaterali, l'ipotesi
\end{flushleft}


\begin{flushleft}
nulla \`{e} della forma H 0:𝜗 ⩽𝜗0 (rispettivamente H0:𝜗 ⩾𝜗 0) e l'ipotesi alternativa \`{e} della forma H 1:𝜗 $>$
\end{flushleft}


\begin{flushleft}
𝜗 0 (rispettivamente H1: 𝜗 $<$ 𝜗0), quindi se $\Theta$ \`{e} lontano da 𝜗 0, ma verso il basso, cio\`{e} \`{e} molto minore
\end{flushleft}


\begin{flushleft}
di 𝜗 0 (rispettivamente molto maggiore di 𝜗0) non \`{e} un problema, non usciamo dalla regione di
\end{flushleft}


\begin{flushleft}
accettazione. Ci sar\`{a} allora una costante c (che dovremo determinare) tale che la regione di accettazione sar\`{a} della forma $\Theta$ $-$ 𝜗 0 ⩽ c (rispettivamente $\Theta$ $-$ 𝜗0 ⩾ c)14.3.
\end{flushleft}


\begin{flushleft}
Richiamiamo ora la definizione di 𝛼, cio\`{e} la probabilit\`{a} di un errore di prima specie, ovvero la
\end{flushleft}


\begin{flushleft}
probabilit\`{a} che il test risponda H 1 se \`{e} vera H0. In questo caso unilaterale abbiamo
\end{flushleft}


\begin{flushleft}
𝛼 = P(dire H1 ∣ \`{e} vera H 0) = P($\Theta$ $-$ 𝜗0 $>$ c ∣ 𝜗 ⩽ 𝜗 0)
\end{flushleft}


\begin{flushleft}
e possiamo proseguire se abbiamo la distribuzione di $\Theta$. Vediamo qualche esempio.
\end{flushleft}


\begin{flushleft}
Esempio 14.8. Torniamo al caso della media di una popolazione Gaussiana di varianza nota.
\end{flushleft}


\begin{flushleft}
Allora 𝜗 = 𝜇, $\Theta$ = X e sappiamo anche che la statistica standard \`{e}
\end{flushleft}


\begin{flushleft}
Z=
\end{flushleft}





\begin{flushleft}
X$-$𝜇
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
$\sim$ 𝒩(0, 1).
\end{flushleft}





\begin{flushleft}
Vogliamo testare l'ipotesi nulla H 0: 𝜇 ⩽ 𝜇 0 contro l'ipotesi alternativa H1: 𝜇 $>$ 𝜇0. Allora
\end{flushleft}


\begin{flushleft}
𝛼 = P(dire H1 ∣ \`{e} vera H 0) = P(X $-$ 𝜇0 $>$ c ∣ 𝜇 ⩽ 𝜇 0)
\end{flushleft}





\begin{flushleft}
((( X $-$ 𝜇 + 𝜇 $-$ 𝜇 $>$ c ||𝜇 ⩽ 𝜇 )))
\end{flushleft}


(( /


))


/


/ ||


\begin{flushleft}
( X $-$ 𝜇 $>$ c + 𝜇 $-$ 𝜇 ||𝜇 ⩽ 𝜇 )).
\end{flushleft}


\begin{flushleft}
= P(
\end{flushleft}


(( /


))


/ |


\begin{flushleft}
= P
\end{flushleft}





0





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





0





\begin{flushleft}
n
\end{flushleft}





0





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





0





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Sotto l'ipotesi nulla, 𝜇 ⩽ 𝜇0, quindi c + 𝜇0 $-$ 𝜇 ⩾ c e, il massimo di questa probabilit\`{a} al variare di
\end{flushleft}


\begin{flushleft}
𝜇 ⩽ 𝜇 0 \`{e} nel caso 𝜇 = 𝜇 0, perch\'{e} la funzione P(X $>$ d) \`{e} decrescente in d. Per essere sicuri di avere
\end{flushleft}


\begin{flushleft}
una probabilit\`{a} di errore di prima specie non superiore ad 𝛼 ci basta allora considerare il caso
\end{flushleft}


\begin{flushleft}
peggiore, ossia in cui 𝜇 = 𝜇 0:
\end{flushleft}


\begin{flushleft}
𝛼=P
\end{flushleft}


\begin{flushleft}
Quindi
\end{flushleft}





\begin{flushleft}
(( X $-$ 𝜇 $>$ c + 𝜇 $-$ 𝜇 ||𝜇 ⩽ 𝜇 )) ⩽ P(( X $-$ 𝜇
\end{flushleft}


(( /


)) (( /


/ |


\begin{flushleft}
1 $-$ 𝛼 = P(
\end{flushleft}


\begin{flushleft}
((( X $-$ /𝜇 ⩽ c / ))))
\end{flushleft}


0





\begin{flushleft}
𝜎
\end{flushleft}





2





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎
\end{flushleft}





2





0





\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





2





0





\begin{flushleft}
n
\end{flushleft}





$>$





\begin{flushleft}
c
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
)) $\Rightarrow$$\Leftarrow$$\Rightarrow$$\Leftarrow$ 𝛼.
\end{flushleft}


)


/ )





2





!





\begin{flushleft}
n
\end{flushleft}





0





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
e, approfittando del fatto che
\end{flushleft}





\begin{flushleft}
X $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
𝜎2
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
ha distribuzione normale standard, c =$\Phi$ $-$1(1 $-$ 𝛼)
\end{flushleft}





\begin{flushleft}
parole accettiamo l'ipotesi nulla 𝜇 ⩽𝜇0 se X⩽𝜇 0 +$\Phi$ $-$1(1 $-$ 𝛼)
\end{flushleft}


$-$1





\begin{flushleft}
𝜎
\end{flushleft}





\begin{flushleft}
𝜎 2/ .
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
In altre
\end{flushleft}





\begin{flushleft}
/n e la rifiutiamo se invece abbiamo
\end{flushleft}





2





\begin{flushleft}
X $>$ 𝜇 0 + $\Phi$ (1 $-$ 𝛼) /n , se la significativit\`{a} che abbiamo fissato \`{e} 𝛼.
\end{flushleft}


\begin{flushleft}
Ovviamente anche in questo caso unilaterale possiamo ricavare il p-dei-dati, infatti rispondiamo H 0 se e solo se
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}





2





\begin{flushleft}
Z0 =
\end{flushleft}





\begin{flushleft}
X $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
⩽ $\Phi$ $-$1(1 $-$ 𝛼) ⟺ $\Phi$(Z 0) ⩽ 1 $-$ 𝛼 ⟺ 𝛼 ⩽ 1 $-$ $\Phi$(Z0),
\end{flushleft}





\begin{flushleft}
14.3. Potremmo anche (se 𝜗 0 $>$ 0) considerare il rapporto $\Theta$/𝜗0 ⩽ c, per un altro, opportuno, c.
\end{flushleft}





\newpage
200





\begin{flushleft}
TEST STATISTICI
\end{flushleft}





\begin{flushleft}
ossia il p-dei-dati \`{e} 1 $-$ $\Phi$(Z 0).
\end{flushleft}


\begin{flushleft}
Osservazione 14.9. Con il p-dei-dati quantifichiamo la probabilit\`{a} (condizionata all'evento {``}l'ipotesi nulla \`{e} soddisfatta'') di vedere una statistica del test {``}più estrema'' di quella standard. I
\end{flushleft}


\begin{flushleft}
risultati {``}più estremi'' sono quelli che ci aspettiamo si verifichino nel caso sia vera l'ipotesi alternativa, quindi nel caso dei test unilaterali, quelli nel verso dell'ipotesi alternativa (o equivalentemente
\end{flushleft}


\begin{flushleft}
di senso contrario all'ipotesi nulla).
\end{flushleft}


\begin{flushleft}
Osservazione 14.10. L'asimmetria tra ipotesi nulla e ipotesi alternativa \`{e} forse ancora più evidente nel caso di test unilaterali: se consideriamo due test speculari
\end{flushleft}


\begin{flushleft}
H 0: 𝜗 ⩽ 𝜗 0
\end{flushleft}


\begin{flushleft}
H 1: 𝜗 $>$ 𝜗 0
\end{flushleft}





\begin{flushleft}
H0: 𝜗 ⩾ 𝜗0
\end{flushleft}


\begin{flushleft}
H1: 𝜗 $<$ 𝜗0
\end{flushleft}





\begin{flushleft}
\`{e} possibile che accettiamo l'ipotesi nulla in entrambi (e non in uno solo dei due come ci potremmo
\end{flushleft}


\begin{flushleft}
aspettare). Il motivo di ci\`{o} \`{e} nel gi\`{a} citato diverso valore delle due ipotesi, nulla e alternativa.
\end{flushleft}


\begin{flushleft}
Infatti scegliamo l'ipotesi alternativa (rifiutando quindi l'ipotesi nulla) se abbiamo evidenza statistica a suo favore, ma scegliamo l'ipotesi nulla (ossia quella di default) se non abbiamo sufficiente
\end{flushleft}


\begin{flushleft}
evidenza statistica per rifiutarla.
\end{flushleft}


\begin{flushleft}
Questo ci impone di prestare molta attenzione (soprattutto nel caso dei test unilaterali) alla
\end{flushleft}


\begin{flushleft}
scelta dell'ipotesi nulla. Essa dipender\`{a} dal caso particolare che stiamo considerando e da quale
\end{flushleft}


\begin{flushleft}
vogliamo che sia la nostra risposta in caso non ci sia evidenza in un senso o nell'altro.
\end{flushleft}


\begin{flushleft}
Esempio 14.11. Un'azienda produce microprocessori e sta considerando l'acquisto di una nuova
\end{flushleft}


\begin{flushleft}
linea di produzione. I microprocessori prodotti hanno una distribuzione Gaussiana e una linea
\end{flushleft}


\begin{flushleft}
di produzione \`{e} considerata affidabile se la performance dei processori prodotti in un certo benchmark ha deviazione standard non superiore a 0.15 ms. Da una prima produzione di prova
\end{flushleft}


\begin{flushleft}
della nuova linea, abbiamo un campione di taglia 20, da cui ricaviamo una varianza campionaria
\end{flushleft}


\begin{flushleft}
s 2 = 0.025 ms 2. La nuova linea di produzione \`{e} affidabile o no?
\end{flushleft}


\begin{flushleft}
Mettiamoci come prima cosa nei panni del venditore. Il nostro scopo \`{e} mostrare che il dato
\end{flushleft}


\begin{flushleft}
sia compatibile con il fatto che la linea di produzione sia affidabile, ossia che non c'\`{e} evidenza
\end{flushleft}


\begin{flushleft}
statistica che la linea non sia affidabile. Scegliamo allora come ipotesi del test statistico
\end{flushleft}


\begin{flushleft}
H0 : 𝜎 2 ⩽ (0.15)2 = 0.0225
\end{flushleft}


\begin{flushleft}
H 1 : 𝜎 2 $>$ 0.0225.
\end{flushleft}


\begin{flushleft}
Stiamo facendo un test statistico unilaterale sulla varianza di una distribuzione Gaussiana. La
\end{flushleft}


\begin{flushleft}
funzione ancillare \`{e}
\end{flushleft}


\begin{flushleft}
S2
\end{flushleft}


\begin{flushleft}
W = 2 (n $-$ 1) $\sim$ 𝜒 2(n $-$ 1)
\end{flushleft}


\begin{flushleft}
𝜎
\end{flushleft}


\begin{flushleft}
e la statistica test \`{e} W0 = s 2 (n $-$ 1) 𝜎0$-$2. I valori di S 2 più vicini a 0 concordano con la nostra ipotesi
\end{flushleft}


\begin{flushleft}
nulla, quindi i valori {``}estremi'' che ci interessano per determinare il p-dei-dati sono quelli per cui
\end{flushleft}


\begin{flushleft}
la 𝜒 2 \`{e} maggiore della statistica test:
\end{flushleft}


\begin{flushleft}
s2
\end{flushleft}


\begin{flushleft}
s2
\end{flushleft}


\begin{flushleft}
(n $-$ 1) = 1 $-$ F𝜒$-$12(n$-$1) 2 (n $-$ 1)
\end{flushleft}


2


\begin{flushleft}
𝜎0
\end{flushleft}


\begin{flushleft}
𝜎0
\end{flushleft}


0.025


\begin{flushleft}
= 1 $-$ F𝜒$-$12(19)
\end{flushleft}


\begin{flushleft}
⋅ 19 = 1 $-$ F𝜒$-$12(19)(21.11)
\end{flushleft}


0.0225


= 1 $-$ 0.669 = 0.331





((





\begin{flushleft}
P(W $>$ W0) = P W $>$
\end{flushleft}





))





((





))





\begin{flushleft}
e siccome questo valore \`{e} relativamente alto, non rifiuteremo (e dunque accetteremo) l'ipotesi
\end{flushleft}


\begin{flushleft}
nulla, ossia che la linea di produzione sia affidabile, per ogni ragionevole significativit\`{a} 𝛼.
\end{flushleft}


\begin{flushleft}
Mettiamoci ora nei panni dell'acquirente. Il nostro scopo \`{e} avere evidenza statistica del fatto
\end{flushleft}


\begin{flushleft}
che la linea di produzione sia affidabile: vogliamo essere convinti che la linea sia affidabile, di
\end{flushleft}


\begin{flushleft}
default rispondiamo che non lo \`{e}. Scegliamo allora come ipotesi del test statistico
\end{flushleft}


\begin{flushleft}
H0 : 𝜎 2 ⩾ (0.15)2 = 0.0225
\end{flushleft}


\begin{flushleft}
H 1 : 𝜎 2 $<$ 0.0225.
\end{flushleft}





\begin{flushleft}
\newpage
14.3 TEST STATISTICI UNILATERALI
\end{flushleft}





201





\begin{flushleft}
Stiamo sempre facendo un test statistico unilaterale sulla varianza di una distribuzione Gaussiana con la medesima funzione ancillare di prima, solo che ora i valori di S 2 più vicini a 0 non
\end{flushleft}


\begin{flushleft}
sono in accordo con la nostra ipotesi nulla, quindi i valori {``}estremi'' che ci interessano per determinare il p-dei-dati sono quelli per cui la statistica \`{e} minore della statistica test:
\end{flushleft}





((





\begin{flushleft}
P(W $<$ W0) = P W $<$
\end{flushleft}





\begin{flushleft}
s2
\end{flushleft}


\begin{flushleft}
s2
\end{flushleft}


$-$1


\begin{flushleft}
(n
\end{flushleft}


$-$


1)


=


\begin{flushleft}
F
\end{flushleft}


\begin{flushleft}
2(n$-$1)
\end{flushleft}


\begin{flushleft}
(n $-$ 1)
\end{flushleft}


\begin{flushleft}
𝜒
\end{flushleft}


\begin{flushleft}
𝜎02
\end{flushleft}


\begin{flushleft}
𝜎02
\end{flushleft}





))





\begin{flushleft}
= F𝜒$-$12(19)(21.11) = 0.669.
\end{flushleft}





((





))





\begin{flushleft}
Non abbiamo allora abbastanza evidenza statistica per rifiutare l'ipotesi nulla, ossia che la linea
\end{flushleft}


\begin{flushleft}
di produzione non sia affidabile.
\end{flushleft}


\begin{flushleft}
Siamo allora in una situazione in cui i dati osservati non hanno abbastanza forza statistica per
\end{flushleft}


\begin{flushleft}
puntare nell'una o nell'altra direzione: non siamo in grado di rifiutare alcuna delle due ipotesi
\end{flushleft}


\begin{flushleft}
nulle, anche se esse sono apparentemente opposte. Come possiamo risolvere una situazione di
\end{flushleft}


\begin{flushleft}
stallo come questa? Raccogliendo nuovi dati.
\end{flushleft}


\begin{flushleft}
Esempio 14.12. Supponiamo di voler fare un test sul parametro di una popolazione Bernoulliana,
\end{flushleft}


\begin{flushleft}
ad esempio per determinare se la probabilit\`{a} di passare l'esame di Probabilit\`{a} e Statistica (o equivalentemente la proporzione di studentesse e studenti che lo passano sul totale di chi lo ha in
\end{flushleft}


\begin{flushleft}
piano di studi) sia inferiore al 75\%.
\end{flushleft}


\begin{flushleft}
Mettiamoci nei panni dei rappresentanti degli studenti14.4: di default sostengono che l'esame
\end{flushleft}


\begin{flushleft}
sia troppo difficile e che la probabilit\`{a} di passare sia minore o uguale al 75\%. L'ipotesi nulla \`{e}
\end{flushleft}


\begin{flushleft}
quindi H 0: p ⩽ p 0 = 0.75, mentre l'ipotesi alternativa \`{e} H1: p $>$ p0.
\end{flushleft}


\begin{flushleft}
Sappiamo che uno stimatore per il parametro di una Bernoulliana \`{e} X, inoltre, se moltiplichiamo X per n, abbiamo una variabile aleatoria che conta i successi all'interno del campione,
\end{flushleft}


\begin{flushleft}
di cui quindi sappiamo la distribuzione: \`{e} una variabile aleatoria binomiale di parametri n e p.
\end{flushleft}


\begin{flushleft}
Allora abbiamo la nostra statistica standard: B $\sim$ bin(n, p), per essa sappiamo che vale
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
P(B ⩾ a) =
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
P(B = k) =
\end{flushleft}


\begin{flushleft}
k =⌈a⌉
\end{flushleft}





\begin{flushleft}
k =⌈a⌉
\end{flushleft}





\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
p (1 $-$ p)n$-$k .
\end{flushleft}


\begin{flushleft}
k
\end{flushleft}





(14.1)





\begin{flushleft}
Ricordiamoci che siamo interessati a controllare la probabilit\`{a} di errori di prima specie, vogliamo
\end{flushleft}


\begin{flushleft}
cio\`{e} che la probabilit\`{a} di rifiutare l'ipotesi nulla se essa \`{e} vera sia controllata dalla significativit\`{a}
\end{flushleft}


\begin{flushleft}
fissata 𝛼. Come prima cosa, notiamo che con l'ipotesi nulla scelta i casi estremi che spingono a
\end{flushleft}


\begin{flushleft}
rifiutare H 0 sono quelli per cui B = n X \`{e} oltre una certa soglia c che dobbiamo determinare.
\end{flushleft}


\begin{flushleft}
Osserviamo inoltre che la (14.1) \`{e} crescente se vista come funzione di p: infatti se la probabilit\`{a}
\end{flushleft}


\begin{flushleft}
di successo in un singolo tentativo \`{e} maggiore, sar\`{a} maggiore anche la probabilit\`{a} di ottenere
\end{flushleft}


\begin{flushleft}
almeno a successi in n tentativi, quindi sotto l'ipotesi nulla tale probabilit\`{a} \`{e} massima per p = p0,
\end{flushleft}


\begin{flushleft}
cio\`{e}
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
𝛼 = P(dire H1 ∣ \`{e} vera H 0) = P(B ⩾ c ∣ p ⩽ p0) ⩽
\end{flushleft}


\begin{flushleft}
p (1 $-$ p0)n$-$k
\end{flushleft}


\begin{flushleft}
k 0
\end{flushleft}


\begin{flushleft}
k =⌈c⌉
\end{flushleft}





\begin{flushleft}
e se vogliamo che 𝛼 ⩽ 𝛼 dobbiamo prendere c tale che ∑nk =⌈c⌉ nk p0k (1 $-$ p 0)n$-$k ⩽ 𝛼, in particolare il
\end{flushleft}


\begin{flushleft}
più piccolo c tale per cui ci\`{o} valga, che denotiamo con c min. Allora accetteremo l'ipotesi nulla con
\end{flushleft}


\begin{flushleft}
un livello di significativit\`{a} 𝛼 se n x $<$ cmin.
\end{flushleft}


\begin{flushleft}
Calcolare questo valore cmin non \`{e} semplicissimo, anche se fattibile usando qualche software,
\end{flushleft}


\begin{flushleft}
per esempio R. Tuttavia, da quanto abbiamo osservato sopra ricaviamo immediatamente quale
\end{flushleft}


\begin{flushleft}
sia il p-dei-dati: siccome vogliamo la probabilit\`{a} di vedere eventi più estremi rispetto a quello
\end{flushleft}


\begin{flushleft}
misurato (ossia n x) supponendo che H0 sia vera, ci basta calcolare
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
P(B ⩾ n x ∣ p ⩽ p0) ⩽
\end{flushleft}


\begin{flushleft}
k =nx
\end{flushleft}





\begin{flushleft}
n k
\end{flushleft}


\begin{flushleft}
p (1 $-$ p0)n$-$k
\end{flushleft}


\begin{flushleft}
k 0
\end{flushleft}





\begin{flushleft}
14.4. Chiaramente esiste anche il punto di vista opposto, quello per cui in mancanza di evidenza statistica in contrario
\end{flushleft}


\begin{flushleft}
l'esame \`{e} da ritenersi di difficolt\`{a} adeguata, in cui sono scambiate ipotesi nulla e ipotesi alternativa rispetto al caso presentato nello svolgimento di questo esempio.
\end{flushleft}





\newpage
202





\begin{flushleft}
TEST STATISTICI
\end{flushleft}





\begin{flushleft}
cio\`{e} pbinom(q, size = n, prob = p0, lower.tail = FALSE), con q = n x.
\end{flushleft}


\begin{flushleft}
Se per esempio fossero passati all'esame 40 studenti su 50 del campione (cio\`{e} l'80\% del campione), il p-dei-dati sarebbe 0.164, ossia non si potrebbe rifiutare l'ipotesi nulla che la probabilit\`{a}
\end{flushleft}


\begin{flushleft}
di passare l'esame sia minore o uguale del 75\%.
\end{flushleft}


\begin{flushleft}
Osservazione 14.13. Nel caso Bernoulliano (come in altri casi) possiamo anche usare le statistiche
\end{flushleft}


\begin{flushleft}
approssimate che abbiamo visto grazie ai teoremi limite. Sappiamo infatti che
\end{flushleft}


\begin{flushleft}
Z=
\end{flushleft}





\begin{flushleft}
nX$-$np
\end{flushleft}


$\sim$


\begin{flushleft}
˙ 𝒩(0, 1)
\end{flushleft}


\begin{flushleft}
n p (1 $-$ p)
\end{flushleft}





\begin{flushleft}
Z0 =
\end{flushleft}





\begin{flushleft}
n X $-$ n p0
\end{flushleft}


.


\begin{flushleft}
n p0 (1 $-$ p0)
\end{flushleft}





\begin{flushleft}
In questo caso per il test delle ipotesi H 0: p ⩽ p 0 e H 1: p $>$ p0 a livello 𝛼 abbiamo che la regione di
\end{flushleft}


\begin{flushleft}
accettazione per Z0 \`{e} della forma ($-$$\infty$, b] con b = $\Phi$ $-$1(1 $-$ 𝛼) (infatti se p ≪ p 0 la statistica Z0 \`{e}
\end{flushleft}


\begin{flushleft}
sempre più piccola e vogliamo che cada nella regione di accettazione).
\end{flushleft}


\begin{flushleft}
Se invece volessimo fare il test delle ipotesi H 0: p ⩾ p0 e H 1: p $<$ p 0 a livello 𝛼 abbiamo che la
\end{flushleft}


\begin{flushleft}
regione di accettazione per Z 0 \`{e} della forma [a, +$\infty$) con a = $-$$\Phi$ $-$1(1 $-$ 𝛼) = $\Phi$ $-$1(𝛼) (infatti se p ≫ p0
\end{flushleft}


\begin{flushleft}
la statistica Z 0 \`{e} sempre più grande).
\end{flushleft}


\begin{flushleft}
Possiamo anche calcolare il p-dei-dati (approssimato), che in questo caso \`{e} $\Phi$(Z0), perch\'{e} il
\end{flushleft}


\begin{flushleft}
caso estremo che ci interessa \`{e} avere una probabilit\`{a} più piccola di p 0 e quindi un risultato minore
\end{flushleft}


\begin{flushleft}
della statistica Z0 calcolata dal campione. Usando gli stessi dati dell'Esempio 14.12 otteniamo un
\end{flushleft}


\begin{flushleft}
p-dei-dati approssimato uguale a 0.793, non \`{e} quindi possibile rifiutare l'ipotesi che la probabilit\`{a}
\end{flushleft}


\begin{flushleft}
di passare l'esame sia maggiore o uguale al 75\%.
\end{flushleft}





\begin{flushleft}
14.4. TABELLE RIASSUNTIVE
\end{flushleft}


\begin{flushleft}
Raccogliamo ora in alcune tabelle alcuni dei test più rilevanti.
\end{flushleft}


\begin{flushleft}
H0
\end{flushleft}





\begin{flushleft}
H1
\end{flushleft}





\begin{flushleft}
𝜇 = 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 $\neq$ 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 ⩽ 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 $>$ 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 ⩾ 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 $<$ 𝜇0
\end{flushleft}





\begin{flushleft}
Statistica test
\end{flushleft}


\begin{flushleft}
x $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
z0 =
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
x $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
z0 =
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
x $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
z0 =
\end{flushleft}


\begin{flushleft}
𝜎 2/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Regione di accettazione (H0)
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
$-$$\Phi$ $-$1 1 $-$
\end{flushleft}


\begin{flushleft}
⩽ z 0 ⩽ $\Phi$ $-$1 1 $-$
\end{flushleft}


2


2





\begin{flushleft}
p-value
\end{flushleft}


\begin{flushleft}
2 (1 $-$ $\Phi$(|z 0|))
\end{flushleft}





\begin{flushleft}
z0 ⩽ $\Phi$ $-$1(1 $-$ 𝛼)
\end{flushleft}





\begin{flushleft}
1 $-$ $\Phi$(|z 0|)
\end{flushleft}





\begin{flushleft}
z0 ⩾ $-$$\Phi$ $-$1(1 $-$ 𝛼) = $\Phi$ $-$1(𝛼)
\end{flushleft}





\begin{flushleft}
$\Phi$(|z 0|)
\end{flushleft}





\begin{flushleft}
Tabella 14.3. Test delle ipotesi per la media 𝜇 di una popolazione Gaussiana di varianza 𝜎 2 nota. Il campione ha
\end{flushleft}


\begin{flushleft}
taglia n, x \`{e} la media campionaria calcolata nel campione.
\end{flushleft}





\begin{flushleft}
H0
\end{flushleft}





\begin{flushleft}
H1
\end{flushleft}





\begin{flushleft}
𝜇 = 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 $\neq$ 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 ⩽ 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 $>$ 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 ⩾ 𝜇0
\end{flushleft}





\begin{flushleft}
𝜇 $<$ 𝜇0
\end{flushleft}





\begin{flushleft}
Statistica test
\end{flushleft}


\begin{flushleft}
x $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
t0 = 2
\end{flushleft}


\begin{flushleft}
s/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
x $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
t0 = 2
\end{flushleft}


\begin{flushleft}
s/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
x $-$ 𝜇0
\end{flushleft}


\begin{flushleft}
t0 = 2
\end{flushleft}


\begin{flushleft}
s/
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
Regione di accettazione (H 0)
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


$-$1


$-$1


\begin{flushleft}
$-$Ft(n$-$1)
\end{flushleft}


1$-$


\begin{flushleft}
⩽ t 0 ⩽ Ft(n$-$1)
\end{flushleft}


1$-$


2


2





\begin{flushleft}
p-value
\end{flushleft}


\begin{flushleft}
2 (1 $-$ Ft(n$-$1)(|t0|))
\end{flushleft}





$-$1


\begin{flushleft}
t0 ⩽ F t(n$-$1)
\end{flushleft}


\begin{flushleft}
(1 $-$ 𝛼)
\end{flushleft}





\begin{flushleft}
1 $-$ F t(n$-$1)(|t0|)
\end{flushleft}





$-$1


$-$1


\begin{flushleft}
t0 ⩾ $-$F t(n$-$1)
\end{flushleft}


\begin{flushleft}
(1 $-$ 𝛼) = F t(n$-$1)
\end{flushleft}


\begin{flushleft}
(𝛼)
\end{flushleft}





\begin{flushleft}
F t(n$-$1)(|t0|)
\end{flushleft}





\begin{flushleft}
Tabella 14.4. Test delle ipotesi per la media 𝜇 di una popolazione Gaussiana di varianza 𝜎 2 ignota. Il campione
\end{flushleft}


\begin{flushleft}
ha taglia n, x \`{e} la media campionaria e s 2 la varianza campionaria, calcolate nel campione.
\end{flushleft}





\begin{flushleft}
\newpage
14.4 TABELLE RIASSUNTIVE
\end{flushleft}





\begin{flushleft}
H0
\end{flushleft}





\begin{flushleft}
H1
\end{flushleft}





\begin{flushleft}
𝜎 2 = 𝜎02
\end{flushleft}





\begin{flushleft}
𝜎 2 $\neq$ 𝜎02
\end{flushleft}





\begin{flushleft}
𝜎 2 ⩽ 𝜎02
\end{flushleft}





\begin{flushleft}
𝜎 2 $>$ 𝜎02
\end{flushleft}





\begin{flushleft}
𝜎 2 ⩾ 𝜎02
\end{flushleft}





\begin{flushleft}
𝜎 2 $<$ 𝜎02
\end{flushleft}





203





\begin{flushleft}
Statistica test
\end{flushleft}


\begin{flushleft}
s2
\end{flushleft}


\begin{flushleft}
(n $-$ 1)
\end{flushleft}


\begin{flushleft}
𝜎02
\end{flushleft}


\begin{flushleft}
s2
\end{flushleft}


\begin{flushleft}
w0 = 2 (n $-$ 1)
\end{flushleft}


\begin{flushleft}
𝜎0
\end{flushleft}


\begin{flushleft}
s2
\end{flushleft}


\begin{flushleft}
w0 = 2 (n $-$ 1)
\end{flushleft}


\begin{flushleft}
𝜎0
\end{flushleft}


\begin{flushleft}
w0 =
\end{flushleft}





\begin{flushleft}
Regione di accettazione
\end{flushleft}


\begin{flushleft}
F𝜒$-$1n$-$1
\end{flushleft}


2





\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
⩽w0 ⩽F𝜒$-$1n$-$1
\end{flushleft}


2


1$-$


2


2





\begin{flushleft}
p-value
\end{flushleft}


\begin{flushleft}
2 (w 0) $\land$ 1 $-$ F 2 (w 0)
\end{flushleft}


\begin{flushleft}
2 F𝜒n$-$1
\end{flushleft}


\begin{flushleft}
𝜒n$-$1
\end{flushleft}





\begin{flushleft}
w0 ⩽ F𝜒$-$1n$-$1
\end{flushleft}


\begin{flushleft}
2 (1 $-$ 𝛼)
\end{flushleft}





\begin{flushleft}
2 (w 0)
\end{flushleft}


\begin{flushleft}
1 $-$ F𝜒n$-$1
\end{flushleft}





\begin{flushleft}
w0 ⩾ F𝜒$-$1n$-$1
\end{flushleft}


\begin{flushleft}
2 (𝛼)
\end{flushleft}





\begin{flushleft}
2 (w 0)
\end{flushleft}


\begin{flushleft}
F𝜒n$-$1
\end{flushleft}





\begin{flushleft}
Tabella 14.5. Test delle ipotesi per la varianza 𝜎 2 di una popolazione Gaussiana (di media 𝜇 ignota). Il campione
\end{flushleft}


\begin{flushleft}
ha taglia n e s 2 \`{e} la varianza campionaria calcolata nel campione.
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
Parte III
\end{flushleft}


\begin{flushleft}
Appendici
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
APPENDICE A
\end{flushleft}


\begin{flushleft}
RICHIAMI
\end{flushleft}


\begin{flushleft}
A.1. RICHIAMI DI TEORIA ELEMENTARE DEGLI INSIEMI
\end{flushleft}


\begin{flushleft}
Un insieme, dal punto di vista matematico, \`{e} una collezione di oggetti detti elementi. Esso pu\`{o}
\end{flushleft}


\begin{flushleft}
essere caratterizzato per estensione, andando a elencarne tutti gli elementi. \`{E} il modo forse più
\end{flushleft}


\begin{flushleft}
naturale, ma \`{e} possibile solamente se l'insieme \`{e} finito ed \`{e} pratico solo se l'insieme ha pochi
\end{flushleft}


\begin{flushleft}
elementi. In alternativa, possiamo caratterizzare un insieme mediante le propriet\`{a} soddisfatte da
\end{flushleft}


\begin{flushleft}
tutti e soli i suoi elementi. In questo caso parliamo di definizione intensiva.
\end{flushleft}


\begin{flushleft}
Se per\`{o} dobbiamo lavorare con più di un insieme, ci piacerebbe avere un modo per confrontarli e identificarli. Diciamo che due insiemi A e B sono uguali e scriviamo A = B se ciascuno \`{e}
\end{flushleft}


\begin{flushleft}
sottoinsieme dell'altro, A $\subseteq$ B e B $\subseteq$ A, ossia se tutti gli elementi di A sono anche elementi di B e
\end{flushleft}


\begin{flushleft}
viceversa.
\end{flushleft}


\begin{flushleft}
D'altra parte ci sono, soprattutto in combinatoria, occasioni in cui non ci interessa sapere quali
\end{flushleft}


\begin{flushleft}
sono gli elementi di un insieme, ma solamente quanti sono. Di conseguenza vogliamo identificare
\end{flushleft}


\begin{flushleft}
due insiemi che abbiano lo stesso numero di elementi (anche se gli elementi non sono gli stessi).
\end{flushleft}


\begin{flushleft}
Da questo punto di vista un insieme con sei foglie non \`{e} diverso da un insieme con sei palline
\end{flushleft}


\begin{flushleft}
o con sei punti. Questo \`{e} molto {``}matematico'': estraiamo e astraiamo dagli oggetti solo quelle
\end{flushleft}


\begin{flushleft}
propriet\`{a} che ci interessano, ignorando tutte le altre.
\end{flushleft}


\begin{flushleft}
Vogliamo contare il numero di elementi di un insieme, cio\`{e} conoscere la sua cardinalit\`{a}. Useremo il simbolo \#A per indicare la cardinalit\`{a} di un insieme A. Questa pu\`{o} essere un numero
\end{flushleft}


\begin{flushleft}
(naturale) finito, ma anche infinito, sia numerabile, denotato con $\aleph$0, sia pari al continuo, denotato
\end{flushleft}


\begin{flushleft}
con 2 $\aleph$0. Per il momento ci limitiamo a insiemi con un numero finito di elementi, cio\`{e} insiemi di
\end{flushleft}


\begin{flushleft}
cardinalit\`{a} finita.
\end{flushleft}


\begin{flushleft}
Torniamo agli insiemi e alle loro operazioni. Cominciamo con l'intersezione e l'unione. L'intersezione di due insiemi A e B \`{e} l'insieme, denotato con A $\cap$ B che contiene tutti gli elementi che
\end{flushleft}


\begin{flushleft}
appartengono sia ad A che a B, cio\`{e}
\end{flushleft}


\begin{flushleft}
A $\cap$ B = \{x : x $\in$ A $\land$ x $\in$ B\}.
\end{flushleft}


\begin{flushleft}
L'unione di due insiemi A e B \`{e} l'insieme, denotato con A $\cup$ B che contiene tutti gli elementi che
\end{flushleft}


\begin{flushleft}
appartengono ad almeno uno tra A e B, cio\`{e}
\end{flushleft}


\begin{flushleft}
A $\cup$ B = \{x : x $\in$ A $\lor$ x $\in$ B\}.
\end{flushleft}


\begin{flushleft}
Un'altra operazione \`{e} quella di differenza tra due insiemi: l'insieme A ∖ B contiene tutti gli elementi che appartengono ad A, ma non a B. Viceversa l'insieme B ∖ A contiene tutti gli elementi di
\end{flushleft}


\begin{flushleft}
B che non sono anche elementi di A,
\end{flushleft}


\begin{flushleft}
A ∖ B = \{x : x $\in$ A $\land$ x $\notin$ B\}.
\end{flushleft}


\begin{flushleft}
C'\`{e}, per ogni insieme A, una particolare collezione di sue rappresentazioni diverse: la collezione
\end{flushleft}


\begin{flushleft}
delle partizioni di A. Dato un insieme A, una sua partizione \`{e} una famiglia 𝒮 di sottoinsiemi di
\end{flushleft}


\begin{flushleft}
A tali che ogni elemento di A appartiene a uno e uno solo degli insiemi in 𝒮. In altre parole,
\end{flushleft}


\begin{flushleft}
⋃S$\in$𝒮 S = A ed \`{e} un'unione disgiunta: due insiemi non coincidenti S, T $\in$ 𝒮 hanno intersezione
\end{flushleft}


\begin{flushleft}
vuota. Vale la pena osservare che nella definizione di partizione non \`{e} richiesto che A sia non
\end{flushleft}


\begin{flushleft}
vuoto. L'insieme vuoto ha un'unica partizione, l'insieme vuoto stessoA.1.
\end{flushleft}


\begin{flushleft}
A.1. Si potrebbe fare un'osservazione filosofica che la partizione dell'insieme vuoto non \`{e} l'insieme vuoto stesso, ma
\end{flushleft}


\begin{flushleft}
\`{e} semplicemente a esso isomorfa: infatti nel secondo caso gli elementi che non sono nell'insieme vuoto sono loro stessi
\end{flushleft}


\begin{flushleft}
insiemi (i sottoinsiemi dell'insieme vuoto). Un bel grattacapo, che possiamo lasciare tranquillamente ai logici e ai teorici
\end{flushleft}


\begin{flushleft}
degli insiemi.
\end{flushleft}





207





\newpage
208





\begin{flushleft}
RICHIAMI
\end{flushleft}





\begin{flushleft}
Per tornare verso la combinatoria e la probabilit\`{a}, possiamo chiederci quante siano, per un
\end{flushleft}


\begin{flushleft}
insieme finito, le partizioni possibili. Se abbiamo un insieme finito di cardinalit\`{a} n, il numero delle
\end{flushleft}


\begin{flushleft}
sue partizioni \`{e} B n, l'n-esimo numero di BellA.2 (come mostrato nel Problema 1.1).
\end{flushleft}


\begin{flushleft}
Abbiamo gi\`{a} introdotto alcune operazioni tra insiemi, unione, intersezione e differenza. Queste
\end{flushleft}


\begin{flushleft}
operazioni sono binarie, perch\'{e} coinvolgono due insiemi. C'\`{e} per\`{o} un'altra importante operazione
\end{flushleft}


\begin{flushleft}
unaria per gli insiemi: il complementare. Dato un insieme A contenuto nell'insieme universo
\end{flushleft}


\begin{flushleft}
$\Omega$ (cio\`{e} A $\subseteq$ $\Omega$) il complementare di A \`{e} l'insieme denotato con Ac che contiene tutti gli elementi
\end{flushleft}


\begin{flushleft}
di $\Omega$ non contenuti in A.
\end{flushleft}


\begin{flushleft}
$\bullet$ Intersezione e unione sono idempotenti, cio\`{e} A $\cap$ A = A e A $\cup$ A = A.
\end{flushleft}


\begin{flushleft}
$\bullet$ Intersezione e unione sono commutative, cio\`{e} A $\cap$ B = B $\cap$ A e A $\cup$ B = B $\cup$ A.
\end{flushleft}


\begin{flushleft}
$\bullet$ Intersezione e unione sono associative, cio\`{e} A $\cap$ B $\cap$ C = (A $\cap$ B) $\cap$ C = A $\cap$ (B $\cap$ C) e A $\cup$ B $\cup$ C =
\end{flushleft}


\begin{flushleft}
(A $\cup$ B) $\cup$ C = A $\cup$ (B $\cup$ C).
\end{flushleft}


\begin{flushleft}
$\bullet$ Intersezione e unione sono distributive l'una rispetto all'altra, cio\`{e} A $\cap$ (B $\cup$ C) = (A $\cap$ B) $\cup$ (A $\cap$
\end{flushleft}


\begin{flushleft}
C) e A $\cup$ (B $\cap$ C) = (A $\cup$ B) $\cap$ (A $\cup$ C).
\end{flushleft}


\begin{flushleft}
$\bullet$ Il complementare \`{e} involutorio, ossia \`{e} l'operazione inversa di se stesso, cio\`{e} (Ac)c = A.
\end{flushleft}


\begin{flushleft}
$\bullet$ La differenza pu\`{o} essere scritta in termini di intersezioni e complementare, A ∖ B = A $\cap$ B c.
\end{flushleft}


\begin{flushleft}
In realt\`{a} ci \`{e} sufficiente avere una sola delle operazioni tra unione e intersezione, perch\'{e} grazie
\end{flushleft}


\begin{flushleft}
al risultato seguente possiamo scrivere l'operazione binaria rimanente in termini dell'operazione
\end{flushleft}


\begin{flushleft}
binaria che conosciamo e del complementare.
\end{flushleft}


\begin{flushleft}
TEOREMA A.1. (LEGGI DI DE MORGANA.3) Se A e B sono due insiemi, valgono le seguenti identit\`{a}:
\end{flushleft}


\begin{flushleft}
$\bullet$ (A $\cap$ B) c = Ac $\cup$ B c
\end{flushleft}


\begin{flushleft}
$\bullet$ (A $\cup$ B) c = Ac $\cap$ B c.
\end{flushleft}


\begin{flushleft}
Vediamo ora alcuni modi di scrivere la differenza simmetrica tra due insiemi A △ B, definita
\end{flushleft}


\begin{flushleft}
come A △ B = (A ∖ B) $\cup$ (B ∖ A). La dimostrazione del prossimo risultato \`{e} un esercizio di teoria
\end{flushleft}


\begin{flushleft}
degli insiemi, che richiede le leggi di De Morgan.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE A.2. Dati due insiemi A e B, i seguenti insiemi sono uguali: A △ B, (A $\cup$ B) ∖ (A $\cap$ B),
\end{flushleft}


\begin{flushleft}
(A $\cup$ B) $\cap$ (A $\cap$ B) c, (A $\cup$ B) $\cap$ (Ac $\cup$ B c), (A $\cap$ B c) $\cup$ (Ac $\cap$ B), Ac △ B c.
\end{flushleft}


\begin{flushleft}
Se, dati due insiemi A e B, esiste una funzione iniettiva f : A $\rightarrow$ B, allora \#A ⩽ \#B. Se inoltre
\end{flushleft}


\begin{flushleft}
non esiste una funzione biettiva tra i due, possiamo dire che \#A $<$ \#B. Attenzione: nel momento
\end{flushleft}


\begin{flushleft}
in cui iniziamo a maneggiare gli infiniti dobbiamo procedere con estrema cautela. Infatti non \`{e}
\end{flushleft}


\begin{flushleft}
necessariamente vero (all'interno della teoria degli insiemi) che valga la propriet\`{a} di tricotomia,
\end{flushleft}


\begin{flushleft}
ossia che dati due insiemi debba essere vera una delle seguenti: \#A $<$ \#B, \#A = \#B o \#B $<$ \#A. Il
\end{flushleft}


\begin{flushleft}
problema si ha con i cardinali infiniti e, in particolare, la tricotomia equivale all'assioma della
\end{flushleft}


\begin{flushleft}
scelta.
\end{flushleft}


\begin{flushleft}
Esempio A.3. Consideriamo l'insieme 2 ℕ dei numeri naturali pari. Esso \`{e} un sottoinsieme proprio dell'insieme ℕ dei numeri naturali. Tuttavia 2 ℕ e ℕ hanno la stessa cardinalit\`{a}. Infatti
\end{flushleft}


\begin{flushleft}
possiamo prendere f : ℕ $\rightarrow$ 2 ℕ tale che f (n) = 2 n. La funzione f \`{e} biettiva: la sua inversa \`{e} f $-$1:
\end{flushleft}


\begin{flushleft}
2 ℕ$\rightarrow$ ℕ con f $-$1 (2 m)=m. Allora i due insiemi 2 ℕ e ℕ sono equipotenti, ossia ci sono tanti numeri
\end{flushleft}


\begin{flushleft}
naturali pari quanti numeri naturali.
\end{flushleft}


\begin{flushleft}
Dobbiamo quindi procedere con cautela, come mostrato anche dal seguente risultato.
\end{flushleft}


\begin{flushleft}
TEOREMA A.4. (CANTORA.4-BERNSTEINA.5) Dati due insiemi A e B, se esistono due funzioni iniettive f :
\end{flushleft}


\begin{flushleft}
A $\rightarrow$ B e g: B $\rightarrow$ A, allora esiste almeno una funzione biettiva tra i due insiemi. In altri termini, se \#A ⩽ \#B
\end{flushleft}


\begin{flushleft}
e \#B ⩽ \#A, allora \#A = \#B.
\end{flushleft}


\begin{flushleft}
A.2.
\end{flushleft}


\begin{flushleft}
A.3.
\end{flushleft}


\begin{flushleft}
A.4.
\end{flushleft}


\begin{flushleft}
A.5.
\end{flushleft}





\begin{flushleft}
Eric Temple Bell (1883 -- 1960).
\end{flushleft}


\begin{flushleft}
Augustus De Morgan (1806 -- 1871).
\end{flushleft}


\begin{flushleft}
Georg Cantor (1845 -- 1918).
\end{flushleft}


\begin{flushleft}
Felix Bernstein (1878 -- 1956).
\end{flushleft}





\begin{flushleft}
\newpage
A.1 RICHIAMI DI TEORIA ELEMENTARE DEGLI INSIEMI
\end{flushleft}





209





\begin{flushleft}
Questa affermazione sulla cardinalit\`{a} di due insiemi sembra assolutamente ovvia. Ma, come
\end{flushleft}


\begin{flushleft}
abbiamo visto nell'Esempio A.3, l'uso degli infiniti pu\`{o} trarre in inganno. Perci\`{o} il teorema \`{e}
\end{flushleft}


\begin{flushleft}
necessario; la sua dimostrazione, comunque, non \`{e} per niente banale.
\end{flushleft}


\begin{flushleft}
Esempio A.5. Dato un insieme A, le funzioni da A a \{0, 1\} formano un insieme di cardinalit\`{a}
\end{flushleft}


\begin{flushleft}
2 \#A. Infatti una funzione da A a \{0, 1\} associa a ogni elemento di A uno tra 0 e 1 e la scelta per un
\end{flushleft}


\begin{flushleft}
elemento di A non influenza quella per gli altri. Quindi abbiamo 2 scelte per ciascun elemento e
\end{flushleft}


\begin{flushleft}
i fattori 2 devono essere moltiplicati tra loro. Gli elementi di A sono \#A, da cui il risultato.
\end{flushleft}


\begin{flushleft}
In generale possiamo dire qualcosa di più: le funzioni da un insieme A a un insieme B formano
\end{flushleft}


\begin{flushleft}
un insieme di cardinalit\`{a} \#B \#A. Per questo motivo l'insieme delle funzioni da A a B si scrive B A.
\end{flushleft}


\begin{flushleft}
PROPOSIZIONE A.6. Dato un insieme A di cardinalit\`{a} eventualmente infinita (anche più che numerabile)
\end{flushleft}


\begin{flushleft}
l'insieme delle parti di A (o insieme potenza di A) 𝒫(A) ha cardinalit\`{a} \#𝒫(A) = 2 \#A.
\end{flushleft}


\begin{flushleft}
Dimostrazione. Come detto in precedenza, per mostrare che un insieme ha una certa cardinalit\`{a},
\end{flushleft}


\begin{flushleft}
quello che possiamo fare \`{e} costruire una relazione biunivoca (o una codifica) dal nostro insieme
\end{flushleft}


\begin{flushleft}
a un insieme che sappiamo avere la cardinalit\`{a} cercata. Sappiamo anche che un insieme che ha
\end{flushleft}


\begin{flushleft}
proprio 2 \#A elementi \`{e} l'insieme delle funzioni da A in \{0, 1\}. Quello che ci resta da fare, dunque, \`{e}
\end{flushleft}


\begin{flushleft}
far vedere che i sottoinsiemi di A sono tanti quanti le funzioni da A in \{0,1\}. Per ogni sottoinsieme
\end{flushleft}


\begin{flushleft}
S $\subseteq$ A definiamo la funzione fS: A $\rightarrow$ \{0, 1\} come segue: fS(a) = 1S(a). In sostanza, codifichiamo con
\end{flushleft}


\begin{flushleft}
un 1 la presenza dell'elemento nel sottoinsieme, con 0 la sua assenza. Viceversa per ogni funzione
\end{flushleft}


\begin{flushleft}
f : A $\rightarrow$ \{0, 1\} possiamo definire S f = f $-$1(1), cio\`{e} il sottoinsieme di $\Omega$ contenente tutti gli a per cui
\end{flushleft}


\begin{flushleft}
f (a) = 1. Si verifica facilmente che le relazioni S $\rightarrow$ fS e f $\rightarrow$ Sf sono entrambe iniettiveA.6, quindi
\end{flushleft}


\begin{flushleft}
\#𝒫(A) ⩽ 2 \#A ⩽ \#𝒫(A) (Teorema di Cantor-Bernstein) e abbiamo l'uguaglianza cercata.
\end{flushleft}


□


\begin{flushleft}
TEOREMA A.7. (CANTOR) Non esiste alcuna funzione suriettiva da un insieme A al suo insieme delle parti
\end{flushleft}


\begin{flushleft}
𝒫(A). In particolare, quindi, \#A $<$ \#𝒫(A).
\end{flushleft}


\begin{flushleft}
Dimostrazione. Cominciamo osservando che 𝒫(A) contiene una copia di A: la funzione i: A $\rightarrow$
\end{flushleft}


\begin{flushleft}
𝒫(A) che manda ogni elemento di A nel suo singoletto \`{e} iniettiva, quindi \#A ⩽ \#𝒫(A).
\end{flushleft}


\begin{flushleft}
Procediamo ora per assurdo e supponiamo di avere una funzione f :A$\rightarrow$ 𝒫(A) suriettiva. Consideriamo l'insieme N = \{a $\in$ A : a $\notin$ f (a)\} degli elementi di A che non appartengono alla propria
\end{flushleft}


\begin{flushleft}
immagine mediante f . Dal momento che f \`{e} suriettiva su 𝒫(A), esiste un elemento 𝛼 $\in$ A tale che
\end{flushleft}


\begin{flushleft}
f (𝛼) = N. A questo punto abbiamo una contraddizione: se 𝛼 $\in$ N, allora dalla definizione di N
\end{flushleft}


\begin{flushleft}
segue 𝛼 $\notin$ f (𝛼) = N. Se invece 𝛼 $\notin$ N, allora 𝛼 $\in$ f (𝛼) = N. Dunque non pu\`{o} esistere una funzione
\end{flushleft}


\begin{flushleft}
suriettiva da A a 𝒫(A).
\end{flushleft}


\begin{flushleft}
Se non possono esistere funzioni suriettive, non possono in particolare esistere funzioni biiettive: pertanto i due insiemi hanno cardinalit\`{a} diversa e vale la disuguaglianza stretta.
\end{flushleft}


□


\begin{flushleft}
PROPOSIZIONE A.8. L'insieme 𝒫(ℕ) ha cardinalit\`{a} uguale a quella dei numeri reali.
\end{flushleft}


\begin{flushleft}
Dimostrazione. L'idea di Cantor che sta alla base di questa dimostrazione \`{e} far vedere che possiamo identificare i sottoinsiemi dei numeri naturali con i numeri reali nell'intervallo [0,1]. Questo
\end{flushleft}


\begin{flushleft}
intervallo, a sua volta, ha tanti elementi quanti tutti i numeri reali.
\end{flushleft}


\begin{flushleft}
Cominciamo con la prima parte. Per prima cosa, forti di quanto visto sopra, identifichiamo
\end{flushleft}


\begin{flushleft}
𝒫(ℕ) con l'insieme delle successioni binarie. Vogliamo interpretarle come rappresentazioni
\end{flushleft}


\begin{flushleft}
binarie dei numeri reali in [0,1], considerandole come se fossero le cifre dopo la virgola. In questo
\end{flushleft}


\begin{flushleft}
modo abbiamo tutti e soliA.7 i numeri reali in [0, 1].
\end{flushleft}


\begin{flushleft}
A.6. Sono anche suriettive e in particolare l'una \`{e} l'inversa dell'altra.
\end{flushleft}


\begin{flushleft}
A.7. In realt\`{a} stiamo un po' imbrogliando: come nel caso delle rappresentazioni decimali abbiamo il problema dei
\end{flushleft}


\begin{flushleft}
numeri che finiscono con un 9 periodico o con uno 0 periodico. Questi numeri vengono ``contati'' due volte, quindi
\end{flushleft}


\begin{flushleft}
abbiamo un problema simile con i numeri che finiscono con 1 periodico o con 0 periodico, che possiamo caratterizzare
\end{flushleft}


\begin{flushleft}
come i numeri con un numero finito di cifre. Tuttavia con un po' di accortezza siamo in grado di aggirare questo ostacolo,
\end{flushleft}


\begin{flushleft}
tenendo conto che questi numeri sono in quantit\`{a} numerabile.
\end{flushleft}





\newpage
210





\begin{flushleft}
RICHIAMI
\end{flushleft}





.





\begin{flushleft}
Figura A.1. Una biiezione tra (0, 1) e ℝ
\end{flushleft}





\begin{flushleft}
Ora vogliamo identificare [0, 1] con l'intera retta reale. In realt\`{a} identifichiamo l'intervallo
\end{flushleft}


\begin{flushleft}
aperto (0, 1) con la retta reale. Per fare ci\`{o} deformiamo il segmento senza estremi (0, 1) in una
\end{flushleft}


\begin{flushleft}
semicirconferenza, anch'essa senza estremi. Prendiamo la retta reale e disegniamola in modo
\end{flushleft}


\begin{flushleft}
che sia tangente al punto medio della semicirconferenza. A questo punto possiamo tracciare le
\end{flushleft}


\begin{flushleft}
semirette uscenti dal centro della semicirconferenza che intersecano la semicirconferenza stessa,
\end{flushleft}


\begin{flushleft}
come rappresentato in Figura A.1. Ciascuna di esse incontra la retta reale in uno e un solo punto.
\end{flushleft}


\begin{flushleft}
Abbiamo così stabilito una relazione biunivoca tra ogni punto della semicirconferenza (e quindi
\end{flushleft}


\begin{flushleft}
ogni numero nell'intervallo (0, 1)) e ogni punto della retta reale (cio\`{e} ogni numero reale).
\end{flushleft}


□





\begin{flushleft}
I risultati precedenti danno due informazioni interessanti riguardo ad alcuni insiemi che
\end{flushleft}


\begin{flushleft}
abbiamo appena visto.
\end{flushleft}


\begin{flushleft}
COROLLARIO A.9. L'insieme ℝ dei numeri reali ha cardinalit\`{a} 2 $\aleph$0 strettamente maggiore della cardinalit\`{a}
\end{flushleft}


\begin{flushleft}
$\aleph$ 0 dell'insieme dei numeri naturali.
\end{flushleft}


\begin{flushleft}
COROLLARIO A.10. L'insieme 𝒫(ℝ) ha cardinalit\`{a} 2 (2 ), che in particolare \`{e} più grande di quella di ℝ.
\end{flushleft}


\begin{flushleft}
$\aleph$0
\end{flushleft}





\begin{flushleft}
Dimostrazione. La prima parte segue dalla Proposizione A.6. La seconda parte dal Teorema A.7.
\end{flushleft}


□


\begin{flushleft}
Due ultime curiosit\`{a}, prima di andare oltre la cardinalit\`{a}. Ci sono infinite cardinalit\`{a} infinite,
\end{flushleft}


\begin{flushleft}
di cui $\aleph$0 non \`{e} che la prima. Osserviamo per\`{o} che non abbiamo detto che la cardinalit\`{a} 2$\aleph$0 dei
\end{flushleft}


\begin{flushleft}
reali (detta anche continuo e indicata con 𝔠) sia il secondo numero cardinale infinito (cio\`{e} $\aleph$ 1). Non
\end{flushleft}


\begin{flushleft}
lo abbiamo fatto perch\'{e} non \`{e} (necessariamente) vero: \`{e} la famosa ipotesi del continuo.
\end{flushleft}





\begin{flushleft}
A.2. SERIE ARITMETICA E SERIE GEOMETRICA
\end{flushleft}


\begin{flushleft}
Per la serie aritmetica ci interessa sapere che
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
k=
\end{flushleft}


\begin{flushleft}
k =1
\end{flushleft}





\begin{flushleft}
n (n + 1)
\end{flushleft}


.


2





\begin{flushleft}
k
\end{flushleft}


\begin{flushleft}
Una serie si dice geometrica se \`{e} della forma ∑+$\infty$
\end{flushleft}


\begin{flushleft}
k =0 r , per qualche r $\in$ ℝ. Possiamo considerare a
\end{flushleft}


\begin{flushleft}
parte il caso r = 1 (una somma di 1), per cui la somma diverge a +$\infty$. Per r $\neq$ 1, consideriamo la
\end{flushleft}


\begin{flushleft}
somma troncata s n = ∑nk =0 r k . Allora, moltiplicando sn per r e sottraendo da s n abbiamo
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
sn $-$ r sn =
\end{flushleft}





\begin{flushleft}
r k $-$ r k +1 = 1 $-$ r n+1,
\end{flushleft}





\begin{flushleft}
k =0
\end{flushleft}





\begin{flushleft}
1 $-$ r n+1
\end{flushleft}





\begin{flushleft}
cio\`{e} s n = 1 $-$ r .
\end{flushleft}


\begin{flushleft}
Se vogliamo il comportamento per n $\rightarrow$ +$\infty$, osserviamo che per |r| $>$ 1, |r n+1| $\rightarrow$ +$\infty$, quindi la
\end{flushleft}


\begin{flushleft}
serie non converge, per r = $-$1 la serie oscilla tra 0 e 1 (quindi non converge), mentre per |r| $<$ 1,
\end{flushleft}


\begin{flushleft}
r n+1 $\rightarrow$ 0 per n $\rightarrow$ +$\infty$ e quindi sn $\rightarrow$ s = (1 $-$ r)$-$1.
\end{flushleft}





\begin{flushleft}
A.3. L'INTEGRALE GAUSSIANO
\end{flushleft}


\begin{flushleft}
Ci interessano gli integrali definiti
\end{flushleft}





\begin{flushleft}
\newpage
A.3 L'INTEGRALE GAUSSIANO
\end{flushleft}





\begin{flushleft}
I1 =
\end{flushleft}





2





\begin{flushleft}
+$\infty$ $-$ x
\end{flushleft}


2





$-$$\infty$





\begin{flushleft}
e
\end{flushleft}





211





\begin{flushleft}
I2 =
\end{flushleft}





\begin{flushleft}
dx
\end{flushleft}





\begin{flushleft}
x2
\end{flushleft}





2





\begin{flushleft}
+$\infty$ $-$ x
\end{flushleft}


2





\begin{flushleft}
e
\end{flushleft}





0





\begin{flushleft}
I=
\end{flushleft}





\begin{flushleft}
dx
\end{flushleft}





+$\infty$


0





\begin{flushleft}
e $-$x dx
\end{flushleft}


2





\begin{flushleft}
Osserviamo che I1 =2 I 2 perch\'{e} la funzione e $-$ /2 \`{e} simmetrica rispetto a x =0. Inoltre I 2 =I 2 , come
\end{flushleft}


\begin{flushleft}
si vede con un cambio di variabile. Ci basta allora calcolare l'integrale indefinito I.
\end{flushleft}


2


\begin{flushleft}
Questo integrale si pu\`{o} calcolare in molti modi, pur non avendo e $-$x una primitiva. Vediamone alcuni.
\end{flushleft}


\begin{flushleft}
Iniziamo definendo le due funzioni ausiliarie
\end{flushleft}


2


2


\begin{flushleft}
t
\end{flushleft}


\begin{flushleft}
1 e $-$t (1+x )
\end{flushleft}


\begin{flushleft}
$-$x 2
\end{flushleft}


\begin{flushleft}
f (t) = e dx
\end{flushleft}


\begin{flushleft}
g(t) =
\end{flushleft}


\begin{flushleft}
dx
\end{flushleft}


0


0


\begin{flushleft}
1 + x2
\end{flushleft}


\begin{flushleft}
e osserviamo che
\end{flushleft}


\begin{flushleft}
( f (t))2 + g(t) = const,
\end{flushleft}


\begin{flushleft}
infatti
\end{flushleft}


\begin{flushleft}
d
\end{flushleft}


\begin{flushleft}
( f (t))2 = 2 f (t) f ′(t) = 2
\end{flushleft}


\begin{flushleft}
dt
\end{flushleft}





\begin{flushleft}
t
\end{flushleft}


0





\begin{flushleft}
e $-$x dx e $-$t = 2
\end{flushleft}


2





2





\begin{flushleft}
t
\end{flushleft}


0





\begin{flushleft}
e $-$x
\end{flushleft}





2





\begin{flushleft}
$-$t 2
\end{flushleft}





\begin{flushleft}
dx
\end{flushleft}





\begin{flushleft}
ma, allo stesso tempo, se facciamo il cambio di variabili x = y t,
\end{flushleft}


\begin{flushleft}
t
\end{flushleft}





2


\begin{flushleft}
D'altro canto,
\end{flushleft}


\begin{flushleft}
g′(t) =
\end{flushleft}





1





\begin{flushleft}
e $-$t
\end{flushleft}





0


2





\begin{flushleft}
e $-$x
\end{flushleft}





2





\begin{flushleft}
$-$t 2
\end{flushleft}





\begin{flushleft}
dx =
\end{flushleft}





1


0





\begin{flushleft}
2 e $-$t
\end{flushleft}





2





\begin{flushleft}
(y 2 +1)
\end{flushleft}





\begin{flushleft}
($-$2 t)(1 + x 2)
\end{flushleft}


\begin{flushleft}
dx = $-$
\end{flushleft}


\begin{flushleft}
1 + x2
\end{flushleft}





\begin{flushleft}
(1+x 2)
\end{flushleft}





0





\begin{flushleft}
t dy.
\end{flushleft}


1


0





\begin{flushleft}
2 e $-$t
\end{flushleft}





2





\begin{flushleft}
(1+x 2)
\end{flushleft}





\begin{flushleft}
dx.
\end{flushleft}





\begin{flushleft}
Quindi per ogni t, ( f (t))2 + g(t) = ( f (0))2 + g(0) e quindi
\end{flushleft}


\begin{flushleft}
I 2 = lim ( f (t))2 = g(0) $-$ lim g(t)
\end{flushleft}


\begin{flushleft}
t$\rightarrow$+$\infty$
\end{flushleft}





=





1


0





1


\begin{flushleft}
dx $-$ lim
\end{flushleft}


\begin{flushleft}
1 + x2
\end{flushleft}


\begin{flushleft}
t$\rightarrow$+$\infty$
\end{flushleft}





\begin{flushleft}
t$\rightarrow$+$\infty$
\end{flushleft}


2


2


\begin{flushleft}
1 $-$t (1+x )
\end{flushleft}





\begin{flushleft}
e
\end{flushleft}





0





\begin{flushleft}
1 + x2
\end{flushleft}





\begin{flushleft}
dx
\end{flushleft}





1





\begin{flushleft}
= atan(x) 0 $-$ 0
\end{flushleft}


\begin{flushleft}
𝜋
\end{flushleft}


=


4


\begin{flushleft}
da cui abbiamo I = $\surd$𝜋/2.
\end{flushleft}


\begin{flushleft}
[TBC] Altri modi per calcolarlo si possono trovare in questo documento: https://
\end{flushleft}


\begin{flushleft}
kconrad.math.uconn.edu/blurbs/analysis/gaussianintegral.pdf.
\end{flushleft}





\begin{flushleft}
\newpage
\newpage
APPENDICE B
\end{flushleft}


\begin{flushleft}
TAVOLE
\end{flushleft}





\begin{flushleft}
Tavole della funzione di ripartizione per una
\end{flushleft}


\begin{flushleft}
distribuzione normale standard
\end{flushleft}


\begin{flushleft}
x2
\end{flushleft}


\begin{flushleft}
z
\end{flushleft}


1


$-$


\begin{flushleft}
$\Phi$(z) =
\end{flushleft}


\begin{flushleft}
e 2 dx
\end{flushleft}


\begin{flushleft}
$-$$\infty$ 2 $\pi$
\end{flushleft}





\begin{flushleft}
z
\end{flushleft}


0.0


0.1


0.2


0.3


0.4


0.5


0.6


0.7


0.8


0.9


1.0


1.1


1.2


1.3


1.4


1.5


1.6


1.7


1.8


1.9


2.0


2.1


2.2


2.3


2.4


2.5


2.6


2.7


2.8


2.9


3.0


3.1


3.2


3.3


3.4





0.00


0.5000


0.5398


0.5793


0.6179


0.6554


0.6915


0.7257


0.7580


0.7881


0.8159


0.8413


0.8643


0.8849


0.9032


0.9192


0.9332


0.9452


0.9554


0.9641


0.9713


0.9772


0.9821


0.9861


0.9893


0.9918


0.9938


0.9953


0.9965


0.9974


0.9981


0.9987


0.9990


0.9993


0.9995


0.9997





0.01


0.5040


0.5438


0.5832


0.6217


0.6591


0.6950


0.7291


0.7611


0.7910


0.8186


0.8438


0.8665


0.8869


0.9049


0.9207


0.9345


0.9463


0.9564


0.9649


0.9719


0.9778


0.9826


0.9864


0.9896


0.9920


0.9940


0.9955


0.9966


0.9975


0.9982


0.9987


0.9991


0.9993


0.9995


0.9997





0.02


0.5080


0.5478


0.5871


0.6255


0.6628


0.6985


0.7324


0.7642


0.7939


0.8212


0.8461


0.8686


0.8888


0.9066


0.9222


0.9357


0.9474


0.9573


0.9656


0.9726


0.9783


0.9830


0.9868


0.9898


0.9922


0.9941


0.9956


0.9967


0.9976


0.9982


0.9987


0.9991


0.9994


0.9995


0.9997





0.03


0.5120


0.5517


0.5910


0.6293


0.6664


0.7019


0.7357


0.7673


0.7967


0.8238


0.8485


0.8708


0.8907


0.9082


0.9236


0.9370


0.9484


0.9582


0.9664


0.9732


0.9788


0.9834


0.9871


0.9901


0.9925


0.9943


0.9957


0.9968


0.9977


0.9983


0.9988


0.9991


0.9994


0.9996


0.9997





0.04


0.5160


0.5557


0.5948


0.6331


0.6700


0.7054


0.7389


0.7704


0.7995


0.8264


0.8508


0.8729


0.8925


0.9099


0.9251


0.9382


0.9495


0.9591


0.9671


0.9738


0.9793


0.9838


0.9875


0.9904


0.9927


0.9945


0.9959


0.9969


0.9977


0.9984


0.9988


0.9992


0.9994


0.9996


0.9997





213





0.05


0.5199


0.5596


0.5987


0.6368


0.6736


0.7088


0.7422


0.7734


0.8023


0.8289


0.8531


0.8749


0.8944


0.9115


0.9265


0.9394


0.9505


0.9599


0.9678


0.9744


0.9798


0.9842


0.9878


0.9906


0.9929


0.9946


0.9960


0.9970


0.9978


0.9984


0.9989


0.9992


0.9994


0.9996


0.9997





\begin{flushleft}
$\Phi$(z)
\end{flushleft}


\begin{flushleft}
z
\end{flushleft}


0.06


0.5239


0.5636


0.6026


0.6406


0.6772


0.7123


0.7454


0.7764


0.8051


0.8315


0.8554


0.8770


0.8962


0.9131


0.9279


0.9406


0.9515


0.9608


0.9686


0.9750


0.9803


0.9846


0.9881


0.9909


0.9931


0.9948


0.9961


0.9971


0.9979


0.9985


0.9989


0.9992


0.9994


0.9996


0.9997





0.07


0.5279


0.5675


0.6064


0.6443


0.6808


0.7157


0.7486


0.7794


0.8078


0.8340


0.8577


0.8790


0.8980


0.9147


0.9292


0.9418


0.9525


0.9616


0.9693


0.9756


0.9808


0.9850


0.9884


0.9911


0.9932


0.9949


0.9962


0.9972


0.9979


0.9985


0.9989


0.9992


0.9995


0.9996


0.9997





0.08


0.5319


0.5714


0.6103


0.6480


0.6844


0.7190


0.7517


0.7823


0.8106


0.8365


0.8599


0.8810


0.8997


0.9162


0.9306


0.9429


0.9535


0.9625


0.9699


0.9761


0.9812


0.9854


0.9887


0.9913


0.9934


0.9951


0.9963


0.9973


0.9980


0.9986


0.9990


0.9993


0.9995


0.9996


0.9997





0.09


0.5359


0.5753


0.6141


0.6517


0.6879


0.7224


0.7549


0.7852


0.8133


0.8389


0.8621


0.8830


0.9015


0.9177


0.9319


0.9441


0.9545


0.9633


0.9706


0.9767


0.9817


0.9857


0.9890


0.9916


0.9936


0.9952


0.9964


0.9974


0.9981


0.9986


0.9990


0.9993


0.9995


0.9997


0.9998





\newpage
214





\begin{flushleft}
TAVOLE
\end{flushleft}





\begin{flushleft}
Tavole dei quantili per una distribuzione t di Student
\end{flushleft}


\begin{flushleft}
df 𝛼
\end{flushleft}


1


2


3


4


5


6


7


8


9


10


11


12


13


14


15


16


17


18


19


20


21


22


23


24


25


26


27


28


29


30


40


60


120


+$\infty$





0.1


3.078


1.886


1.638


1.533


1.476


1.440


1.415


1.397


1.383


1.372


1.363


1.356


1.350


1.345


1.341


1.337


1.333


1.330


1.328


1.325


1.323


1.321


1.319


1.318


1.316


1.315


1.314


1.313


1.311


1.310


1.303


1.296


1.289


1.282





0.05 0.025


0.01 0.005


6.314 12.706 31.821 63.657


2.920 4.303 6.965 9.925


2.353 3.182 4.541 5.841


2.132 2.776 3.747 4.604


2.015 2.571 3.365 4.032


1.943 2.447 3.143 3.707


1.895 2.365 2.998 3.499


1.860 2.306 2.896 3.355


1.833 2.262 2.821 3.250


1.812 2.228 2.764 3.169


1.796 2.201 2.718 3.106


1.782 2.179 2.681 3.055


1.771 2.160 2.650 3.012


1.761 2.145 2.624 2.977


1.753 2.131 2.602 2.947


1.746 2.120 2.583 2.921


1.740 2.110 2.567 2.898


1.734 2.101 2.552 2.878


1.729 2.093 2.539 2.861


1.725 2.086 2.528 2.845


1.721 2.080 2.518 2.831


1.717 2.074 2.508 2.819


1.714 2.069 2.500 2.807


1.711 2.064 2.492 2.797


1.708 2.060 2.485 2.787


1.706 2.056 2.479 2.779


1.703 2.052 2.473 2.771


1.701 2.048 2.467 2.763


1.699 2.045 2.462 2.756


1.697 2.042 2.457 2.750


1.684 2.021 2.423 2.704


1.671 2.000 2.390 2.660


1.658 1.980 2.358 2.617


1.645 1.960 2.326 2.576





\begin{flushleft}
1$-$𝛼
\end{flushleft}


\begin{flushleft}
𝛼
\end{flushleft}


\begin{flushleft}
F t$-$1
\end{flushleft}


(1


\begin{flushleft}
$-$ 𝛼)
\end{flushleft}


\begin{flushleft}
n
\end{flushleft}





\begin{flushleft}
\newpage
TAVOLE
\end{flushleft}





215





\begin{flushleft}
Tavole dei quantili per una distribuzione $\chi$ 2
\end{flushleft}


\begin{flushleft}
1$-$𝛼
\end{flushleft}





\begin{flushleft}
𝛼
\end{flushleft}





\begin{flushleft}
F𝜒$-$1n2(1$-$𝛼)
\end{flushleft}





\begin{flushleft}
df 𝛼
\end{flushleft}


0.995


0.99 0.975


0.95


0.05


0.025


0.01


1 0.00004 0.00016 0.001 0.004


3.841


5.024


6.635


2


0.010


0.020 0.051 0.103


5.991


7.378


9.210


3


0.072


0.115 0.216 0.352


7.815


9.348 11.345


4


0.207


0.297 0.484 0.711


9.488 11.143 13.277


5


0.412


0.554 0.831 1.145 11.070 12.833 15.086


6


0.676


0.872 1.237 1.635 12.592 14.449 16.812


7


0.989


1.239 1.690 2.167 14.067 16.013 18.475


8


1.344


1.646 2.180 2.733 15.507 17.535 20.090


9


1.735


2.088 2.700 3.325 16.919 19.023 21.666


10


2.156


2.558 3.247 3.940 18.307 20.483 23.209


11


2.603


3.053 3.816 4.575 19.675 21.920 24.725


12


3.074


3.571 4.404 5.226 21.026 23.337 26.217


13


3.565


4.107 5.009 5.892 22.362 24.736 27.688


14


4.075


4.660 5.629 6.571 23.685 26.119 29.141


15


4.601


5.229 6.262 7.261 24.996 27.488 30.578


16


5.142


5.812 6.908 7.962 26.296 28.845 32.000


17


5.697


6.408 7.564 8.672 27.587 30.191 33.409


18


6.265


7.015 8.231 9.390 28.869 31.526 34.805


19


6.844


7.633 8.907 10.117 30.144 32.852 36.191


20


7.434


8.260 9.591 10.851 31.410 34.170 37.566


21


8.034


8.897 10.283 11.591 32.671 35.479 38.932


22


8.643


9.542 10.982 12.338 33.924 36.781 40.289


23


9.260 10.196 11.689 13.091 35.172 38.076 41.638


24


9.886 10.856 12.401 13.848 36.415 39.364 42.980


25 10.520 11.524 13.120 14.611 37.652 40.646 44.314


26 11.160 12.198 13.844 15.379 38.885 41.923 45.642


27 11.808 12.879 14.573 16.151 40.113 43.195 46.963


28 12.461 13.565 15.308 16.928 41.337 44.461 48.278


29 13.121 14.256 16.047 17.708 42.557 45.722 49.588


30 13.787 14.953 16.791 18.493 43.773 46.979 50.892


40 20.707 22.164 24.433 26.509 55.758 59.342 63.691


50 27.991 29.707 32.357 34.764 67.505 71.420 76.154


60 35.534 37.485 40.482 43.188 79.082 83.298 88.379


70 43.275 45.442 48.758 51.739 90.531 95.023 100.425


80 51.172 53.540 57.153 60.391 101.879 106.629 112.329


90 59.196 61.754 65.647 69.126 113.145 118.136 124.116


100 67.328 70.065 74.222 77.929 124.342 129.561 135.807





0.005


7.879


10.597


12.838


14.860


16.750


18.548


20.278


21.955


23.589


25.188


26.757


28.300


29.819


31.319


32.801


34.267


35.718


37.156


38.582


39.997


41.401


42.796


44.181


45.559


46.928


48.290


49.645


50.993


52.336


53.672


66.766


79.490


91.952


104.215


116.321


128.299


140.169





\begin{flushleft}
Come si leggono le tavole?
\end{flushleft}


\begin{flushleft}
Cominciamo dalla tavola per $\Phi$. Supponiamo di voler calcolare $\Phi$(1.26). Allora cerchiamo nella
\end{flushleft}


\begin{flushleft}
prima colonna la riga corrispondente a 1.2 e, su quella riga, individuiamo la cella nella colonna
\end{flushleft}


\begin{flushleft}
corrispondente a 0.06. Abbiamo allora $\Phi$(1.26) ≃ 0.8962. Se invece volessimo calcolare $\Phi$($-$0.78),
\end{flushleft}


\begin{flushleft}
come prima cosa ricordiamo che $\Phi$($-$0.78) = 1 $-$ $\Phi$(0.78) poi cerchiamo quest'ultimo nella tabella,
\end{flushleft}


\begin{flushleft}
all'incrocio tra la riga 0.7 e la colonna 0.08: $\Phi$(0.78) ≃ 0.7823, quindi $\Phi$($-$0.78) ≃ 0.2177.
\end{flushleft}





\newpage



\end{document}
